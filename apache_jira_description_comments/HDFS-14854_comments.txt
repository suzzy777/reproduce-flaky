I have uploaded a 001 patch version which implements what I suggested in the design document. I have not yet added any new tests, but I hope to re-use the existing decommission tests and run them with both versions of the monitor. I did that manually locally and all but 1 or 2 passed, and those which failed were expected due to the changes.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 38m 27s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 50s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  7s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 24s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  3s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  8s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 50s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 9 new + 453 unchanged - 0 fixed = 462 total (was 453) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  6s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 33s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 23s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 2 new + 0 unchanged - 0 fixed = 2 total (was 0) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}159m 28s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 42s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}258m 12s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |
|  |  Useless condition:isHealthy == false at this point  At DatanodeAdminManager.java:[line 1138] |
|  |  org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager$MonitorV2.processPendingReplication() makes inefficient use of keySet iterator instead of entrySet iterator  At DatanodeAdminManager.java:keySet iterator instead of entrySet iterator  At DatanodeAdminManager.java:[line 1392] |
| Failed junit tests | hadoop.hdfs.TestFileAppend2 |
|   | hadoop.hdfs.TestRollingUpgrade |
|   | hadoop.hdfs.TestErasureCodingPoliciesWithRandomECPolicy |
|   | hadoop.hdfs.TestUnsetAndChangeDirectoryEcPolicy |
|   | hadoop.hdfs.TestFileChecksumCompositeCrc |
|   | hadoop.hdfs.TestEncryptedTransfer |
|   | hadoop.hdfs.qjournal.server.TestJournalNodeSync |
|   | hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy |
|   | hadoop.hdfs.qjournal.client.TestQJMWithFaults |
|   | hadoop.hdfs.TestPread |
|   | hadoop.hdfs.TestErasureCodingExerciseAPIs |
|   | hadoop.hdfs.server.namenode.ha.TestBootstrapStandby |
|   | hadoop.hdfs.qjournal.client.TestQuorumJournalManager |
|   | hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithRandomECPolicy |
|   | hadoop.hdfs.TestReconstructStripedFile |
|   | hadoop.hdfs.TestDistributedFileSystem |
|   | hadoop.hdfs.TestErasureCodingMultipleRacks |
|   | hadoop.hdfs.TestLargeBlock |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy |
|   | hadoop.hdfs.TestDistributedFileSystemWithECFile |
|   | hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy |
|   | hadoop.hdfs.server.namenode.TestFSImage |
|   | hadoop.hdfs.TestErasureCodingAddConfig |
|   | hadoop.tools.TestHdfsConfigFields |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=19.03.1 Server=19.03.1 Image:yetus/hadoop:39e82acc485 |
| JIRA Issue | HDFS-14854 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12980771/HDFS-14854.001.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 26024b25bbc2 4.15.0-60-generic #67-Ubuntu SMP Thu Aug 22 16:55:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 126ef77 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_222 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/27911/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/27911/artifact/out/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/27911/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/27911/testReport/ |
| Max. process+thread count | 3205 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/27911/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



Hi [~sodonnell] some minor review comments, since it is quite a big patch will need more time to loop through all the logic:

* _dfs.namenode.decommission.monitor.version_ Instead of version strings, why not provide which concrete implementation of the interface to use. It also makes it easily extensible.
* {code} 	            if (blocksProcessed >= 1000) { {code} hard-coded limit


I uploaded version 2 with just the changes to address one of the findbugs and the style issues.

I also raised HDFS-14861 to see if we can find a solution for blocks which are left behind in the LowRedundancyBlocks queue due to how the iterator is bookmarked (problem 6 in the PDF attached to this Jira) as the changes in the attached patch does not address that point.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 44s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 18m 54s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 59s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  4s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} shadedclient {color} | {color:red}  2m 29s{color} | {color:red} branch has errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  7s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 13s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 43s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:red}-1{color} | {color:red} shadedclient {color} | {color:red}  0m 25s{color} | {color:red} patch has errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 12s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  8s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}110m  5s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 34s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}145m 41s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |
|  |  Useless condition:isHealthy == false at this point  At DatanodeAdminManager.java:[line 1138] |
| Failed junit tests | hadoop.fs.TestHdfsNativeCodeLoader |
|   | hadoop.hdfs.server.namenode.ha.TestHASafeMode |
|   | hadoop.tools.TestHdfsConfigFields |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=19.03.2 Server=19.03.2 Image:yetus/hadoop:39e82acc485 |
| JIRA Issue | HDFS-14854 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12980929/HDFS-14854.002.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 32d176f924d6 4.15.0-60-generic #67-Ubuntu SMP Thu Aug 22 16:55:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 1654497 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_222 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/27922/artifact/out/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/27922/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/27922/testReport/ |
| Max. process+thread count | 2625 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/27922/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



Great writeup, thanks [~sodonnell].
I suspect we want to call the new implementation (and the configuration key) something other than decommission monitor, since this encompasses both decomm and maintenance mode. Call it DatanodeAdminManager v2 maybe?

Thanks for the review [~swagle]  and [~weichiu]. I have addressed the following points in a new patch version:
 * From Sid - Use reflection to create the monitor class version. Note that this does not make the monitor completely pluggable, as it is an inner class of the DatanodeAdminManager class, so if a 3rd version was introduced that class would need to be modified anyway.
 * From Sid - Remove the hard coded 'blocks per lock' of 1000 and create a new parameter "{color:#6a8759}dfs.namenode.decommission.backoff.monitor.pending.blocks.per.lock{color}"
 * From Wei-Chiu - I agree call this a "decommission monitor" is not ideal as it does maintenance too, however all the existing keys defined for decom and maintenance are called "dfs.namenode.decommission...." so if we added new keys with a different name it would make it even more confusing. I think keeping the parameter name as "decommission" is least confusing.
 * I have changed the name of the new monitor to "BackoffMonitor" rather than MonitorV2. This reflects what it does, in that it backs off from adding too many blocks to the replication queue.
 * There appear to be two classes which test decommission currently - TestDecommission and TestDecommissionStatus. I have sub-classed these two tests and refactored one slightly to allow me to change the config to enable the Backoff Monitor and then re-run all the existing tests with the new monitor version. One test is not valid in the new monitor and one needed some small changes in the extended class to get it to pass. The others all passed with no changes.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  1m 17s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 22m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 11s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 59s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m 14s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 38s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 21s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 17s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 55s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 18 new + 460 unchanged - 6 fixed = 478 total (was 466) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 17s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 34s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  3m  1s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 18s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}105m 35s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}178m 28s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |
|  |  Useless condition:isHealthy == false at this point  At DatanodeAdminManager.java:[line 1150] |
| Failed junit tests | hadoop.tools.TestHdfsConfigFields |
|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestSpaceReservation |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=18.09.7 Server=18.09.7 Image:yetus/hadoop:efed4450bf1 |
| JIRA Issue | HDFS-14854 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12981876/HDFS-14854.003.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 7c91639d0fb1 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 8efd25b |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_222 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/27993/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/27993/artifact/out/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/27993/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/27993/testReport/ |
| Max. process+thread count | 2898 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/27993/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  1m 12s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 23m 57s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  5s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 23s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 34s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 13s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 44s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 7 new + 461 unchanged - 5 fixed = 468 total (was 466) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 32s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 22s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 11s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 99m 18s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 33s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}167m 48s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |
|  |  Useless condition:isHealthy == false at this point  At DatanodeAdminManager.java:[line 1156] |
| Failed junit tests | hadoop.hdfs.qjournal.server.TestJournalNodeSync |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=18.09.7 Server=18.09.7 Image:yetus/hadoop:efed4450bf1 |
| JIRA Issue | HDFS-14854 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12981890/HDFS-14854.004.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux 870326c4768a 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 425a6c8 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_222 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/27996/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/27996/artifact/out/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/27996/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/27996/testReport/ |
| Max. process+thread count | 2861 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/27996/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



Thanks [~sodonnell] for  [^HDFS-14854.004.patch].
What about taking all the Monitor out of DatanodeAdminManager?
I think it serves its own package including:
* Interface with proper javadoc explaining the whole thing.
* The default manager changing the name to DefaultDecomMonitor.
* The new BackoffMonitor.

This may require some additional refactor but I think it's worth not to keep growing this file.

For the configuration, I would prefer to use ReflectionUtils and pass all the parameters as part of the conf.

[~elgoiri] Thanks for the comments. I have had a quick look at what it would take to move the existing monitor out of the DatanodeAdminManager class. It is doable without too much effort, but it would cost a reasonable amount of change to the implementation which is there and working, which makes this change more difficult to review and risky.

Ultimately I would like to end up with 1 decommission monitor, however while I believe the new implementation will work better than the existing, we won't know until it is tried on real clusters. Therefore I would like to give the option to use the new one, and if it does not work better, the existing is there to fall back to. Another option may be to move the new monitor into a standalone class with a different constructor, and leave the existing implementation untouched. I will spend a bit of time looking at this option and see what I come up with.

Another option is to just make the refactoring of DatanodeAdminManager in a separate JIRA.


It turned out to be fairly easy to take the monitor classes out the DatanodeAdminManager class, but it does make it difficult to see the changes made the to original monitor to allow this to happen.

Basically I had to move "pendingNodes" into the monitor classes and have DatanodeAdminManager call the monitor to add and remove nodes from it. I also need to pass namesystem, blockManager and the DatanodeAdminManager to the monitor constructor so they can access these things which were shared with the DatanodeAdmin class.

I think this change is a positive one, and it does make the monitor fully pluggable.

All existing decommission tests pass locally and my additional tests classes which reuse the original decom test in TestDecommissioningStatusWithBackoffMonitor and TestDecommissionWithBackoffMonitor are passing too.

I spotted a couple of minor issues with the v5 patch so I have uploaded v6.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 50s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 20m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  4s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 25s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m 24s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 44s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 32s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 14s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  5s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  5s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 53s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 9 new + 462 unchanged - 5 fixed = 471 total (was 467) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 16s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 43s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 45s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 2 new + 0 unchanged - 0 fixed = 2 total (was 0) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 23s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}110m 17s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 33s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}179m 53s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |
|  |  Useless condition:isHealthy == false at this point  At DatanodeAdminBackoffMonitor.java:[line 389] |
|  |  Should org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminBackoffMonitor$BlockStats be a _static_ inner class?  At DatanodeAdminBackoffMonitor.java:inner class?  At DatanodeAdminBackoffMonitor.java:[lines 758-785] |
| Failed junit tests | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |
|   | hadoop.hdfs.tools.TestDFSZKFailoverController |
|   | hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=19.03.3 Server=19.03.3 Image:yetus/hadoop:1dde3efb91e |
| JIRA Issue | HDFS-14854 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12982552/HDFS-14854.005.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux 7addbe471a48 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 1d27930 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_222 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/28042/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/28042/artifact/out/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28042/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28042/testReport/ |
| Max. process+thread count | 2784 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28042/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 23s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m  4s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m  5s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 18s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 14s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  5s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  5s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 47s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 8 new + 462 unchanged - 5 fixed = 470 total (was 467) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m  5s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 40s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 2 new + 0 unchanged - 0 fixed = 2 total (was 0) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 14s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 93m 20s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 46s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}156m  9s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |
|  |  Useless condition:isHealthy == false at this point  At DatanodeAdminBackoffMonitor.java:[line 392] |
|  |  Should org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminBackoffMonitor$BlockStats be a _static_ inner class?  At DatanodeAdminBackoffMonitor.java:inner class?  At DatanodeAdminBackoffMonitor.java:[lines 761-788] |
| Failed junit tests | hadoop.hdfs.server.namenode.TestRedudantBlocks |
|   | hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy |
|   | hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=19.03.2 Server=19.03.2 Image:yetus/hadoop:1dde3efb91e |
| JIRA Issue | HDFS-14854 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12982559/HDFS-14854.006.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux 834c8549feeb 4.15.0-60-generic #67-Ubuntu SMP Thu Aug 22 16:55:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / be901f4 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_222 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/28043/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/28043/artifact/out/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28043/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28043/testReport/ |
| Max. process+thread count | 3260 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28043/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



Thanks [~sodonnell] for the refactor, I like the new split.
A few comments:
* Can DatanodeAdminBackoffMonitor extend DatanodeAdminDefaultMonitor? I haven't checked too carefully but it looks like they share a base.
* Can we add a general javadoc to DatanodeAdminBackoffMonitor?
* Let's define DatanodeAdminBackoffMonitor#pendingRep as Map<>, no need for HashMap (it should even fit in one line).
* The initializer of the monitor in DatanodeAdminManager does a log and throw, following [~belugabehr] work, we should avoid this.
* I still think we can use ReflectionUtils#newInstance now that we have this refactor. We can use the setConf() and set the BlockManager and DatanodeAdminManager as a setter.

[~belugabehr], this looks like the kind of patch you would go over in the future.
Do you mind taking a full pass on this?

I will upload a new patch that addresses the find bugs and hopefully most styles issues, but some keys are too long for one line so we cannot get rid of all the check style warnings.

{quote}

Can DatanodeAdminBackoffMonitor extend DatanodeAdminDefaultMonitor? I haven't checked too carefully but it looks like they share a base.

{quote}

The do have some copy and pasted code. I need to see how much they can actually shared, and if we have a long term goal of removing the original monitor, then maybe its best they are completely separated, or they both inherit from an abstract base class. I will look into it some more.

I have added the Java doc and changed the definition of pendingRep to be a map<>.

{quote}

The initializer of the monitor in DatanodeAdminManager does a log and throw, following [~belugabehr] work, we should avoid this.

{quote}

Can you expand on this as I am not sure what David changed / suggested for this type of scenario? If the monitor fails to initialize we certainly want to throw, so do we just not need the log message too as it will be logged elsewhere?

{quote}

I still think we can use ReflectionUtils#newInstance now that we have this refactor. We can use the setConf() and set the BlockManager and DatanodeAdminManager as a setter.

{quote}

Do you know of any good examples where reflection utils does this? I had a quick look at the ReflectionUtils class, and its not clear how to use it, but I did not spend too much time looking at it.

 

 

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  1m 38s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 24m 24s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 23s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m 21s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 13s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 44s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 5 new + 462 unchanged - 5 fixed = 467 total (was 467) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m  3s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 20s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 10s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 99m 39s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 36s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}169m 25s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped |
|   | hadoop.hdfs.server.balancer.TestBalancer |
|   | hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=19.03.3 Server=19.03.3 Image:yetus/hadoop:1dde3efb91e |
| JIRA Issue | HDFS-14854 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12982608/HDFS-14854.007.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux dceae6237efe 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 2d81abc |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_222 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/28047/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28047/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28047/testReport/ |
| Max. process+thread count | 2836 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28047/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



* For log and throw, yes, the theory is that if you throw, that's enough as something else catching the exception would log or do something relevant. Standard anti-pattern idea.
* For ReflectionUtils, the typical thing is to use conf#getClass() and then just do:
{code}
Class<?> clazz = conf.getClass(key, value, interface);
DatanodeAdminMonitorInterface monitor = ReflecitonUtils.newInstance(clazz, conf);
monitor.setBlockManager(blockManager);
...
{code}

You would have to make DatanodeAdminMonitorInterface  implement Configurable too to make this fly.

I have just uploaded another patch. This uses ReflectionUtils to create the monitor instance and adds DatanodeAdminMonitorBase which the two monitor classes extend to allow some code to be shared. I still want to make as little changes as possible to the original decommission class, so I have not gone to a great effort to avoid any duplicated code between the two monitors, but I have pulled some obvious stuff into the Base class. I also have a long term view that the "DefaultMonitor" should be deprecated if we get the BackoffMonitor tried, tested and proven to be an improvement.

I think the 008 patch addresses all the review comments so far.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 50s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 18s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 48s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  5s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 18s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 11s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 42s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 11 new + 462 unchanged - 5 fixed = 473 total (was 467) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m  8s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 20s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 10s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}106m  4s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 34s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}167m 35s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.tools.TestDFSZKFailoverController |
|   | hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=19.03.3 Server=19.03.3 Image:yetus/hadoop:104ccca9169 |
| JIRA Issue | HDFS-14854 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12982972/HDFS-14854.008.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux c8b148555e6a 4.15.0-60-generic #67-Ubuntu SMP Thu Aug 22 16:55:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 5cc7873 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_222 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/28086/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28086/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28086/testReport/ |
| Max. process+thread count | 2877 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28086/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



Thanks [~sodonnell] for the update.
Regarding the sharing, just one minor one: what are the issues with sharing maxConcurrentTrackedNodes and numBlocksChecked?
{{outOfServiceNodeBlocks}} could also potentially just be a Map and internally use TreeMap but I understand it has issues with the API so I'm finw with it.
Other than that, I like the new approach.

I'm looking at this now, but one nit:
{code:java|title=Currently}
     try {
        namesystem.writeLock();
        ...
      } finally {
        namesystem.writeUnlock();
      }
{code}
Best practice is to grab the lock outside of the try statement.
 [https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/locks/ReentrantLock.html]
{code:java|title=Currently}
     namesystem.writeLock();
     try {
        ...
      } finally {
        namesystem.writeUnlock();
      }
{code}

The {{cancelledNodes}} data structure is a {{List}} but it should be a {{Queue}}

 

{code:java}
while (!queue.isEmpty()) {
    queue.poll();
}
{code}

{code:java}
    while (!pendingNodes.isEmpty() &&
        (maxConcurrentTrackedNodes == 0 ||
            outOfServiceNodeBlocks.size() < maxConcurrentTrackedNodes)) {
      outOfServiceNodeBlocks.put(pendingNodes.poll(), null);
    }
{code}

Using 'null' values is very out of vogue.  Better to put a new {{HashMap}} here. Allows for simplification of the code by assuming that values will never be 'null'.   The cost of creating a HashMap is very low here, especially it's only one per DataNode.

The method {{scanDatanodeStorage}} uses the {{namesystem.readLock();}} in a pretty verbose and complicated way.

If the idea here is to grab the {{readLock}} for each DataNode, and unlock it after processing each DataNode, simply move the {{try...finally}} block inside the loop.

{code:java}
  private void processPendingNodes() {
    while (!pendingNodes.isEmpty() &&
        (maxConcurrentTrackedNodes == 0 ||
            outOfServiceNodeBlocks.size() < maxConcurrentTrackedNodes)) {
      outOfServiceNodeBlocks.put(pendingNodes.poll(), null);
    }
  }
{code}

This method is accessed by the local running Thread.  However, {{pendingNodes}} does not appear to be a thread-safe Collection.  Perhaps the collection cannot be modified because of the external locking of the {{writeLock}} but there is no requirement to have the lock stated in the {{startTrackingNode}} method javadoc.

Nit: this is not very java-y...
{code:java}
    final List<DatanodeDescriptor> toRemove = new ArrayList<>();
...
    processMaintenanceNodes(toRemove);
...

    // Check if any nodes have reached zero blocks and also update the stats
    // exposed via JMX for all nodes still being processed.
    checkForCompletedNodes(toRemove);

    // Finally move the nodes to their final state if they are ready.
    processCompletedNodes(toRemove);
{code}
Better to remove coupling:
{code:java}
    final List<DatanodeDescriptor> maintenanceExpiredNodes = getMaintenanceNodes();
...

    final List<DatanodeDescriptor> completedNodes = getCompletedNodes();

Iterable<String> nodesToRemove = Iterables.unmodifiableIterable(
  Iterables.concat(maintenanceExpiredNodes , completedNodes));

    // Finally move the nodes to their final state if they are ready.
    processCompletedNodes(Lists.newArrayList(nodesToRemove));
{code}

Please remove this method.  It can be replaced with {{map.computeIfAbsent(key, k -> new LinkedList<V>()).add(v);}}

{code:java}
private void addBlockToPending(DatanodeDescriptor dn, BlockInfo block) {
List<BlockInfo> blockList = pendingRep.get(dn);
  if (blockList == null) {
     blockList = new LinkedList<>();
    pendingRep.put(dn, blockList);
  }
  blockList.add(block);
}
{code}

https://docs.oracle.com/javase/8/docs/api/java/util/Map.html#computeIfAbsent-K-java.util.function.Function-

This code knows the pendingCount value and the pendingRepLimit... do not grab the write lock if the function is going to immediately return anyway.

{code:java}
    int pendingCount = getPendingCount();

    try {
      namesystem.writeLock();
      long repQueueSize = blockManager.getLowRedundancyBlocksCount();
...
      if (pendingCount >= pendingRepLimit) {
        return;
      }
{code}

{code:java}
    if (blockManager.blocksMap.getStoredBlock(block) == null) {
      LOG.trace("Removing unknown block {}", block);
      return true;
    }

    long bcId = block.getBlockCollectionId();
    if (bcId == INodeId.INVALID_INODE_ID) {
      // Orphan block, will be invalidated eventually. Skip.
      return false;
    }
{code}

I think it should return 'true' if the block is orphaned, no?  It should skip them in the same way that an 'unknown' block is.

[~sodonnell] [~elgoiri]  I provided some feedback for you to review regarding this specific patching.

However, I would like to draw your attention to something I was saying before...

I think it would be cool if we could also include the {{BlockManager#neededReconstruction}} in improving decommissioning.  There is a bunch of polling going on in this class, checking sizes and statuses.  I think some of that could be removed by making the {{BlockManager#neededReconstruction}} Collection a synchronized priority queue.... perhaps it should just be it's own priority queue-backed {{ExecutorService}}.  This will help in that requests from dead nodes will be prioritized ahead of requests for decommissioning.  You could probably also make it a {{BlockingQueue}} with a fixed-size so that threads block if the queue gets too large.  In this way, there doesn't need to be batching.  Just figure out the next block to replicate, give up the global lock, try to add it to the {{neededReconstruction}} queue, and once complete, go find the next block to replicate.  Something like that.

[~belugabehr] Thanks for the comments. I have addressed some in the 009 patch and a few I have not addressed. Please see below which gives the summary:

{quote}
Best practice is to grab the lock outside of the try statement.
{quote}

Maybe there is something I don't understand and I see it does state the best practice you mentioned in the link, but I don't see how:
{code:java}
 lock
try {
   ...
} finally {
unlock
}{code}
Is better than:
{code:java}
 try {
   lock()
   ...
} finally {
   unlock()
}{code}

{quote}
The cancelledNodes data structure is a List but it should be a Queue
{quote}

True, I have changed it to an ArrayDeque like with pendingNodes.

{quote}
Using 'null' values is very out of vogue. Better to put a new HashMap here. Allows for simplification of the code by assuming that values will never be 'null'.
{quote}

I use the fact that the value is null to decide whether the datanode needs an initial scan or not. The flow is:

1. Take a nodes from pendingNodes and add to outOfServiceNodeBlocks with a null value.

2. Later, in the check() method, for each null entry in outofServiceNodeBlocks scan the node and add a hashmap of the blocks needing processed.

{quote}
The method scanDatanodeStorage uses the namesystem.readLock(); in a pretty verbose and complicated way.
{quote}

We need to hold the read lock when calling dn.getStorageInfos() in the outer loop, but we want to drop the lock after processing each storage and then take it again. I could refactor this to call dn.getStorageInfos() in a block, eg:
{code:java}
DatanodeStorageInfo[] storages;
namesystem.readLock()
try {
 storages = dn.getStorageInfo();
} finally {
 namesystem.readUnlock();
} {code}
And then simplify the locking code which is there, but I feel this isn't much better than what is there.


{quote}
This method is accessed by the local running Thread. However, pendingNodes does not appear to be a thread-safe Collection. Perhaps the collection cannot be modified because of the external locking of the writeLock but there is no requirement to have the lock stated in the startTrackingNode method javadoc.
{quote}

For nodes to be added to pendingNodes, that is always done under the namenode writeLock which is taken in fsnamesystem. Then the only place pendingNodes is processed in BackOffMonitor in via the monitor thread, and it ensures it holds the write lock when processing pendingNodes here:
{code:java}
@Override
 public void run() {
 LOG.debug("DatanodeAdminMonitorV2 is running.");
 if (!namesystem.isRunning()) {
 LOG.info("Namesystem is not running, skipping " +
 "decommissioning/maintenance checks.");
 return;
 }
 // Reset the checked count at beginning of each iteration
 numBlocksChecked = 0;
 // Check decommission or maintenance progress.
 try {
 try {
 /**
 * Other threads can modify the pendingNode list and the cancelled
 * node list, so we must process them under the NN write lock to
 * prevent any concurrent modifications.
 */
 namesystem.writeLock();
 // Always process the cancelled list before the pending list, as
 // it is possible for a node to be cancelled, and then quickly added
 // back again. If we process these the other way around, the added
 // node will be removed from tracking by the pending cancel.
 processCancelledNodes();
 processPendingNodes();
 } finally {
 namesystem.writeUnlock();
 } {code}

{quote}
Nit: this is not very java-y...
{quote}

I think we could argue this one either way. I think my version looks cleaner, but I admit modifying the passed in structure can be slightly confusing.


{quote}
Please remove this method. It can be replaced with map.computeIfAbsent(key, k -> new LinkedList<V>()).add(v);
{quote}

Thanks for pointing this out. I did not know about that method. I have changed this to use computeIfAbsent.

{quote}
This code knows the pendingCount value and the pendingRepLimit... do not grab the write lock if the function is going to immediately return anyway.
{quote}

The problem is, we need the lock to check blockManager.getLowRedundancyBlocksCount() and if the pendingCount is not reducing, then I would really like to log the replication queue size, as it may be due to an overloaded replication queue that the pendingCount is not reducing. In an earlier version I did have the check outside the lock but then I wanted to added the rep queue size to the log and moved it back in. This code is only run once per 30 seconds and the lock would only be held a tiny amount of time, so I think the additional details in the log are worth the lock price.


{quote}
I think it should return 'true' if the block is orphaned, no? It should skip them in the same way that an 'unknown' block is.
{quote}

That code is take from the original decommissioning code, and I have not changed it. I believe it returns false as it keeps tracking the block in the decommission structures until the NN cleans it out. Then it would become an unknown block and be deleted by the "unknown block" code.

[~elgoiri] Thanks for the comments. I added maxConcurrentTrackedNodes to the shared code, but left numBlocksChecked unshared. Both classes use this variable in a slightly different way, so I did not want to confuse things.

 

[~belugabehr] There probably is merit to looking at the replication queue implementation, but that is an area that can affect many parts of the namenode code, so we need to tread carefully with making too many changes. I feel we should get this decommission code into shape and testing in real world clusters and then we can revisit the queue and see what can be done.

 

 

[~elgoiri]

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} docker {color} | {color:red}  0m  0s{color} | {color:red} Docker failed to build yetus/hadoop:104ccca9169. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HDFS-14854 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12983085/HDFS-14854.009.patch |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28091/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



# https://stackoverflow.com/questions/10868423/lock-lock-before-try
# Please grab the lock for {{dn.getStorageInfos()}} in its own block.  Easier to reason about.
# Using a 'null' value in this way is overloading the use of the {{Map}} class and it's not clearly articulated in the comments how this works.  I think it would be much cleaner to have {{processPendingNodes()}} return a list of nodes that need to be processed instead of populating the {{Map}} in this way.

{code:java}
      List<DataNodeDescriptor> pendingNodes;
     try {
        ...
        processCancelledNodes();
        pendingNodes = processPendingNodes();
      } finally {
        namesystem.writeUnlock();
      }
     ...
     check(pendingNodes);
{code}

4. 

bq. For nodes to be added to pendingNodes, that is always done under the namenode writeLock

Please put that as a requirement in the JavaDoc for {{startTrackingNode}} method.

5.  I worry about the needless locking because that lock is a very hot lock,... used all over the place, and the time per iteration is configurable, so 30 seconds is the default, but user may opt to lower to 1 second and there's no information for them to know that this will increase the lock retention, even if there is nothing to replicate.


What I was saying before,... now that I've dug into it a bit more, is that we should look at revamping the {{org.apache.hadoop.hdfs.server.blockmanagement.LowRedundancyBlocks}} class as part of this effort.

For LowRedundancyBlocks, any changes are certainly a separate Jira. This one is already large enough. I am also wary of a major refactor in a critical area, while what is there works quite well generally.

For your further comments.
 # I will move all the locks outside of the try blocks.
 # I will clean this part up.
 # I am going to keep what is there. The pattern was established this way in the default monitor, so both of them work in roughly the same way. The current approach also lends some flexibility to throttling the number of nodes which have their storage scanned in a pass of the check loop in a similar way to the default monitor, if we later decided that is needed.
 # I will add the Java Doc.
 # In general this loop will find blocks it needs to move to the pending list and if there are no nodes decommissioning this code will never be called. On balance I feel the extra information we get from the taking the lock is worth it. Additionally in the BackOffMonitor the locking is much less aggressive than what it replaces so we should be good there.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 51s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 21m 11s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 48s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  7s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 19s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 16s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 45s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 12 new + 462 unchanged - 5 fixed = 474 total (was 467) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 15s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 19s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 99m 42s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 34s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}163m 22s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits |
|   | hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=19.03.3 Server=19.03.3 Image:yetus/hadoop:104ccca9169 |
| JIRA Issue | HDFS-14854 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12983148/HDFS-14854.010.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux 53ec2adf14cb 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / bbcf0b9 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_222 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/28096/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28096/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28096/testReport/ |
| Max. process+thread count | 2904 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28096/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



[~sodonnell] Thanks.  Looks good!

[~belugabehr], thanks for taking a pass.

[~sodonnell], a few minor things:
* I would solve the HiddenField checkstyle warning.
* Not very common to have a break line between the class and its javadoc.
* Add short javadocs (one line /** */ for cancelledNodes and blocksPerLock.
* Unify the comments lines 174-182 in the new monitor.
* moveBlocksToPending is a little hard to read. The loops specially breaking in a couple places. Extracting some might also help, for example 469.
* L633 should be a single line.

Other than these cosmetic changes, this looks good.
As this is pretty big, I'd like others to take another look.

[~elgoiri] I have addressed all the latest comments, I think.

moveBlocksToPending is tricky to make much simpler, as it needs to break out of the inner or outer loop on various conditions. However I pulled some of the logic into a new method and added a few commends, which I think it improves it a bit. Let me know what you think.

Thanks for the changes, [^HDFS-14854.011.patch] looks good to me.
One minor thing, we can use Configuration#getClass() in DatanodeAdminManager#136 as it will take care of getting the class an making it an interface, etc.

Anybody else up for going over this?

Let me have a look at that Configuration change too ...

[~weichiu] has told me he plans to review this when he gets some time. As we have had a few review cycles already it should be in good shape for him to have a thorough look now.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  1m 37s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 24m 49s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  2s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 22s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m 40s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 16s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 13s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 45s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 11 new + 462 unchanged - 5 fixed = 473 total (was 467) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  1s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 19s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 21s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  8s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 99m 53s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 33s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}170m 32s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.TestDistributedFileSystem |
|   | hadoop.hdfs.tools.TestDFSZKFailoverController |
|   | hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=19.03.3 Server=19.03.3 Image:yetus/hadoop:104ccca9169 |
| JIRA Issue | HDFS-14854 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12983289/HDFS-14854.011.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux a1d0fabd0d16 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 3990ffa |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_222 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/28104/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28104/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28104/testReport/ |
| Max. process+thread count | 3312 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28104/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



Thanks [~sodonnell]
I finally gave it a hard look at the patch. The patch looks reasonable to me. But a patch this big will inevitably introduce bugs in corner cases or race condition bugs. Next step would be to set up a small cluster, generate a few million files and shake out easy bugs.

There's a minor conflict because of HDFS-14847.

There's a typo:
{code}
LOG.error("P{ is set to an invalid value, it must be greater than "+
              "zero. Defaulting to {}",
{code}
I think you wanted instead
{code}
LOG.error("{} is set to an invalid value, it must be greater than "+
              "zero. Defaulting to {}",
{code}

Uploading another revision which addresses the typo Wei-Chiu spotted and I have addressed the conflict caused by HDFS-14847.

I also extended the TestDecommissionWithStripped class to give a TestDecommissionWithStrippedBackoffMonitor class, to ensure all the stripped tests are run against both monitors. All tests in those classes pass locally with no changes for me.

Next step is to run this on a small cluster and decom and recommission a few nodes as well as putting nodes in an out of maintenance to ensure it all works fine. I did this earlier, but there has been a reasonable amount of refactoring since then, so I need to run through the tests again.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 38s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 5 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m  4s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  7s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 57s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 20s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 18s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  4s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 48s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 12 new + 466 unchanged - 5 fixed = 478 total (was 471) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  6s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 23s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 18s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 17s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}100m 53s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 41s{color} | {color:red} The patch generated 1 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}159m 47s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.TestDecommission |
|   | hadoop.hdfs.server.namenode.TestFSDirectory |
|   | hadoop.hdfs.TestMultipleNNPortQOP |
|   | hadoop.hdfs.TestReconstructStripedFile |
|   | hadoop.hdfs.server.namenode.TestListCorruptFileBlocks |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=19.03.4 Server=19.03.4 Image:yetus/hadoop:104ccca9169 |
| JIRA Issue | HDFS-14854 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12984606/HDFS-14854.012.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux f705bb1d446c 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / ef9d12d |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_222 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/28224/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28224/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28224/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/28224/artifact/out/patch-asflicense-problems.txt |
| Max. process+thread count | 4289 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28224/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 51s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 5 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m  7s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 48s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  7s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 48s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 15s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 45s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 11 new + 464 unchanged - 5 fixed = 475 total (was 469) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 27s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 25s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  8s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}108m 19s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}170m 32s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy |
|   | hadoop.hdfs.tools.TestDFSZKFailoverController |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=19.03.4 Server=19.03.4 Image:yetus/hadoop:104ccca9169 |
| JIRA Issue | HDFS-14854 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12985123/HDFS-14854.013.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux 08e6e288090c 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / dd90025 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_222 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/28264/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28264/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28264/testReport/ |
| Max. process+thread count | 2875 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28264/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



I have addressed the earlier conflict and the error in the log message Wei-Chiu raised in his last comment. To test the patch in more detail I then did the following:

1) Enabled the new BackOff Monitor.
2) Created a 7 node cluster where the datanodes have simulated storage and then executed some tests as detailed below:

 * Decommission 2 nodes which have no overlapping blocks
    -> Confirmed both nodes make progress at roughly the same rate.
    -> Confirm nodes complete decommission in the logs and webUI
    -> Stop nodes and ensure no missing blocks after 10 minutes using fsck
    -> Recommissioned nodes and ensure all remains healthy
    -> Ensured over-replicated blocks on recommission and they are removed by namenode. 

 * Decommission 2 nodes. Cancel decommission on one.
    -> Ensured the cancelled node stops decom and the other node continues
    -> Confirmed the node completes decom.
    -> Stopped the node and ensured no missing blocks.
    -> Recommissioned and ensured over replicated blocks are removed.

 * Put two nodes to maintenance with min replicas set to 2. Set different expiry time for each node.
    -> Confirmed some blocks needed replicated, then maintenance mode is entered
    -> Observed one node ending maintenance at the set time automatically.
    -> Observed the other node ending maintenance at the set time.
    !! -> I found a bug here, in that the blocks on the node were getting scanned as the node leaves maintenance, which is not necessary. The reason, is that the call to dnAdmin.stopMaintenance adds the node to the cancelled list, but I was also adding it to the toRemove list.

 * Put one node to maintenance on a healthy cluster.
    -> Confirmed the node enters maintenance on the first monitor tick, as no blocks need replicated.
    -> Stopped the node and observed no missing blocks.
    -> Started the node again and observed no over-replicated blocks.

 * Put two nodes to maintenance with no end time and then cancel maintenance on one
    -> Confirmed the node cancels and the other node remains in maintenance

As part of doing this, I uncovered on bug mentioned about, and also noted a few log messages that were too verbose. With that in mind I uploaded patch 013. As this patch is so large I will also attach a diff of the changes between 012 and 013 to make it easier to review.

This feature seems to be working on a small cluster and the code is in pretty good shape, so I think it is ready to commit if [~elgoiri] and [~weichiu] are happy with the latest revision.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:blue}0{color} | {color:blue} patch {color} | {color:blue}  0m  5s{color} | {color:blue} The patch file was not named according to hadoop's naming conventions. Please see https://wiki.apache.org/hadoop/HowToContribute for instructions. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  9s{color} | {color:red} HDFS-14854 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HDFS-14854 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12985213/012_to_013_changes.diff |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28271/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



Thanks [~sodonnell] for the careful testing.

Can we add a test for the bug?
(I'm not sure is easy to test TBH.)

In a more general thought, should we extend the tests to cover as much as possible the cases you tested manually?

BTW, let's use getClass() in DatanodeAdminManager#137 and setClass in the others (e.g., TestDecommissionWithBackoffMonitor, TestDecommissioningStatusWithBackoffMonitor)

The existing set of tests should do everything I ran manually, but I wanted to run though a set of tests on a larger cluster that is decommissioning more than just a handful of blocks each time. I have extended all the decommission tests to run with both monitors, so we should be good there.

I don't think it would be easy to create a unit test for the issue I found. I only spotted it from the logs as functionally things were fine. It was just scanning the blocks to check if they were replicated an extra time, so it was more of a performance issue than a functional defect.

I will make those further changes and upload v014 soon.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 49s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 5 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 28s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 50s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  4s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 35s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 14s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  2s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 45s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 11 new + 464 unchanged - 5 fixed = 475 total (was 469) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 38s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 20s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}100m 44s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 35s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}163m 24s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.namenode.TestNameNodeMXBean |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=19.03.4 Server=19.03.4 Image:yetus/hadoop:104ccca9169 |
| JIRA Issue | HDFS-14854 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12985278/HDFS-14854.014.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux 75453069aebf 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 247584e |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_222 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/28274/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28274/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28274/testReport/ |
| Max. process+thread count | 2837 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28274/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



I think this patch is ready to go as long as we mark it as an "experimental" feature and users is expected to hit snags.
Plan to commit it in trunk for 3.3.0 release.

[~weichiu], marking it as experimental sounds good.

+1 on  [^HDFS-14854.014.patch].

Committing 014 patch

Committed to trunk for 3.3.0 release.
Thanks numerous iterations of review from [~belugabehr] and [~elgoiri], and thanks [~sodonnell] for offering the patch.

I filed HDFS-15047 to document this feature so that we can get community to use this feature and get feedback.

SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17749 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17749/])
HDFS-14854. Create improved decommission monitor implementation. (weichiu: rev c93cb6790e0f1c64efd03d859f907a0522010894)
* (add) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminDefaultMonitor.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDecommissioningStatus.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* (add) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDecommissionWithStripedBackoffMonitor.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDecommissionWithStriped.java
* (add) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminBackoffMonitor.java
* (add) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminMonitorBase.java
* (add) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDecommissioningStatusWithBackoffMonitor.java
* (add) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDecommissionWithBackoffMonitor.java
* (add) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminMonitorInterface.java


SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17756 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17756/])
HDFS-15047. Document the new decommission monitor (HDFS-14854). (#1755) (github: rev bdd00f10b46c1c856433e2948906f36c70d3a0be)
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/site/markdown/HdfsDataNodeAdminGuide.md


[~sodonnell], I see that you commented out one of the checks in "{{TestDecommissioningStatus.testDecommissionStatus()"}}

Can you please  share your experience with that test case and why you decided to remove the check?

There are some old Jiras suggesting that "{{testDecommissionStatus"}} is flaky.
 * HDFS-12188
 * HDFS-9599
 * HDFS-9950
 * HDFS-10755
  

I don't recall why I commented that check out. Perhaps the test was giving some problems, and I commented it out to see if it fixed the problem but forgot to put in back in again. I don't believe I intended for that change to get committed as I did not intend to change any logic of existing tests as part of this work. I only refactored them so they could be sub-classed to create new tests for the new monitor implementation.

hi [~sodonnell] thanx for the work here.

Do you have any performance numbers for this on a actual cluster.

Just to know how much does this improve

Hi [~ayushtkn] - unfortunately we have not been able to run this on anything outside of a test cluster as yet, but I am very keen to hear reports from anyone willing to give it a try.

Its really hard to know how much this patch would improve decommission speed by. On one hand, the speed is still limited by the pending replication queue, which the decommission monitor places blocks onto. However, the new monitor places the block on it in a more random fashion to avoid replicating blocks off the same disk all the time. I also hope the new monitor has less of an overhead on the namenode as its running, as it does not hold the write lock as often, or spend time scanning the same blocks over and over.

Tried decommissioning using this with 30 Lack blocks, 3 datanodes. Sadly, this didn't save any time for me. To my surprise time taken with this and without this was exactly same. 

Hi [~ayushtkn] there are quite a few factors to consider in this.

Firstly, decommission speed is mostly dictated by the speed the replication manager works at, and nothing about that has changed with this patch.

One thing we did attempt to do, was ensure that the blocks were shuffled so that if the decommissioning node has many disks, it should not pick blocks only from the same disk, which is what the origional monitor did. Depending on your settings for max-streams and work-multiplier, there may not be enough blocks moving at the same time to saturate a disk and therefore you would not see any benefit of this.

This change should also result in less load on the NN. It scans the blocks less often to check if they have completed replication, does a lot of work under the read lock rather than write lock. For maintenance, it should also result in nodes going into maintenance faster provided they don't need to do any replication.

Even if replication happens at the same speed, the new monitor should use less CPU and cause less lock contention on the NN, which is a good thing, but very hard to measure.

