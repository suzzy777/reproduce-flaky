didn't increase to critical as I don't know if this is a test issue or not, so hoping someone more familiar can validate and correct the state.

Just saw it again today in CircleCI:
https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/545/workflows/f797bf58-b572-4d8c-831e-a61936d23624/jobs/3027

Running the CAS test locally randomly fails for me in 3 different ways: this ticket, CASSANDRA-16317 [timeouts|https://issues.apache.org/jira/browse/CASSANDRA-16317?focusedCommentId=17267739&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17267739] or OOM. Proposing to address them all here.

{quote}Proposing to address them all here.{quote}
It makes sense to me.


ci-cassandra's [test page for CASTest|https://ci-cassandra.apache.org/job/Cassandra-trunk-jvm-dtest/lastCompletedBuild/jdk=jdk_1.8_latest,label=cassandra/testReport/org.apache.cassandra.distributed.test/CASTest/] is reporting flakiness at 37%.

h4. Searching nightlies.a.o

The logs for this test are archived at
{noformat}
https://nightlies.apache.org/cassandra/Cassandra-trunk-jvm-dtest/jdk=jdk_1.8_latest,label=cassandra/*/build/test/logs/org.apache.cassandra.distributed.test.CASTest/
{noformat}
for example, the following are the logs for the {{incompletePropose}} failures…
- https://nightlies.apache.org/cassandra/Cassandra-trunk-jvm-dtest/jdk=jdk_1.8_latest,label=cassandra/478/build/test/logs/org.apache.cassandra.distributed.test.CASTest/
- https://nightlies.apache.org/cassandra/Cassandra-trunk-jvm-dtest/jdk=jdk_1.8_latest,label=cassandra/476/build/test/logs/org.apache.cassandra.distributed.test.CASTest/

To search in the archives, we can do**…
{code}
# webdav mount https://nightlies.apache.org/cassandra/ to /Volumes/cassandra
cd /Volumes/cassandra

xzgrep "name=\"CASTest\"" Cassandra-trunk/*/TESTS-TestSuites.xml.xz
{code}
shows error (for the class) in builds:
- [Cassandra-trunk#197|https://nightlies.apache.org/cassandra/Cassandra-trunk/197]
- [Cassandra-trunk#202|https://nightlies.apache.org/cassandra/Cassandra-trunk/202]
- [Cassandra-trunk#212|https://nightlies.apache.org/cassandra/Cassandra-trunk/212]

Note, these are other test failures than {{incompletePropose}}.


**) The test xml for the jvm-dtest jobs, like [this|https://ci-cassandra.apache.org//job/Cassandra-trunk-jvm-dtest/jdk=jdk_1.8_latest,label=cassandra/lastSuccessfulBuild/artifact/build/test/output/], are not archived (yet) so the slower greps against the full pipeline xml test reports have to done.


I digged into the tests and it seems that the issue is that the timeouts are probably to low for the  CI environment. I noticed that the initial insert query is slower to reach the paxos logic that the following ones.

For the {{incompletePropose}} test, what is happening is that the initial insert timeout in the {{prepare}} round before this phase is actually completed on the node. Due to that the original update is never taken into account. The following update fail silently and the problem is caught by the {{SELECT}} query.
Another scenario that can happen is that the {{prepare}} round complete but the {{proposal}} one fail for the coordinator node due to a timeout. In this case the following update will found the prepared value and ensure that it is proposed and committed before applying the update. So in practice the test will succeed even if the executed scenario is not the expected one.

For the {{incompleteCommit}} test what is happening  is due to the extra work left by the original insert the update take longer than expected and timeout. 

 
 

|| Branch || CI ||
|[cassandra-3.0|https://github.com/apache/cassandra/pull/901]|[j8|https://app.circleci.com/pipelines/github/blerer/cassandra/103/workflows/98620a40-f8aa-48bd-b61e-e301a05c16ae]|
|[cassandra-3.11|https://github.com/apache/cassandra/pull/902]|[j8|https://app.circleci.com/pipelines/github/blerer/cassandra/106/workflows/11713aa2-d80e-4ddf-b760-c5128c26a460]|
|[trunk|https://github.com/apache/cassandra/pull/903]| [j8|https://app.circleci.com/pipelines/github/blerer/cassandra/107/workflows/b39bd3e7-9029-440b-a50f-3c4f985a3b88], [j11|https://app.circleci.com/pipelines/github/blerer/cassandra/107/workflows/e9cc0ea1-c851-438b-aa13-608ced7ae28d]|

It sounds very plausible than 200ms is on the low end for CI, and [~blerer] explanations of why timeouts would lead to the failure seen on this ticket make sense.

So +1 for the patch raising the timeout. Maybe just a nit: I'd use the opportunity for moving the timeout value into a constant.

That said, it's a bit unfortunate the test failures don't surface more clearly that this is due to a timeout. The reason this happen, at least for `incompletePropose` and if I understand correctly, is that while the initial inserts timeout _before_ it was supposed to, the `catch` doesn't know that. So what about modifying `IMessageFilters.Filter` so that it counts the number of messages it drops? With that, we could check after that the first insert timeout that the filter was triggered. And if it wasn't, that would imply we timed out before we were supposed too (and we could have a message saying "Hey, CI is slow again today").

But I do understand this imply a change and subsequent release of the in-jvm dtest API, so I'd be fine committing the timeout bump now for the sake of cleaning up CI and have that "improvement" in a followup (or not at all, it's just a suggestion).


Created CASSANDRA-16454 to address the problem raised by [~slebresne].

Committed into cassandra-3.0 at df0216c345b0b03f1b394fe092667e5d6bcd2957 and merged into cassandra-3.11 and trunk.

