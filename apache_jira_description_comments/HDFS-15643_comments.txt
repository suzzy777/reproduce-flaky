Looking at the logs, my best guess is that there is a race when the unit-test shuts down a datanode and trying to access the file.

It seems that in a slow execution, the threads will race and there is no enough time to reconstruct the blocks following a shutdown.

The fix also applies for {{TestFileChecksum}} .


Error log:
{noformat}
2020-10-29 04:55:00,418 [DataXceiver for client /127.0.0.1:60824 [Getting checksum for block groupBP-406455512-192.168.249.5-1603947295509:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(3
24)) - 127.0.0.1:36907:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:60824 dst: /127.0.0.1:36907
java.lang.UnsupportedOperationException
        at java.nio.ByteBuffer.array(ByteBuffer.java:994)
        at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
        at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
        at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
        at java.lang.Thread.run(Thread.java:748)
2020-10-29 04:55:00,418 [Time-limited test] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[1]=DatanodeInfoWithStorage[127.0.0.1:36907,DS-e9365b1c-9803-4d66-ac04-9aa2de6181cd,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
        at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:528)
        at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
        at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
        at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
        at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
        at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1851)
        at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1871)
        at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1903)
        at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1900)
        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1917)
        at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:602)
        at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:318)
        at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery11(TestFileChecksum.java:444)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
        at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
        at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.lang.Thread.run(Thread.java:748) {noformat}

Thank you [~aajisaka], I could not reproduce it on my local environment.

Anyway, the exception is thrown after the unit test shuts down a datanode.
 The following {{getFileChecksum()}} seems to construct the checksum before the block reconstruction is complete.
 Because reconstruction is not complete, the {{StripedBlockChecksumReconstructor}} uses the wrong buffer type,
 which leads to calling {{toArray()}} on a {{DirectBuffer}}.
 I remember that I pointed out to similar issue with EC and stripped group blocks in HDFS-15459.

Regarding this unit test, I think that my early suggestion to wait until reconstruction is complete needs to be added to the test.
 However, I prefer that someone familiar with EC takes a look at the implementation because this is most probably a major bug
 in the code of the EC and striped files.

[~inigoiri], [~aajisaka]. Thank you guys for your help. Unfortunately, I won't have much time in the next couple of weeks to dig
 into the EC and striped files implementation.

[~weichiu] , who is familiar with EC and can help with looking at those bugs? (this one and HDFS-15459)
 Until then, I suggest we turn off both {{TestFileChecksumCompositeCrc}} and {{TestFileChecksum}} at least to give us a chance
 to save time and get more accurate reports excluding the side effects of those two test classes.

[~aajisaka] can you try the patch. I think there is an issue with the code itself, In case of Native Encoders, In case EC isn't using the Native Encoding, this seems to be good. Well, It didn't directly repro for me also, I just tried to repro this by some code tweaks, And tried just one test in TestFileChecksum. 

[~ayushtkn], do you think this is the root of the problem or the symptoms?

That code in \{{StripedBlockChecksumReconstructor}} is pretty old.

Yeps, That is quite old, but in EC, if you don't have the native loaded, it will silently ignore and go ahead with the non-native encoders. So, I think this issue was there already but the native wasn't loaded during test.
I suspect it may be because of HADOOP-17224

Thanks [~ayushtkn] , I probably messed HADOOP-17224

I remember I this unit test used to show up earlier than August; but anyway, I hope that this will be the fix.

 

Yetus was recently running Out of memory and all submitted patches did not run. You can go ahead
with creating a new PR with your changes. Then if the test case passes, we can close the current opened one.

 

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime ||  Logfile || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 33m 11s{color} |  | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} || ||
| {color:green}+1{color} | {color:green} dupname {color} | {color:green}  0m  0s{color} |  | {color:green} No case conflicting files found. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} |  | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} |  | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} trunk Compile Tests {color} || ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 22m  1s{color} |  | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 19s{color} |  | {color:green} trunk passed with JDK Ubuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 12s{color} |  | {color:green} trunk passed with JDK Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 46s{color} |  | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 16s{color} |  | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 18m 15s{color} |  | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 52s{color} |  | {color:green} trunk passed with JDK Ubuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 20s{color} |  | {color:green} trunk passed with JDK Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10 {color} |
| {color:blue}0{color} | {color:blue} spotbugs {color} | {color:blue}  3m 10s{color} |  | {color:blue} Used deprecated FindBugs config; considering switching to SpotBugs. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m  8s{color} |  | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} || ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 13s{color} |  | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 13s{color} |  | {color:green} the patch passed with JDK Ubuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 13s{color} |  | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  6s{color} |  | {color:green} the patch passed with JDK Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  6s{color} |  | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} blanks {color} | {color:green}  0m  0s{color} |  | {color:green} The patch has no blanks issues. {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 40s{color} |  | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 15s{color} |  | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 18m 43s{color} |  | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 49s{color} |  | {color:green} the patch passed with JDK Ubuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 20s{color} |  | {color:green} the patch passed with JDK Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10 {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 13s{color} |  | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} || ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}113m 16s{color} | [/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt|https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/276/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt] | {color:red} hadoop-hdfs in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 35s{color} |  | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}224m 43s{color} |  | {color:black}{color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.namenode.TestNamenodeCapacityReport |
|   | hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/276/artifact/out/Dockerfile |
| JIRA Issue | HDFS-15643 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/13014377/Test-Fix-01.patch |
| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient findbugs checkstyle |
| uname | Linux fc526f00d14d 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | personality/hadoop.sh |
| git revision | trunk / 8ee6bc2518bfdf7ad257cc1cf3c73f4208c49fc0 |
| Default Java | Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10 |
| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10 |
|  Test Results | https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/276/testReport/ |
| Max. process+thread count | 3037 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/276/console |
| versions | git=2.17.1 maven=3.6.0 findbugs=4.1.3 |
| Powered by | Apache Yetus 0.14.0-SNAPSHOT https://yetus.apache.org |


This message was automatically generated.



bq. Akira Ajisaka can you try the patch.

I tried the patch in https://github.com/apache/hadoop/pull/2421/files but it failed.

The following test cases failed in TestFileChecksum:
{noformat}
[ERROR] Errors: 
[ERROR]   TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1:279->getFileChecksum:602 ? PathIO
[ERROR]   TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2:296->getFileChecksum:604 ? PathIO
[ERROR]   TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery12:455->testStripedFileChecksumWithMissedDataBlocksRangeQuery:318->getFileChecksum:602 ? PathIO
[ERROR]   TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13:466->testStripedFileChecksumWithMissedDataBlocksRangeQuery:318->getFileChecksum:602 ? PathIO
[ERROR]   TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14:477->testStripedFileChecksumWithMissedDataBlocksRangeQuery:318->getFileChecksum:602 ? PathIO
[ERROR]   TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15:488->testStripedFileChecksumWithMissedDataBlocksRangeQuery:318->getFileChecksum:602 ? PathIO
[ERROR]   TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17:514->testStripedFileChecksumWithMissedDataBlocksRangeQuery:318->getFileChecksum:602 ? PathIO
[ERROR]   TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19:538->testStripedFileChecksumWithMissedDataBlocksRangeQuery:318->getFileChecksum:602 ? PathIO
[ERROR]   TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2:345->testStripedFileChecksumWithMissedDataBlocksRangeQuery:318->getFileChecksum:602 ? PathIO
[ERROR]   TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20:551->testStripedFileChecksumWithMissedDataBlocksRangeQuery:318->getFileChecksum:602 ? PathIO
[ERROR]   TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery8:411->testStripedFileChecksumWithMissedDataBlocksRangeQuery:318->getFileChecksum:602 ? PathIO
[ERROR]   TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery9:422->testStripedFileChecksumWithMissedDataBlocksRangeQuery:318->getFileChecksum:602 ? PathIO
{noformat}

{quote}I tried the patch in [https://github.com/apache/hadoop/pull/2421/files] but it failed.
{quote}
Thanx [~aajisaka] for trying out, do you mean to say you tried locally applying the patch along with the above PR? Since my changes aren't there in the PR.

I triggered jenkins for the patch [above|https://issues.apache.org/jira/browse/HDFS-15643?focusedCommentId=17223295&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17223295] , and the tests passed :

[https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/276/testReport/org.apache.hadoop.hdfs/TestFileChecksum/]

[https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/276/testReport/org.apache.hadoop.hdfs/TestFileChecksumCompositeCrc/]

 

Thank you [~ayushtkn] for pointing out. I'll try https://issues.apache.org/jira/secure/attachment/13014377/Test-Fix-01.patch

I tried the above patch and the test passed in my docker environment. Thank you [~ayushtkn]

The patch copies the data in memory three times if \{{requestedLen <= toReconstructLen}}:
 * L90 -> L216: Copy from direct byte buffer from bytes[] via getBufferArray()
 * L143 -> L216: Copy from direct byte buffer from bytes[] via getBufferArray()
 * L143: Copy from bytes[] to bytes[] via Arrays.copyOf()

The copy operations may be reduced.

A simple change could be at L143 :
{code:java}
-      outputData = Arrays.copyOf(targetBuffer.array(), remainingLen);
+      outputData = Arrays.copyOf(outputData, remainingLen);
{code}
So, the number should get reduced to 2 for native Encoders, for the non native it would be still 1 only.

To reduce one more copy as well, can refactor the method something like this :

 
{noformat}
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockChecksumReconstructor.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockChecksumReconstructor.java
index b2e64966a18..848d8dee654 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockChecksumReconstructor.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockChecksumReconstructor.java
@@ -86,8 +86,7 @@ public void reconstruct() throws IOException {
         reconstructTargets(toReconstructLen);


         // step3: calculate checksum
-        checksumDataLen += checksumWithTargetOutput(
-            targetBuffer.array(), toReconstructLen);
+        checksumDataLen += checksumWithTargetOutput(toReconstructLen);


         updatePositionInBlock(toReconstructLen);
         requestedLen -= toReconstructLen;
@@ -132,7 +131,7 @@ protected DataOutputBuffer getChecksumWriter() {
     return checksumWriter;
   }


-  private long checksumWithTargetOutput(byte[] outputData, int toReconstructLen)
+  private long checksumWithTargetOutput(int toReconstructLen)
       throws IOException {
     long checksumDataLength = 0;
     // Calculate partial block checksum. There are two cases.
@@ -140,7 +139,7 @@ private long checksumWithTargetOutput(byte[] outputData, int toReconstructLen)
     // case-2) length of data bytes which is less than bytesPerCRC
     if (requestedLen <= toReconstructLen) {
       int remainingLen = Math.toIntExact(requestedLen);
-      outputData = Arrays.copyOf(targetBuffer.array(), remainingLen);
+     byte[] outputData =  getBufferArray(targetBuffer, remainingLen);


       int partialLength = remainingLen % getChecksum().getBytesPerChecksum();


@@ -175,6 +174,7 @@ private long checksumWithTargetOutput(byte[] outputData, int toReconstructLen)
       // calculated checksum for the requested length, return checksum length.
       return checksumDataLength;
     }
+    byte[] outputData = getBufferArray(targetBuffer, targetBuffer.remaining());
     getChecksum().calculateChunkedSums(outputData, 0,
         outputData.length, checksumBuf, 0);


@@ -207,4 +207,18 @@ private void clearBuffers() {
   public long getChecksumDataLen() {
     return checksumDataLen;
   }
-}
+
+  public static byte[] getBufferArray(ByteBuffer targetBuffer,
+      int remainingLen) {
+    byte[] buff = new byte[remainingLen];
+    if (targetBuffer.hasArray()) {
+      buff = targetBuffer.array();
+      if (remainingLen != targetBuffer.remaining()) {
+        Arrays.copyOf(buff, remainingLen);
+      }
+    } else {
+      targetBuffer.slice().get(buff);
+    }
+    return buff;{noformat}
But might be we can go with the first approach, seems little safe, in case of EC if the index gets mixed up in any way, the data gets corrupted. Let me know your thoughts, Will update accordingly

{quote}But might be we can go with the first approach, seems little safe, in case of EC if the index gets mixed up in any way, the data gets corrupted.
{quote}
Agreed. Let's refactor in a separate jira.

[~touchida] told me HDFS-15237 is related to this issue. Link HDFS-15237

Thanx [~aajisaka], I made the change to reduce one copy operation as suggested by you here :

https://github.com/apache/hadoop/pull/2424

{quote}I tried the patch in https://github.com/apache/hadoop/pull/2421/files but it failed.{quote}

I have a little bit bad feeling about that. I suspect there is something else somewhere that needs fixing.

Once, this fix gets merged into trunk, I will close the existing PRs I created. Then open a new one that refactors that Junit test
and improve the cleaning inside "@After" (HDFS-15648)

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime ||  Logfile || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 56s{color} |  | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} || ||
| {color:green}+1{color} | {color:green} dupname {color} | {color:green}  0m  0s{color} |  | {color:green} No case conflicting files found. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} |  | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} |  | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} trunk Compile Tests {color} || ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 24m 15s{color} |  | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 31s{color} |  | {color:green} trunk passed with JDK Ubuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 16s{color} |  | {color:green} trunk passed with JDK Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 44s{color} |  | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 19s{color} |  | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 20m 48s{color} |  | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 21s{color} | [/branch-javadoc-hadoop-hdfs-project_hadoop-hdfs-jdkUbuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1.txt|https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/282/artifact/out/branch-javadoc-hadoop-hdfs-project_hadoop-hdfs-jdkUbuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1.txt] | {color:red} hadoop-hdfs in trunk failed with JDK Ubuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1. {color} |
| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 29s{color} | [/branch-javadoc-hadoop-hdfs-project_hadoop-hdfs-jdkPrivateBuild-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10.txt|https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/282/artifact/out/branch-javadoc-hadoop-hdfs-project_hadoop-hdfs-jdkPrivateBuild-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10.txt] | {color:red} hadoop-hdfs in trunk failed with JDK Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10. {color} |
| {color:blue}0{color} | {color:blue} spotbugs {color} | {color:blue} 22m 10s{color} |  | {color:blue} Used deprecated FindBugs config; considering switching to SpotBugs. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 30s{color} | [/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs.txt|https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/282/artifact/out/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs.txt] | {color:red} hadoop-hdfs in trunk failed. {color} |
|| || || || {color:brown} Patch Compile Tests {color} || ||
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 23s{color} | [/patch-mvninstall-hadoop-hdfs-project_hadoop-hdfs.txt|https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/282/artifact/out/patch-mvninstall-hadoop-hdfs-project_hadoop-hdfs.txt] | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red}  0m 23s{color} | [/patch-compile-hadoop-hdfs-project_hadoop-hdfs-jdkUbuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1.txt|https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/282/artifact/out/patch-compile-hadoop-hdfs-project_hadoop-hdfs-jdkUbuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1.txt] | {color:red} hadoop-hdfs in the patch failed with JDK Ubuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1. {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red}  0m 23s{color} | [/patch-compile-hadoop-hdfs-project_hadoop-hdfs-jdkUbuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1.txt|https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/282/artifact/out/patch-compile-hadoop-hdfs-project_hadoop-hdfs-jdkUbuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1.txt] | {color:red} hadoop-hdfs in the patch failed with JDK Ubuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1. {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red}  0m 23s{color} | [/patch-compile-hadoop-hdfs-project_hadoop-hdfs-jdkPrivateBuild-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10.txt|https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/282/artifact/out/patch-compile-hadoop-hdfs-project_hadoop-hdfs-jdkPrivateBuild-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10.txt] | {color:red} hadoop-hdfs in the patch failed with JDK Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10. {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red}  0m 23s{color} | [/patch-compile-hadoop-hdfs-project_hadoop-hdfs-jdkPrivateBuild-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10.txt|https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/282/artifact/out/patch-compile-hadoop-hdfs-project_hadoop-hdfs-jdkPrivateBuild-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10.txt] | {color:red} hadoop-hdfs in the patch failed with JDK Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10. {color} |
| {color:green}+1{color} | {color:green} blanks {color} | {color:green}  0m  0s{color} |  | {color:green} The patch has no blanks issues. {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 21s{color} | [/buildtool-patch-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt|https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/282/artifact/out/buildtool-patch-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt] | {color:orange} The patch fails to run checkstyle in hadoop-hdfs {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 23s{color} | [/patch-mvnsite-hadoop-hdfs-project_hadoop-hdfs.txt|https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/282/artifact/out/patch-mvnsite-hadoop-hdfs-project_hadoop-hdfs.txt] | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  1m 53s{color} |  | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 10s{color} | [/results-javadoc-javadoc-hadoop-hdfs-project_hadoop-hdfs-jdkUbuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1.txt|https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/282/artifact/out/results-javadoc-javadoc-hadoop-hdfs-project_hadoop-hdfs-jdkUbuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1.txt] | {color:red} hadoop-hdfs-project_hadoop-hdfs-jdkUbuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1 with JDK Ubuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1 generated 99 new + 0 unchanged - 0 fixed = 99 total (was 0) {color} |
| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 34s{color} | [/results-javadoc-javadoc-hadoop-hdfs-project_hadoop-hdfs-jdkPrivateBuild-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10.txt|https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/282/artifact/out/results-javadoc-javadoc-hadoop-hdfs-project_hadoop-hdfs-jdkPrivateBuild-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10.txt] | {color:red} hadoop-hdfs-project_hadoop-hdfs-jdkPrivateBuild-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10 with JDK Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10 generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 46s{color} |  | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} || ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}122m  0s{color} | [/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt|https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/282/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt] | {color:red} hadoop-hdfs in the patch passed. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 34s{color} | [/results-asflicense.txt|https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/282/artifact/out/results-asflicense.txt] | {color:red} The patch generated 19 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}184m 42s{color} |  | {color:black}{color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.viewfs.TestViewFileSystemLinkFallback |
|   | hadoop.hdfs.web.TestWebHDFSAcl |
|   | hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate |
|   | hadoop.hdfs.TestDFSStartupVersions |
|   | hadoop.hdfs.TestGetFileChecksum |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |
|   | hadoop.fs.viewfs.TestViewFileSystemAtHdfsRoot |
|   | hadoop.fs.viewfs.TestNNStartupWhenViewFSOverloadSchemeEnabled |
|   | hadoop.hdfs.tools.TestDFSZKFailoverController |
|   | hadoop.fs.viewfs.TestViewFileSystemWithXAttrs |
|   | hadoop.fs.viewfs.TestViewFileSystemHdfs |
|   | hadoop.hdfs.TestMultipleNNPortQOP |
|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl |
|   | hadoop.fs.viewfs.TestViewFSOverloadSchemeWithMountTableConfigInHDFS |
|   | hadoop.fs.viewfs.TestViewFsLinkFallback |
|   | hadoop.fs.viewfs.TestViewFileSystemLinkRegex |
|   | hadoop.hdfs.TestClientProtocolForPipelineRecovery |
|   | hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA |
|   | hadoop.hdfs.web.TestWebHDFS |
|   | hadoop.fs.viewfs.TestViewFsAtHdfsRoot |
|   | hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes |
|   | hadoop.hdfs.server.datanode.TestDataNodeUUID |
|   | hadoop.hdfs.TestStripedFileAppend |
|   | hadoop.fs.viewfs.TestViewFsWithAcls |
|   | hadoop.fs.viewfs.TestViewFileSystemLinkMergeSlash |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/282/artifact/out/Dockerfile |
| JIRA Issue | HDFS-15643 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/13014427/HDFS-15643-01.patch |
| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient findbugs checkstyle |
| uname | Linux ccdc929a514f 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | personality/hadoop.sh |
| git revision | trunk / 8ee6bc2518bfdf7ad257cc1cf3c73f4208c49fc0 |
| Default Java | Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10 |
| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10 |
|  Test Results | https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/282/testReport/ |
| Max. process+thread count | 4210 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/282/console |
| versions | git=2.17.1 maven=3.6.0 |
| Powered by | Apache Yetus 0.14.0-SNAPSHOT https://yetus.apache.org |


This message was automatically generated.



Though the build failed, but the test passed. :P

[https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/282/testReport/org.apache.hadoop.hdfs/TestFileChecksum/]

 

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime ||  Logfile || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  1m 24s{color} |  | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} || ||
| {color:green}+1{color} | {color:green} dupname {color} | {color:green}  0m  0s{color} |  | {color:green} No case conflicting files found. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} |  | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} |  | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} trunk Compile Tests {color} || ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 36m  7s{color} |  | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 23s{color} |  | {color:green} trunk passed with JDK Ubuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 11s{color} |  | {color:green} trunk passed with JDK Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 45s{color} |  | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 27s{color} |  | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 19m 46s{color} |  | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 57s{color} |  | {color:green} trunk passed with JDK Ubuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 23s{color} |  | {color:green} trunk passed with JDK Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10 {color} |
| {color:blue}0{color} | {color:blue} spotbugs {color} | {color:blue}  3m 23s{color} |  | {color:blue} Used deprecated FindBugs config; considering switching to SpotBugs. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 20s{color} |  | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} || ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 14s{color} |  | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 23s{color} |  | {color:green} the patch passed with JDK Ubuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 23s{color} |  | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 11s{color} |  | {color:green} the patch passed with JDK Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 11s{color} |  | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} blanks {color} | {color:green}  0m  0s{color} |  | {color:green} The patch has no blanks issues. {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 41s{color} |  | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 22s{color} |  | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 20m 22s{color} |  | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  3s{color} |  | {color:green} the patch passed with JDK Ubuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 28s{color} |  | {color:green} the patch passed with JDK Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10 {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 58s{color} |  | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} || ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}129m 28s{color} | [/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt|https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/283/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt] | {color:red} hadoop-hdfs in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 46s{color} |  | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}228m 55s{color} |  | {color:black}{color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.TestMultipleNNPortQOP |
|   | hadoop.hdfs.server.balancer.TestBalancerRPCDelay |
|   | hadoop.hdfs.server.datanode.TestBPOfferService |
|   | hadoop.hdfs.TestGetFileChecksum |
|   | hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/283/artifact/out/Dockerfile |
| JIRA Issue | HDFS-15643 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/13014427/HDFS-15643-01.patch |
| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient findbugs checkstyle |
| uname | Linux 406a7a924495 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | personality/hadoop.sh |
| git revision | trunk / c47c9fd65d835fc53c9eef59a05b97335b04e320 |
| Default Java | Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10 |
| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.9+11-Ubuntu-0ubuntu1.18.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_272-8u272-b10-0ubuntu1~18.04-b10 |
|  Test Results | https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/283/testReport/ |
| Max. process+thread count | 3052 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/283/console |
| versions | git=2.17.1 maven=3.6.0 findbugs=4.1.3 |
| Powered by | Apache Yetus 0.14.0-SNAPSHOT https://yetus.apache.org |


This message was automatically generated.



Thank you [~ayushtkn] for the progress done on this jira.
Is there any thing can be done for all those OOM on Yetus?
I sent an email on hadoop mailing list, but this problem is there for so long.


Thank you [~ayushtkn] for the progress done on that Jira.
Is there something that can be done for the OOM errors on Yetus? It has been there for few months.
I sent an email on the mailing list sometime ago to give heads-up.
I wonder if there is a recent commit that caused leak in native memory.

Committed to trunk, branch-3.3,3.2,3.1

Thanx Everyone!!!

{quote}Is there something that can be done for the OOM errors on Yetus? It has been there for few months.
{quote}
If we are sure it isn't because of some leak in native memory, then we can raise an INFRA Jira and ask the folks to figure out things.

But I don't deny the fact, it can be due to some faulty test causing issue, IIRC couple of months back there was a Jira which led to such a situation.

Thanks [~ayushtkn] and [~ahussein] for your works. Backport to branch-3.2.2.

