if this is impacting 4.0 as well we should add 4.0.x to fix version; not confirmed though

have a patch which replicates the problem and found several other issues as well.  This issue only triggers disk policy for zero-copy-streaming but the error handling in streaming also was causing issues as it wouldn't properly close the session; leaving it hanging...

To show that the test actually detects the issue, remove the core of the patch which fixes the issue

{code}
git checkout trunk src/java/org/apache/cassandra/db/streaming test/unit/org/apache/cassandra/io/sstable/format/big/BigTableZeroCopyWriterTest.java src/java/org/apache/cassandra/io/sstable/format/big/BigTableZeroCopyWriter.java
{code}

patch breaks streaming in python dtest; nice!

trying to debug why org.apache.cassandra.distributed.test.ring.BootstrapTest is flaky.  It seems that it times out on Cluster.close, and only happens for a single test sometimes... trying to look to see if I can get more insights into why this happens.

now that I don't try to hide channel close, it seems that python dtest is failing as the logs show the exception.  What is weird to me is that this happens in the happy path as well, so not sure how things were "success" if the session fails due to channel close... 

I am trying to look closer at the streaming code, and I think there is a race condition

{code}
// only part of the code which sends COMPLETE
channel.sendControlMessage(new CompleteMessage());
closeSession(State.COMPLETE);
{code}

There is a concept of a control message, which is its own channel.  This means we have 2 channels: control, data (don't know better name); we close data after sending COMPLETE on control, but there is nothing in place to make sure the followers don't see the channel closed BEFORE seeing COMPLETE...

cool, by trying to write CompleteMessage on the outbound channel (to avoid the race condition issue) LegacySSTableTest starts to fail with 

{code}
ERROR [Reference-Reaper] 2021-11-16 15:55:07,656 LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@637953b7) to class org.apache.cassandra.io.sstable.format.SSTableReader$InstanceTidier@1459220591:/Users/davidcapwell/src/github/apache/cassandra/trunk/test/data/legacy-sstables/nb/legacy_tables/legacy_nb_simple/nb-1-big was not released b
efore the reference was garbage collected
ERROR [Reference-Reaper] 2021-11-16 15:55:07,657 Allocate trace org.apache.cassandra.utils.concurrent.Ref$State@637953b7:
Thread[main,5,main]
        at java.lang.Thread.getStackTrace(Thread.java:1559)
        at org.apache.cassandra.utils.concurrent.Ref$Debug.<init>(Ref.java:248)
        at org.apache.cassandra.utils.concurrent.Ref$State.<init>(Ref.java:178)
        at org.apache.cassandra.utils.concurrent.Ref.<init>(Ref.java:100)
        at org.apache.cassandra.io.sstable.format.SSTableReader.<init>(SSTableReader.java:679)
        at org.apache.cassandra.io.sstable.format.SSTableReader.<init>(SSTableReader.java:643)
        at org.apache.cassandra.io.sstable.format.big.BigTableReader.<init>(BigTableReader.java:57)
        at org.apache.cassandra.io.sstable.format.big.BigFormat$ReaderFactory.open(BigFormat.java:103)
        at org.apache.cassandra.io.sstable.format.SSTableReaderBuilder$ForRead.build(SSTableReaderBuilder.java:370)
        at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:510)
        at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:381)
        at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:376)
        at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:371)
        at org.apache.cassandra.io.sstable.LegacySSTableTest.streamLegacyTable(LegacySSTableTest.java:425)
        at org.apache.cassandra.io.sstable.LegacySSTableTest.streamLegacyTables(LegacySSTableTest.java:416)
        at org.apache.cassandra.io.sstable.LegacySSTableTest.testStreamLegacyCqlTables(LegacySSTableTest.java:301)
{code}

and

{code}
DEBUG [main] 2021-11-16 15:55:14,453 Got exception trying to acquire sstables
org.apache.cassandra.db.repair.PendingAntiCompaction$SSTableAcquisitionException: Prepare phase failed because it encountered legacy sstables that don't support pending repair, run upgradesstables before starting incremental repairs, repair session (a4751540-4738-11ec-8f0a-09f160ae1e48)
        at org.apache.cassandra.db.repair.PendingAntiCompaction$AntiCompactionPredicate.apply(PendingAntiCompaction.java:132)
        at org.apache.cassandra.db.repair.PendingAntiCompaction$AntiCompactionPredicate.apply(PendingAntiCompaction.java:104)
        at com.google.common.base.Predicate.test(Predicate.java:79)
        at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:174)
        at java.util.Iterator.forEachRemaining(Iterator.java:116)
        at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
        at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
        at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
        at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
        at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566)
        at org.apache.cassandra.db.repair.PendingAntiCompaction$AcquisitionCallable.acquireTuple(PendingAntiCompaction.java:198)
        at org.apache.cassandra.db.ColumnFamilyStore.runWithCompactionsDisabled(ColumnFamilyStore.java:2447)
        at org.apache.cassandra.db.repair.PendingAntiCompaction$AcquisitionCallable.call(PendingAntiCompaction.java:234)
        at org.apache.cassandra.io.sstable.LegacySSTableTest.testPendingAntiCompactionOldSSTables(LegacySSTableTest.java:373)
{code}

I don't grasp how this patch breaks it o_O

In talking with [~djoshi] this is the following feedback

* from an API point of view we do not know if the FileChannel or the SocketChannel is closed; FileChannel implies race condition bug where as socket channel may be just "network hates us".  Based off stack trace we know this case is network close.
* when we send COMPLETE we also shutdown the channels, this doesn't give the followers enough time to consistently handle this; the feedback was to extend the state machine to have a COMPLETE_ACK (to attempt backwards compatibility, if we timeout and the channel is closed, assume the closed channel is an ACK (current behavior))
* "streaming doesn't support backwards compatibility" - me: "I have been called into prod to support repair in mixed mode... so lets try ^_^"

I think with the introduction of {{COMPLETE_ACK}}, we would need to also introduce a timeout after the {{COMPLETE}} message is transmitted but before the sender closes the Channel. This would give the receiving peer time to consume all the data and the {{COMPLETE}} message. This would not only solve the issue but also be backward compatible as we could send {{COMPLETE_ACK}} to peers that support the message and not to other peers.

Also didn't bother debugging but feel the bootstrap timeout tests (see https://app.circleci.com/pipelines/github/dcapwell/cassandra/1129/workflows/43d3d109-58a5-42ac-846a-1eca0e9233ed/jobs/8175) are caused by this bug.  when the streams are in limbo jvm-dtest waits for them

did the POC, possible I messed everything up, but it doesn't solve anything; fails the same way...  going to do something simpler and see about just delaying close and see what happens.

delaying the close base off stream timeout seems to be more stable...

[~jasonstack] [~sbtourist] would love your feedback on how to deal with this.  Started down this rabbit hole trying to fix a flaky test, but do not know streaming well enough.

I wonder if the answer here is to instead set some state such that the ZCS code can catch the exception and check "was this streaming op canceled?" and if so not trigger the disk failure?

bq. ZCS code can catch the exception and check "was this streaming op canceled?"

We do this right now in the patch.   I moved the closed exception to no longer be re-thrown as a FSWriteError, this bubbles up to the top which notifies the session.onError method; I updated this method to special case this the same way EOF was special cased.  This works fine if we do not hit the COMPLETE/close race condition, if we see COMPLETE first we log a debug message, if we see close first we fail the stream.

I took a look at this as well, and it seems that the follower keeps track of the number of {{RECEIVED}} messages it expects and the number of received messages it has seen. Only when the follower has seen all the {{RECEIVED}} messages it expects to see, will the follower initiate the {{COMPLETE}} message, and close the connections.

It looks like the initiator is sending back the received message before actually receiving the stream. The code sits in {{org.apache.cassandra.streaming.StreamSesssion.receive(IncomingStreamMessage)}}. We can see that the control message is being sent and then the receiver receives the stream.

A potential solution to the race is delaying the sending of the {{RECEIVED}} message right after the stream has been consumed (maybe in the finally block of the {{receive}} method).

Unfortunately, I have not found a good way to reproduce the issue, so I don't know if that will be sufficient to resolve the race issue. Maybe if [~dcapwell] can try it, or give me some guidance on how to repro the issue, I can take a look into it further. 

[~djoshi] and I took another look at this, it seems that the race is happening in {{org.apache.cassandra.streaming.StreamSession#maybeCompleted()}}. 

The race is most likely happening in the code block below.

{code:java}
    channel.sendControlMessage(new CompleteMessage());
    closeSession(State.COMPLETE);
{code}

The {{channel.sendControlMessage}} call returns a future and we immediately close the session without waiting for the future to execute. In the majority of cases, the message will be delivered on time,
Network delays/system load/thread scheduling can cause the {{CompleteMessage}} to be sent/received after the session has been closed triggering the {{java.nio.channels.ClosedChannelException}}.

A potential solution is to add a listener for the future, and only then close the session.

{code:java}
    Future<?> messageFuture = channel.sendControlMessage(new CompleteMessage());
    messageFuture.addListener(f -> closeSession(State.COMPLETE));
{code}

I like the listener way... seems clean if it works

{code}
Future<?> messageFuture = channel.sendControlMessage(new CompleteMessage());
messageFuture.addListener(f -> closeSession(State.COMPLETE));
{code}

I can try adding the listener to my patch and run through CI to see if anything keeps failing... can keep triggering python dtests

Great, let me know when you trigger CI. I can take a look and hopefully it solves the race condition.

rebased and push the change to my branch

heh. https://app.circleci.com/pipelines/github/dcapwell/cassandra/1150/workflows/e1f0b429-c024-4b3e-8e97-07669f60996a/jobs/8438

test_preview - repair_tests.preview_repair_test.TestPreviewRepair

{code}
test teardown failure
Unexpected error found in node logs (see stdout for full details). Errors: [ERROR [Stream-Deserializer-/127.0.0.1:7000-e3a2ecc2] 2022-01-06 02:26:28,485 StreamSession.java:650 - [Stream #0d9ed480-6e98-11ec-91be-5f7fa67bb742] Socket closed before session completion, peer 127.0.0.1:7000 is probably down.
java.nio.channels.ClosedChannelException: null
	at org.apache.cassandra.net.AsyncStreamingInputPlus.reBuffer(AsyncStreamingInputPlus.java:136)
	at org.apache.cassandra.io.util.RebufferingInputStream.readByte(RebufferingInputStream.java:178)
	at org.apache.cassandra.streaming.messages.StreamMessage.deserialize(StreamMessage.java:49)
	at org.apache.cassandra.streaming.StreamDeserializingTask.run(StreamDeserializingTask.java:59)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834), ERROR [Stream-Deserializer-/127.0.0.1:7000-e3a2ecc2] 2022-01-06 02:26:28,485 StreamSession.java:650 - [Stream #0d9ed480-6e98-11ec-91be-5f7fa67bb742] Socket closed before session completion, peer 127.0.0.1:7000 is probably down.
java.nio.channels.ClosedChannelException: null
	at org.apache.cassandra.net.AsyncStreamingInputPlus.reBuffer(AsyncStreamingInputPlus.java:136)
	at org.apache.cassandra.io.util.RebufferingInputStream.readByte(RebufferingInputStream.java:178)
	at org.apache.cassandra.streaming.messages.StreamMessage.deserialize(StreamMessage.java:49)
	at org.apache.cassandra.streaming.StreamDeserializingTask.run(StreamDeserializingTask.java:59)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)]
{code}

{code}
boolean isEofException = e instanceof EOFException || e instanceof ClosedChannelException;
        if (isEofException)
        {
            if (state.finalState)
            {
                logger.debug("[Stream #{}] Socket closed after session completed with state {}", planId(), state);

                return null;
            }
            else
            {
                logger.error("[Stream #{}] Socket closed before session completion, peer {} is probably down.",
                             planId(),
                             peer.getHostAddressAndPort(),
                             e);

                return closeSession(State.FAILED);
            }
        }
{code}

so closing after the write future notifies, we still see the issue.  [~djoshi] [~frankgh]

after looking closer with [~frankgh] it looks like this is a race condition issue in how we close connections, trying to figure out where.

I see that adding a 10s sleep causes us to give enough time for the follower to send COMPLETE and close, and without that it some times works and some times doesn't; the fun behavior is we see COMPLETE isn't sent from the follower, yet the initiator closes the session as complete!

I think we finally found the issue!  When the follower sends the last msg, there is a race condition as we do the following

{code}
send(lastMessage);
// with bad OS scheduling issues, this may happen AFTER the initiator closes the socket
closeSession(COMPLETE);
{code}

if the OS scheduler runs the closeSession(COMPLETE) logic AFTER getting the socket close msg from initiator, then the socket will be closed and cause the ClosedChannelException, and since the state isn't final we fail the session...

To fix this, moved end messages to the following pattern

{code}
setState(WAIT_COMPLETE);
setState(COMPLETE);
send(lastMessage);
closeSession(COMPLETE);
{code}

Relative to trunk, it looks like CI is finally green!  

Trunk: https://app.circleci.com/pipelines/github/dcapwell/cassandra/1163/workflows/17e71cd2-1e9c-48db-bde4-63a290a90499
Patch: https://app.circleci.com/pipelines/github/dcapwell/cassandra/1162/workflows/c22e4720-bbd0-4a0a-bc9b-2e99d7b0c5b6

Going to do one more round of cleanup, but think ready for review

I have a small commit for {{cassandra-dtest}} for new expected output in the logs of one of the tests:

https://github.com/apache/cassandra-dtest/pull/172

Made a first pass at the [trunk PR|https://github.com/apache/cassandra/pull/1301] and left some minor comments. I still want to look at the new {{StreamCloseInMiddleTest}} one more time though...

+1

[~djoshi] approved in GH, so 2 +1s

Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-17116-trunk-9F17D44F-1990-4FA1-B04B-B908D0533DF7]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-17116-trunk-9F17D44F-1990-4FA1-B04B-B908D0533DF7]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1398/]|


Aborted commit due to change in AbstractCluster breaking a few upgrade tests.  Also found out that some upgrade tests don't actually test against trunk... so fixing...

pushed changes to fix the upgrade test issues

{code}
commit 1a43be88a433307c47521e3d890687bf784f4e1f (HEAD -> CASSANDRA-17116, origin/CASSANDRA-17116)
Author: David Capwell <dcapwell@apache.org>
Date:   Thu Feb 3 17:58:08 2022 -0800

    fixed it so singleUpgrade no longer takes to, as that allows us to not test against CURRENT

test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeGossipTest.java
test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeMessageForwardTest.java
test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeReadTest.java
test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeRepairTest.java
test/distributed/org/apache/cassandra/distributed/upgrade/Pre40MessageFilterTest.java
test/distributed/org/apache/cassandra/distributed/upgrade/UpgradeTestBase.java

commit 9dcdb1448284f4bd259b144a49e4b9e37408bda3
Author: David Capwell <dcapwell@apache.org>
Date:   Thu Feb 3 17:51:04 2022 -0800

    only clear delegate if it shutdown or if address changed, no other reason

test/distributed/org/apache/cassandra/distributed/impl/AbstractCluster.java
{code}

Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-17116-trunk-04BC233C-9090-4A35-8909-4BC19A3667EF]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-17116-trunk-04BC233C-9090-4A35-8909-4BC19A3667EF]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1404/]|


Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-17116-trunk-D65E87A1-597B-4BC8-A340-DA5754F5625C]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-17116-trunk-D65E87A1-597B-4BC8-A340-DA5754F5625C]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1405/]|


