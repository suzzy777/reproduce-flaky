The tests actually already account for the eventual consistency of the filter propagation, they include a call to `awaitRemove()` which is empty for most implementations and is defined as 
{code:java}
@Override
public void awaitRemove() {
    try {
        Thread.sleep(100);
    } catch (InterruptedException e) {
        throw new RuntimeException(e);
    }
} {code}
in PulsarMailqueueTest

 

What likely happens is that 100ms is too little for the CI plateform, there are 2 options:

- change all the assertions on remove to use awaitility
- increase the wait time (if possible only on CI, we could try to resolve the CI env variable and conditionnaly have a larger wait time)

awaitility won't cut it as "if the mail is dequeued prior the filter applies" we won't converge to the desired time.

I agree increasing wait time. 100ms seems optimistic. 500ms would seems great to me.

>  (if possible only on CI, we could try to resolve the CI env variable and conditionnaly have a larger wait time)

This makes build profiles harder to grasp, issues harder to reproduce. Could also be seen as an entry barreer to people running the build for the first time on slow environments.




> This makes build profiles harder to grasp, issues harder to reproduce. Could also be seen as an entry barreer to people running the build for the first time on slow environments.

As long as we use a constant increase factor shared in all tests and applied to all static wait times, it shouldn't affect the build profile. On the other hand, don't you think the current build time of James is also a barrier to entry (IIRC a full build is somewhere around 2h30, I don't even try to run it anymore since it's so slow) ? 

Static wait times mean slower tests *everywhere* ,  tests slower than they need to be on developpers machine means wasted human time :( 

 

