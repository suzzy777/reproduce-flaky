User 'zsxwing' has created a pull request for this issue:
https://github.com/apache/spark/pull/3889

This was merged in https://github.com/apache/spark/commit/5c506cecb933b156b2f06a688ee08c4347bf0d47

Reopening because this is still flaky:

https://amplab.cs.berkeley.edu/jenkins/job/Spark-Master-SBT/AMPLAB_JENKINS_BUILD_PROFILE=hadoop2.0,label=centos/1771/
https://amplab.cs.berkeley.edu/jenkins/job/Spark-Master-SBT/AMPLAB_JENKINS_BUILD_PROFILE=hadoop2.0,label=centos/1770/
https://amplab.cs.berkeley.edu/jenkins/job/Spark-Master-SBT/AMPLAB_JENKINS_BUILD_PROFILE=hadoop2.0,label=centos/1761/
https://amplab.cs.berkeley.edu/jenkins/job/Spark-Master-SBT/AMPLAB_JENKINS_BUILD_PROFILE=hadoop2.0,label=centos/1754/

{code}
"...e to stage failure: [Task serialization failed: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:101) org.apache.spark.SparkContext.broadcast(SparkContext.scala:1037) org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks(DAGScheduler.scala:839) org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$submitStage(DAGScheduler.scala:778) org.apache.spark.scheduler.DAGScheduler$$anonfun$resubmitFailedStages$3.apply(DAGScheduler.scala:590) org.apache.spark.scheduler.DAGScheduler$$anonfun$resubmitFailedStages$3.apply(DAGScheduler.scala:589) scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33) scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108) org.apache.spark.scheduler.DAGScheduler.resubmitFailedStages(DAGScheduler.scala:589) org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1396) org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1354) org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48) ]" did not equal "...e to stage failure: [Exception failure in map stage]"
{code}

User 'zsxwing' has created a pull request for this issue:
https://github.com/apache/spark/pull/5903

Issue resolved by pull request 5903
[https://github.com/apache/spark/pull/5903]

