[~ashutoshc] [~poeppt] [~stakiar] What do you think about this change? We have found this variable name a little confusing because it is a Hadoop-specific variable, and the Utilities is used just for Hive. The new and old variable will do the same thing during Hive 2.x.

From what I can tell, saying
bq. These methods are Hive related
isn't exactly true. 

I agree that the configuration value name is confusing, mainly because of the inclusion of {{mapred}} (we support Tez too, right? ;) ). But it seems like the dfsclient (HDFS, S3a, etc) should actually have some level of control over the number of threads being used to access it. What if we have some {{FileSystem}} implementation that, for some reason, is non-threadsafe? It should be able to limit threads. Renaming the config to something like {{hive.get.input.listing.num.threads}} can hide what's _really_ happening here, which would be the dfsclient controlling its maximum allowable number of parallel accessors on its own.

That being said, I can't find a link in open source Hadoop to this configuration value. Can you link it here? If it is actually only used by Hive across the entire Hadoop ecosystem, then I have no problem doing what you suggest. I just have a hard time believing that's the case.

As far as I can tell, this config *is only used by Hive* across the entire Hadoop ecosystem.

The only reference I have found to it is here: https://github.com/facebookarchive/hadoop-20/blob/master/src/mapred/org/apache/hadoop/mapred/FileInputFormat.java - but this seems to be an archived version of a Facebook specific version of Hadoop. I've checked Hadoop trunk a few times and have found no reference to this config. Even in old commits to trunk, I see no reference to this config.

It was originally added in HIVE-2051 by [~sdong].

Spent a little more time looking into this, found the same thing as Sahil. I would like to suggest some edits:

I would change the naming of the variable. As I said above, {{hive.get.input.listing.num.threads}} isn't exactly clear, and because this is used for two things ({{getInputSummary}} and {{getInputPaths}}) I would like to propose a different way of doing this.

* Two configuration values, one for each usage:
** {{hive.exec.input.paths.num.threads}} for {{getInputPaths}}
** {{hive.exec.input.summary.num.threads}} for {{getInputSummary}}
* Bonus is that these follow existing {{HiveConf}} patterns

Other questions that should be asked:
* what is the default value? 
** I'm looking through {{HiveConf}}, but not seeing any other config value that might suffice. Maybe we just use 1?

Also, I'm a fan of '0' meaning 'maximum number allowable' with these types of config values, but that can be up for discussion. We would need a way to figure out what "max allowable" actually _means_, either through another configuration value or based on the OS structure? I don't know.

I think for Utilities#getInputSummary the property name should be "hive.exec.input.summary.max.threads", to be consistent with other properties in HiveConf. This value is not used as is to create a thread pool, it is only an upper limit for the thread pool size. If number of input paths is less than hive.exec.input.summary.max.threads it will be used instead. It means the actual number of threads will be <= hive.exec.input.summary.max.threads.

Thanks guys for giving more ideas. [~etf] I like that idea of the "max.threads" option. I will implement it in that way to avoid creating a threadpool with more threads than the number of input locations.

[~poeppt] I like those names better. I wonder if we should have 1 variable config for both instead of one per method. Don't you guys get messy with too many configurations variables for the number of threads?

[~spena] Good point. To take into account everyone's ideas, maybe something like {{hive.exec.input.listing.max.threads}}? It's tough, but I'm not sure there will be one obvious best answer, I think each one will have pros and cons compared to any other. 

Agree with [~yalovyyi]'s suggestion as well. What would we want default to be? Looking through {{HiveConf}}, the different {{*.max.threads}} values are:
* {{METASTORESERVERMAXTHREADS("hive.metastore.server.max.threads", 1000,}}
* {{HIVE_SERVER2_WEBUI_MAX_THREADS("hive.server2.webui.max.threads", 50, "The max HiveServer2 WebUI threads"),}}
* {{LLAP_DAEMON_AM_REPORTER_MAX_THREADS("hive.llap.daemon.am-reporter.max.threads", 4,}}

So.. all over the place. How would we decide on a suitable default? Or maybe, the default is "as many as possible" and it can be lowered by users themselves?

Great, thanks for the suggestions. [~poeppt] Although I like your idea of the 'maximum number allowable' using 0, I think we should continue using the 0 as using only one thread for the work. The rest of the configuration variables for threads use 0 to disable the use of threads. Let's keep it consistent.

I will submit a patch with the following:
- New variable name {{hive.exec.input.listing.max.threads}} for getInputSummary and getInputPaths
- Mark {{mapred.dfsclient.parallelism.max}} as deprecated, but continue using it.
- Default the value for {{hive.exec.input.listing.max.threads}} to 0 (no threads or just one thread). I think we should keep it disable because
  on HDFS there's no benefit of using threads, and we can multiple RPC connections with the namenode.

[~stakiar] [~poeppt] [~etf] [~ashutoshc] Coul you review the patch?



Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12852686/HIVE-15881.1.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 8 failed/errored test(s), 10238 tests executed
*Failed tests:*
{noformat}
TestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cbo_rp_auto_join1] (batchId=3)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[join31] (batchId=81)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[multiMapJoin2] (batchId=152)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=223)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join31] (batchId=133)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3558/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3558/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3558/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 8 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12852686 - PreCommit-HIVE-Build

[~poeppt] I attached a new patch here and on RB addressing your comments.

Hey [~spena], updated the RB. Just one question, otherwise non-binding +1 pending QA 



Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12853804/HIVE-15881.2.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 16 failed/errored test(s), 10252 tests executed
*Failed tests:*
{noformat}
TestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=223)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[auto_sortmerge_join_14] (batchId=100)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[auto_sortmerge_join_15] (batchId=100)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[bucket_map_join_tez2] (batchId=100)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[bucketmapjoin8] (batchId=100)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[groupby5_map_skew] (batchId=100)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join_reorder] (batchId=100)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[sample1] (batchId=100)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt4] (batchId=106)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union10] (batchId=100)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union34] (batchId=100)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_count_distinct] (batchId=106)
org.apache.hive.beeline.TestBeeLineWithArgs.testQueryProgress (batchId=211)
org.apache.hive.beeline.TestBeeLineWithArgs.testQueryProgressParallel (batchId=211)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3677/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3677/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3677/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 16 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12853804 - PreCommit-HIVE-Build



Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12853997/HIVE-15881.3.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 10253 tests executed
*Failed tests:*
{noformat}
TestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=223)
org.apache.hive.beeline.TestBeeLineWithArgs.testQueryProgress (batchId=211)
org.apache.hive.beeline.TestBeeLineWithArgs.testQueryProgressParallel (batchId=211)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3698/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3698/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3698/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12853997 - PreCommit-HIVE-Build

PATCH 3 looks good.  +1
Please make sure the test failures are not related.

New patch that added a new unit tests & use SizeValidator on the HiveConf variable to limit the number of threads (min: 0, max: 1024)



Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12854267/HIVE-15881.5.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3774/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3774/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3774/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'
2017-02-25 07:26:29.532
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'MAVEN_OPTS=-Xmx1g '
+ MAVEN_OPTS='-Xmx1g '
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-3774/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date '+%Y-%m-%d %T.%3N'
2017-02-25 07:26:29.534
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 2f6f6bd HIVE-15951 : Make sure base persist directory is unique and deleted (Slim Bouguerra via Ashutosh Chauhan)
+ git clean -f -d
+ git checkout master
Already on 'master'
Your branch is up-to-date with 'origin/master'.
+ git reset --hard origin/master
HEAD is now at 2f6f6bd HIVE-15951 : Make sure base persist directory is unique and deleted (Slim Bouguerra via Ashutosh Chauhan)
+ git merge --ff-only origin/master
Already up-to-date.
+ date '+%Y-%m-%d %T.%3N'
2017-02-25 07:26:33.301
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
error: a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java: No such file or directory
error: a/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java: No such file or directory
error: a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestUtilities.java: No such file or directory
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12854267 - PreCommit-HIVE-Build

Patch rebased.



Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12854812/HIVE-15881.6.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 10268 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=140)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)
org.apache.hive.beeline.TestBeeLineWithArgs.testQueryProgress (batchId=211)
org.apache.hive.jdbc.TestJdbcDriver2.testSelectExecAsync2 (batchId=215)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3803/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3803/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3803/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12854812 - PreCommit-HIVE-Build

Thanks [~poeppt] [~yalovyyi] [~stakiar] [~ychena] for your review. I committed this to master. Tests are not related and they are already reported as flaky.

Doc note:  This adds *hive.exec.input.listing.max.threads* to HiveConf.java, so it needs to be documented in the wiki.  See HIVE-14270 and HIVE-15121 for other blobstore configs.

* [Hive Configuration Properties | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties]

Added a TODOC2.2 label.

[~leftylev] I added a few configurations on the wiki used for blobstore.
[https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-Blobstore(i.e.AmazonS3)]

Thanks for the documentation, Sergio.  Here's a link to *hive.exec.input.listing.max.threads*:

* [Configuration Properties -- hive.exec.input.listing.max.threads | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.exec.input.listing.max.threads]

Removing the TODOC2.2 label.

