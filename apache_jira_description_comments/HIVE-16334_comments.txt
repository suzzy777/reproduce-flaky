Introduce a new configuration change which defines the max query string length in the lock objects

Review board created: https://reviews.apache.org/r/58086/

Why does the query string need to be written to ZK in the first place? Wouldn't it be sufficient to just use some query-id.



Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12861288/HIVE-16334.patch

{color:green}SUCCESS:{color} +1 due to 4 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 10541 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[comments] (batchId=35)
org.apache.hive.hcatalog.api.TestHCatClient.testTransportFailure (batchId=172)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/4468/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/4468/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4468/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12861288 - PreCommit-HIVE-Build

+1 https://issues.apache.org/jira/browse/HIVE-16334?focusedCommentId=15949585&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15949585

Thanks for the reviews [~stakiar], [~ekoifman]!

@sahil: The user can query the detailed lock information by the {{show locks customers extended;}}
It will output this:
{code}
+----------------------------------------------------+---------+--+
|                      tab_name                      |  mode   |
+----------------------------------------------------+---------+--+
| default@customers                                  | SHARED  |
| LOCK_QUERYID:hive_20170331023232_0a132ae3-d304-4b29-950f-68dce115bb9a | NULL    |
| LOCK_TIME:1490952750561                            | NULL    |
| LOCK_MODE:IMPLICIT                                 | NULL    |
| LOCK_QUERYSTRING:select * from customers c1 join customers c2 on c1.id=c2.id | NULL    |
+----------------------------------------------------+---------+--+
{code}

This helps the user to understand why is the table locked. I think it is good to have the possibility to print the actual query string, but truncate it. What do you think?

Peter

[~pvary] yes its good to display the actual query when running {{show locks ...}} but the full query string should already be stored in HS2, right? So there shouldn't be a reason to store the same query string inside Zookeeper. Hive should just store the query-id in ZK, and then use the query-id to do a lookup of the full query string in HS2. This should reduce a lot of memory pressure on ZK nodes.

[~stakiar]: I considered the following things:
- The query is stored in HS2, but the locks should be displayed on every client even when HS2 is in HA. So if we want to keep the query string in a shared database, or another ZooKeeper node next to the lock.
- Since the query string is read by humans, I do not think that it is worth to display a string which is longer than 1000 chars.

ZooKeeper scales fairly well if we limit the size of the nodes, so considering the points above I think it might not worth the complexity to externalize the query string from the locks.

What do you think? Did I miss some important point?

Thanks for the review!
Peter

[~pvary]

{quote}
The query is stored in HS2, but the locks should be displayed on every client even when HS2 is in HA. So if we want to keep the query string in a shared database, or another ZooKeeper node next to the lock.
{quote}

I'm not super familiar with HS2 HA so thats entirely possible. However, there should be ways to get around that. I would hope that HA supports {{TCLIService.GetOperationStatus}}, which should return the query string given the operation id.

{quote}
Since the query string is read by humans, I do not think that it is worth to display a string which is longer than 1000 chars.
{quote}

Thats probably true, but I can think of a few caveats: (1) {{show locks}} could be read via JDBC and its output parsed by some Java code, (2) in production clusters, there are often several queries that are very long and very similar except for a few changes to constant values.

{quote}
ZooKeeper scales fairly well if we limit the size of the nodes, so considering the points above I think it might not worth the complexity to externalize the query string from the locks.
{quote}

I think there are some caveats: (1) ZK isn't really designed to store massive Hive query strings, (2) in production clusters, ZK may be shared amongst multiple distributed systems (HBase, Kafka, etc.), (2) ZK does scale well in some ways, but in terms of memory usage it is limited to the RAM of a single machine. IMO the less load on ZK the better.

That being said. I still think your approach is a good improvement. All the points above can be considered as follow up items. I'll take a look at your RB.

A few more things to think about:
* The description of this JIRA mentions that when there are a high number of partitions, there can be increased load on ZK. Does that mean the lock for each partition is storing a separate copy of the query string? If so, we should definitely fix that - use a reference to the same query string, used string interning
* If there was an OOM in ZK, it would be nice to get a heap dump so we can analyze it using standard analysis tools

Patch addressing the review board comments.

Followup jira is created for not storing the query string, or storing it only once: HIVE-16382

Query strings are already interned, so we are good here :):
https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/HiveLockObject.java#L59
https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/HiveLockObject.java#L78

Unfortunately I do not have a dump, but the user is fairly sure, that the locks caused the problem.

Thanks for the reviews!

Peter



Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12862116/HIVE-16334.2.patch

{color:green}SUCCESS:{color} +1 due to 4 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 10578 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[drop_with_concurrency] (batchId=234)
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[escape_comments] (batchId=234)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=142)
org.apache.hive.jdbc.TestJdbcDriver2.testResultSetMetaData (batchId=220)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/4561/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/4561/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4561/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12862116 - PreCommit-HIVE-Build

The test errors are not related:
- HIVE-15776 - Flaky test: TestMiniLlapLocalCliDriver vector_if_expr
- HIVE-16345 - Will solve the problems with the 2 TestBeeLineDriver errors
- HIVE-16381 - Flaky test: org.apache.hive.jdbc.TestJdbcDriver2.testResultSetMetaData

Thanks,
Peter

Resetting the default value in configuration before testing the truncation, to avoid future flakiness

Changed the default value from Integer.MAX_VALUE to 1000000, so it aligns better with the data limit of a znode, which is 1MB

LGTM, +1



Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12862323/HIVE-16334.4.patch

{color:green}SUCCESS:{color} +1 due to 4 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 10580 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[drop_with_concurrency] (batchId=235)
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[escape_comments] (batchId=235)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=143)
org.apache.hive.jdbc.TestJdbcDriver2.testResultSetMetaData (batchId=221)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/4588/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/4588/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4588/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12862323 - PreCommit-HIVE-Build



Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12862323/HIVE-16334.4.patch

{color:green}SUCCESS:{color} +1 due to 4 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 10576 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[drop_with_concurrency] (batchId=235)
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[escape_comments] (batchId=235)
org.apache.hadoop.hive.cli.TestSparkNegativeCliDriver.org.apache.hadoop.hive.cli.TestSparkNegativeCliDriver (batchId=237)
org.apache.hive.jdbc.TestJdbcDriver2.testResultSetMetaData (batchId=221)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/4597/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/4597/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4597/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12862323 - PreCommit-HIVE-Build

The failed tests are not related:
- TestBeeLineDriver error will be solved with HIVE-16345
- HIVE-16405 - Flaky Test: org.apache.hive.jdbc.TestJdbcDriver2.testResultSetMetaData
- HIVE-15165 - Flaky test: TestSparkNegativeCliDriver

I think the patch is ready to commit.

Thanks,
Peter

Committed to 3.0.0. Thanks [~pvary] for the patch. I think you may need to update the document for the new property.

Thanks for the commit [~ctang.ma]!
Updated the document, added the new property.

Hive 3.0.0 has been released so closing this jira.

