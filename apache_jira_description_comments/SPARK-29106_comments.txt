I changed the affected version to 3.0.0 because this is a new feature at testing and it seems that there is only `master` branch testing.
- http://status.openlabtesting.org/builds?project=apache/spark

[~dongjoon], thanks :)

Till now we made two arm test periodic jobs for spark in OpenLab, one is based on master with hadoop 2.7(similar with QA test of amplab jenkins), other one is based on a new branch which we made on date 09-09, see  [http://status.openlabtesting.org/builds/job/spark-master-unit-test-hadoop-2.7-arm64]  and [http://status.openlabtesting.org/builds/job/spark-unchanged-branch-unit-test-hadoop-2.7-arm64,|http://status.openlabtesting.org/builds/job/spark-unchanged-branch-unit-test-hadoop-2.7-arm64] I think we only have to care about the first one when integrate arm test with amplab jenkins. In fact we have took test for k8s on arm, see [https://github.com/theopenlab/spark/pull/17], maybe we can integrate it later.  And we plan test on other stable branches too, and we can integrate them to amplab when they are ready.

We have offered an arm instance and sent the infos to shane knapp, thanks shane to add the first arm job to amplab jenkins :) 

The other important thing is about the leveldbjni [https://github.com/fusesource/leveldbjni,|https://github.com/fusesource/leveldbjni/issues/80] spark depends on leveldbjni-all-1.8 [https://mvnrepository.com/artifact/org.fusesource.leveldbjni/leveldbjni-all/1.8], we can see there is no arm64 supporting. So we build an arm64 supporting release of leveldbjni see [https://mvnrepository.com/artifact/org.openlabtesting.leveldbjni/leveldbjni-all/1.8], but we can't modified the spark pom.xml directly with something like 'property'/'profile' to choose correct jar package on arm or x86 platform, because spark depends on some hadoop packages like hadoop-hdfs, the packages depend on leveldbjni-all-1.8 too, unless hadoop release with new arm supporting leveldbjni jar. Now we download the leveldbjni-al-1.8 of openlabtesting and 'mvn install' to use it when arm testing for spark.

PS: The issues found and fixed:
 SPARK-28770
 [https://github.com/apache/spark/pull/25673]
  
 SPARK-28519
 [https://github.com/apache/spark/pull/25279]
  
 SPARK-28433
 [https://github.com/apache/spark/pull/25186]
  
  

The other important thing is about the leveldbjni [https://github.com/fusesource/leveldbjni,|https://github.com/fusesource/leveldbjni/issues/80] spark depends on leveldbjni-all-1.8 [https://mvnrepository.com/artifact/org.fusesource.leveldbjni/leveldbjni-all/1.8], we can see there is no arm64 supporting. So we build an arm64 supporting release of leveldbjni see [https://mvnrepository.com/artifact/org.openlabtesting.leveldbjni/leveldbjni-all/1.8], but we can't modified the spark pom.xml directly with something like 'property'/'profile' to choose correct jar package on arm or x86 platform, because spark depends on some hadoop packages like hadoop-hdfs, the packages depend on leveldbjni-all-1.8 too, unless hadoop release with new arm supporting leveldbjni jar. Now we download the leveldbjni-al-1.8 of openlabtesting and 'mvn install' to use it when arm testing for spark.

Ur, [~huangtianhua]. You should update the `Description`. Comments are hidden easily. Could you organize the information into `Description?

worker is up and sshable from the jenkins master:
https://amplab.cs.berkeley.edu/jenkins/computer/spark-arm-vm/

waiting on VM config to be sorted by [~huangtianhua] and then i will ensure i can launch the worker process and run the build.

steps for the VM:
* java is not installed, please install the following:
  - java8 min version 1.8.0_191
  - java11 min version 11.0.1

* it appears from the ansible playbook that there are other deps that need to be installed.
  - please install all deps
  - manually run the tests until they pass

* the jenkins user should NEVER have sudo or any root-level access!

* once the arm tests pass when manually run, take a snapshot of this image so we can recreate it w/o needing to reinstall everything


Hi [~shaneknapp] Shane,
 As the whole test take some times, so I can not send out this summarize yesterday.

First Notes: The ARM VM just test with java8, as the java11 didn't get test before,
                   so we plan to add it in the future, and we test the java8 first.
 * You mentioned the dependencies of ansible had been installed.
 * Also the dependencies which would use sudo priority have be installed by user 'root'.  The 'jenkins' user doesn't have sudo or any root-level access.
 * Source code location: /home/jenkins/spark – 2019/10/16 master branch
 * The all ansible test scripts are stored in /home/jenkins/ansible_test_scripts  You can run the test with the ansible CMD.
 * When we finish the whole test on the target ARM VM, we make a whole VM snapshot for it.

Now I have finished the following tests on the ARM VM:
 1. maven test - Spark Build and UT
 =======================
 env: java8

       javac 1.8.0_222
 spark: master branch
 TEST STEPS: 
 - ./build/mvn -B -e clean install -DskipTests -Phadoop-2.7 -Pyarn -Phive -Phive-thriftserver -Pkinesis-asl -Pmesos 
 - ./build/mvn -B -e test -Phadoop-2.7 -Pyarn -Phive -Phive-thriftserver -Pkinesis-asl -Pmesos
 TEST ANSIBLE CMD:  
 - ansible-playbook -i /home/jenkins/ansible_test_scripts/inventory /home/jenkins/ansible_test_scripts/maven_unittest.yml
 TEST LOG(including the full log, but success at the last time):  
 - /home/jenkins/ansible_test_scripts/test_logs/spark_build.log
   - /home/jenkins/ansible_test_scripts/test_logs/spark_test_original.log
   - /home/jenkins/ansible_test_scripts/test_logs/spark_test.log
     - For the spark_test.log, as I operate mistake, there is an error in the middle of the maven UT test, and stop the test(It seems I did other thing to locate the RAM to raise "not enough RAM" during test).   So I split the log into 2 file, One is test_logs/spark_test.log_before_test_fail,   the other is test_logs/spark_test_including_fail_and_following.log(This is rerun the fail test and the following tests which not run in the first log file) .The main reason is the maven test take so much time, and the whole tests are pass in the end. So I think it's better to not waste too much time here, then we could move the integration process forward quickly.

2. Pyspark and SparkR test
 =======================
 env: python2.7  python3.6  for PySpark test
      R 3.6.1 for SparkR test
 TEST STEPS:
   - python/run-tests --python-executables=python2.7,python3.6
   - ./R/run-tests.shTEST 
 ANSIBLE CMD: 
   - ansible-playbook -i /home/jenkins/ansible_test_scripts/inventory /home/jenkins/ansible_test_scripts/pyspark_sparkr_test.yml
 TEST LOG(including the full log, but success at the last time):
    - /home/jenkins/ansible_test_scripts/test_logs/pyspark_test.log
   - /home/jenkins/ansible_test_scripts/test_logs/sparkr_test.log

In the end, through the real test on the ARM vm, to be honest, we want to show you the time cost when test on ARM.
 Test cost summarize:
 The whole test may take very long time.
 * Spark build by maven  – First build take 1h42m, after that, this would take 1h29m(This may be affected by the VM host performance during the time, the cost time may be shorter than we test.)
 * Spark UT test by maven  – This may take 8h-9h to finish the whole test
 * PySpark test  – 20 - 23 mins
 * SparkR test  – 15 - 20 mins

As the above time cost for different test jobs, we can choose multiple ways to test them as Periodic test jobs.
 * Split them and test one by one.
   - such as, if we just want to test PySpark, then we just add the periodic test  which including Spark Build and Pyspark test. That would just cost 2h per test. But if we want to test SparkR, we still need to test Spark Build. That means each test type, we must test it after Spark Build testing.
 * Test all of them each time.

we test all of them in one periodic test job, and just run Spark Build testing 1 time. But it would cost nearly 11h.
 Each way is OK for us, you could choose the way to add the periodic testing for ARM.If you want to discuss and know more, please feel free to contact us.  

Hi [~shaneknapp] ,

We had updated the VM configuration like above, and exec tests including maven build, maven UT test, pyspark test and sparkR test manually. All  of them are success. Also the spark integrate test with K8S is on the way recently. 

If you are free today, could you please test your jenkins script on the VM? Thank you very much. ;) .

Here is 0:05 am, if you are free, please go ahead to test and tell us the issue if you hit. We will be back after 8 hours.

 

this is great.  i will think about test strategies today and how we can split these up and have them run in parallel.  11h is insane.  :)

some questions:  

* do we want to have a pull request builder job for ARM?  this can be triggered by putting an {{[arm]}} tag in the subject, much like we have for K8s.
* how do we want the general tests to be triggered?  if they're taking 11h then i would suggest nightly builds vs being triggered by SCM changes.

Thanks [~shaneknapp], yeah the time cost may be too long for the PULL Request right now.

For the questions, I will answer them one by one:
 # Yeah, we want to do the same thing like X86 ARCH. So PullRequestTrigger build is also a work for us. But right now, the VM performance can not fully match our requirement. For solving this, we are looking for ways to coordinate the higher performance VMs and maybe there are some increasing the performance solutions to be done for us.
 # what we want to do is like a periodic test job, which runs only several times per day(maybe 1 or 2 times). That would match the 11h the test cost. And we need to consider the 24/11 = 2.... If you think "nightly builds vs being triggered by SCM changes" is good, that's great, let's do it. Sorry about we still not very familiar with jenkins test jobs definition. ;)

For now, we are very clear that doing the same test on arm with X86 must be a hard work to be done. Including  the cost time ,performance and the scale size. But we think that must be done through our hard work and good cooperation. And we are happy that we will get the first step once the first arm VM test is ready for our community. Thanks shane for your kind help.

build running:
https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-maven-arm/2/

Thanks [~shaneknapp] , I see it.

I see the log show that , the jenkins script just call ansible-playbook to run the test. The demo ansible playbook yamls are just the demo test scripts to show you the test process. Is that possible just call the CLI CMD directly? Such as, EXEC ./build/mvn test/build XXXX, in the spark home dir and don't redirect the log info to the file, just show the log info in the stdout.

Thank you very much

[~shaneknapp], thanks for working on this :)

Yes, I agree with [~bzhaoopenstack], maybe we can provide a shell script that do things as following:
 # update spark repo with master? Or there is an other way you could do this?
 # call mvn build or mvn test like './build/mvn clean package -DskipTests -Phadoop-2.7 -Pyarn -Phive -Phive-thriftserver -Pkinesis-asl -Pmesos' and './build/mvn test -Phadoop-2.7 -Pyarn -Phive -Phive-thriftserver -Pkinesis-asl -Pmesos'

And there is important thing that we installed our leveldbjni-all 1.8 locally, which I mentioned before, we released a new jar to support aarch64 platform.

Now the demo ansible script has three steps to run the tests:
 # build spark
 # run tests without install our leveldbjni jar package, an error will raised like " [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /usr/local/src/spark/common/kvstore/target/tmp/libleveldbjni-64-1-610267671268036503.8: /usr/local/src/spark/common/kvstore/target/tmp/libleveldbjni-64-1-610267671268036503.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a AARCH64-bit platform)]" 
 # run tests with our leveldbjni jar which supports aarch64 platform, and then the tests will be past.

I think we don't have to run the step2 anymore on community jenkins, right? We will remove the step in script.

[~bzhaoopenstack] [~huangtianhua] yeah i was wondering about the ansible stuff...  i can take care of the script that launches things.  jenkins will pull master from github and we can go from there.

today was a bit crazy as we're hosting a large event for our lab (risecamp.cs.berkeley.edu), so i didn't have a chance to really start unravelling things.  i should have a little time tomorrow, and definitely next week.

[~shaneknapp], the build [https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-maven-arm/2/] was aborted due to timeout, seems [~bzhaoopenstack] and I made a mistake, we run unit tests twice because we install our leveldbjni jar locally already (the step2 expected to fail in one or two minutes, but it ran more than 3 hours), we have modified the scripts, let's run again when you have time and see the result. Note: The tests will fail sometimes because of the vm performance. 

Hi, 

I create a pretty simple shell script in /home/jenkins/ansible_test_scripts/, it's named "sample_shell_test.sh" .

You can run the script directly after setting a "SPARK_HOME" env. [~shaneknapp], how about we try this script with jenkins?

 

The reason to introducing the shell script is that I found if we call ansible script, it won't log the real-time log information.;)

re: real time logging -- yeah i noticed that.  :)

i'll look at that script and play around w/it today.

we're definitely going to have an issue w/the both R and python tests as it looks like none of the testing deps have been installed.

we use anaconda python to manage our bare metal, so i'll have to see if i can make things work w/virtualenv.

R, well, that's always a can of worms best left untouched.

Thanks @shane. Correct, the test dependency of pyspark and spark R are installed when we test the demo on the VM after your email.  For now, we can focus on the maven test, the pyspark and spark R test are just show both of them can success on VM. If we find there would be some improvements about all thing, just feel free to point out and we try the best to do that. And that would be great if the first periodic job join in our jenkins env recently. 

And if possible and you are free, could you please help us to make the test script better and make it more like a good test process? Such as, you mentioned installing test debs before test some modules..  Thanks very much, @shane

i'm actually not going to use the script – the testing code will be in the jenkins job config:

[https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-maven-arm/]

 

once i get the build config sorted and working as expected i'll be sure to give you all a copy.  :)

also, i will be exploring the purchase of an ARM server for our cluster.  the VM is just not going to be enough for our purposes.  this won't happen immediately, so we'll use the VM until then.

Thanks [~shaneknapp].

That's great that you will copy a full jenkins configuration test code to us. ;) We are very happy that the test result for the fist periodic arm test job. For us, building  a powerful ARM testing architecture is still a very hard work to be done, and from our team, we are plan to integrate more and higher performance ARM VMs into community for supporting the PullRequest Trigger type testing jobs, also more works to improve exec testing for matching the PullRequest Trigger requirement are waiting for us..

Now let's see the test result.

[~shaneknapp]，I am happy that there are two builds success :). I find the arm job now is triggered by 'SCM' change, it's good. I wonder the periodic time. Thanks.

> I find the arm job now is triggered by 'SCM' change, it's good. I wonder the periodic time. Thanks.

i had it poll once per day at ~midnight...  however, i just updated that to poll twice each day (noon and midnight).

> we are plan to integrate more and higher performance ARM VMs into community for supporting the PullRequest Trigger type testing jobs, also more works to improve exec testing for matching the PullRequest Trigger requirement are waiting for us..

this would be great!

[~shaneknapp], thank you for clarification. And thanks for your work (y)

Shane, thanks for recheck the #9 build fail, let's see whether the issue could be reproduced in #10. If it still happen, we should fix it.  Thank you:) 

[~shaneknapp]，there are two small suggestions:
 # we don't have to download and install leveldbjni-all-1.8 in our arm test instance, we have installed it and it was there.
 # maybe we can try to use 'mvn clean package ....' instead of 'mvn clean install ....'?

Hi [~shaneknapp],

Sorry for disturb. I have some questions about the following work want to discuss with you. I list them in the following.
 # For pyspark test, you mentioned we didn't install any python debs for testing. Is there any "requirements.txt" or "test-requirements.txt" in the spark repo? I'm failed to find them. When we test the pyspark before, we just realize that we need to install numpy package with pip, because when we exec the pyspark test scripts, the fail message noticed us. So you mentioned "pyspark testing debs" before, you mean that we should figure all out manually? Is there any kind suggest from your side?
 # For sparkR test, we compile a higher R version 3.6.1 by fix many lib dependency, and make it work. And exec the R test script, till to all of them return pass. So we wonder the difficult about the test when we truelly in amplab, could you please share more to us?
 # For current periodic jobs, you said it will be triggered 2 times per day. Each build will cost most 11 hours. I have a thought about the next job deployment, wish to know your thought about it. My thought is we can setup 2 jobs per day, one is the current maven UT test triggered by SCM changes(11h), the other will run the pyspark and sparkR tests also triggered by SCM changes(including spark build and tests, may cost 5-6 hours). How about this? We can talk and discuss if we don't realize how difficult to do these now.

Thanks very much, shane. And hope you could reply if you are free. ;)

[~huangtianhua]:

> we don't have to download and install leveldbjni-all-1.8 in our arm test instance, we have installed it and it was there.

it's a very inexpensive step to execute and i'd rather have builds be atomic.  if for some reason the dependency get wiped/corrupted/etc, the download will ensure we're properly building.

> maybe we can try to use 'mvn clean package ....' instead of 'mvn clean install ....'?

sure, i'll give that a shot now.

> For pyspark test, you mentioned we didn't install any python debs for testing. Is there any "requirements.txt" or "test-requirements.txt" in the spark repo? I'm failed to find them. When we test the pyspark before, we just realize that we need to install numpy package with pip, because when we exec the pyspark test scripts, the fail message noticed us. So you mentioned "pyspark testing debs" before, you mean that we should figure all out manually? Is there any kind suggest from your side?

i manage the jenkins configs via ansible, and python specifically through anaconda.  anaconda was my initial choice for package management because we need to support multiple python versions (2.7, 3.x, pypy) and specific package versions for each python version itself.

sadly there is no official ARM anaconda python distribution, which is a BIG hurdle for this project.

i also don't use requirements.txt and pip to do the initial python env setup as pip is flakier than i like, and the conda envs just work a LOT better.

see:  https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#building-identical-conda-environments

i could check in the specific python package configs in to the spark repo, but they're specific to our worker configsn and even though the worker deployment process is automated (via ansible) there is ALWAYS some stupid dependency loop that pops up and requires manual intervention.

another issue is that i do NOT want any builds installing/updating/creating either python environments OR packages.  builds should NEVER EVER modify the bare-metal (or VM) system-level configs.

so, to summarize what needs to happen to get the python tests up and running:
1) there is no conda distribution for the ARM architecture, meaning...
2) i need to use venv to install everything...
3) which means i need to use pip/requirements.txt, which is known to be flaky...
4) and the python packages for ARM are named differently than x86...
5) or don't exist...
6) or are the wrong version...
7) meaning that setting up and testing three different python versions with differing package names and versions makes this a lot of trial and error.

i would like to get this done asap, but i will need to carve some serious time to get my brain wrapped around the 

> For sparkR test, we compile a higher R version 3.6.1 by fix many lib dependency, and make it work. And exec the R test script, till to all of them return pass. So we wonder the difficult about the test when we truelly in amplab, could you please share more to us?

i have a deep and comprehensive hatred of installing and setting up R.  i've attached a couple of files showing the packages installed, their versions, and some of the ansible snippets i use to do the initial install.

https://issues.apache.org/jira/secure/attachment/12983856/R-ansible.yml
https://issues.apache.org/jira/secure/attachment/12983857/R-libs.txt

just like you, i need to go back and manually fix lib dependency and version errors once the initial setup is complete.

this is why i have a deep and comprehensive hatred of installing and setting up R.

> For current periodic jobs, you said it will be triggered 2 times per day. Each build will cost most 11 hours. I have a thought about the next job deployment, wish to know your thought about it. My thought is we can setup 2 jobs per day, one is the current maven UT test triggered by SCM changes(11h), the other will run the pyspark and sparkR tests also triggered by SCM changes(including spark build and tests, may cost 5-6 hours). How about this? We can talk and discuss if we don't realize how difficult to do these now.

yeah, i am amenable to having a second ARM build.  i'd be curious as to the impact on the VM's performance when we have two builds running simultaneously.  if i have some time today i'll experiment.

shane

Hi [~shaneknapp],

Thanks very much for sharing so much things to us.

> For pyspark conversation:

First I want to share the details what we have done in Openlab test env.

[https://github.com/theopenlab/spark/pull/32/files#diff-ff133db31a4c2f724e9edfb0f70d243dR33]

Anaconda python package management is very good for python and R ecosystem, but I think it is for the most popular ARCH ecosystem(X86 or other famous ARCH), because it just claimed "Cross platform". We hit the same issue, such as, we have to compile, install and test the dependeny libraries on ARM, that's why we want to improve the ARM ecosystem. 

1) If we can not use Anaconda, how about manage the packages via ansible too? Just for ARM now?  Such as for py27, we need to install what packages from pip/somewhere and need to install manually(For manually installed packages, if possible, we can do something like leveldbjni on maven, provider a public/official way to fit the ARM package downloading/installation). For now, I personally think it's very difficult to use Anaconda, as there aren't so much package management platform for ARM, eventhrough we start up Anaconda on ARM. If we do that, we need to fix the all gaps, that's a very huge project.

2) For multiple python version, py27 py34 py36 and pypy, the venv is the right choice now. But how about support part of them for the first step? Such as only 1 or 2 python version support now, as we already passed on py27 and py36 testing. Let's see that ARM eco is very limited now. ;)

3) As the following integration work is in your sight, we can not know so much details about what problem you hit. So please feel free to tell us how can we help you, we are looking forward to work with you. ;)

 

> For sparkR conversation:

I also share the details what we did in Openlab test env.

[https://github.com/theopenlab/spark/pull/28/files#diff-ff133db31a4c2f724e9edfb0f70d243dR4]

For more quick to test SparkR, I install manually in the ARM jenkins worker, because the R installation also need so much time, including deb librarise install and R itself. So I found amplab jenkins job also manage the R installation before the real spark test execution? Is that happened in each build?

 

> For more jenkins jobs conversation:

I think the current maven UT test could be run 1 time per day, and pyspark/sparkR runs 1 time per day. Eventhough they are running simultaneously, but we can make the 2 jobs trigger in different time period, such as maven UT test(From 0:00 am to 12:00 am), pyspark/sparkR(From 1:00pm to 10:00pm).

> First I want to share the details what we have done in Openlab test env.

this is an extremely basic python installation, and doesn't include important things that pyspark needs to test against, like pandas and pyarrow.

> 1) If we can not use Anaconda, how about manage the packages via ansible too? Just for ARM now?  Such as for py27, we need to install what packages from pip/somewhere and need to install manually(For manually installed packages, if possible, we can do something like leveldbjni on maven, provider a public/official way to fit the ARM package downloading/installation). For now, I personally think it's very difficult to use Anaconda, as there aren't so much package management platform for ARM, eventhrough we start up Anaconda on ARM. If we do that, we need to fix the all gaps, that's a very huge project.

a few things here:

* i am already using ansible to set up and deploy python via anaconda (and pip) on the x86 workers
* we can't use anaconda for ARM, period.  we have to use python virtual envs
* i still haven't had the cycles to dive in to trying to recreate the 3 python envs on ARM yet

> 2) For multiple python version, py27 py34 py36 and pypy, the venv is the right choice now. But how about support part of them for the first step? Such as only 1 or 2 python version support now, as we already passed on py27 and py36 testing. Let's see that ARM eco is very limited now. 

yeah, i was planning on doing one at a time.

> 3) As the following integration work is in your sight, we can not know so much details about what problem you hit. So please feel free to tell us how can we help you, we are looking forward to work with you.

that's the plan!  :)

> For more quick to test SparkR, I install manually in the ARM jenkins worker, because the R installation also need so much time, including deb librarise install and R itself. So I found amplab jenkins job also manage the R installation before the real spark test execution? Is that happened in each build?

no, R is set up via ansible and not modified by the build.

> I think the current maven UT test could be run 1 time per day, and pyspark/sparkR runs 1 time per day. Eventhough they are running simultaneously, but we can make the 2 jobs trigger in different time period, such as maven UT test(From 0:00 am to 12:00 am), pyspark/sparkR(From 1:00pm to 10:00pm).

sure, sounds like a plan once we/i get those two parts set up on the worker in an atomic and reproducible way.

btw the VM is currently experiencing a lot of network latency and relatively high ping times to github.com, and the job is having trouble cloning the git repo.  i rebooted the VM, but it doesn't seem to be helping much.

my lead sysadmin will be out for the next week and a half, but when he returns we'll look in to getting a basic ARM server for our build system.  i'm pretty unhappy w/the VM option and think we'll have a lot more luck w/bare metal.  the VM will definitely help us get the ansible configs built but i'd like to get off of it ASAP.

i bumped the git timeout to 30mins, which is a much more obfuscated set of tasks than i ever would have imagined lol...

relaunched the job and let's see if it fetches/clones in time.

Notes: Hadoop has supported leveldbjni of aarch64 platform, see https://issues.apache.org/jira/browse/HADOOP-16614

Hi all, I'm Kevin Zhao from Linaro Developer Cloud, we've offered the resources for Aarch64 CI. Thanks for using our resources.

I'm sorry that yesterday night we have a network upgrade in Linaro Developer Cloud, and it lead to the network problems for the vm instances you use. Now the problem has been fixed. Pls try again if possible.

In the future if there is an upgrading, I will notify OpenLab first, in case of the convenient conditions. Thanks very much!

 

[~shaneknapp], hi, the arm job has built for some days, althought there are some failures due to poor performance of arm instance or the network upgrade, but the good news is that we got several successes, at least it means that spark supports on arm platform :) 

According the discussion 'Deprecate Python < 3.6 in Spark 3.0' I think now we can do the python test only for python3.6, it will be more simple for us? So how about to add a new arm job for python3.6 tests? 

first pass @ the python tests:
https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-python-arm/3

i'll fix the scheduling later, as well as whack-a-mole any python modules that i might have missed.

i wasn't able to get pyarrow to install, but it looks like ARM support for arrow is limited at best.

note to self:  holy crap this was a serious PITA getting this stuff installed.

Hi [~shaneknapp],

Sorry for late. We are trying the best to coordinate the new ARM VMs in these days, and we worked out a remedy plan via getting the new ARM VMs from our existing resource pool. So We are testing the build and testing on our new ARM VMs recently. The reason to do this is we want to pre-solve the possible issues on new ARM VMs. The new ARM VMs are using ubuntu 1804. So we are afraid that there are some lib deps issues from ubuntu 1604 to 1804, and we are trying the fix the gaps between them. Once that's OK, We think that's the time to change the jenkins worker location for getting good performance.

 

Thank you very much

just uploaded the pip requirements.txt file that i used to get the majority of the python tests to run with.

sadly, we will not be able to test against arrow/pyarrow for the foreseeable as they're moving to a full conda-forge package solution rather than pip.

Thanks very much, [~shaneknapp] . 

So apologize that the VM is down last night, but it's back now.

Yeah, I also post an issue [1] to get the status of arm support in apache/arrow community. There are very little resource to support it, even from community and us. So I think pyarrow is difficult to support arm/finish for now.

Also notes: We got some powerful ARM resources which could replace the current test VM, and we had test it good to go now. How do you think it? ;)

 

[1] https://issues.apache.org/jira/browse/ARROW-7042

Er,, linaro seems in trouble. The VM can not online now. We will try to contact the maintainer asap.

Sorry for that.

The arm worker is back. Sorry for late.

And for the above several comments I left, we hope [~shaneknapp], you could give us some kind advices, we plan to on board it recently, but need some test, so we think to keep the existing worker for a period, and we integrate the new VM at the same time.

Here I can share current VM summary to you:

cpu: 8u

Memory: 16G

location: BeiJing, China (This could affect the network performance as the VM is in China, but we had improved the network performance via configuring internal source)

As we tested, the same maven test will last 5h33min， and build will last 43min。So I think it's good to be a test worker in jenkins. ;)

 

Thanks

 

i would definitely be happy to have a faster VM available for testing...  5h33m is a major improvement over 10h.  :)

at the same time, i'm working w/my lead sysadmin and we will most likely be purchasing an actual aarch64/ARM server for our build system.  the ETA for this will be most likely in early 2020, so we can start testing on the new VM as soon as you're ready.

[~shaneknapp], the vm is ready, I have build/test in /home/jenkins/spark, and because the image of old arm testing instance is too large, so we can't create the new instance with the image, we copy the contents of /home/jenkins/ into new instance.

And because of the network performance, we cache the local source some about "hive-ivy"  into /home/jenkins/hive-ivy-cache, please export the environment {color:#de350b}SPARK_VERSIONS_SUITE_IVY_PATH=/home/jenkins/hive-ivy-cache/{color} before maven test.  

I will send the details info of the vm to your email later.

Please add it as worker of amplab jenkins, and try to build the two jobs as we did before, don't hesitate to contact us if you have any questions, thanks very much.

Hi [~shaneknapp],

I had success to build apache/arrow in the new ARM test worker(high performance). And SparkR and pyspark(python3.6 exec) testings are pass(including arrow and pandas tests). But for SparkR CRAN testing, there is a issue can not avoid, the testing will access wiki and return 443(as this VM is in China, it returns Connection time out), others are all pass. 

In the new ARM test worker, I install apache/arrow and other deps in a specific directory which not in /usr/lib, and uses another venv to test. So how do you think to add sparkR test as SCM periodic test, and ingoring the network accesstion error? Just want to know your advice.

Also I will create the script on the new ARM test worker for sparkR and pyspark test, and you can have a brief about the configuration of the testing.

 

please see the new attachment, I describe what I had done in the new test VM, and please have a look the ENV in the script, I install the deps with some specific dirs.

 

Thanks very much.

 

Hi [~shaneknapp],

If you feel sparkR testing is good with a new job and can ignoring the 443 network error, could you please add sparkR periodic task on the new test ARM VM? Thanks very much.

[~shaneknapp], the arm jobs are failed, I think we should add right profile '-Phive-1.2' instead of '-Phive1.2' when mvn test. 

[~shaneknapp]，I modified the script /tmp/hudson517681717587319554.sh manually on arm instance. Let's wait the result :)

[~shaneknapp], and I have a good news about the arm testing instance, now we gona to donate arm instance in Singapore region,  I will test first, if we are ready will contact you to integreate it. 

So the arm instance in beijing region we mentioned above will be deleted (afaik, you havn't add it as jenkins worker, right?) 

[~shaneknapp], now we don't have to install leveldbjni-all manually, the pr has been merged [https://github.com/apache/spark/pull/26636], please add profile -Paarch64 when running maven commands for arm testing jobs, thanks.

got it, thanks!

[~shaneknapp], ok, thanks, sorry and I found the mvn command of arm test still is "./build/mvn test -Paarch64 -Phadoop-2.7 {color:#de350b}-Phive1.2{color} -Pyarn -Phive -Phive-thriftserver -Pkinesis-asl -Pmesos" , it should be {color:#de350b}-Phive-1.2{color}?

nice catch...  fixed and relaunched.

[~shaneknapp]，：）

So seems you're back:)  Could you please to add the new arm instance into amplab, it has high performance, maven test costs about 5 hours, the instance info I have sent to your email few days ago. And if you have any problem please contact me, thank you very much! 

ok, i have time today to get working on this.

i logged in to the  instance and found the py36 env is broken...  i'll work on that, and move the regular maven build over to the new VM.

ok, maven build running on the new VM:

[https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-maven-arm/77/]

also, is there an account w/sudo privs that i can get access to?  i'm currently unable to pip install virtualenv and friends....  thanks!

Thank you very much, [~shaneknapp]. Sorry for our mistake. Just sent out an email to you about the new sudo user, you can configure the ARM VM as you wish. ;)

[~shaneknapp], thanks, [https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-maven-arm/77/] has finished, it cost about 6 hours:), and please to modify the instance info, the OS is Ubuntu 18.04.1 LTS

huh...  i created a new python 3.6 env, ran the python test and saw some strange failures (skipping pandas tests, etc)...  while everything seemed to install properly, when i went in to the interpreter and tried to import stuff it failed:

 
{noformat}
(py36) jenkins@spark-jenkins-arm-worker:~/python-envs$ python3
Python 3.6.9 (default, Nov  7 2019, 10:44:02)
[GCC 8.3.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import pandas
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/jenkins/python-envs/py36/lib/python3.6/site-packages/pandas/__init__.py", line 19, in <module>
    "Missing required dependencies {0}".format(missing_dependencies))
ImportError: Missing required dependencies ['numpy']
>>> import numpy
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/jenkins/python-envs/py36/lib/python3.6/site-packages/numpy/__init__.py", line 150, in <module>
    from . import random
  File "/home/jenkins/python-envs/py36/lib/python3.6/site-packages/numpy/random/__init__.py", line 143, in <module>
    from .mtrand import *
ImportError: /home/jenkins/python-envs/py36/lib/python3.6/site-packages/numpy/random/mtrand.cpython-36m-aarch64-linux-gnu.so: undefined symbol: PyFPE_jbuf
>>>{noformat}
i'll poke around some more later today.

alright, i installed gfortran and successfully (i think?) compiled numpy 1.16.2 from source.

running the python build now!

also got scipy compiled from source!

pyarrow need to be 1.15.1, so i might try that next.

The arm maven job failed for these days again, and the reason is same as last time, the memory is high even if there is no job running, and there are many processes still running after maven jobs executed for some days, see [http://paste.openstack.org/show/789561] I killed them and let's see test result.

 

 

Hi all,

Regarding the leveldbjni dependency, why is the openlabtesting version of leveldbjni-1.8-all.jar not active for all builds of Spark going forward?  To get spark most will likely download from the Apache mirrors and those tarballs are built on an x86 system, so the aarch64 supported version of leveldbjni is hidden from all except those brave enough to try building from source.

Thanks,

Geoff Blake

[~blakegw] Sorry to reply you so late, yes, now we can't download tgz from spark.apache.org which built with leveldbjni, like spark-3.0.0-bin-hadoop2.7.tgz miss leveldbjni arm64 supporting jar in it. 

[~shaneknapp] and [~srowen], sorry to disturb you. There is an issue for spark arm64 jenkins, the test 'org.apache.spark.DistributedSuite' failed for several days, and I don't know the reason and can't fix it, see https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-maven-arm, and I have filed a jira SPARK-32691, could you have a look for it, I can provide arm64 instance if needed, thanks very much. 

ps: seems the issue happended after the commit b421bf0196897fa66d6d15ba6461a24b23ac6dd3

