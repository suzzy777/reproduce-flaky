I suspect we need to force a flush to avoid races here.

||Branch||CI||
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-18710-trunk]|[unit repeat|https://app.circleci.com/pipelines/github/driftx/cassandra/1156/workflows/79383b9c-7759-4b21-afc4-7c5098e0ea4c/jobs/40077]|


I am not able to reproduce the issue in CircleCI even before the patch.

[https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra?branch=18710-trunk]

But it seems reasonable to me. Also, I can see how timing in Jenkins could influence it to fail that way. I think the flush was just forgotten when the test was written, +1

Committed.

 I can see again failures in Jenkins:
[https://ci-cassandra.apache.org/job/Cassandra-trunk/1669/testReport/junit/org.apache.cassandra.io/DiskSpaceMetricsTest/testFlushSize_compression_jdk17/]
h3.  
{code:java}
Error Message
expected:<7313.0> but was:<2837.567441189888>

Stacktrace
junit.framework.AssertionFailedError: expected:<7313.0> but was:<2837.567441189888> at org.apache.cassandra.io.DiskSpaceMetricsTest.testFlushSize(DiskSpaceMetricsTest.java:120) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
{code}
 

Now I suspect the problem is adding the flush fixed the instance where we need to flush, but also caused a problem when we don't, making us flush a small value.

Actually, adding the flush was probably incorrect since insertN [does that|https://github.com/apache/cassandra/blob/trunk/test/unit/org/apache/cassandra/io/DiskSpaceMetricsTest.java#L139]. Something must be wrong with the metrics, because if I dig into nightlies for the [log|https://nightlies.apache.org/cassandra/trunk/Cassandra-trunk-test-compression/1741/Cassandra-trunk-test-compression/jdk=jdk_17_latest,label=cassandra,split=6/build/test/logs/compression.jdk17/TEST-org.apache.cassandra.io.DiskSpaceMetricsTest.log.xz] from your last failure, the smallest flush is 4.926KiB.

I don't see anything wrong with the metrics so I'm currently out of ideas here.  I did manage to repro once in [circle|https://app.circleci.com/pipelines/github/driftx/cassandra/1220/workflows/e0c90c4a-115b-45f7-a798-c5e21dc937f9/jobs/46827/tests], with the mistaken flush commit removed.

This test was added as part of CASSANDRA-18397 - https://github.com/apache/cassandra/commit/957eca2fb53477d56bdc9a97c612f1fbecfb5d41#diff-af921b889c103e8ba6c4c21566a6b1264b7ebcea8d8c374a9105252418618e6cR99

From the PR in that ticket, it seems that there was a try to fix the flakiness there (that explains why it is very hard to reproduce in CircleCI)- [https://github.com/blambov/cassandra/commit/6b7e755db20bb1b63dd18f3a03830b8dee909672]

Maybe [~blambov] will have some hints here? 

This kind of flakiness usually comes from truncation of a table from a different concurrently completed test causing a flush of the whole keyspace.

The {{KEYSPACE_PER_TEST}} changes fix this, and I must have done a repeated run on CircleCI to verify (I don't remember if I really did at the time).

bq. from a different concurrently completed test

I am running this test in isolation, however.

bq. I must have done a repeated run on CircleCI to verify

It is super hard to repro there, we probably wouldn't even know about this if it weren't for Jenkins.

Unassigning in case someone else wants to take a shot, I have more tractable tickets to work on but I'll come back to this if it's still open later.

I'm back with a new plan.  If we run with the idea that _something_ else is interfering with the flushes and the metrics are accurate, then maybe we can [detect it early|https://github.com/driftx/cassandra/commit/6e5ae2150c5ad0973b056d47f9d7e36cdbf7525b] and note which file it is, then trace that back through the logs to figure out what is causing it.  Now I just need to reproduce again.

Running with [this patch|https://github.com/driftx/cassandra/commit/286bb5cd7c36c62e541cc79b025931215a982bc3], I've managed to reproduce, and it indicates the culprit sstable:

bq. [junit-timeout] INFO  [main] 2023-10-12 21:55:12,181 DiskSpaceMetricsTest.java:125 - smallest sstable is /tmp/cassandra/build/test/cassandra/data/cql_test_keyspace_alt/table_01-03e61210694a11eeb4091bdb4ac3170b/nc-1-big-Data.db at 2329 bytes

If we grep the log for that sstable:
{quote}
[junit-timeout] INFO  [PerDiskMemtableFlushWriter_0:2] 2023-10-12 21:55:11,128 Flushing.java:180 - Completed flushing /tmp/cassandra/build/test/cassandra/data/cql_test_keyspace_alt/table_01-03e61210694a11eeb4091bdb4ac3170b/nc-1-big-Data.db (6.839KiB) for commitlog position CommitLogPosition(segmentId=1697147706890, position=211)
[junit-timeout] DEBUG [MemtableFlushWriter:2] 2023-10-12 21:55:11,177 ColumnFamilyStore.java:1345 - Flushed to [BigTableReader:big(path='/tmp/cassandra/build/test/cassandra/data/cql_test_keyspace_alt/table_01-03e61210694a11eeb4091bdb4ac3170b/nc-1-big-Data.db')] (1 sstables, 11.232KiB), biggest 11.232KiB, smallest 11.232KiB
[junit-timeout] INFO  [main] 2023-10-12 21:55:12,181 DiskSpaceMetricsTest.java:125 - smallest sstable is /tmp/cassandra/build/test/cassandra/data/cql_test_keyspace_alt/table_01-03e61210694a11eeb4091bdb4ac3170b/nc-1-big-Data.db at 2329 bytes
{quote}

It looks like SSTR.onDiskLength() and bytesOnDisk() disagree at some point, which seems like a bug.  [~blambov] can you take a look? I've uploaded the full log from the failure.

It looks like the reason for the unexpected flush is the commit log:
{code:java}
[junit-timeout] INFO  [OptionalTasks:1] 2023-10-12 21:55:11,095 ColumnFamilyStore.java:1017 - Enqueuing flush of cql_test_keyspace_alt.table_01, Reason: COMMITLOG_DIRTY, Usage: 74.752KiB (0%) on-heap, 3.777KiB (0%) off-heap
[junit-timeout] INFO  [PerDiskMemtableFlushWriter_0:2] 2023-10-12 21:55:11,103 Flushing.java:154 - Writing Memtable-table_01@1180822937(6.854KiB serialized bytes, 242 ops, 74.916KiB (0%) on-heap, 3.781KiB (0%) off-heap), flushed range = [null, null)
[junit-timeout] INFO  [PerDiskMemtableFlushWriter_0:2] 2023-10-12 21:55:11,128 Flushing.java:180 - Completed flushing /tmp/cassandra/build/test/cassandra/data/cql_test_keyspace_alt/table_01-03e61210694a11eeb4091bdb4ac3170b/nc-1-big-Data.db (6.839KiB) ... {code}
which is flushing just 242 out of the 1000 ops that the test needs per table.

We need to understand what causes these {{COMMITLOG_DIRTY}} flushes, because there are quite a few tests that will fail if a flush happens at the wrong time. Or maybe somehow disable commitlog-driven flushing for tests (e.g. by setting a really large commit log space limit).

bq. We need to understand what causes these COMMITLOG_DIRTY flushes, because there are quite a few tests that will fail if a flush happens at the wrong time. Or maybe somehow disable commitlog-driven flushing for tests (e.g. by setting a really large commit log space limit).

I remember running into this same situation in CASSANDRA-18706 now, and I think something in 5.0 must have changed to cause this.  I'll see if I can track that down, but we could also shut the optional tasks executor down since whatever is triggering the flushes is going through it.

Dropping a CF eventually leads to CFS.onTableDropped, which then [force recycles|https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/db/ColumnFamilyStore.java#L3379] the commit log segments, which leads to our flushes with COMMITLOG_DIRTY.  This was added in CASSANDRA-17071 which is in 4.1, though.

So the {{KEYSPACE_PER_TEST}} fix for unexpected flushes no longer works after CASSANDRA-17071? All of the tests that use it will be having intermittent failures unless we find a way to block this.

Before CASSANDRA-17071 (and currently in 4.0) we also force recycled the commitlog, but sooner in [Schema.dropTable|https://github.com/apache/cassandra/blob/cassandra-4.0/src/java/org/apache/cassandra/schema/Schema.java#L803], and it didn't cause small flushes of the active CF.  After CASSANDRA-17071 that has moved to CFS.onTableDropped and it seems the timing of this now does cause the small flushes.  I'm not super strong in this area of the code but it seems like maybe this could be massaged again to prevent this from happening as before?

Here's a reproduction with additional logging at ERROR showing the drop of table_00 causing the small flush of table_01 shortly after creation:
{noformat}
[junit-timeout] INFO  [main] 2023-10-25 20:12:32,442 ColumnFamilyStore.java:493 - Initializing cql_test_keyspace_alt.table_01
[junit-timeout] DEBUG [main] 2023-10-25 20:12:32,443 DiskBoundaryManager.java:54 - Refreshing disk boundary cache for cql_test_keyspace_alt.table_01
[junit-timeout] DEBUG [main] 2023-10-25 20:12:32,443 DiskBoundaryManager.java:93 - Got local ranges [] (ringVersion = 0)
[junit-timeout] DEBUG [main] 2023-10-25 20:12:32,447 DiskBoundaryManager.java:57 - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=build/test/cassandra/data}], positions=null, ringVersion=0, directoriesVersion=0} for cql_test_keyspace_alt.table_01
[junit-timeout] INFO  [main] 2023-10-25 20:12:32,453 ViewManager.java:127 - Not submitting build tasks for views in keyspace cql_test_keyspace_alt as storage service is not initialized
[junit-timeout] DEBUG [OptionalTasks:1] 2023-10-25 20:12:32,459 DefaultSchemaUpdateHandler.java:259 - Schema updated: SchemaTransformationResult{e9de990e-f2fd-3f3e-97fb-e351f5dae8d3 --> 111d2c16-fe3d-3fcf-9dc1-9cafe8d9b926, diff=KeyspacesDiff{created=[], dropped=[], altered=[KeyspaceDiff{before=KeyspaceMetadata{name=cql_test_keyspace, kind=REGULAR, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[cql_test_keyspace.table_00], views=[], functions=[], types=[]}, after=KeyspaceMetadata{name=cql_test_keyspace, kind=REGULAR, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[], views=[], functions=[], types=[]}, tables=Diff{created=[], dropped=[cql_test_keyspace.table_00], altered=[]}, views=Diff{created=[], dropped=[], altered=[]}, types=Diff{created=[], dropped=[], altered=[]}, udfs=Diff{created=[], dropped=[], altered=[]}, udas=Diff{created=[], dropped=[], altered=[]}}]}}
[junit-timeout] ERROR [OptionalTasks:1] 2023-10-25 20:12:32,571 ColumnFamilyStore.java:1013 - Bad flush reason: COMMITLOG_DIRTY
[junit-timeout] ERROR [OptionalTasks:1] 2023-10-25 20:12:32,571 ColumnFamilyStore.java:1014 - [org.apache.cassandra.db.ColumnFamilyStore.logFlush(ColumnFamilyStore.java:1012)
[junit-timeout]  org.apache.cassandra.db.ColumnFamilyStore.switchMemtable(ColumnFamilyStore.java:999)
[junit-timeout]  org.apache.cassandra.db.ColumnFamilyStore.switchMemtableIfCurrent(ColumnFamilyStore.java:981)
[junit-timeout]  org.apache.cassandra.db.ColumnFamilyStore.flushMemtable(ColumnFamilyStore.java:1065)
[junit-timeout]  org.apache.cassandra.db.ColumnFamilyStore.forceFlush(ColumnFamilyStore.java:1040)
[junit-timeout]  org.apache.cassandra.db.commitlog.AbstractCommitLogSegmentManager.flushDataFrom(AbstractCommitLogSegmentManager.java:457)
[junit-timeout]  org.apache.cassandra.db.commitlog.AbstractCommitLogSegmentManager.forceRecycleAll(AbstractCommitLogSegmentManager.java:334)
[junit-timeout]  org.apache.cassandra.db.commitlog.CommitLog.forceRecycleAllSegments(CommitLog.java:261)
[junit-timeout]  org.apache.cassandra.db.ColumnFamilyStore.onTableDropped(ColumnFamilyStore.java:3382)
[junit-timeout]  org.apache.cassandra.db.Keyspace.dropCf(Keyspace.java:383)
[junit-timeout]  org.apache.cassandra.schema.Schema.dropTable(Schema.java:756)
[junit-timeout]  org.apache.cassandra.schema.Schema.lambda$alterKeyspace$14(Schema.java:672)
[junit-timeout]  java.base/java.lang.Iterable.forEach(Iterable.java:75)
[junit-timeout]  org.apache.cassandra.schema.Schema.alterKeyspace(Schema.java:672)
[junit-timeout]  org.apache.cassandra.schema.Schema.lambda$merge$12(Schema.java:655)
[junit-timeout]  com.google.common.collect.ImmutableList.forEach(ImmutableList.java:422)
[junit-timeout]  org.apache.cassandra.schema.Schema.merge(Schema.java:655)
[junit-timeout]  org.apache.cassandra.schema.Schema.mergeAndUpdateVersion(Schema.java:607)
[junit-timeout]  org.apache.cassandra.schema.DefaultSchemaUpdateHandler.updateSchema(DefaultSchemaUpdateHandler.java:260)
[junit-timeout]  org.apache.cassandra.schema.DefaultSchemaUpdateHandler.apply(DefaultSchemaUpdateHandler.java:242)
[junit-timeout]  org.apache.cassandra.schema.Schema.transform(Schema.java:620)
[junit-timeout]  org.apache.cassandra.cql3.statements.schema.AlterSchemaStatement.execute(AlterSchemaStatement.java:114)
[junit-timeout]  org.apache.cassandra.cql3.statements.schema.AlterSchemaStatement.executeLocally(AlterSchemaStatement.java:71)
[junit-timeout]  org.apache.cassandra.cql3.CQLTester.schemaChange(CQLTester.java:1460)
[junit-timeout]  org.apache.cassandra.cql3.CQLTester$2.run(CQLTester.java:471)
[junit-timeout]  org.apache.cassandra.concurrent.ExecutionFailure$1.run(ExecutionFailure.java:133)
[junit-timeout]  org.apache.cassandra.concurrent.ExecutionFailure$1.run(ExecutionFailure.java:133)
[junit-timeout]  java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[junit-timeout]  java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[junit-timeout]  java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
{noformat}

{quote}After CASSANDRA-17071 that has moved to CFS.onTableDropped and it seems the timing of this now does cause the small flushes. I'm not super strong in this area of the code but it seems like maybe this could be massaged again to prevent this from happening as before?
{quote}
So if I read correctly, this _may be_ a 4.1+ regression?

[~jlewandowski] , [~blambov] , do you mind to take a look and advise, please? 

Yes, this looks like a 4.1 regression that is affecting all tests that are sensitive to the number of sstables. Such tests usually run in a separate keyspace (using {{KEYSPACE_PER_TEST}}) to avoid the keyspace flush that dropping a table triggers, but this new commit log recycling is triggering another flush that is not restricted to the affected keyspace.

I tried to reproduce this on 4.1 by backporting the test but iterating the sstables again instead of using the metric, since that part was non-trivial to add, [here|https://github.com/driftx/cassandra/commit/1ac64e63de7b0d0f7c63dd953e81fbeb66ff77d9].  Indeed, this fails on 4.1 in the same way, as seen here: https://app.circleci.com/pipelines/github/driftx/cassandra/1353/workflows/621a816d-9309-4e7c-910c-f56d36281bd0/jobs/60078/tests

I noticed that the refactoring around this in CASSANDRA-17071 kept the general order of events but slightly changed the behavior, which I've restored [here|https://github.com/driftx/cassandra/commit/b25d1819faf3a963e6e40a2afe6b9e648c4d2aee].  -As one might expect, I haven't been able to reproduce in 5.0 with that patch ([here|https://app.circleci.com/pipelines/github/driftx/cassandra/1362/workflows/ccc0dc0b-7342-4637-a983-160b3f3a6ea5] or [here|https://app.circleci.com/pipelines/github/driftx/cassandra/1362/workflows/c35b0923-d293-4197-a58d-7498ab499e09]).  If this looks good and will still work for CASSANDRA-17071's goals, I can prepare the branches and run full CI.-

This did reproduce after I wrote that, [here|https://app.circleci.com/pipelines/github/driftx/cassandra/1362/workflows/ccc0dc0b-7342-4637-a983-160b3f3a6ea5].  I'll have to dig into that.

I think I've done what I can here, I'm too far out of my wheelhouse if making the execution order the same after the refactoring doesn't fix it.  Something else from CASSANDRA-17071 is causing this interaction with commitlog recycling forcing small flushes, I will defer to [~jlewandowski].

I've managed to reproduce it locally with IntelliJ repeated test runs... 

a full fresh log

{noformat}
INFO  [main] 2023-11-14 15:39:38,817 CQLTester.java:1004 - CREATE TABLE cql_test_keyspace_alt.table_26 (pk bigint, PRIMARY KEY (pk))
DEBUG [main] 2023-11-14 15:39:38,818 DefaultSchemaUpdateHandler.java:259 - Schema updated: SchemaTransformationResult{16db0888-1bd6-360e-a84c-fff0101449fa --> 6ec911f6-0117-3684-ab6b-1366e985c0fe, diff=KeyspacesDiff{created=[], dropped=[], altered=[KeyspaceDiff{before=KeyspaceMetadata{name=cql_test_keyspace_alt, kind=REGULAR, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[], views=[], functions=[], types=[]}, after=KeyspaceMetadata{name=cql_test_keyspace_alt, kind=REGULAR, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[cql_test_keyspace_alt.table_26], views=[], functions=[], types=[]}, tables=Diff{created=[cql_test_keyspace_alt.table_26], dropped=[], altered=[]}, views=Diff{created=[], dropped=[], altered=[]}, types=Diff{created=[], dropped=[], altered=[]}, udfs=Diff{created=[], dropped=[], altered=[]}, udas=Diff{created=[], dropped=[], altered=[]}}]}}
INFO  [main] 2023-11-14 15:39:38,819 Keyspace.java:366 - Creating replication strategy cql_test_keyspace_alt params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}
INFO  [main] 2023-11-14 15:39:38,819 ColumnFamilyStore.java:495 - Initializing cql_test_keyspace_alt.table_26
DEBUG [main] 2023-11-14 15:39:38,819 DiskBoundaryManager.java:54 - Refreshing disk boundary cache for cql_test_keyspace_alt.table_26
DEBUG [main] 2023-11-14 15:39:38,819 DiskBoundaryManager.java:93 - Got local ranges [] (ringVersion = 0)
DEBUG [main] 2023-11-14 15:39:38,819 DiskBoundaryManager.java:57 - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=build/test/cassandra/data}], positions=null, ringVersion=0, directoriesVersion=0} for cql_test_keyspace_alt.table_26
INFO  [main] 2023-11-14 15:39:38,821 ViewManager.java:127 - Not submitting build tasks for views in keyspace cql_test_keyspace_alt as storage service is not initialized
INFO  [main] 2023-11-14 15:39:38,845 ColumnFamilyStore.java:1021 - Enqueuing flush of cql_test_keyspace_alt.table_26, Reason: UNIT_TESTS, Usage: 309.570KiB (0%) on-heap, 15.625KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:2] 2023-11-14 15:39:38,854 Flushing.java:154 - Writing Memtable-table_26@1116421524(28.320KiB serialized bytes, 1000 ops, 309.570KiB (0%) on-heap, 15.625KiB (0%) off-heap), flushed range = [null, null)
INFO  [PerDiskMemtableFlushWriter_0:2] 2023-11-14 15:39:38,855 Flushing.java:180 - Completed flushing /home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/cql_test_keyspace_alt/table_26-a398db1082fb11eeb194e5f4789e9eaa/nc-1-big-Data.db (27.743KiB) for commitlog position CommitLogPosition(segmentId=1699972753906, position=65263)
INFO  [MemtableFlushWriter:2] 2023-11-14 15:39:38,888 LogTransaction.java:249 - Unfinished transaction log, deleting /home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/cql_test_keyspace_alt/table_26-a398db1082fb11eeb194e5f4789e9eaa/nc_txn_flush_a39d20d0-82fb-11ee-b194-e5f4789e9eaa.log 
DEBUG [MemtableFlushWriter:2] 2023-11-14 15:39:38,895 ColumnFamilyStore.java:1349 - Flushed to [BigTableReader:big(path='/home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/cql_test_keyspace_alt/table_26-a398db1082fb11eeb194e5f4789e9eaa/nc-1-big-Data.db')] (1 sstables, 31.852KiB), biggest 31.852KiB, smallest 31.852KiB
INFO  [main] 2023-11-14 15:39:38,913 ColumnFamilyStore.java:1021 - Enqueuing flush of cql_test_keyspace_alt.table_26, Reason: UNIT_TESTS, Usage: 309.570KiB (0%) on-heap, 15.625KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:1] 2023-11-14 15:39:38,921 Flushing.java:154 - Writing Memtable-table_26@1957761258(28.320KiB serialized bytes, 1000 ops, 309.570KiB (0%) on-heap, 15.625KiB (0%) off-heap), flushed range = [null, null)
INFO  [PerDiskMemtableFlushWriter_0:1] 2023-11-14 15:39:38,923 Flushing.java:180 - Completed flushing /home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/cql_test_keyspace_alt/table_26-a398db1082fb11eeb194e5f4789e9eaa/nc-2-big-Data.db (27.427KiB) for commitlog position CommitLogPosition(segmentId=1699972753906, position=126263)
INFO  [MemtableFlushWriter:1] 2023-11-14 15:39:38,952 LogTransaction.java:249 - Unfinished transaction log, deleting /home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/cql_test_keyspace_alt/table_26-a398db1082fb11eeb194e5f4789e9eaa/nc_txn_flush_a3a78110-82fb-11ee-b194-e5f4789e9eaa.log 
DEBUG [MemtableFlushWriter:1] 2023-11-14 15:39:38,958 ColumnFamilyStore.java:1349 - Flushed to [BigTableReader:big(path='/home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/cql_test_keyspace_alt/table_26-a398db1082fb11eeb194e5f4789e9eaa/nc-2-big-Data.db')] (1 sstables, 30.995KiB), biggest 30.995KiB, smallest 30.995KiB
INFO  [main] 2023-11-14 15:39:38,976 ColumnFamilyStore.java:1021 - Enqueuing flush of cql_test_keyspace_alt.table_26, Reason: UNIT_TESTS, Usage: 309.570KiB (0%) on-heap, 15.625KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:2] 2023-11-14 15:39:38,983 Flushing.java:154 - Writing Memtable-table_26@242024199(28.320KiB serialized bytes, 1000 ops, 309.570KiB (0%) on-heap, 15.625KiB (0%) off-heap), flushed range = [null, null)
INFO  [PerDiskMemtableFlushWriter_0:2] 2023-11-14 15:39:38,984 Flushing.java:180 - Completed flushing /home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/cql_test_keyspace_alt/table_26-a398db1082fb11eeb194e5f4789e9eaa/nc-3-big-Data.db (27.435KiB) for commitlog position CommitLogPosition(segmentId=1699972753906, position=187263)
INFO  [MemtableFlushWriter:2] 2023-11-14 15:39:39,014 LogTransaction.java:249 - Unfinished transaction log, deleting /home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/cql_test_keyspace_alt/table_26-a398db1082fb11eeb194e5f4789e9eaa/nc_txn_flush_a3b11e00-82fb-11ee-b194-e5f4789e9eaa.log 
DEBUG [MemtableFlushWriter:2] 2023-11-14 15:39:39,020 ColumnFamilyStore.java:1349 - Flushed to [BigTableReader:big(path='/home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/cql_test_keyspace_alt/table_26-a398db1082fb11eeb194e5f4789e9eaa/nc-3-big-Data.db')] (1 sstables, 31.011KiB), biggest 31.011KiB, smallest 31.011KiB

java.lang.AssertionError:
Expected :9435.0
Actual   :10002.088009199999
<Click to see difference>


	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:553)
	at org.junit.Assert.assertEquals(Assert.java:683)
	at org.apache.cassandra.io.DiskSpaceMetricsTest.testFlushSize(DiskSpaceMetricsTest.java:123)
	at jdk.internal.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:30)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)


{noformat}

Updated: includes just the test case, without beforeTest/afterTest

and this is a good run, without a failure:

{noformat}
INFO  [main] 2023-11-14 15:39:30,254 CQLTester.java:1004 - CREATE TABLE cql_test_keyspace_alt.table_16 (pk bigint, PRIMARY KEY (pk))
DEBUG [main] 2023-11-14 15:39:30,256 DefaultSchemaUpdateHandler.java:259 - Schema updated: SchemaTransformationResult{83424b78-ee1a-38f8-acb8-73e354fbca5b --> 8323ff58-4946-3c75-bedb-b4cfb7108a11, diff=KeyspacesDiff{created=[], dropped=[], altered=[KeyspaceDiff{before=KeyspaceMetadata{name=cql_test_keyspace_alt, kind=REGULAR, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[], views=[], functions=[], types=[]}, after=KeyspaceMetadata{name=cql_test_keyspace_alt, kind=REGULAR, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[cql_test_keyspace_alt.table_16], views=[], functions=[], types=[]}, tables=Diff{created=[cql_test_keyspace_alt.table_16], dropped=[], altered=[]}, views=Diff{created=[], dropped=[], altered=[]}, types=Diff{created=[], dropped=[], altered=[]}, udfs=Diff{created=[], dropped=[], altered=[]}, udas=Diff{created=[], dropped=[], altered=[]}}]}}
INFO  [main] 2023-11-14 15:39:30,256 Keyspace.java:366 - Creating replication strategy cql_test_keyspace_alt params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}
INFO  [main] 2023-11-14 15:39:30,256 ColumnFamilyStore.java:495 - Initializing cql_test_keyspace_alt.table_16
DEBUG [main] 2023-11-14 15:39:30,257 DiskBoundaryManager.java:54 - Refreshing disk boundary cache for cql_test_keyspace_alt.table_16
DEBUG [main] 2023-11-14 15:39:30,257 DiskBoundaryManager.java:93 - Got local ranges [] (ringVersion = 0)
DEBUG [main] 2023-11-14 15:39:30,257 DiskBoundaryManager.java:57 - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=build/test/cassandra/data}], positions=null, ringVersion=0, directoriesVersion=0} for cql_test_keyspace_alt.table_16
INFO  [main] 2023-11-14 15:39:30,259 ViewManager.java:127 - Not submitting build tasks for views in keyspace cql_test_keyspace_alt as storage service is not initialized
INFO  [NonPeriodicTasks:1] 2023-11-14 15:39:30,260 LogTransaction.java:249 - Unfinished transaction log, deleting /home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/system_schema/aggregates-924c55872e3a345bb10c12f37c1ba895/nc_txn_compaction_9e72cd30-82fb-11ee-b194-e5f4789e9eaa.log
INFO  [main] 2023-11-14 15:39:30,278 ColumnFamilyStore.java:1021 - Enqueuing flush of cql_test_keyspace_alt.table_16, Reason: UNIT_TESTS, Usage: 309.570KiB (0%) on-heap, 15.625KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:2] 2023-11-14 15:39:30,286 Flushing.java:154 - Writing Memtable-table_16@70866609(28.320KiB serialized bytes, 1000 ops, 309.570KiB (0%) on-heap, 15.625KiB (0%) off-heap), flushed range = [null, null)
INFO  [PerDiskMemtableFlushWriter_0:2] 2023-11-14 15:39:30,288 Flushing.java:180 - Completed flushing /home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/cql_test_keyspace_alt/table_16-9e7e65f082fb11eeb194e5f4789e9eaa/nc-1-big-Data.db (27.456KiB) for commitlog position CommitLogPosition(segmentId=1699972753896, position=77015)
INFO  [MemtableFlushWriter:2] 2023-11-14 15:39:30,320 LogTransaction.java:249 - Unfinished transaction log, deleting /home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/cql_test_keyspace_alt/table_16-9e7e65f082fb11eeb194e5f4789e9eaa/nc_txn_flush_9e81e860-82fb-11ee-b194-e5f4789e9eaa.log
DEBUG [MemtableFlushWriter:2] 2023-11-14 15:39:30,326 ColumnFamilyStore.java:1349 - Flushed to [BigTableReader:big(path='/home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/cql_test_keyspace_alt/table_16-9e7e65f082fb11eeb194e5f4789e9eaa/nc-1-big-Data.db')] (1 sstables, 31.116KiB), biggest 31.116KiB, smallest 31.116KiB
INFO  [main] 2023-11-14 15:39:30,344 ColumnFamilyStore.java:1021 - Enqueuing flush of cql_test_keyspace_alt.table_16, Reason: UNIT_TESTS, Usage: 309.570KiB (0%) on-heap, 15.625KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:1] 2023-11-14 15:39:30,351 Flushing.java:154 - Writing Memtable-table_16@1253443750(28.320KiB serialized bytes, 1000 ops, 309.570KiB (0%) on-heap, 15.625KiB (0%) off-heap), flushed range = [null, null)
INFO  [PerDiskMemtableFlushWriter_0:1] 2023-11-14 15:39:30,353 Flushing.java:180 - Completed flushing /home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/cql_test_keyspace_alt/table_16-9e7e65f082fb11eeb194e5f4789e9eaa/nc-2-big-Data.db (27.350KiB) for commitlog position CommitLogPosition(segmentId=1699972753896, position=138015)
INFO  [MemtableFlushWriter:1] 2023-11-14 15:39:30,384 LogTransaction.java:249 - Unfinished transaction log, deleting /home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/cql_test_keyspace_alt/table_16-9e7e65f082fb11eeb194e5f4789e9eaa/nc_txn_flush_9e8bfa80-82fb-11ee-b194-e5f4789e9eaa.log
DEBUG [MemtableFlushWriter:1] 2023-11-14 15:39:30,391 ColumnFamilyStore.java:1349 - Flushed to [BigTableReader:big(path='/home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/cql_test_keyspace_alt/table_16-9e7e65f082fb11eeb194e5f4789e9eaa/nc-2-big-Data.db')] (1 sstables, 30.804KiB), biggest 30.804KiB, smallest 30.804KiB
INFO  [main] 2023-11-14 15:39:30,410 ColumnFamilyStore.java:1021 - Enqueuing flush of cql_test_keyspace_alt.table_16, Reason: UNIT_TESTS, Usage: 309.570KiB (0%) on-heap, 15.625KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:2] 2023-11-14 15:39:30,421 Flushing.java:154 - Writing Memtable-table_16@75630209(28.320KiB serialized bytes, 1000 ops, 309.570KiB (0%) on-heap, 15.625KiB (0%) off-heap), flushed range = [null, null)
INFO  [PerDiskMemtableFlushWriter_0:2] 2023-11-14 15:39:30,422 Flushing.java:180 - Completed flushing /home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/cql_test_keyspace_alt/table_16-9e7e65f082fb11eeb194e5f4789e9eaa/nc-3-big-Data.db (27.478KiB) for commitlog position CommitLogPosition(segmentId=1699972753896, position=199015)
INFO  [MemtableFlushWriter:2] 2023-11-14 15:39:30,453 LogTransaction.java:249 - Unfinished transaction log, deleting /home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/cql_test_keyspace_alt/table_16-9e7e65f082fb11eeb194e5f4789e9eaa/nc_txn_flush_9e960ca0-82fb-11ee-b194-e5f4789e9eaa.log
DEBUG [MemtableFlushWriter:2] 2023-11-14 15:39:30,461 ColumnFamilyStore.java:1349 - Flushed to [BigTableReader:big(path='/home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/cql_test_keyspace_alt/table_16-9e7e65f082fb11eeb194e5f4789e9eaa/nc-3-big-Data.db')] (1 sstables, 31.175KiB), biggest 31.175KiB, smallest 31.175KiB
{noformat}

Comparing to the bad run, I can see only one extra log line in the good run:

{noformat}
INFO  [NonPeriodicTasks:1] 2023-11-14 15:39:30,260 LogTransaction.java:249 - Unfinished transaction log, deleting /home/jlewandowski/dev/cassandra/cassandra-5.0/build/test/cassandra/data/system_schema/aggregates-924c55872e3a345bb10c12f37c1ba895/nc_txn_compaction_9e72cd30-82fb-11ee-b194-e5f4789e9eaa.log
{noformat}


I've tried to follow what are the updates applied to the metrics so that it leads to the assertion failure. It seems that in the failed case there are no problems at all - I can see 3 updates as expected: 9670, 8787, 8885, which give the moving average with alpha=0.0046 = 9662, and avg=9114, so at least there is no problem there.

Another question is whether values like 9670, 8787, 8885 are correct, and what is the sources of such randomness.


ah.... so compression is used regardless we use compression config or not.... 


[~blambov] the test seems to run ok with increased delta, but I don't think this is the point - I assume you do not want to test the correctness of the {{MovingAverage}} implementation there. So perhaps the expected value should be calculated as a moving average by updating it with subsequent table sizes.

I didn't manage to reproduce the case with extra flush so far

{quote}So perhaps the expected value should be calculated as a moving average by updating it with subsequent table sizes.
{quote}
This makes sense. Sorting the sstable files by name should give them in the correct order, so we can easily calculate the moving average from them.

Actually, that would solve the extra flush problem as well, wouldn't it?

I'm not sure, it seems like a value of "0" might be registered in the metrics while there is no such sstable so you would not iterate over it to calculate the expected average, right?

ok, disregard my comment

Now I'm able to reproduce the extra flush consistently. Dropping tables after test is executed asynchronously, so in some rare cases it may get executed while we are adding rows to our test table, thus causing extra flush (or even flushes).

I think that regardless whether it is correct to flush everything on each schema change or not, I think that changing schema and dropping sstables asynchronously after each test can cause flakiness. Also I don't see much justification for doing that async as it take usually less than a second per test case.

So, summing up, I propose to fix this by calculating moving average as an expected value and create another ticket to convert that async processing (which should be applied to other branches as well) - I suppose that we do not need to remove tables - only KEYSPACE_PER_TEST is expected to be empty

https://github.com/apache/cassandra/pull/2900 - [~blambov] could you review?

Also created https://issues.apache.org/jira/browse/CASSANDRA-19026


bq. in some rare cases it may get executed while we are adding rows to our test table, thus causing extra flush (or even flushes)

Is this being solved, or just worked around by avoidance?

this fix should make the test agnostic to this kind of events, CASSANDRA-19026 should eliminate unexpected async processing  at all

https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/1080/workflows/59cc5d3b-de09-4c43-9bd9-be9b94f3c8df

I guess my question is, independent of these tests, will it still be possible to create the small flush scenario?  If not and this solves it, we can revert my fix in CASSANDRA-18706 which suffered the same problem but without any drops.  There may be other tests that are also affected.

fix for this ticket does not prevent small flush scenario - this is addressed in CASSANDRA-19026 in general for all tests

fix for this ticket makes this particular test resilient to small flush problem but also to other scenarios where it was failing (when there was no such small flush)


My understanding then is that we are not fixing the small flush scenario, and we will live with it and just workaround it like CASSANDRA-18706?

This small test shows that small flushes during schema changes are not caused by CASSANDRA-17071:

{code:java}
@Test
    public void test() {
        SchemaLoader.prepareServer();

        QueryProcessor.executeInternal("CREATE KEYSPACE ks WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};");

        QueryProcessor.executeInternal("CREATE TABLE ks.tab1 (key int PRIMARY KEY, value int);");
        QueryProcessor.executeInternal("INSERT INTO ks.tab1 (key, value) VALUES (1, 1);");

        QueryProcessor.executeInternal("CREATE TABLE ks.tab2 (key int PRIMARY KEY, value int);");
        QueryProcessor.executeInternal("INSERT INTO ks.tab2 (key, value) VALUES (1, 1);");

        QueryProcessor.executeInternal("DROP TABLE ks.tab1;");

        Set<SSTableReader> sstables = ColumnFamilyStore.getIfExists("ks", "tab2").getLiveSSTables();
        Assertions.assertThat(sstables.size()).isEqualTo(0);
    }
{code}

It fails the same way on 4.0 and 4.1 (which means that the tab2 was flushed when tab1 was dropped)


The problem with small flush affecting the test case in question can be easily reliably reproduced by adding the following delays:

in DiskSizeMetricsTest:
{code:java}
private void insertN(String keyspace, ColumnFamilyStore cfs, int n, long base) throws Throwable
{
    for (int i = 0; i < n; i++)
    {
        Thread.sleep(1);  // <------------ HERE
        executeFormattedQuery(formatQuery(keyspace, "INSERT INTO %s (pk) VALUES (?)"), base + i);
    }

    // flush to write the sstable
    cfs.forceBlockingFlush();
}
{code}

in CQLTester:
{code:java}
@After
public void afterTest() throws Throwable
{
    dropPerTestKeyspace();
...
    // We want to clean up after the test, but dropping a table is rather long so just do that asynchronously
    ScheduledExecutors.optionalTasks.execute(new Runnable()
    {
        public void run()
        {
            try
            {
                Thread.sleep(500); // <----------------- HERE
                for (int i = tablesToDrop.size() - 1; i >= 0; i--)
                    schemaChange(String.format("DROP TABLE IF EXISTS %s.%s", KEYSPACE, tablesToDrop.get(i)));
{code}

Then run the whole test class (not just the test case)


CASSANDRA-17071 relaxes some synchronization requirements for schema changes, in particular some changes against one ks does not block some changes against other ks. This might have changed some timings and made that race more apparent. But adding those delays shows that the race is a problem on all versions.


Thanks for the explanation, my worry that this was a performance regression has been put to rest.

I've run repeated tests in a couple of configurations (links in the PRs), all passed, and [~blambov] approved the PR. Merging


