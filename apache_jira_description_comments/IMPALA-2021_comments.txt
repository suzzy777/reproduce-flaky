Another failure:
http://sandbox.jenkins.cloudera.com/view/Impala/view/Nightly-Builds/job/impala-s3/130/console

01:34:51.555 E   Failed to open HDFS file s3a://ishaan-impala/test-warehouse/tpch.lineitem/lineitem.tbl
01:34:51.555 E   Error(255): Unknown error 255

We've also now seen the s3 cmdline tool choke while accessing s3:

http://sandbox.jenkins.cloudera.com/view/Impala/view/S3/job/impala-s3/131/console

00:02:48.079 ++ aws s3 ls s3://ishaan-impala/
00:02:48.343 Traceback (most recent call last):
00:02:48.343   File "/usr/bin/aws", line 27, in <module>
00:02:48.343     sys.exit(main())



Ishaan, can you check that the bucket and ec2 instance are both in the same region?  And maybe create a new bucket called impala-cdh5-trunk for this job?

Another similar case:
http://sandbox.jenkins.cloudera.com/view/Impala/view/Nightly-Builds/job/impala-s3/140/console

I don't think we've seen it with the 5.4 S3 job which is why I suspect it's related to the bucket and/or ec2 instance or something else environmental.

{code}
03:50:19 E   ImpalaBeeswaxException: ImpalaBeeswaxException:
03:50:19 E    Query aborted:
03:50:19 E   Read failed while trying to finish scan range: s3a://ishaan-impala/test-warehouse/tpch.lineitem/lineitem.tbl:402653184
03:50:19 E   Failed to open HDFS file s3a://ishaan-impala/test-warehouse/tpch.lineitem/lineitem.tbl
03:50:19 E   Error(255): Unknown error 255
03:50:19 E   
03:50:19 E   
03:50:19 E   
03:50:19 E   
03:50:19 E   Read failed while trying to finish scan range: s3a://ishaan-impala/test-warehouse/tpch.lineitem/lineitem.tbl:402653184
03:50:19 E   Failed to open HDFS file s3a://ishaan-impala/test-warehouse/tpch.lineitem/lineitem.tbl
03:50:19 E   Error(255): Unknown error 255
03:50:19 E   
03:50:19 E   Read failed while trying to finish scan range: s3a://ishaan-impala/test-warehouse/tpch.lineitem/lineitem.tbl:402653184
03:50:19 E   Failed to open HDFS file s3a://ishaan-impala/test-warehouse/tpch.lineitem/lineitem.tbl
03:50:19 E   Error(255): Unknown error 255
{code}

Another, though slightly different but probably same root cause. http://sandbox.jenkins.cloudera.com/view/Impala/view/Nightly-Builds/job/impala-s3/138.

{code}
3:39:37 beeswax/impala_beeswax.py:347: in wait_for_completion
03:39:37     raise ImpalaBeeswaxException("Query aborted:" + error_log, None)
03:39:37 E   ImpalaBeeswaxException: ImpalaBeeswaxException:
03:39:37 E    Query aborted:
03:39:37 E   Error seeking to 22 in file: s3a://ishaan-impala/test-warehouse/testescape_32_crlf/114 
03:39:37 E   Error(95): Operation not supported
03:39:37 E   
03:39:37 E   
03:39:37 E   
03:39:37 E   Error seeking to 22 in file: s3a://ishaan-impala/test-warehouse/testescape_32_crlf/114 
03:39:37 E   Error(95): Operation not supported
{code}

Actually, we have now seen this with the 5.4 S3 job as well:
http://sandbox.jenkins.cloudera.com/job/impala-s3-cdh5-2.2.0_5.4.x/468/

The fix is to add fs.s3a.connection.maximum = 9999 in core-site.xml

Hi Sailesh,
Could you please confirm that the workaround here.
fs.s3a.connection.maximum = 1500 should be a good number, 9999 may be too high

Thanks

[~pgarg_impala_3a7b] Yes, 1500 should be a good number. We're not sure of the negative implications of 9999 connections yet. But for now 1500 is good.

Appreciate your input here.
Thanks

This is fixed for our test infrastructure:
http://github.mtv.cloudera.com/CDH/Impala/commit/09d1d08b3769a0e703737678a1ba5cf87a6c430b

