Patch looks good.
Do you mind submitting for QA run again ?


Patch looks fine Jimmy but why do we have to force the reassign?  Why does it not work w/o forcing it?

Tried to submit to hadoop qa again.

As to focing reassign, it is needed since the region state in memory may show the missing daughter is open.
Since it is not in meta, SSH will assign it only in fixupDaughters.  Without forcing it, assign won't do
anything since it is already open.

Try hadoop-qa again.

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12551760/trunk-7083.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 hadoop2.0{color}.  The patch compiles against the hadoop 2.0 profile.

    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated 85 warning messages.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 3 new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

     {color:red}-1 core tests{color}.  The patch failed these unit tests:
                       org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit
                  org.apache.hadoop.hbase.master.TestSplitLogManager

Test results: https://builds.apache.org/job/PreCommit-HBASE-Build/3211//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3211//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3211//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3211//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3211//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3211//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html
Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/3211//console

This message is automatically generated.

Integrated into trunk.  Thanks Stack and Ted for the review.
The failed unit tests are flaky, seem to be fine locally.

bq. As to focing reassign, it is needed since the region state in memory may show the missing daughter is open.

[~jxiang] When would the above case be true?  It was not in .META. so its edit failed?  How then could it be open in the master given its a new region?

Also, if open already in master, could it be open on a regionserver?  So this assign will mean double assignment?

Integrated in HBase-TRUNK #3508 (See [https://builds.apache.org/job/HBase-TRUNK/3508/])
    HBASE-7083 SSH#fixupDaughter should force re-assign missing daughter (Revision 1404867)

     Result = FAILURE
jxiang : 
Files : 
* /hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java


At first, there won't be double assignment since currently, the region will be closed if it is indeed open (HBASE-6611).  In this scenario, it is open on the dead region server, so no double assignment for sure. Since it is on the dead server, SSH should fix it.  However, it can't since the region is not in meta.

That's probably a scenario cooked up in the unit test. In the unit test, the daughter is open and good.  The meta entry is removed intentionally.
In real cluster, it may probably not happen.  However, force-assign is safe, just in case.

Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #248 (See [https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/248/])
    HBASE-7083 SSH#fixupDaughter should force re-assign missing daughter (Revision 1404867)

     Result = FAILURE
jxiang : 
Files : 
* /hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java


Seems like a good fix for 0.94.

For 0.94, forcing re-assign could cause double-assignment. This patch depends on other assignment manager patches, which are radical for 0.94. :)

Thanks Jimmy. Let's not do that for 0.94. :)

Marking closed.

