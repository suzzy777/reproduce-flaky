[~mjsax] what would be the expected behaviour in this scenario? I see three possible behaviours:
 # Throwing a Kafka specific exception
 # Ignoring the empty partition silently
 # Ignoring the empty partition and logging a warn 

I would guess that 2 is the way to go, because an empty partition is technically speaking, reset to any duration or timestamp that can be requested.

I guess the problem is, that we don't have any timestamp information from the time index, and thus we cannot get the offset we want to commit. – Silently ignoring seems the worst option from the three you suggested, because in the end, we don't know where the application will effectively start to consume – either there is an exiting committed offset or we might fall back to `auto.offset.reset`. Note, that we cannot make any assumption what the time gap between resetting and restarting is, and thus, new data might be written into the topic in the meantime. Thus, I think we should at least inform the user that no offset was committed for some partitions (and report the corresponding partitions), thus, option 3 might be the best? Option 1 would also be ok IMHO. With one is better seems to depend how "robust" the tool should be (don't have strong opinion about it). The point is that both options allow the user to react without the danger of unexpected behavior on restart of the application.

Btw: I would assume that this issue not only affects the "stream reset tool" but also the "consumer group" tool that offset a similar feature (cf. KIP-122 [https://cwiki.apache.org/confluence/display/KAFKA/KIP-122%3A+Add+Reset+Consumer+Group+Offsets+tooling] and KIP-171 [https://cwiki.apache.org/confluence/display/KAFKA/KIP-171+-+Extend+Consumer+Group+Reset+Offset+for+Stream+Application])

Not sure what behavior [~jbfletch] had in mind? Maybe [~jeqo] (who proposed the feature originally) has some input?

Btw: the ticket is assigned to [~jbfletch] so she should first agree to hand it off to you before you start working on it.

[~mjsax] I see your point. Indeed in this scenario makes more sense to notify the user about it.

The bug is caused because of this line [here|https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java#L516] - that returns by default a null value on the map.
 The following method
{code:java}
client.seek(topicPartition, topicPartitionsAndOffset.get(topicPartition).offset());{code}
uses it as an argument without optional handling - which indeed causes a NPE for keys with null values on the map.
 [~jbfletch] it think it should be straight forward to fix, do you mind if I assign the bug to me?

Hi there!

The NPE is caused by topic partitions where no offset is found after a timestamp, not by consumer offsets related to the topic partition.

This could mean topic-partition that hasn't received records yet, or a topic partition with no records after a retention delete exec (actually I'm not sure about this scenario if it returns null or the latest known offset, but anyway).

At the moment, here is how it's handled in the consumer group's reset-offset: [https://github.com/apache/kafka/blob/70404baffa47b99914d34143e779b0e65522a5ef/core/src/main/scala/kafka/admin/ConsumerGroupCommand.scala#L672-L688]

Where, if offset by timestamp is null, then it fallbacks to the end offset. 

Resetting to the latest offset seem like a sensible default, as resetting by timestamp/duration command allows to go backwards (most cases) or forward (same as to-latest?). Resetting to offset=0 when no records (i.e. as backwards as possible) or offset=latest when all records removed seem to match the semantics.

Also, dry-run could be seen as a kind of "logging".

Bringing this into the table to be considered while the NPE is fixed.

{quote}Where, if offset by timestamp is null, then it fallbacks to the end offset.
{quote}
Interesting. Was this part of the KIP design or just a PR-scoped decision? Overall, it might be best to align both tools to do the same thing?
{quote}Also, dry-run could be seen as a kind of "logging".
{quote}
Well, what would --dry-run print for this case? The offset number of end-offset or a hint that it did not "seek by time" but defaulted to "end offset". The later seems more reasonable to me? Personally, I would still suggest to also log a WARN for this case during execution, as we should not rely on people to do a dry-run first.

> Interesting. Was this part of the KIP design or just a PR-scoped decision? Overall, it might be best to align both tools to do the same thing?

I can't find comments about this in the KIP or the thread, so a PR-scoped decision most probably.

> Well, what would --dry-run print for this case? 

Atm prints the end offset.

> The later seems more reasonable to me? Personally, I would still suggest to also log a WARN for this case during execution, as we should not rely on people to do a dry-run first.

Good point. Will create a ticket to follow this up.

https://issues.apache.org/jira/browse/KAFKA-12287

[~jeqo] Understood. About returning the latest offset - if we perform no .seek() operation on empty partitions, the consumer offset will be handled by "auto.offset.reset" configuration - and thus by default return latest.

Should I rely on this configuration or you rather have an explicit client.seekToEnd() call?

Since the reporter is currently inactive and is an old ticket, I am taking it over and will forward a PR in a bit.

PR ready.
Please let me know your thoughts and what needs changing (e.g. explicit seekToEnd or the displayed message).
Also, I couldn't find a reason for the CI failing on JDK11 and passing on 8 and 15. Did I make something wrong or is it flaky?

Thanks for taking this on [~marcolotz]

Thanks everyone. I'll try to review the PR soon – but we have 2.8.0 deadline and we want to do a 2.6.2 release that I need to take care of first. – We can discuss more details on the PR. And yes, we have flaky tests so don't worry about it.

[~marcolotz], relying on "auto.offset.reset" would be different from seeking to end in the specific scenario where there is new records available in a topic-partition that was empty when offsets were reset.

In this scenario, when consumers resume polling, consumption from this topic-partition will be different depending on "auto.offset.reset": latest or earliest.

`seekToEnd` will make the starting point consistent though. To keep this change consistent with consumer-groups reset-offset, `seekToEnd` should be used.

