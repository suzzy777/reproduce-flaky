Assignee just because code history looks like you might have most recent memory of the test. What do you think?

Looks like a flaky. This test includes 5 pipelines run on the Dataflow. It takes lots of time to start up and tear down the worker, and it exceeds the duration threshold this time. If it continuously happens, we should consider to disable this test from the PostCommitITTests.

 

Happened again: https://scans.gradle.com/s/whyjrsgtrhme4/console-log?task=:beam-sdks-python:postCommitITTests#L219

Increasing python test time limit from 3000s to 4500s. It would prevent the timeout issue in datastore tests. [https://github.com/apache/beam/pull/6833/files#diff-5924c115647bc4008928b5855e17d635R218] 

Looks like this is now hitting a 3600s timeout on dataflow.
https://builds.apache.org/job/beam_PostCommit_Python_Verify/6933/consoleFull

_Workflow failed. Causes: The Dataflow job appears to be stuck because no worker activity has been seen in the last 1h. You can get help with Cloud Dataflow at [https://cloud.google.com/dataflow/support.]_

*There are errors repeat in the worker log, which cause the worker failed to start:* 

_Error syncing pod 30a7faf11edde2d98e5bf5992f52eb63 ("dataflow-beamapp-jenkins-122719345-12271141-5f05-harness-41l1_default(30a7faf11edde2d98e5bf5992f52eb63)"), skipping: failed to "StartContainer" for "python" with CrashLoopBackOff: "Back-off 5m0s restarting failed container=python pod=dataflow-beamapp-jenkins-122719345-12271141-5f05-harness-41l1_default(30a7faf11edde2d98e5bf5992f52eb63)"_

 

Stack driver: https://pantheon.corp.google.com/logs/viewer?resource=dataflow_step%2Fjob_id%2F2018-12-27_11_41_05-5516523713456997908&interval=NO_LIMIT&project=apache-beam-testing&minLogLevel=0&expandAll=false&timestamp=2018-12-27T23:08:47.767000000Z&customFacets=&limitCustomFacetWidth=true&scrollTimestamp=2018-12-27T20:38:56.483664000Z&dateRangeUnbound=backwardInTime 

Errors occurred when reading metadata of some google-dockercfg packages:

while reading 'google-dockercfg-url' metadata: http status code: 404 while fetching url [http://metadata.google.internal./computeMetadata/v1/instance/attributes/google-dockercfg-url]

"Failed to install packages: failed to install SDK: exit status 1" 

Are you actively working on this? Maybe release the bug so someone going around deflaking will try it and see.

released the bug with unassigned. 

cc: [~chamikara]

What suite is exercising this now? Is it beamPostCommitPython{36,37,38}?

I don't see any recent flakes in those, e.g.: https://ci-beam.apache.org/view/PostCommit/job/beam_PostCommit_Python36/lastCompletedBuild/testReport/junit/apache_beam.io.gcp.datastore.v1new.datastore_write_it_test/DatastoreWriteIT/history/

Given that and the fact no one has reported a flake here recently I think this is safe to close.

