How long does it take for subscriber information to get propagated? This doesn't seem like a bug unless that interval is large. Subscribers will register themselves, and then receive their first topic update ~500ms in the future IIRC. Shouldn't the test just wait for the backend to be ready?

Sleeping for one second is not sufficient, but sleeping for 3 seconds is.

[~henryr], can you clarify what it means for the backend to be ready? Looking through Impala's json metrics, I don't see one that I could wait on that would work for this purpose. 

I could still rewrite the test to function without the addition of a metric by repeatedly trying the query, catching any relevant connection exception, and then possibly failing the query after a timeout period.

Stacktrace from failed test

{{
____ TestProcessFailures.test_restart_statestore[exec_option: {'disable_codegen': False, 'abort_on_error': 1, 'batch_size': 0, 'num_nodes': 0} | table_format: text/none] ____
experiments/test_process_failures.py:86: in test_restart_statestore
    self.execute_query_using_client(client, QUERY, vector)
common/impala_test_suite.py:291: in execute_query_using_client
    return client.execute(query)
common/impala_connection.py:159: in execute
    return self.__beeswax_client.execute(sql_stmt)
beeswax/impala_beeswax.py:163: in execute
    handle = self.__execute_query(query_string.strip())
beeswax/impala_beeswax.py:312: in __execute_query
    self.wait_for_completion(handle)
beeswax/impala_beeswax.py:331: in wait_for_completion
    raise ImpalaBeeswaxException("Query aborted:" + error_log, None)
E   ImpalaBeeswaxException: ImpalaBeeswaxException:
E    Query aborted:Cancelled due to unreachable impalad(s): alexleblang-OptiPlex-9020:22002, alexleblang-OptiPlex-9020:22000
}}

Information from log:
{{
I0911 16:22:05.212661 30394 status.cc:44] Cancelled due to unreachable impalad(s): alexleblang-OptiPlex-9020:22002, alexleblang-OptiPlex-9020:22000
    @           0xebf072  impala::Status::Status()
    @           0xfbedc2  impala::ImpalaServer::MembershipCallback()
    @          0x1018b6b  boost::_mfi::mf2<>::operator()()
    @          0x1014918  boost::_bi::list3<>::operator()<>()
    @          0x100ddb4  boost::_bi::bind_t<>::operator()<>()
    @          0x1001f5e  boost::detail::function::void_function_obj_invoker2<>::invoke()
    @          0x10da45e  boost::function2<>::operator()()
    @          0x10d7e90  impala::StatestoreSubscriber::UpdateState()
    @          0x10d8d08  impala::StatestoreSubscriberThriftIf::UpdateState()
    @          0x132be54  impala::StatestoreSubscriberProcessor::process_UpdateState()
    @          0x132bb8b  impala::StatestoreSubscriberProcessor::dispatchCall()
    @           0xfc3b8a  apache::thrift::TDispatchProcessor::process()
    @          0x1f2726d  apache::thrift::server::TThreadedServer::Task::run()
    @           0xf158bf  impala::ThriftThread::RunRunnable()
    @           0xf16f24  boost::_mfi::mf2<>::operator()()
    @           0xf16d8c  boost::_bi::list3<>::operator()<>()
    @           0xf16b1f  boost::_bi::bind_t<>::operator()()
    @           0xf16a42  boost::detail::function::void_function_obj_invoker0<>::invoke()
    @           0xf3936c  boost::function0<>::operator()()
    @          0x1117598  impala::Thread::SuperviseThread()
    @          0x111f49c  boost::_bi::list4<>::operator()<>()
    @          0x111f3e5  boost::_bi::bind_t<>::operator()()
    @          0x111f378  boost::detail::thread_data<>::run()
    @     0x7fbeeee03ce9  (unknown)
    @     0x7fbeeebe1e9a  start_thread
    @     0x7fbeec75031d  (unknown)
I0911 16:22:05.212707 28341 impala-server.cc:749] Cancel(): query_id=864b3912e0c87af9:20734074f5b1e286
I0911 16:22:05.212718 30394 simple-scheduler.cc:342] Registering local backend with statestore
I0911 16:22:05.212738 28341 coordinator.cc:1094] Cancel() query_id=864b3912e0c87af9:20734074f5b1e286
I0911 16:22:05.212743 28341 plan-fragment-executor.cc:526] Cancel(): instance_id=864b3912e0c87af9:20734074f5b1e287
I0911 16:22:05.212749 28341 data-stream-mgr.cc:156] cancelling all streams for fragment=864b3912e0c87af9:20734074f5b1e287
I0911 16:22:05.212759 28341 data-stream-recvr.cc:230] cancelled stream: fragment_instance_id_=864b3912e0c87af9:20734074f5b1e287 node_id=2
I0911 16:22:05.212777 28341 coordinator.cc:1146] sending CancelPlanFragment rpc for instance_id=864b3912e0c87af9:20734074f5b1e288 backend=alexleblang-OptiPlex-9020:22000
I0911 16:22:05.212836 28341 client-cache.cc:106] CreateClient(): creating new client for alexleblang-OptiPlex-9020:22000
I0911 16:22:05.217567 30500 impala-server.cc:1086] CancelPlanFragment(): instance_id=864b3912e0c87af9:20734074f5b1e288
I0911 16:22:05.217658 30500 plan-fragment-executor.cc:526] Cancel(): instance_id=864b3912e0c87af9:20734074f5b1e288
I0911 16:22:05.217666 30500 data-stream-mgr.cc:156] cancelling all streams for fragment=864b3912e0c87af9:20734074f5b1e288
I0911 16:22:05.217720 28341 coordinator.cc:1146] sending CancelPlanFragment rpc for instance_id=864b3912e0c87af9:20734074f5b1e289 backend=alexleblang-OptiPlex-9020:22001
I0911 16:22:05.217867 28341 coordinator.cc:1146] sending CancelPlanFragment rpc for instance_id=864b3912e0c87af9:20734074f5b1e28a backend=alexleblang-OptiPlex-9020:22002
I0911 16:22:05.217919 28341 client-cache.cc:106] CreateClient(): creating new client for alexleblang-OptiPlex-9020:22002

}}


Ok, this is weird - it looks like Impala schedules a query on some nodes (via the simple scheduler), but then it hears from the statestore that they don't exist, and cancels the query. 

Needs further investigation.

Don't think we've seen this in two years.

