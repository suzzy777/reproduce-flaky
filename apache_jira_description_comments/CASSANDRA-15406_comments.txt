Hi [~maxwellguo] , you can see in which mode a node is with the first line of {{nodetool netstats output}}. e.g. "Mode: NORMAL" 

Mode can be: [STARTING, NORMAL, JOINING, LEAVING, DECOMMISSIONED, MOVING, DRAINING, DRAINED|https://github.com/apache/cassandra/blob/e4287d04feaa168802168352412d5d74fc7faae4/src/java/org/apache/cassandra/service/StorageService.java#L219]

When a node is bootstrapping (JOINING)  you can have an idea of the progress with:
{code:java}
 nodetool netstats -H | grep -v 100%{code}
I don't say that's perfect, a more user friendly command like {{nodetool progress}} (or a {{netstats}} option) with a global percentage could be a good idea.

[~rha] Thank you for your reply, The mode of the node is a good way to get the node's joining/leaving status. But what i mean is just the percentage of the progress . 

When we do bootstrap, the node is doing streaming for some days, but people don't know the rate of progress for streaming,80% ? 90% ? increasing  or just stuck at 90% progress? or during the state of rebuild secondary index after all data streaming finished? 

Querying log and doing some calculation is a way but not intuitive. So I think a command for nodetool to show the rate is intuitive and it  is easy to find problems when the rate keep at  50% for some hours ( for example ).

I can take over this issue latter to finish this and I think this work have meaning.


Linked with CASSANDRA-15399 since repair needs similar abilities.  I am working on repair coordinator and validation now, was planning to look into sync (streaming) after that work was complete.

[~dcapwell] where do we stand with this? I was reading your pull request for 15399 and do I understand it right that one is postponed indefinitely? (at least until 4.0 is out)

 

I would like to work on this but I am not sure if there is some reasonable probability it will eventually and actually end up being merged before 4.0 is out. 

 

Could you elaborate more about what parts of this code would be similar with your issue which ended up postponed so we would not duplicate things?

 

Next, [~maxwellguo], I am not completely sure how you want to actually measure the progress of a bootstrap. As I understand it, if you bootstrap, Cassandra is not completely up so one might only query it via JMX or is it true that virtual tables would work too?

 

[~dcapwell] do you know some entry points in the code base which I could navigate into so I would somehow start to dig deeper?

I will assign this to myself temporarily (as it was unassigned), is somebody objects please feel free to raise your opinion here. Thank you.

I have added "global percentage" functionality into netstats both for sending and receiving. It looks like this:

 
{code:java}
Mode: NORMAL
Rebuild 2c0b43f0-735d-11ea-9346-fb0ffe238736
    /127.0.0.1
        Receiving 133 files, 27664559 bytes total. Already received 21 files (15.79%), 918834 bytes total (3.32%)
            /tmp/dtests15682026295742741219/node2/data/distributed_test_keyspace/cf-196b3...
            ....{code}
 

On sending:
{code:java}
Mode: NORMAL
Rebuild 2c0b43f0-735d-11ea-9346-fb0ffe238736
    /127.0.0.2
        Sending 133 files, 27664559 bytes total. Already sent 42 files (31.58%), 1841015 bytes total (6.65%) 
            /tmp/dtests15682026295742741219/node2/data/distributed_test_keyspace/cf-196b3...
            ....{code}
 

There is a bug in the current code as if we are streaming entire SSTables via CassandraEntireSSTableStreamWriter and CassandraOutgoingFile respectively, there is not any update on particular components of a SSTable as it counts only "db" file to be there. That introduces this bug:
{code:java}
Mode: NORMAL
Rebuild 2c0b43f0-735d-11ea-9346-fb0ffe238736
    /127.0.0.2 Sending 19 files, 27664559 bytes total. Already sent 133 files, 27664559 bytes total
        /tmp/dtests15682026295742741219/node2/data/distributed_test_keyspace/cf-196b3...
        ....
{code}
Basically, number of files to be sent is lower than files sent.

Maybe something for [~djoshi] as food for thought.

I have fixed it here [https://github.com/apache/cassandra/compare/trunk...smiklosovic:CASSANDRA-15406] (forget the test, will be finished). 

[~jasonstack], this fix would be way better if we manage to merge yours CASSANDRA-15657 because mine is checking if SSTable is meant to be streamed entirely and this is not performance-friendly. With your patch it would be just one call to already cached value because you have introduced a field for that.

Could somebody please give me some feedback here if this is what we want?

Thanks

@

bq. David Capwell where do we stand with this? I was reading your pull request for 15399 and do I understand it right that one is postponed indefinitely? (at least until 4.0 is out)

Yes, since the repair work are improvements and new features, its best they are not in 4.0.0 as 4.0.0 is is under freeze right now.  I want early feedback on the tables so different tools could provide feedback or feature requests, but still should not go into 4.0.0.

bq. I would like to work on this but I am not sure if there is some reasonable probability it will eventually and actually end up being merged before 4.0 is out. 

Best to ask on the dev mailing list.
 
bq. Could you elaborate more about what parts of this code would be similar with your issue which ended up postponed so we would not duplicate things?

I left a comment https://issues.apache.org/jira/browse/CASSANDRA-15399?focusedCommentId=17072219&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17072219 that shows what part of the code.  How I understand this JIRA is not that they conflict, but that this JIRA benefits 15399; I may be wrong in this understanding.
 
bq. query it via JMX or is it true that virtual tables would work too?

The trend is to kill off JMX in favor of virtual tables.  I have not looked at your code, but many prefer virtual tables over JMX.


Hi [~dcapwell],

I think that this ticket will be more or less transformed just into a bug fix. I do not think that there is a need for a "command" for nodetool and having a lot of work before release anyway, it is not a good idea to introduce something completely new.

As I see it, this ticket will be just about the introduction of global percentage into netstats output + I think I hit a bug when we stream entire SSTables and netstats is displaying it weirdly so that should be fixed too.

cool, thanks for letting me know

[~stefan.miklosovic] thanks for bringing up this issue. I am not sure if the goal of this ticket is to fix the accounting bug. It would be great to file a separate bug so this ticket can be used for the original issue.

[~djoshi] yes I can do that but without fixing the underlying issue when the streaming of entire sstable is happening, it does not make sense to continue with the computation and rendering of the progress in percentage as the computed figure would not make any sense and we would have to yet do some workarounds which is imho not desirable.

 

Hence, the course of action will be: 1) create new ticket as you suggested describing the problem of not updated figures properly when sstable is streamed in its entirety 2) momentarilly abandoning this ticket, marking it as dependant to the newly created one and returning to it once the former is resolved.

For the reference this is a branch it is fixed, with test checking that figures do match 

 

[https://github.com/smiklosovic/cassandra/commit/e98338082a73e5f360c6d9eb234710810eba5cea]

This issue should be blocked to work on until the underlying bug when streaming of entire sstables is resolved as the figures for the computation of progress would not make sense anyway.

[~djoshi] as we resolved CASSANDRA-15694  there is nothing which prevents us from merging this as well. Would you mind to go over this please? (PR in description of this issue).

Do we want to back-port this progress into Cassandra 3.x as well? I am fine having this just in 4 only.

This is technically not a bug fix so we should do this for 4.0.

For progress of index building, I have created this issue and respective patch https://issues.apache.org/jira/browse/CASSANDRA-15759

I think we should reuse system views as much as possible once we have it.

https://github.com/apache/cassandra/pull/558

[~djoshi] any chance to merge this one?

[~stefan.miklosovic] I was looking at this and wondering the same you did, why not backport it? Also for the 4.0 review it would be good to have CI ran. Wdyt?

Edit: I just learned we don't do improvements on older branches. Apologies for the noise. 4.0 only it is :-)

I triggered a [jenkins|https://ci-cassandra.apache.org/job/Cassandra-devbranch/172/] run.

[~stefan.miklosovic] do you mind rebasing your patch? I believe that it is the root cause for most of the DTests failures.

[~blerer] done, same PR.

[~stefan.miklosovic] Thanks.
New Jenkins [run|https://ci-cassandra.apache.org/job/Cassandra-devbranch/195/] 


Would it make sense to add some testing either in a junit hijacking {{System.out}} and mocking things around in {{NodeToolTest.java}} i.e. Or even in {{nodetool_test.py}} dtest? I am aware the nodetool tool doesn't have this sort of testing atm (only some dtests) so we can use this as an opportunity to kickstart now. You can also tell me you'd rather do this in another ticket as it's not a quick fix :-) depending on how OCD on testing you feel on this one.

My OCD here is pretty weak, I would just move it to other PR, I was talking about testing of nodetools output with [~ifesdjeen] and how we could go about that in testing framework but no luck so far ... 

Ok so here's an opportunity for CASSANDRA-15502 or even as the quality 4.0 effort. Some scaffolding for cmd line tooling testing. Thx otherwise, pending CI lgtm.

That test run looks like a mess, with nodes not starting + CASSANDRA-15925. I say we wait for 15925, rebase as there have been many flaky tests fixes and re-run a CI.

CASSANDRA-15925 has been committed. Maybe worth firing another CI run [~blerer]?

[~Bereng] [~blerer] any progress here or we are waiting for the release? I think it will also automatically fix https://issues.apache.org/jira/browse/CASSANDRA-14192

[~stefan.miklosovic] I would rebase once again, yeah I'm OCD about it apologies but it will take you just 1m :-) As Benjamin is going to be on holidays for a few weeks I'd suggest you jump on Slack and ask for sbdy to run CI for you?

[~Bereng] [~blerer] done [https://github.com/apache/cassandra/pull/558]

Triggered Ci run: https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/211/pipeline

CI run lgtm. Notice the stages have failures despite the overall test report CASSANDRA-15925

 I have updated PR with a test, it is testing the output of the netstats command [https://github.com/apache/cassandra/pull/711]

Build: [https://ci-cassandra.apache.org/job/Cassandra-devbranch/235/] 

 

left a few comments, need to still review closer

I have implemented your suggestions however I think we need to release new dtest api.

Looking forward to have further feedback.

We have done it without the need to release dtest api

I am getting this exception randomly and test fail. Seems to be interal error of Cassandra during streaming / repair.

[https://gist.githubusercontent.com/smiklosovic/1ad5d7d356e880611d47b37edce9b933/raw/1992ab56415d25d629a09393ef4392da66fa7825/NetstatsTest.java]

bq. We have done it without the need to release dtest api

Yep, the work around lets us not have to worry about this, but long term we should move this logic into the api

Ok finally did a full pass and overall LGTM.  I left a few small comments in GitHub and ran the logic with lower resources in a loop to show it was stable.

bq. I am getting this exception randomly and test fail. Seems to be interal error of Cassandra during streaming / repair.

The logs given don't show the test failing (at least I couldn't find it), all the errors thrown were during shutdown which makes sense (if the instance is shutting down there will be many different subsystems throwing since our shutdown isn't that clean).  

I suspect that the issue was that you run repair in the background and block waiting on streaming.  If repair takes more than 1m to complete the stream then the test would get a timeout and fail (though don't see the logs showing this).  In GH I recommended using nodetool repair and that will block the test, so you don't wait on streaming as much; with this change I couldn't get the test to fail running in a loop with lower resources.

[~blerer] still planning to review?  I am almost ready to +1 this so would be good to get a second review.

Speaking to [~stefan.miklosovic] in Slack he was planning to adding bootstrap into the test, this would get a good addition (make sure to put into its own class file to avoid CI test timeout)

Sorry guys, I am a bit confused. Which one is the new PR? The one I found appears closed. 

[~blerer] this one [https://github.com/apache/cassandra/pull/711]

I ll write more tests and reflect needed changes today.

Build: [https://ci-cassandra.apache.org/job/Cassandra-devbranch/255/]

PR: [https://github.com/apache/cassandra/pull/711]

I have found a bug during this implementation. In a nutshell, I hope it helps you during review, the issue is that the size in CassandraOutgoingFile#getSize() is computed from header.size() but that is wrong because size from header is done in CassandraStreamHeader#calculateSize and that is either based on compression info or otherwise it just computes stuff from "sections". However there is a weird clash when this is computed because Netstats reports the total bytes to be sent as total over this "sections size" even it is sent over like compressed, it is compressed by default by CassandraCompressedStreamWriter and the individual "total bytes" per each item to be streamed is taken from its totalSize method and there it is computed as compressed so the numbers dont match.

What I did was that I computed CassandraOutgoingFile#getSize() in advance just once with help of header.calculateCompressionInfo in its constructor.

The PR is consisting of two commits, the second one tries to simplify the logic related to the computation of size and it reduce that logic to one central place.

Tests are testing bootstrapping and normal repair, compression turned on / off and entire sstable streaming on / off. Btw, I am not able to test as of now the output of the bootstrapping node. My suspicion is that the output is there, sure, even for the bootstrapping one, but dtest api and things around are hairy a bit so nothing is shown, I am getting some errors while doing nodetool netstats against a node which is under bootstrap.
  
 For percentage progress for building indexes, the progress is there, I have managed to push this through some time ago so that one is just fine [https://github.com/apache/cassandra/commit/38f5f9caccabee2601ca5e95884d83857d22bf33]

Once this is merged, issues described in CASSANDRA-14192 will be fixed as well. I found out the exact same reason as Vincent White in his first comment and that is what is included in this patch as well.

Not familiar enough with streaming, so will take a bit to review the latest changes. 

[~blerer] would you mind to go over that? 

Sorry, [~stefan.miklosovic] I got dragged into other things. I will review it tomorrow.  

{quote}However there is a weird clash when this is computed because Netstats reports the total bytes to be sent as total over this "sections size" even it is sent over like compressed, it is compressed by default by CassandraCompressedStreamWriter and the individual "total bytes" per each item to be streamed is taken from its totalSize method and there it is computed as compressed so the numbers dont match.{quote}

In {{CassandraStreamHeader}} if no {{CompressionInfo}} has been provided via the {{CassandraStreamHeader.Builder}} the {{size}} field will be computed in the constructor assuming a {{null}} {{CompressionInfo}}. As {{CassandraOutgoingFile}} creates a {{CassandraStreamHeader}} without providing a {{CompressionInfo}} the size computed will always be wrong for compressed streams.

The correct way to fix the code is in my opinion to remove from the constructor and the builder the {{compressionInfo}} parameter, to remove the {{calculateCompressionInfo()}} method and to compute the {{compressionInfo}} field value within the constructor.

The {{transient}} keyword from the {{compressionInfo}} field can also be removed as the class does not implement {{Serializable}}.

I also noticed that there is an inconsitency between the {{CassandraOutgoingFile#write}} and the {{CassandraStreamHeader#calculateSize}} methods.
If the {{shouldStreamEntireSSTable}} is {{true}} but the {{out}} parameter from the {{write}} method is not an {{AsyncStreamingOutputPlus}} instance the computed size will be the wrong one. I did not investigate in which case this scenario can occurs but we should probably check it too.

[~blerer]

I have incorporated your changes.


Regarding for your last paragraph, the path how output stream gets into CassandraOutgoingFile#write. is located in NettyStreamingMessageSender#FileStreamTask#run() 

{code:java}
                try (DataOutputStreamPlus outPlus = new AsyncStreamingOutputPlus(channel))
                {
                    StreamMessage.serialize(msg, outPlus, streamingVersion, session);
                }
                finally
                {
                    channel.attr(TRANSFERRING_FILE_ATTR).set(Boolean.FALSE);
                }
{code}

The other intersting place is 

NettyStreamingMessageSender#sendControlMessage on line 272 but that code path does not exercise the CassandraOutgoingFile code.

{code:java}
        DataOutputBufferFixed out = new DataOutputBufferFixed(nioBuf);
        StreamMessage.serialize(message, out, streamingVersion, session);
{code}

DataOutputBufferFixed extends DataOutputBuffer whic extend BufferedDataOutputStreamPlus which extends DataOutputStreamPlus so it is not an instance of AsyncStreamingOutputPlus anyway.

CassandraStreamWriter and CassandraCompressedStreamWriter are always casting parameter of their write method to AsyncStreamingOutputPlus.
CassandraEntireSSTableStreamWriter does this casting in CassandraOutgoingFile instead and it takes AsyncStreamingOutputPlus into its write method already.

Hence I believe that such instanceof check is not necessary and it is useless there and I removed it. I have run all junit tests locally and nothing has errored out on that change.

https://github.com/apache/cassandra/pull/711

reviewing CASSANDRA-15861 and think there is a conflict with this patch and that one.  

https://github.com/apache/cassandra/pull/642/files#diff-4df1a97c076e275cb93b00aa7b5624f0R122

just started reviewing, but I think that patch is also trying to fix the size, but does so differently

Overall LGTM, left 2 comments in the PR (should keep header the same as CASSANDRA-15861 and for now lets keep the instanceOf check).  

Going to start testing this patch

CI build: https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=CASSANDRA-15406

Plan to deploy to a cluster to monitor the netstat changes

[~stefan.miklosovic] the changes in CASSANDRA-15861 should have improved the situation on the server side of part.
The size might not be always accurate for a zero copy streaming if the sstable was modified between the streaming plan creation and the sstable transfert but hopefully it should not happen too often.

[~blerer] interesting, I was living with an opinion that SSTable is an immutable construct? How it may happen that the reported size differs over time? 

Some of the SSTable components are not. immutable The statistics contains the sstable level that can change. The index summary can also change when an index redistribution is performed. The index redistribution resize the index summaries in order to give more memory to hot sstables and less memory to cold sstables. 

[~blerer] [~dcapwell] I have rebased this on top of current trunk where CASSANDRA-15861. It is same PR. Jenkins build is here: https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/16/

thanks, I think I can start EOD or tomorrow.

The patch looks good to me.

Thanks [~blerer], I think we need to wait a bit before this hits trunk - there are some bits here which are covering what I do more properly - https://issues.apache.org/jira/browse/CASSANDRA-16057

(y)

up to you but it likely will be a while.  There are a few patches pending for jvm-dtest, then we need to release, then update all branches.

patch +1

Spoke with Stefan in slack and merged as this patch doesn't conflict with the nodetool stdout patch, so no need to wait on it.

CI results:
https://app.circleci.com/pipelines/github/dcapwell/cassandra/537/workflows/57dac3da-9a5d-43f2-a9ae-79999bd1a329
https://ci-cassandra.apache.org/job/Cassandra-devbranch/24/

