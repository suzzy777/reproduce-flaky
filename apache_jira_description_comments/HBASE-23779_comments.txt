Chatting w/ Sean out on slack:
{code}
saintstack Yesterday at 3:57 PM
Looking at faster builds (prompted by a colleagues' exploration). Was looking to up the default fork count. Our jenkins builds seem to use default. Was going to do a fraction of CPUs. Looking at random build, there are 24 CPUs in the build boxes. Looking at the uptime load, says '2'. Could look around more but was thinking of going from default of 4 forks to 0.5CPU#. Testing locally to make sure pass profile is not distrubted (Our test classification has gotten messy... cleaning that up too). Shout if input. Thanks.
6 replies
busbey  16 hours ago
Remember there are 2 executors per node, so optimistically we get 12 cores
busbey  15 hours ago
And if we land on a node with Hadoop tests then maybe only like half that
saintstack  3 minutes ago
So, 0.5CPU sounds like a good number then as its pretty much what we have now
saintstack  3 minutes ago
... only it has advantage of varying w/ machine cpu count.
saintstack  2 minutes ago
...rather than being hardcoded.
{code}

... so let me down what I have here from .75C to 0.5C so we are close to the settings we already have (The patch has 0.75 -- not 0.5 as I suggest in the comment).

Latest patches add MAVEN_ARGs to our yetus hbase personality passing "-T0.5C" which tells maven to run with 0.5 times the count of CPUs of threads. Default is one thread. This change improves build times AND test run times. I got the trick from a [~markrmiller@gmail.com]

bq. More parallelism willl probably mean more test failure. Let me take a look see.

I'm going to convince you this is a good thing! But maybe not on main branches until it's a bit smooth.

Tests passed on branch-2 so pushed it (Thanks for review [~vjasani]). Started https://builds.apache.org/view/H-L/view/HBase/job/HBase%20Nightly/job/branch-2/2451/ Lets see if any difference.  If all good, will push on Master and other branches too. Its a start.

Results for branch branch-2
	[build #2451 on builds.a.o|https://builds.apache.org/job/HBase%20Nightly/job/branch-2/2451/]: (x) *{color:red}-1 overall{color}*
----
details (if available):

(/) {color:green}+1 general checks{color}
-- For more information [see general report|https://builds.apache.org/job/HBase%20Nightly/job/branch-2/2451//General_Nightly_Build_Report/]




(x) {color:red}-1 jdk8 hadoop2 checks{color}
-- For more information [see jdk8 (hadoop2) report|https://builds.apache.org/job/HBase%20Nightly/job/branch-2/2451//JDK8_Nightly_Build_Report_(Hadoop2)/]


(x) {color:red}-1 jdk8 hadoop3 checks{color}
-- For more information [see jdk8 (hadoop3) report|https://builds.apache.org/job/HBase%20Nightly/job/branch-2/2451//JDK8_Nightly_Build_Report_(Hadoop3)/]


(/) {color:green}+1 source release artifact{color}
-- See build output for details.


(/) {color:green}+1 client integration test{color}


After chatting w/ [~busbey] and [~ndimiduk] on slack, change needs to be in master; all nightlies pull the master dev-support (the qa build does use the branch dev-support)... so just now pushed to master. Will report back on how it does.

This run is using the new hbase-personality ... hopefully: https://builds.apache.org/view/H-L/view/HBase/job/HBase%20Nightly/job/branch-2/2452/

Results for branch master
	[build #1621 on builds.a.o|https://builds.apache.org/job/HBase%20Nightly/job/master/1621/]: (x) *{color:red}-1 overall{color}*
----
details (if available):

(/) {color:green}+1 general checks{color}
-- For more information [see general report|https://builds.apache.org/job/HBase%20Nightly/job/master/1621//General_Nightly_Build_Report/]




(x) {color:red}-1 jdk8 hadoop2 checks{color}
-- For more information [see jdk8 (hadoop2) report|https://builds.apache.org/job/HBase%20Nightly/job/master/1621//JDK8_Nightly_Build_Report_(Hadoop2)/]


(x) {color:red}-1 jdk8 hadoop3 checks{color}
-- For more information [see jdk8 (hadoop3) report|https://builds.apache.org/job/HBase%20Nightly/job/master/1621//JDK8_Nightly_Build_Report_(Hadoop3)/]


(/) {color:green}+1 source release artifact{color}
-- See build output for details.


(/) {color:green}+1 client integration test{color}


Results for branch master
	[build #1622 on builds.a.o|https://builds.apache.org/job/HBase%20Nightly/job/master/1622/]: (x) *{color:red}-1 overall{color}*
----
details (if available):

(/) {color:green}+1 general checks{color}
-- For more information [see general report|https://builds.apache.org/job/HBase%20Nightly/job/master/1622//General_Nightly_Build_Report/]




(x) {color:red}-1 jdk8 hadoop2 checks{color}
-- For more information [see jdk8 (hadoop2) report|https://builds.apache.org/job/HBase%20Nightly/job/master/1622//JDK8_Nightly_Build_Report_(Hadoop2)/]


(x) {color:red}-1 jdk8 hadoop3 checks{color}
-- For more information [see jdk8 (hadoop3) report|https://builds.apache.org/job/HBase%20Nightly/job/master/1622//JDK8_Nightly_Build_Report_(Hadoop3)/]


(/) {color:green}+1 source release artifact{color}
-- See build output for details.


(/) {color:green}+1 client integration test{color}


I pushed this last night into master branch as addendum in hbase-personality. It don't seem to work either:
{code}
commit 867b1e9cbca6217da84d12b8a1772af8e607bd36 (HEAD -> m, origin/master, origin/HEAD)
Author: stack <stack@apache.org>
Date:   Wed Feb 5 21:47:34 2020 -0800

    HBASE-23779 Up the default fork count; make count relative to CPU count (#1108)
    ADDENDUM: Try this way of setting MAVEN_ARGS

diff --git a/dev-support/hbase-personality.sh b/dev-support/hbase-personality.sh
index 76fc96bf76..169f19abcc 100755
--- a/dev-support/hbase-personality.sh
+++ b/dev-support/hbase-personality.sh
@@ -81,13 +81,14 @@ function personality_globals

   # Override the maven options
   MAVEN_OPTS="${MAVEN_OPTS:-"-Xms4G -Xmx4G"}"
+
   # Pass maven a -T argument. Should make it run faster. Pass conservative value.
   # Default is one thread. 0.5C on an apache box of 24 cores and 2 executors should
   # make for 6 threads? Lets see. Setting this here for yetus to pick up. See
   # https://yetus.apache.org/documentation/0.11.1/precommit-advanced/#global-definitions
   # See below for more on -T:
   # https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3
-  export MAVEN_ARGS="-T0.5C ${MAVEN_ARGS}"
+  MAVEN_ARGS=("-T0.5C" "${MAVEN_ARGS[@]}")
{code}

In theory https://builds.apache.org/view/H-L/view/HBase/job/PreCommit-HBASE-Build/1121/ will tell us if the yetus patch works.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  1m 13s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} dupname {color} | {color:green}  0m  0s{color} | {color:green} No case conflicting files found. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:orange}-0{color} | {color:orange} test4tests {color} | {color:orange}  0m  0s{color} | {color:orange} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} master Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  5m 27s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  3m  4s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 44s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m  3s{color} | {color:green} master passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  5m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  3m  6s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  3m  6s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  5m 13s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |
| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green} 16m 31s{color} | {color:green} Patch does not cause any errors with Hadoop 2.8.5 2.9.2 or 3.1.2. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m  8s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}112m 48s{color} | {color:red} root in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}170m 50s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hbase.mapred.TestTableOutputFormatConnectionExhaust |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=19.03.5 Server=19.03.5 base: https://builds.apache.org/job/PreCommit-HBASE-Build/1121/artifact/patchprocess/Dockerfile |
| JIRA Issue | HBASE-23779 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12992800/test_yetus_934.0.patch |
| Optional Tests | dupname asflicense javac javadoc unit shadedjars hadoopcheck xml compile |
| uname | Linux fff8a70ade7d 4.15.0-60-generic #67-Ubuntu SMP Thu Aug 22 16:55:30 UTC 2019 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | dev-support/hbase-personality.sh |
| git revision | master / 93c5e7691f |
| Default Java | 1.8.0_181 |
| unit | https://builds.apache.org/job/PreCommit-HBASE-Build/1121/artifact/patchprocess/patch-unit-root.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/1121/testReport/ |
| Max. process+thread count | 8328 (vs. ulimit of 10000) |
| modules | C: . U: . |
| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/1121/console |
| versions | git=2.11.0 maven=2018-06-17T18:33:14Z) |
| Powered by | Apache Yetus 0.11.1 https://yetus.apache.org |


This message was automatically generated.



Dang... Still not picking up our MAVEN_ARGS https://builds.apache.org/view/H-L/view/HBase/job/PreCommit-HBASE-Build/1121/consoleText

That didn't use my yetus repo. Trying again, https://builds.apache.org/view/H-L/view/HBase/job/PreCommit-HBASE-Build/1122/

Okay, I cannot test my yetus patch using our precommit because the layout of the repo artifact generated by GitHub doesn't match that script's expectations. Looks like {{test-patch.sh}} was moved since this job was authored, it's now under {{precommit/src/main/shell}}.

{noformat}
08:34:51 + prerelease_dirs=(${TEST_FRAMEWORK}/${YETUS_PRERELEASE_GITHUB/\//-}-*)
08:34:51 + TESTPATCHBIN=/home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/test_framework/ndimiduk-yetus-7d6ff39/precommit/test-patch.sh
08:34:51 + TESTPATCHLIB=/home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/test_framework/ndimiduk-yetus-7d6ff39/precommit
08:34:51 + [[ true = \t\r\u\e ]]
08:34:51 + ls -l /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/test_framework/ndimiduk-yetus-7d6ff39/precommit/test-patch.sh
08:34:51 ls: cannot access '/home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/test_framework/ndimiduk-yetus-7d6ff39/precommit/test-patch.sh': No such file or directory
08:34:52 Build step 'Execute shell' marked build as failure
{noformat}

[~busbey] any objection if I modify the Jenkins script as follows?

{noformat}
diff --git a/dev-support/PreCommit-HBase-Build.sh b/dev-support/PreCommit-HBase-Build.sh
index f1494978ea..798b829c3d 100644
--- a/dev-support/PreCommit-HBase-Build.sh
+++ b/dev-support/PreCommit-HBase-Build.sh
@@ -82,8 +82,8 @@ else
     tar xvpf yetus.tar.gz
     prerelease_dirs=(${TEST_FRAMEWORK}/${YETUS_PRERELEASE_GITHUB/\//-}-*)
   fi
-  TESTPATCHBIN=${prerelease_dirs[0]}/precommit/test-patch.sh
-  TESTPATCHLIB=${prerelease_dirs[0]}/precommit
+  TESTPATCHBIN=${prerelease_dirs[0]}/precommit/src/main/shell/test-patch.sh
+  TESTPATCHLIB=${prerelease_dirs[0]}/precommit/src/main/shell
 fi
 
 if [[ "true" = "${DEBUG}" ]]; then
{noformat}

New addendum. See below. Pushed on Master only for now. Kicked off https://builds.apache.org/view/H-L/view/HBase/job/HBase%20Nightly/job/branch-2/2456/ Lets see. This addendum comes of discussion over in https://github.com/apache/yetus/pull/86

{code}
commit ef380e0a2e3ba138391968126fd0e9d5c910df88 (HEAD -> m, origin/master, origin/HEAD)
Author: stack <stack@apache.org>
Date:   Fri Feb 7 09:40:51 2020 -0800

     HBASE-23779 Up the default fork count; make count relative to CPU count (#1108)
     ADDENDUM: Refactor that comes of discussion up on https://github.com/apache/yetus/pull/86
     because what I committed originally, and amended in a subsequent
     ADDENDUM is not taking effect.

diff --git a/dev-support/hbase-personality.sh b/dev-support/hbase-personality.sh
index 169f19abcc..7f961c0e1e 100755
--- a/dev-support/hbase-personality.sh
+++ b/dev-support/hbase-personality.sh
@@ -82,14 +82,6 @@ function personality_globals
   # Override the maven options
   MAVEN_OPTS="${MAVEN_OPTS:-"-Xms4G -Xmx4G"}"

-  # Pass maven a -T argument. Should make it run faster. Pass conservative value.
-  # Default is one thread. 0.5C on an apache box of 24 cores and 2 executors should
-  # make for 6 threads? Lets see. Setting this here for yetus to pick up. See
-  # https://yetus.apache.org/documentation/0.11.1/precommit-advanced/#global-definitions
-  # See below for more on -T:
-  # https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3
-  MAVEN_ARGS=("-T0.5C" "${MAVEN_ARGS[@]}")
-
   # Yetus 0.7.0 enforces limits. Default proclimit is 1000.
   # Up it. See HBASE-19902 for how we arrived at this number.
   #shellcheck disable=SC2034
@@ -148,7 +140,11 @@ function personality_modules

   clear_personality_queue

-  extra="-DHBasePatchProcess"
+  # Pass maven a -T argument. Should make it run faster. Pass conservative value.
+  # Default is one thread. 0.5C on an apache box of 24 cores and 2 executors should
+  # make for 6 threads? Lets see. See below for more on -T:
+  # https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3
+  extra="-T0.5C -DHBasePatchProcess"
   if [[ "${PATCH_BRANCH}" = branch-1* ]]; then
     extra="${extra} -Dhttps.protocols=TLSv1.2"
   fi
{code}

Added addendum as patch here.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  7s{color} | {color:red} HBASE-23779 does not apply to master. Rebase required? Wrong Branch? See https://yetus.apache.org/documentation/in-progress/precommit-patchnames for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HBASE-23779 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12992918/addendum2.patch |
| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/1124/console |
| versions | git=2.17.1 |
| Powered by | Apache Yetus 0.11.1 https://yetus.apache.org |


This message was automatically generated.



So editing extras gets my -T into the mix. Hurray! But ouch! The h2 and h3 unit test pages are just cut-off... unfinished. Haven't seen that before.  https://builds.apache.org/view/H-L/view/HBase/job/HBase%20Nightly/job/branch-2/2456/artifact/output-jdk8-hadoop3/patch-unit-root.txt Trying again https://builds.apache.org/view/H-L/view/HBase/job/HBase%20Nightly/job/branch-2/2458/

Ok. An the next run, https://builds.apache.org/view/H-L/view/HBase/job/HBase%20Nightly/job/branch-2/2458/artifact/, hadoop2 test got cut off as in previous run. hadoop3 test made it to the end but a bunch of them timedout w/ process exit complaint.

Reverting the changes in dev-support/hbase-personality.sh from my patch where I try to add -T0.5C to all mvn invocations. Will leave it as default single-threaded for now.

Pushed the patch to branch-2 and master.

Then spent time playing w/ the changes made to hbase-personality seeing if I could speed jenkins even more by adding the -T flag on each jenkins invocation. Took a few ADDENDUMs which show in the master log.  In the end, the -T seems to destabilize jenkins build so the last ADDENDUM reverts changes made to hbase-personality in both master and branch-2.3. All the rest of the patch making forkcount a factor of cpu count remains.

Resolving.

Results for branch branch-2
	[build #2459 on builds.a.o|https://builds.apache.org/job/HBase%20Nightly/job/branch-2/2459/]: (x) *{color:red}-1 overall{color}*
----
details (if available):

(/) {color:green}+1 general checks{color}
-- For more information [see general report|https://builds.apache.org/job/HBase%20Nightly/job/branch-2/2459//General_Nightly_Build_Report/]




(x) {color:red}-1 jdk8 hadoop2 checks{color}
-- For more information [see jdk8 (hadoop2) report|https://builds.apache.org/job/HBase%20Nightly/job/branch-2/2459//JDK8_Nightly_Build_Report_(Hadoop2)/]


(x) {color:red}-1 jdk8 hadoop3 checks{color}
-- For more information [see jdk8 (hadoop3) report|https://builds.apache.org/job/HBase%20Nightly/job/branch-2/2459//JDK8_Nightly_Build_Report_(Hadoop3)/]


(/) {color:green}+1 source release artifact{color}
-- See build output for details.


(/) {color:green}+1 client integration test{color}


Results for branch master
	[build #1623 on builds.a.o|https://builds.apache.org/job/HBase%20Nightly/job/master/1623/]: (x) *{color:red}-1 overall{color}*
----
details (if available):

(/) {color:green}+1 general checks{color}
-- For more information [see general report|https://builds.apache.org/job/HBase%20Nightly/job/master/1623//General_Nightly_Build_Report/]




(x) {color:red}-1 jdk8 hadoop2 checks{color}
-- For more information [see jdk8 (hadoop2) report|https://builds.apache.org/job/HBase%20Nightly/job/master/1623//JDK8_Nightly_Build_Report_(Hadoop2)/]


(x) {color:red}-1 jdk8 hadoop3 checks{color}
-- For more information [see jdk8 (hadoop3) report|https://builds.apache.org/job/HBase%20Nightly/job/master/1623//JDK8_Nightly_Build_Report_(Hadoop3)/]


(/) {color:green}+1 source release artifact{color}
-- See build output for details.


(/) {color:green}+1 client integration test{color}


[~stack] Do we need to bump up the ulimits after these changes? The jobs are running into proc limits (example below). This is happening in the pre-commits too.

{noformat}
Error Message
java.lang.Exception: java.lang.OutOfMemoryError: unable to create new native thread
Stacktrace
java.io.IOException: java.lang.Exception: java.lang.OutOfMemoryError: unable to create new native thread
	at org.apache.hadoop.hbase.replication.multiwal.TestReplicationKillMasterRSCompressedWithMultipleAsyncWAL.setUpBeforeClass(TestReplicationKillMasterRSCompressedWithMultipleAsyncWAL.java:42)
{noformat}

Example: https://builds.apache.org/job/HBase%20Nightly/job/master/1623//testReport/junit/org.apache.hadoop.hbase.replication.multiwal/TestReplicationKillMasterRSCompressedWithMultipleAsyncWAL/health_checks___yetus_jdk8_hadoop2_checks___/

bq. Do we need to bump up the ulimits after these changes? 

Funny. I presumed 'unable to create new native thread' because we were running on a box that was hosting us and others that had hit saturation but your suggestion I think is a good one. Average for file count is reported by yetus and its usually around the 5k. Perhaps the -T has us aggregate file counts? I could try poking here locally (where I seem to have a setup that doesn't have these OOME issues). Sean set up listing machine attributes here: https://builds.apache.org/job/HBase%20Nightly/job/master/1623/artifact/output-general/machine/ulimit-l/*view*/ .... where we can see file count is 16k. Let me open a subtask to experiment in.

Couple notes I've noticed:
 # -T doesn't not seem to work so well for downloading deps at the least. If I don't do a non -T to download and make sure I have all deps at some point first, I see crashes.
 # In my experience, cannot create native thread due to OOM tends to be a RAM issue more often than open file limit issue. You can often help that by not accepting default huge stack sizes per thread - you don't often need nearly as much as some of the high defaults for that these days - try a megabyte.
 # More threads and tests at the same time uses more RAM of course, another way to help is to peg an Xms of like 256 or something, rather than just setting Xmx  - encourage the tests that don't need so much RAM to not claim it to begin with.

{quote}Average for file count is reported by yetus and its usually around the 5k. Perhaps the -T has us aggregate file counts?
{quote}
I don't think it is always around 5k. In fact, I suspected ulimits because the failed jobs I looked at, were running dangerously close to the proc limit of 10k enforced by yetus (example: 9901 (vs. ulimit of 10000)). But I do agree that it could be a memory issue too, like Mark mentioned.

Looks like yetus gets this data by polling it from the OS in a loop [1]. So I'd assume it is accurate. For some reason this report only shows up only in the precommits and not in nightly builds (am I wrong?).

[1] [https://github.com/apache/yetus/blob/b3a402b012773c94e2ade0797e893d9a14e9f0ed/precommit/src/main/shell/coprocs.d/process_counter.sh#L34]

bq. I don't think it is always around 5k. 

You are right. I see 9k+. Let me try [~markrmiller] suggested trick in subtask. Yetus polling probably misses spikes? On native thread creation, my experience has been that not enough file handles can manifest in mysterious ways. Can work on other Mark suggestions in follow-ons. Heading down to the subtask now...

bq. Sean Busbey any objection if I modify the Jenkins script as follows?

Sorry, some how missed this. I think the correct thing to do in the case of running a non-release is to do a build of Yetus and then consume the binary off of that. I *think* yetus precommit works directly from source, but I don't think the project promises it will nor intends folks to do that.

FYI re: the -T arg

I'm finding it's pretty sensitive to the Maven version - the 3.5.* I seem to get from the yetus Dockerfile in dev-support is crashing all the time, 3.6.1 has been behaving as I've been used to (my main desktop had 3.6.1 to start)

I see what's going on here. A lot ;)

To some degree Maven is not helping - the equivalent approximation to Gradles awesome parallel build performance can be a fair bit more expensive at the least. That's just half the equation though. Its really largely small-med or potentially small-med tests masquerading as large or super large tests and/or waiting for a non CI, less intense option. Expanding limits and trying to baby and isolate the tests has gotten HBase to like a billion tests, which I am both impressed and frustrated with. So. Many. Test classes. Just tossing that many no op tests at an executor is going to take some time - toss a new 2800Mb JVM in between for most of them and it will take a little more :)

We could address it all within a few months time (the basics anyway, really so much that can be done and improved on the basics). I'll convince someone to champion a reverse course and shrink resources and expose the tests to a bit of hell on purpose for profit and pleasure. There is a lot of hidden flakiness, which is a valid strategy in these cases - if you can hide it well enough, at least it's a mostly rational signal. But with so many tests and hours running times, any real stability will be forever elusive, a mirage, or hanging on a dime. You also just pay for it in so many ways, even if it does end up with some success.

We can expose these tests to sunlight and it will force us to shape them right up.

 

In the meantime, some some ideas on JVM args that be able to help the situation a little.

-XX:-UseContainerSupport - when running in docker, query docker for hardware info, not the host. I have not played with it, but makes sense to me.

-XX:ActiveProcessorCount - fake the active processer count to 1 - when running multiple jvms, you don't want each one to think it should grab 32 gc threads on your 32 hyperthreaded core machine. I'd much prefer to run 32 JVMs and have 32 gc threads.

-XX:+AlwaysPreTouch -XX:+UseTransparentHugePages - given so much JVM startup and shutdowns, some things might help more when there is more JVM reuse - so much time and cost is in creating large heap jvms and spinning up lots of unused resources and threads that it's hard to win much with good tuning - but huge pages, always a nice win.

-XX:+UseParallelGC -XX:TieredStopAtLevel=1 - even when G1 is available, this is gold standard for test speed. Maybe with like -XX:ParallelGCThreads=1 if not using ActiveProcessorCout. 

Probably not a big advantage when each med/large JVM is spinning up thousands of useless threads that eat ram, heap and os resources, but something, and probably pretty nice for small test single jvm runs now.

It's also generally best to pin Xms and Xmx vs eat all the resizing cost. I suggest the opposite above given the RAM reqs - to keep the JVMs that don't need it from sucking up so much RAM unnecessarily - but with good reuse, you want to pin them.

Most of the tests don't need these huge heaps and limits - I think that having them for the bad apples and outliers just allows the 95% of tests to easily be wasteful and misbehave.

 

 * Note: UseContainerSupport is enabled by default - the above disables - so guess that should already be in affect.

 

{quote}
bq. [~busbey] any objection if I modify the Jenkins script as follows?
Sorry, some how missed this. I think the correct thing to do in the case of running a non-release is to do a build of Yetus and then consume the binary off of that. I *think* yetus precommit works directly from source, but I don't think the project promises it will nor intends folks to do that.
{quote}

We base the assumption that Yetus pre-commit works from source in a handful of places. I found it also in {{Jenkinsfile_Github}} as {{${WORKSPACE}/${YETUS}/precommit/src/main/shell/test-patch.sh}} and in {{hbase_nightly_yetus.sh}} as {{${WORKSPACE}/yetus-git/precommit/test-patch.sh}}.

yeah no, we should not do that. it's only a matter of time before it bites us.

Filed HBASE-23873.

I think this is the root cause of the recently mess? 0.5C seems a bit aggresive? And I think we should also take care of memory? if we run UTs on a 32 core 64GB memory machine, we will have 16 processes and each consume 4GB of memory(we even need more?), it will easy lead to OOM and cause all UTs to fail randomly...

Most tests don’t really need even more than 1GB of memory at most - I think that is the larger issue. The ‘limits’ creep that occurs in the simpler search of more stable tests - it often ends up just being a cover for ugly stuff.

Reopening. Was resolved because thought there no elbow room here but have been making progress on this master project off in side issues. Let me bring the work together back here under this issue.

High-level, trying to run w/ more parallelism -- forkcount and the mvn -T -- we ran into limits. Experiments trying to up our forkcount to 0.5C (8 cores on apache jenkins) ran into container memory (hard-coded at 20G, box is 48G w/ two executors per box so 24G each... See HBASE-24134) and host/user ulimit upper-bounds (per [~bharathv] in his comments above ... see HBASE-24126).  Returning fork count down to 0.25C re-stabilized builds (along w/ test fixes). Minimally would at least like to add -T0.25C to maven before resolving this issue again. Maximally, would like to get build running on jenkins at 0.5C (In local tests build takes twice as long if forkcount+ T arg are halved... say from 0.5C to 0.25C). =

In local tests, I can run with 1.0C.  On a 40CPU linux machine, it is a bit wobbly.  It was wobbly on big GCE instances but I should revisit. On a 16CPU mac, it seems fine as on a 4CPU VM. For Jenkins, 0.5C might be doable. Lets try again now we know more.

Branch-2 has the upped nproc patch applied (HBASE-24126) and infra upped the per-user nproc count from 10000 to 30000. branch-2 also has HBASE-24134 applied so we should use less memory. The new PR against this issue, https://github.com/apache/hbase/pull/1461, changes our forkcount from 0.25 to 0.5 and passes -T to mvn of 0.5C. Looking to see the test run time halved. Below are what branch-2 build times currently look like.

 !Screen Shot 2020-04-08 at 9.19.53 AM.png! 

The new subissue HBASE-24150 takes a different tack. It allows two modules when possible to run their tests in parallel. It leaves the forkcount at 0.25C but ups the mvn --threads argument from default of '1' to '2'. In tests running local builds, a machine completed full test suite in 1hr 15mins w/ forkcount of 1.0C and --threads=1. When same machine ran full suite of tests with forkcount of 0.5C and --threads=2, it completed in 53mins. Lets see what we get.

Heads up in your memory calculations -- after INFRA-20018, there jenkins worker process us allocated 16g of heap. I think it only uses that when it's aggregating surefire reports, so, by definition, after the tests have run.

Ok. Just pushed subtask HBASE-24150. It adds -T2 to all mvn invocations. I pushed it in favor of the patch that is here against this issue which doubles the forkcount from 0.25C to 0.5C since in testing -- both here and locally -- it seems to give the biggest improvement in elapsed build times and is least threatening to stability. Originally I was trying to do a combination of the approaches upping forkcount and passing a fat -T value to mvn but seems to destabilize.

I pushed on branch-2 only for now. Will study it. If all good, will push everywhere.

Waiting for more nightlies to pass so can put up an assessment of speedup that comes of this work.

 !Screen Shot 2020-04-13 at 4.09.49 PM.png! 

Hard to say what definitive improvement is.  Changes went in after build #3589 in the diagram. Looking at the jdk8/hadoop2 column, before patch, tests were taking 4hr25mins approx (Up to 5hrs... but could be as low as 4hrs).  Post patch, same column is about 3hrs 18mins on average. Thats about 25% difference?  Other columns are more erratic in their timings. Hopefully an improvement. Resolving.

Resolved. Upshot of the survey work done in here is summarized in the release note.

