I disabled the tests for now to get a better CI signal: https://github.com/apache/flink/commit/5374cfec2231fb14a70bd786424a18daee383231

[~aljoscha] I would expect 1.9 branch to be affected by this as well.

[~gjy], why adding another source exhausts the available slots? Shouldn't the slots be shared? Also do you know why it happens only "under normal circumstances" and not always?

[~fly_in_gis] FYI

[~gjy] [~pnowojski] [~aljoscha]

I think the flink job should not fail with not enough slots. We start 3 TaskManager with 1 slot for each, and each slot could run a complete pipeline. I have tested on a real yarn cluster, it always works as expected. Only 3 TaskManagers are started and the job finished successfully.

Â 

Â 
{code:java}
./bin/flink run -d -p 3 -m yarn-cluster examples/streaming/WordCount.jar --input dummy://localhost/words --input anotherDummy://localhost/words
{code}
Â 

I have gone over the logs and find that the `SlotPoolImpl` allocates 4 slot. It should be only 3. May some bugs happen in Scheduler internally.Â 

[~fly_in_gis] You might be right? I'll keep investigating this myself. But if more people could look at it it would be good.

Maybe the reason is the same as FLINK-14834 in the end. ðŸ˜…

Does this also happen when running the WordCount job from the IDE or at least in standalone mode? Would be good to be able to set a breakpoint for debugging.

It's very strange, I'm running this on my machine against a standalone 3-TM cluster and it didn't fail so far. It is reproducible on my local machine using the yarn/kerberos docker test, though. But that's hard to debug.

Something very strange is going on. When I try this on a (dockerized) YARN cluster the job sometimes needs 3 slots to run and sometimes needs 4 slots. I run this job:

{code}
bin/flink run -m yarn-cluster -p 3 -yjm 2000 -ytm 2000 examples/streaming/WordCount.jar --input hdfs:///wc-in-1 --input hdfs:///wc-in-2 --output hdfs:///wc-out
{code}

The attached logs show the (DEBUG) jobmanager.log of two different runs. Try searching for "Requesting new slot".

I'm closing this as a duplicate because the underlying reason does indeed seem to be the same as for FLINK-14834

