It's difficult for me to tell why these jobs are failing, the logs are quite verbose.

I'm trying to reproduce it locally but haven't been able to get the error.

This issue is assigned but has not received an update in 30 days so it has been labeled "stale-assigned". If you are still working on the issue, please give an update and remove the label. If you are no longer working on the issue, please unassign so someone else may work on it. In 7 days the issue will be automatically unassigned.

This issue was marked "stale-assigned" and has not received a public comment in 7 days. It is now automatically unassigned. If you are still working on it, you can assign it to yourself again. Please also give an update about the status of the work.

It looks like the error handling code is running into the same problem as BEAM-12794.

[~yichi] - Could you look at this issue when you get a chance? Looks like an issue in the sdk_worker.

I've looked at it before and couldn't get a repro, I think the issue is a transient failure in grpc networking on jenkins machine, as mentioned in [https://grpc.github.io/grpc/core/md_doc_statuscodes.html] status code 14. I guess the easy workaround is to add retry to this test suite that uses grpc. 

I think we should keep this open to identify the root cause and remove the retries. The cause of the flakes is likely a real issue that we're masking with the retries.

I agree that this is probably masking real issues currently, one possible improvement we can try is only retry on grpc networking issues. Or we somehow find out how to avoid this grpc issues.

I did a little bit of investigation I'll summarize here:
 * Per [this SO|https://stackoverflow.com/questions/45668153/when-does-a-broken-pipe-occur-in-a-tcp-stream] broken pipe indicates the other end has closed the TCP connection. I suppose this indicates there's an issue on the runner side of this connection - for some reason closing the connection prematurely?
 * I'm attempting to reproduce the issue locally and/or on Jenkins so we can investigate with that in mind:
 ** Locally - Started exercising fn_runner_test with retries removed repeatedly until a failure occurs:
{code:bash}
i=0; while python -m pytest apache_beam/runners/portability/fn_api_runner/fn_runner_test.py -n 12 -rFe; do i=$((i+1)); echo "FINISHED $i RUNS"; done{code}

 ** On Jenkins - Put up WIP [https://github.com/apache/beam/pull/17528]

After 18 local runs I got one relevant looking failure:
{code:java}
------------------------------------------------ Captured log call -------------------------------------------------
WARNING  root:environments.py:371 Make sure that locally built Python SDK docker image has Python 3.8 interpreter.                                                                                                                      
ERROR    apache_beam.runners.worker.data_plane:data_plane.py:641 Failed to read inputs in the data plane.                                                                                                                               
Traceback (most recent call last):                                                                                                                                                                                                      
  File "/usr/local/google/home/bhulette/working_dir/beam/sdks/python/apache_beam/runners/worker/data_plane.py", line 634, in _read_inputs                                                                                               
    for elements in elements_iterator:                                                                                                                                                                                                  
  File "/usr/local/google/home/bhulette/.pyenv/versions/beam/lib/python3.8/site-packages/grpc/_channel.py", line 426, in __next__                                                                                                       
    return self._next()                                                                                                                                                                                                                 
  File "/usr/local/google/home/bhulette/.pyenv/versions/beam/lib/python3.8/site-packages/grpc/_channel.py", line 809, in _next                                                                                                          
    raise self                                                                                                                                                                                                                          
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:                                                                                                                                          
        status = StatusCode.UNAVAILABLE                                                                                                                                                                                                 
        details = "Broken pipe"                                                                                     
        debug_error_string = "{"created":"@1651529196.891387421","description":"Error received from peer ipv6:[::1]:34715","file":"src/core/lib/surface/call.cc","file_line":903,"grpc_message":"Broken pipe","grpc_status":14}"        
>                                                                                                                   
ERROR    apache_beam.runners.worker.sdk_worker:sdk_worker.py:271 Error processing instruction bundle_58. Original traceback is           
                                                                 Traceback (most recent call last):                 
                                                                   File "/usr/local/google/home/bhulette/working_dir/beam/sdks/python/apache_beam/runners/worker/data_plane.py", line 487, in input_elements                            
                                                                     element = received.get(timeout=1)                                                                                                                                  
                                                                   File "/usr/local/google/home/bhulette/.pyenv/versions/3.8.6/lib/python3.8/queue.py", line 178, in get                                                                
                                                                     raise Empty                                    
                                                                 _queue.Empty                                                                                                                                                           
                                                                                                                                                                                                                                        
                                                                 During handling of the above exception, another exception occurred:                                                                                                    
                                                                                                                                                                                                                                        
                                                                 Traceback (most recent call last):                 
                                                                   File "/usr/local/google/home/bhulette/working_dir/beam/sdks/python/apache_beam/runners/worker/sdk_worker.py", line 267, in _execute                                  
                                                                     response = task()                                                                                                                                                  
                                                                   File "/usr/local/google/home/bhulette/working_dir/beam/sdks/python/apache_beam/runners/worker/sdk_worker.py", line 340, in <lambda>                                  
                                                                     lambda: self.create_worker().do_instruction(request), request)                                                                                                     
                                                                   File "/usr/local/google/home/bhulette/working_dir/beam/sdks/python/apache_beam/runners/worker/sdk_worker.py", line 580, in do_instruction                            
                                                                     return getattr(self, request_type)(            
                                                                   File "/usr/local/google/home/bhulette/working_dir/beam/sdks/python/apache_beam/runners/worker/sdk_worker.py", line 618, in process_bundle                            
                                                                     bundle_processor.process_bundle(instruction_id))                                                                                                                   
                                                                   File "/usr/local/google/home/bhulette/working_dir/beam/sdks/python/apache_beam/runners/worker/bundle_processor.py", line 984, in process_bundle                      
                                                                     for element in data_channel.input_elements(instruction_id,                                                                                                         
                                                                   File "/usr/local/google/home/bhulette/working_dir/beam/sdks/python/apache_beam/runners/worker/data_plane.py", line 490, in input_elements
                                                                     raise RuntimeError('Channel closed prematurely.')                                                                                                                  
                                                                 RuntimeError: Channel closed prematurely.                                                                                                                              
============================================= short test summary info ==============================================
FAILED apache_beam/runners/portability/fn_api_runner/fn_runner_test.py::FnApiRunnerTestWithDisabledCaching::test_sdf_default_truncate_when_unbounded
================================ 1 failed, 336 passed, 40 skipped in 22.71 seconds =================================
{code}

Got another local failure that looks like the originally posted one after 13 tries:
{code}
                                                                   File "/usr/local/google/home/bhulette/.pyenv/versions/3.8.6/lib/python3.8/threading.py", line 932, in _bootstrap_inner
                                                                     self.run()
                                                                   File "/usr/local/google/home/bhulette/.pyenv/versions/3.8.6/lib/python3.8/threading.py", line 870, in run
                                                                     self._target(*self._args, **self._kwargs)
                                                                   File "/usr/local/google/home/bhulette/working_dir/beam/sdks/python/apache_beam/runners/worker/sdk_worker.py", line 990, in pull_responses
                                                                     for response in responses:
                                                                   File "/usr/local/google/home/bhulette/.pyenv/versions/beam/lib/python3.8/site-packages/grpc/_channel.py", line 426, in __next__
                                                                     return self._next()
                                                                   File "/usr/local/google/home/bhulette/.pyenv/versions/beam/lib/python3.8/site-packages/grpc/_channel.py", line 809, in _next
                                                                     raise self
                                                                 RuntimeError: grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
                                                                        status = StatusCode.UNAVAILABLE
                                                                        details = "Broken pipe"
                                                                        debug_error_string = "{"created":"@1651530177.250911467","description":"Error received from peer ipv6:[::1]:46355","file":"src/core/lib/surface/call.cc","file_line":903,"grpc_message":"Broken pipe","grpc_status":14}"
                                                                 > [while running 'ParDo(TimerDoFn)']
============================================= short test summary info ==============================================
FAILED apache_beam/runners/portability/fn_api_runner/fn_runner_test.py::FnApiRunnerTestWithGrpcAndMultiWorkers::test_pardo_timers
================================ 1 failed, 336 passed, 40 skipped in 23.01 seconds =================================
{code}

another failure, this time with debug logging enabled ({{{}i=0; while python -m pytest apache_beam/runners/portability/fn_api_runner/fn_runner_test.py -n 12 -rFe --log-level=DEBUG; do i=$((i+1)); echo "FINISHED $i RUNS"; done{}}})
{code:java}
...
INFO     apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function populate_data_channel_coders at 0x7f79f3c39700> ====================                                             
DEBUG    apache_beam.runners.portability.fn_api_runner.translations:translations.py:716 5 [6, 5, 10, 2, 5]                                                                                                                              
DEBUG    apache_beam.runners.portability.fn_api_runner.translations:translations.py:717 Stages: ['(((((ref_AppliedPTransform_assert_that-Create-Impulse_17)+(ref_AppliedPTransform_assert_that-Create-FlatMap-lambda-at-core-py-3320-_18
))+(ref_AppliedPTransform_assert_that-Create-Map-decode-_20))+(ref_AppliedPTransform_assert_that-Group-CoGroupByKeyImpl-Tag-0-_25))+(assert_that/Group/CoGroupByKeyImpl/Flatten/Transcode/0))+(assert_that/Group/CoGroupByKeyImpl/Flatte
n/Write/0)\n  assert_that/Create/FlatMap(<lambda at core.py:3320>):beam:transform:pardo:v1\nassert_that/Create/Map(decode):beam:transform:pardo:v1\nassert_that/Group/CoGroupByKeyImpl/Tag[0]:beam:transform:pardo:v1\nassert_that/Group
/CoGroupByKeyImpl/Flatten/Transcode/0:beam:transform:flatten:v1\nassert_that/Group/CoGroupByKeyImpl/Flatten/Write/0:beam:runner:sink:v1\nassert_that/Create/Impulse:beam:runner:source:v1\n  must follow: \n  downstream_side_inputs: ',
 '((((ref_AppliedPTransform_Create-Impulse_3)+(ref_AppliedPTransform_Create-FlatMap-lambda-at-core-py-3320-_4))+(ref_AppliedPTransform_Create-MaybeReshuffle-Reshuffle-AddRandomKeys_7))+(ref_AppliedPTransform_Create-MaybeReshuffle-Re
shuffle-ReshufflePerKey-Map-reify_timestamps-_9))+(Create/MaybeReshuffle/Reshuffle/ReshufflePerKey/GroupByKey/Write)\n  Create/FlatMap(<lambda at core.py:3320>):beam:transform:pardo:v1\nCreate/MaybeReshuffle/Reshuffle/AddRandomKeys:
beam:transform:pardo:v1\nCreate/MaybeReshuffle/Reshuffle/ReshufflePerKey/Map(reify_timestamps):beam:transform:pardo:v1\nCreate/MaybeReshuffle/Reshuffle/ReshufflePerKey/GroupByKey/Write:beam:runner:sink:v1\nCreate/Impulse:beam:runner
:source:v1\n  must follow: \n  downstream_side_inputs: ', '(((((((((Create/MaybeReshuffle/Reshuffle/ReshufflePerKey/GroupByKey/Read)+(ref_AppliedPTransform_Create-MaybeReshuffle-Reshuffle-ReshufflePerKey-FlatMap-restore_timestamps-_
11))+(ref_AppliedPTransform_Create-MaybeReshuffle-Reshuffle-RemoveRandomKeys_12))+(ref_AppliedPTransform_Create-Map-decode-_13))+(ref_AppliedPTransform_ParDo-DynamicTimerDoFn-_14))+(ref_AppliedPTransform_assert_that-WindowInto-Windo
wIntoFn-_21))+(ref_AppliedPTransform_assert_that-ToVoidKey_22))+(ref_AppliedPTransform_assert_that-Group-CoGroupByKeyImpl-Tag-1-_26))+(assert_that/Group/CoGroupByKeyImpl/Flatten/Transcode/1))+(assert_that/Group/CoGroupByKeyImpl/Flat
ten/Write/1)\n  Create/MaybeReshuffle/Reshuffle/ReshufflePerKey/GroupByKey/Read:beam:runner:source:v1\nCreate/MaybeReshuffle/Reshuffle/ReshufflePerKey/FlatMap(restore_timestamps):beam:transform:pardo:v1\nCreate/MaybeReshuffle/Reshuf
fle/RemoveRandomKeys:beam:transform:pardo:v1\nCreate/Map(decode):beam:transform:pardo:v1\nParDo(DynamicTimerDoFn):beam:transform:pardo:v1\nassert_that/WindowInto(WindowIntoFn):beam:transform:window_into:v1\nassert_that/ToVoidKey:bea
m:transform:pardo:v1\nassert_that/Group/CoGroupByKeyImpl/Tag[1]:beam:transform:pardo:v1\nassert_that/Group/CoGroupByKeyImpl/Flatten/Transcode/1:beam:transform:flatten:v1\nassert_that/Group/CoGroupByKeyImpl/Flatten/Write/1:beam:runne
r:sink:v1\n  must follow: ((((ref_AppliedPTransform_Create-Impulse_3)+(ref_AppliedPTransform_Create-FlatMap-lambda-at-core-py-3320-_4))+(ref_AppliedPTransform_Create-MaybeReshuffle-Reshuffle-AddRandomKeys_7))+(ref_AppliedPTransform_
Create-MaybeReshuffle-Reshuffle-ReshufflePerKey-Map-reify_timestamps-_9))+(Create/MaybeReshuffle/Reshuffle/ReshufflePerKey/GroupByKey/Write)\n  downstream_side_inputs: ', '(assert_that/Group/CoGroupByKeyImpl/Flatten/Read)+(assert_th
at/Group/CoGroupByKeyImpl/GroupByKey/Write)\n  assert_that/Group/CoGroupByKeyImpl/Flatten/Read:beam:runner:source:v1\nassert_that/Group/CoGroupByKeyImpl/GroupByKey/Write:beam:runner:sink:v1\n  must follow: (((((((((Create/MaybeReshu
ffle/Reshuffle/ReshufflePerKey/GroupByKey/Read)+(ref_AppliedPTransform_Create-MaybeReshuffle-Reshuffle-ReshufflePerKey-FlatMap-restore_timestamps-_11))+(ref_AppliedPTransform_Create-MaybeReshuffle-Reshuffle-RemoveRandomKeys_12))+(re
f_AppliedPTransform_Create-Map-decode-_13))+(ref_AppliedPTransform_ParDo-DynamicTimerDoFn-_14))+(ref_AppliedPTransform_assert_that-WindowInto-WindowIntoFn-_21))+(ref_AppliedPTransform_assert_that-ToVoidKey_22))+(ref_AppliedPTransfor
m_assert_that-Group-CoGroupByKeyImpl-Tag-1-_26))+(assert_that/Group/CoGroupByKeyImpl/Flatten/Transcode/1))+(assert_that/Group/CoGroupByKeyImpl/Flatten/Write/1), (((((ref_AppliedPTransform_assert_that-Create-Impulse_17)+(ref_AppliedP
Transform_assert_that-Create-FlatMap-lambda-at-core-py-3320-_18))+(ref_AppliedPTransform_assert_that-Create-Map-decode-_20))+(ref_AppliedPTransform_assert_that-Group-CoGroupByKeyImpl-Tag-0-_25))+(assert_that/Group/CoGroupByKeyImpl/F
latten/Transcode/0))+(assert_that/Group/CoGroupByKeyImpl/Flatten/Write/0)\n  downstream_side_inputs: ', '((((assert_that/Group/CoGroupByKeyImpl/GroupByKey/Read)+(ref_AppliedPTransform_assert_that-Group-CoGroupByKeyImpl-MapTuple-coll
ect_values-_29))+(ref_AppliedPTransform_assert_that-Group-RestoreTags_30))+(ref_AppliedPTransform_assert_that-Unkey_31))+(ref_AppliedPTransform_assert_that-Match_32)\n  assert_that/Group/CoGroupByKeyImpl/GroupByKey/Read:beam:runner:
source:v1\nassert_that/Group/CoGroupByKeyImpl/MapTuple(collect_values):beam:transform:pardo:v1\nassert_that/Group/RestoreTags:beam:transform:pardo:v1\nassert_that/Unkey:beam:transform:pardo:v1\nassert_that/Match:beam:transform:pardo
:v1\n  must follow: (assert_that/Group/CoGroupByKeyImpl/Flatten/Read)+(assert_that/Group/CoGroupByKeyImpl/GroupByKey/Write)\n  downstream_side_inputs: ']
INFO     apache_beam.runners.portability.fn_api_runner.worker_handlers:worker_handlers.py:521 starting control server on port 38143
INFO     apache_beam.runners.portability.fn_api_runner.worker_handlers:worker_handlers.py:522 starting data server on port 36255                                                                                                        INFO     apache_beam.runners.portability.fn_api_runner.worker_handlers:worker_handlers.py:523 starting state server on port 44945
INFO     apache_beam.runners.portability.fn_api_runner.worker_handlers:worker_handlers.py:524 starting logging server on port 34943
INFO     apache_beam.runners.portability.fn_api_runner.worker_handlers:worker_handlers.py:889 Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedGrpcWorkerHandler object at 0x7f79f087d460> 
for environment ref_Environment_default_environment_1 (beam:env:embedded_python_grpc:v1, b'{"state_cache_size": 0, "data_buffer_time_limit_ms": 0}')                                                        
INFO     apache_beam.runners.worker.statecache:statecache.py:172 Creating state cache with size 100   
INFO     apache_beam.runners.worker.sdk_worker:sdk_worker.py:164 Creating insecure control channel for localhost:38143.                                                 
INFO     apache_beam.runners.worker.sdk_worker:sdk_worker.py:172 Control channel established.
INFO     apache_beam.runners.worker.sdk_worker:sdk_worker.py:215 Initializing SDKHarness with unbounded number of workers.
DEBUG    apache_beam.runners.portability.fn_api_runner.execution:execution.py:847 Scheduling bundle in stage for execution: (((((ref_AppliedPTransform_assert_that-Create-Impulse_17)+(ref_AppliedPTransform_assert_that-Create-FlatMap-
lambda-at-core-py-3320-_18))+(ref_AppliedPTransform_assert_that-Create-Map-decode-_20))+(ref_AppliedPTransform_assert_that-Group-CoGroupByKeyImpl-Tag-0-_25))+(assert_that/Group/CoGroupByKeyImpl/Flatten/Transcode/0))+(assert_that/Gro
up/CoGroupByKeyImpl/Flatten/Write/0)                                                                                
DEBUG    apache_beam.runners.portability.fn_api_runner.execution:execution.py:847 Scheduling bundle in stage for execution: ((((ref_AppliedPTransform_Create-Impulse_3)+(ref_AppliedPTransform_Create-FlatMap-lambda-at-core-py-3320-_4)
)+(ref_AppliedPTransform_Create-MaybeReshuffle-Reshuffle-AddRandomKeys_7))+(ref_AppliedPTransform_Create-MaybeReshuffle-Reshuffle-ReshufflePerKey-Map-reify_timestamps-_9))+(Create/MaybeReshuffle/Reshuffle/ReshufflePerKey/GroupByKey/
Write)                                                                                                              
DEBUG    apache_beam.runners.portability.fn_api_runner.fn_runner:fn_runner.py:388 Remaining ready bundles: 2                                                                                                                            
                                                                                        Watermark pending bundles: 0                                                                                                                    
                                                                                        Time pending bundles: 0                                                                                                                         
DEBUG    apache_beam.runners.portability.fn_api_runner.fn_runner.run_bundle:fn_runner.py:400 Running bundle for stage (((((ref_AppliedPTransform_assert_that-Create-Impulse_17)+(ref_AppliedPTransform_assert_that-Create-FlatMap-lambda
-at-core-py-3320-_18))+(ref_AppliedPTransform_assert_that-Create-Map-decode-_20))+(ref_AppliedPTransform_assert_that-Group-CoGroupByKeyImpl-Tag-0-_25))+(assert_that/Group/CoGroupByKeyImpl/Flatten/Transcode/0))+(assert_that/Group/CoG
roupByKeyImpl/Flatten/Write/0)                                                                                                                                                                                                          
                                                                                                Expected outputs: {'assert_that/Group/CoGroupByKeyImpl/Flatten/Write/0': b'materialize:assert_that/Group/CoGroupByKeyImpl/Flatten'} time
rs: {}                                                                                                                                                                                                                                  
DEBUG    apache_beam.runners.worker.sdk_worker:sdk_worker.py:235 Got work bundle_98                                                                                                                                                     
DEBUG    apache_beam.runners.worker.sdk_worker:sdk_worker.py:343 Currently using 5 threads.                                                                                                                                             
INFO     apache_beam.runners.worker.sdk_worker:sdk_worker.py:840 Creating insecure state channel for localhost:44945.
INFO     apache_beam.runners.worker.sdk_worker:sdk_worker.py:847 State channel established.
INFO     apache_beam.runners.worker.data_plane:data_plane.py:750 Creating client data channel for localhost:36255
ERROR    apache_beam.runners.worker.data_plane:data_plane.py:641 Failed to read inputs in the data plane.                                                                                                                               
Traceback (most recent call last):                                                                                  
  File "/usr/local/google/home/bhulette/working_dir/beam/sdks/python/apache_beam/runners/worker/data_plane.py", line 634, in _read_inputs
    for elements in elements_iterator:                                                                              
  File "/usr/local/google/home/bhulette/.pyenv/versions/beam/lib/python3.8/site-packages/grpc/_channel.py", line 426, in __next__                
    return self._next()                                                                                             
  File "/usr/local/google/home/bhulette/.pyenv/versions/beam/lib/python3.8/site-packages/grpc/_channel.py", line 809, in _next      
    raise self                                                                                                      
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
        status = StatusCode.UNAVAILABLE                                                                                                                                                                                                 
        details = "Broken pipe"                                                                                                                                                                                                         
        debug_error_string = "{"created":"@1651531867.131513924","description":"Error received from peer ipv6:[::1]:36255","file":"src/core/lib/surface/call.cc","file_line":903,"grpc_message":"Broken pipe","grpc_status":14}"
>  
DEBUG    apache_beam.runners.worker.bundle_processor:bundle_processor.py:951 start <DataOutputOperation assert_that/Group/CoGroupByKeyImpl/Flatten/Write/0 >
DEBUG    apache_beam.runners.worker.bundle_processor:bundle_processor.py:951 start <FlattenOperation assert_that/Group/CoGroupByKeyImpl/Flatten/Transcode/0 receivers=[SingletonConsumerSet[assert_that/Group/CoGroupByKeyImpl/Flatten/Transcode/0.out0, coder=WindowedValueCoder[TupleCoder[LengthPrefixCoder[DeterministicFastPrimitivesCoder], LengthPrefixCoder[FastPrimitivesCoder]]], len(consumers)=1]]>
DEBUG    apache_beam.runners.worker.bundle_processor:bundle_processor.py:951 start <DoOperation assert_that/Group/CoGroupByKeyImpl/Tag[0] output_tags=['None'], receivers=[SingletonConsumerSet[assert_that/Group/CoGroupByKeyImpl/Tag[0].out0, coder=WindowedValueCoder[TupleCoder[FastPrimitivesCoder, TupleCoder[StrUtf8Coder, FastPrimitivesCoder]]], len(consumers)=1]]>
DEBUG    apache_beam.runners.worker.bundle_processor:bundle_processor.py:951 start <DoOperation assert_that/Create/Map(decode) output_tags=['None'], receivers=[SingletonConsumerSet[assert_that/Create/Map(decode).out0, coder=WindowedValueCoder[TupleCoder[FastPrimitivesCoder, FastPrimitivesCoder]], len(consumers)=1]]>
DEBUG    apache_beam.runners.worker.bundle_processor:bundle_processor.py:951 start <DoOperation assert_that/Create/FlatMap(<lambda at core.py:3320>) output_tags=['None'], receivers=[SingletonConsumerSet[assert_that/Create/FlatMap(<lambda at core.py:3320>).out0, coder=WindowedValueCoder[BytesCoder], len(consumers)=1]]>
DEBUG    apache_beam.runners.worker.bundle_processor:bundle_processor.py:951 start <DataInputOperation assert_that/Create/Impulse receivers=[SingletonConsumerSet[assert_that/Create/Impulse.out0, coder=WindowedValueCoder[BytesCoder], len(consumers)=1]]>
ERROR    apache_beam.runners.worker.sdk_worker:sdk_worker.py:271 Error processing instruction bundle_98. Original traceback is
                                                                 Traceback (most recent call last):
                                                                   File "/usr/local/google/home/bhulette/working_dir/beam/sdks/python/apache_beam/runners/worker/data_plane.py", line 487, in input_elements
                                                                     element = received.get(timeout=1)
                                                                   File "/usr/local/google/home/bhulette/.pyenv/versions/3.8.6/lib/python3.8/queue.py", line 178, in get
                                                                     raise Empty
                                                                 _queue.Empty
                                                                 
                                                                 During handling of the above exception, another exception occurred:
                                                                 
                                                                 Traceback (most recent call last):
                                                                   File "/usr/local/google/home/bhulette/working_dir/beam/sdks/python/apache_beam/runners/worker/sdk_worker.py", line 267, in _execute
                                                                     response = task()
                                                                   File "/usr/local/google/home/bhulette/working_dir/beam/sdks/python/apache_beam/runners/worker/sdk_worker.py", line 340, in <lambda>
                                                                     lambda: self.create_worker().do_instruction(request), request)
                                                                   File "/usr/local/google/home/bhulette/working_dir/beam/sdks/python/apache_beam/runners/worker/sdk_worker.py", line 580, in do_instruction
                                                                     return getattr(self, request_type)(
                                                                   File "/usr/local/google/home/bhulette/working_dir/beam/sdks/python/apache_beam/runners/worker/sdk_worker.py", line 618, in process_bundle
                                                                     bundle_processor.process_bundle(instruction_id))
                                                                   File "/usr/local/google/home/bhulette/working_dir/beam/sdks/python/apache_beam/runners/worker/bundle_processor.py", line 984, in process_bundle
                                                                     for element in data_channel.input_elements(instruction_id,
                                                                   File "/usr/local/google/home/bhulette/working_dir/beam/sdks/python/apache_beam/runners/worker/data_plane.py", line 490, in input_elements
                                                                     raise RuntimeError('Channel closed prematurely.')
                                                                 RuntimeError: Channel closed prematurely.
                                                                 
INFO     apache_beam.runners.worker.sdk_worker:sdk_worker.py:244 No more requests from control plane
INFO     apache_beam.runners.worker.sdk_worker:sdk_worker.py:245 SDK Harness waiting for in-flight requests to complete
INFO     apache_beam.runners.worker.data_plane:data_plane.py:782 Closing all cached grpc data channels.
INFO     apache_beam.runners.worker.sdk_worker:sdk_worker.py:859 Closing all cached gRPC state handlers.
INFO     apache_beam.runners.worker.sdk_worker:sdk_worker.py:257 Done consuming work.
DEBUG    apache_beam.runners.portability.fn_api_runner.worker_handlers:worker_handlers.py:232 Runner: Requests sent by runner: [('bundle_98', 1)]
============================================= short test summary info ==============================================
FAILED apache_beam/runners/portability/fn_api_runner/fn_runner_test.py::FnApiRunnerTestWithDisabledCaching::test_pardo_dynamic_timer
================================ 1 failed, 336 passed, 40 skipped in 24.82 seconds =================================
{code}

Unfortunately I can't glean anything particularly useful from that debug log. What's interesting is that the gRPC channels were _just_ created, it seems to be one the very first bundle where the "Broken Pipe" occurred. 

For reference, I capture a portion of this sequence from a passing test:
{code}
INFO     apache_beam.runners.portability.fn_api_runner.worker_handlers:worker_handlers.py:521 starting control server on port 46845                                                                                                     
INFO     apache_beam.runners.portability.fn_api_runner.worker_handlers:worker_handlers.py:522 starting data server on port 45973                                                                                                        
INFO     apache_beam.runners.portability.fn_api_runner.worker_handlers:worker_handlers.py:523 starting state server on port 42855                                                                                                       
INFO     apache_beam.runners.portability.fn_api_runner.worker_handlers:worker_handlers.py:524 starting logging server on port 33253                                                                                                     
INFO     apache_beam.runners.portability.fn_api_runner.worker_handlers:worker_handlers.py:889 Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedGrpcWorkerHandler object at 0x7f43757685b0> 
for environment ref_Environment_default_environment_1 (beam:env:embedded_python_grpc:v1, b'{"state_cache_size": 0, "data_buffer_time_limit_ms": 0}')                                                                                    
INFO     apache_beam.runners.worker.statecache:statecache.py:172 Creating state cache with size 100                                                                                                                                     
INFO     apache_beam.runners.worker.sdk_worker:sdk_worker.py:164 Creating insecure control channel for localhost:46845.                                                                                                                 INFO     apache_beam.runners.worker.sdk_worker:sdk_worker.py:172 Control channel established.                                                                                                                                           
INFO     apache_beam.runners.worker.sdk_worker:sdk_worker.py:215 Initializing SDKHarness with unbounded number of workers.                                                                                                              DEBUG    apache_beam.runners.portability.fn_api_runner.execution:execution.py:847 Scheduling bundle in stage for execution: ((((ref_AppliedPTransform_Create-Impulse_3)+(ref_AppliedPTransform_Create-FlatMap-lambda-at-core-py-3320-_4)
)+(ref_AppliedPTransform_Create-MaybeReshuffle-Reshuffle-AddRandomKeys_7))+(ref_AppliedPTransform_Create-MaybeReshuffle-Reshuffle-ReshufflePerKey-Map-reify_timestamps-_9))+(Create/MaybeReshuffle/Reshuffle/ReshufflePerKey/GroupByKey/Write)                                                                                                                                                                                                                                  
DEBUG    apache_beam.runners.portability.fn_api_runner.execution:execution.py:847 Scheduling bundle in stage for execution: (((((ref_AppliedPTransform_assert_that-Create-Impulse_17)+(ref_AppliedPTransform_assert_that-Create-FlatMap-lambda-at-core-py-3320-_18))+(ref_AppliedPTransform_assert_that-Create-Map-decode-_20))+(ref_AppliedPTransform_assert_that-Group-CoGroupByKeyImpl-Tag-0-_25))+(assert_that/Group/CoGroupByKeyImpl/Flatten/Transcode/0))+(assert_that/Gro
up/CoGroupByKeyImpl/Flatten/Write/0)                                                                                                                                                                                                    DEBUG    apache_beam.runners.portability.fn_api_runner.fn_runner:fn_runner.py:388 Remaining ready bundles: 2                                                                                                                            
                                                                                        Watermark pending bundles: 0                                                                                                                                                                                                            Time pending bundles: 0                                                                                                                         
DEBUG    apache_beam.runners.portability.fn_api_runner.fn_runner.run_bundle:fn_runner.py:400 Running bundle for stage ((((ref_AppliedPTransform_Create-Impulse_3)+(ref_AppliedPTransform_Create-FlatMap-lambda-at-core-py-3320-_4))+(ref
_AppliedPTransform_Create-MaybeReshuffle-Reshuffle-AddRandomKeys_7))+(ref_AppliedPTransform_Create-MaybeReshuffle-Reshuffle-ReshufflePerKey-Map-reify_timestamps-_9))+(Create/MaybeReshuffle/Reshuffle/ReshufflePerKey/GroupByKey/Write)
                                                                                                Expected outputs: {'Create/MaybeReshuffle/Reshuffle/ReshufflePerKey/GroupByKey/Write': b'group:ref_AppliedPTransform_Create-MaybeReshuff
le-Reshuffle-ReshufflePerKey-GroupByKey_10'} timers: {}                                                                                                                                                                                 
DEBUG    apache_beam.runners.worker.sdk_worker:sdk_worker.py:235 Got work bundle_1
DEBUG    apache_beam.runners.worker.sdk_worker:sdk_worker.py:343 Currently using 2 threads.
INFO     apache_beam.runners.worker.sdk_worker:sdk_worker.py:840 Creating insecure state channel for localhost:42855.
INFO     apache_beam.runners.worker.sdk_worker:sdk_worker.py:847 State channel established.
INFO     apache_beam.runners.worker.data_plane:data_plane.py:750 Creating client data channel for localhost:45973
DEBUG    apache_beam.runners.worker.bundle_processor:bundle_processor.py:951 start <DataOutputOperation Create/MaybeReshuffle/Reshuffle/ReshufflePerKey/GroupByKey/Write >
DEBUG    apache_beam.runners.worker.bundle_processor:bundle_processor.py:951 start <DoOperation Create/MaybeReshuffle/Reshuffle/ReshufflePerKey/Map(reify_timestamps) output_tags=['None'], receivers=[SingletonConsumerSet[Create/Maybe
Reshuffle/Reshuffle/ReshufflePerKey/Map(reify_timestamps).out0, coder=WindowedValueCoder[TupleCoder[LengthPrefixCoder[DeterministicFastPrimitivesCoder], LengthPrefixCoder[FastPrimitivesCoder]]], len(consumers)=1]]>
DEBUG    apache_beam.runners.worker.bundle_processor:bundle_processor.py:951 start <DoOperation Create/MaybeReshuffle/Reshuffle/AddRandomKeys output_tags=['None'], receivers=[SingletonConsumerSet[Create/MaybeReshuffle/Reshuffle/AddR
andomKeys.out0, coder=WindowedValueCoder[TupleCoder[VarIntCoder, BytesCoder]], len(consumers)=1]]>
DEBUG    apache_beam.runners.worker.bundle_processor:bundle_processor.py:951 start <DoOperation Create/FlatMap(<lambda at core.py:3320>) output_tags=['None'], receivers=[SingletonConsumerSet[Create/FlatMap(<lambda at core.py:3320>).
out0, coder=WindowedValueCoder[BytesCoder], len(consumers)=1]]>
DEBUG    apache_beam.runners.worker.bundle_processor:bundle_processor.py:951 start <DataInputOperation Create/Impulse receivers=[SingletonConsumerSet[Create/Impulse.out0, coder=WindowedValueCoder[BytesCoder], len(consumers)=1]]>
DEBUG    apache_beam.runners.worker.bundle_processor:bundle_processor.py:1000 finish <DataInputOperation Create/Impulse receivers=[SingletonConsumerSet[Create/Impulse.out0, coder=WindowedValueCoder[BytesCoder], len(consumers)=1]]>
DEBUG    apache_beam.runners.worker.bundle_processor:bundle_processor.py:1000 finish <DoOperation Create/FlatMap(<lambda at core.py:3320>) output_tags=['None'], receivers=[SingletonConsumerSet[Create/FlatMap(<lambda at core.py:3320>
).out0, coder=WindowedValueCoder[BytesCoder], len(consumers)=1]]>
{code}

Re-opening this. Action is to investigate the Broken Pipe failures and if possible fix them and remove the retries in fn_runner_test.py

This issue has been migrated to https://github.com/apache/beam/issues/21104

