Peak Execution Memory Quantile is displayed in the regular Spark UI correctly. If the same application is viewed in Spark History Server UI, Peak Execution Memory is always displayed as zero.

Spark event log for the application seem to contain Peak Execution Memory(under the tag "internal.metrics.peakExecutionMemory") correctly.  However this is not reflected in the History Server UI.

*Steps to produce non-zero Peak Execution Memory*

spark.range(0, 200000).map\{x => (x , x % 20)}.toDF("a", "b").createOrReplaceTempView("fred")

spark.range(0, 200000).map\{x => (x , x + 1)}.toDF("a", "b").createOrReplaceTempView("phil")

sql("select p.**,* f.* from phil p join fred f on f.b = p.b").count

 