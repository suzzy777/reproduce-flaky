Investigation notes:

Revision history from the old gemfire repo has this comment from Barry Oglesby about the ping messages:

 

{{"added a server to client ping message to prevent idle subscription connections from being dropped by the firewall"}}

On the server Ping messages are sent once every 60,000 milliseconds by a task scheduled in a Timer.  The interval can be adjusted with the system property "gemfire.serverToClientPingPeriod".  There are no other references to this property in the repo and no tests were included in the original commit.

The client knows nothing about the ping interval setting in the server, so it has no concept that it could miss Ping messages.

The client reads Ping messages in CacheClientUpdater and ignores them.

 

Testing with iptable manipulation shows that a client does not detect that the server is not reachable, and the server does not detect that the client is not there.  The client's sotimeout setting on its socket works during network-down conditions but the socket reports it is not closed and it is still connected.

We allowed the network to be down for over 45 minutes and this condition persisted for the entire time.

Commit 6683b34baae52d912e5514d8008401b6a5481787 in geode's branch refs/heads/feature/GEODE-3948 from [~bschuchardt]
[ https://gitbox.apache.org/repos/asf?p=geode.git;h=6683b34 ]

GEODE-3948 Improve CQ performance under flaky network conditions

removing a debug log statement and correcting some comments


Commit e093db0ff293e078888f1ab6700adfa633dd93bf in geode's branch refs/heads/feature/GEODE-3948 from [~bschuchardt]
[ https://gitbox.apache.org/repos/asf?p=geode.git;h=e093db0 ]

GEODE-3948 Improve CQ performance under flaky network conditions

Addressing review comments.


Commit 906ed2ae369f130f0d6186d636daa5eba0188f43 in geode's branch refs/heads/feature/GEODE-3967 from [~bschuchardt]
[ https://gitbox.apache.org/repos/asf?p=geode.git;h=906ed2a ]

GEODE-3948 Improve CQ performance under flaky network conditions

This adds a new PoolFactory setting allowing subscription connections to
time out and initiate failover to a backup server. The new setting is
setSubscriptionTimeoutMultiplier:

A server has an inactivity monitor that ensures a message is sent to a client at least once a
minute (60,000 milliseconds). If a subscription timeout multipler is set in the client it
enables timing out of the subscription feed with failover to another server.

A value of zero (the default) disables timeouts

A value of one will time out the server connection after one of its ping intervals (not
recommended)

A value of two or more will time out the server connection after that many ping intervals have
elapsed

The client/server handshake is modified for clients having version 1.5 or
later. The server sends its ping-interval setting to the client. The client
then uses this and the multiplier to establish a read-timeout in the
CacheClientUpdater subscription processor.

Two tests are added to ensure that 1) the Message method that allows a
read to timeout functions correctly and 2) the CacheClientUpdater
correctly receives the multiplier setting.

This closes #1364


Commit 906ed2ae369f130f0d6186d636daa5eba0188f43 in geode's branch refs/heads/feature/GEODE-4435 from [~bschuchardt]
[ https://gitbox.apache.org/repos/asf?p=geode.git;h=906ed2a ]

GEODE-3948 Improve CQ performance under flaky network conditions

This adds a new PoolFactory setting allowing subscription connections to
time out and initiate failover to a backup server. The new setting is
setSubscriptionTimeoutMultiplier:

A server has an inactivity monitor that ensures a message is sent to a client at least once a
minute (60,000 milliseconds). If a subscription timeout multipler is set in the client it
enables timing out of the subscription feed with failover to another server.

A value of zero (the default) disables timeouts

A value of one will time out the server connection after one of its ping intervals (not
recommended)

A value of two or more will time out the server connection after that many ping intervals have
elapsed

The client/server handshake is modified for clients having version 1.5 or
later. The server sends its ping-interval setting to the client. The client
then uses this and the multiplier to establish a read-timeout in the
CacheClientUpdater subscription processor.

Two tests are added to ensure that 1) the Message method that allows a
read to timeout functions correctly and 2) the CacheClientUpdater
correctly receives the multiplier setting.

This closes #1364


We need to add this new setting to the XML schema.

Commit 0a6eebdffc9dd1f0393629e43e1f33ff8c71a7f7 in geode's branch refs/heads/develop from [~bschuchardt]
[ https://gitbox.apache.org/repos/asf?p=geode.git;h=0a6eebd ]

GEODE-3948 Improve CQ performance under flaky network conditions

Adding new pool setting to XSD so it can be configured in cache.xml

This closes #1520


Commit 8ce536ec2daf94d7e086871ccf13dcb0cd2b915a in geode's branch refs/heads/develop from [~dbarnes]
[ https://gitbox.apache.org/repos/asf?p=geode.git;h=8ce536e ]

GEODE-3948 Document subscription timeout multiplier


Documented.

Commit 8ce536ec2daf94d7e086871ccf13dcb0cd2b915a in geode's branch refs/heads/feature/GEODE-4685 from [~dbarnes]
[ https://gitbox.apache.org/repos/asf?p=geode.git;h=8ce536e ]

GEODE-3948 Document subscription timeout multiplier


Reopening as the changes for this ticket caused an unintended side-effect.  Some reads are now done w/o a read-timeout.


{quote} 
We have 2 VMs that are running Geode 1.7 servers – one server per VM. Along with Geode Server each VM has one Geode 1.7 Client. Hence we have  2 servers and 2 clients in Geode cluster.

 

While doing validation, we have introduced packet loss(~65%) on first VM “A” and after about 1 minute client of VM “B” reports following:

 

[warning 2019/04/11 16:20:27.502 AMT Collector-c0f1ee3e-366a-4ac3-8fda-60540cdd21c4 <ThreadsMonitor> tid=0x1c] Thread <2182> that was executed at <11 Apr 2019 16:19:11 AMT> has been stuck for <76.204 seconds> and number of thread monitor iteration <1>

  Thread Name <poolTimer-CollectorControllerPool-142>

  Thread state <RUNNABLE>

  Executor Group <ScheduledThreadPoolExecutorWithKeepAlive>

  Monitored metric <ResourceManagerStats.numThreadsStuck>

  Thread Stack:

  java.net.SocketInputStream.socketRead0(Native Method)

  java.net.SocketInputStream.socketRead(SocketInputStream.java:116)

  java.net.SocketInputStream.read(SocketInputStream.java:171)

  java.net.SocketInputStream.read(SocketInputStream.java:141)

  sun.security.ssl.InputRecord.readFully(InputRecord.java:465)

  sun.security.ssl.InputRecord.read(InputRecord.java:503)

  sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:975)

  sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:933)

  sun.security.ssl.AppInputStream.read(AppInputStream.java:105)

  org.apache.geode.internal.cache.tier.sockets.Message.fetchHeader(Message.java:809)

  org.apache.geode.internal.cache.tier.sockets.Message.readHeaderAndBody(Message.java:659)

  org.apache.geode.internal.cache.tier.sockets.Message.receiveWithHeaderReadTimeout(Message.java:1124)

  org.apache.geode.internal.cache.tier.sockets.Message.receive(Message.java:1135)

  org.apache.geode.cache.client.internal.AbstractOp.attemptReadResponse(AbstractOp.java:205)

  org.apache.geode.cache.client.internal.AbstractOp.attempt(AbstractOp.java:386)

  org.apache.geode.cache.client.internal.ConnectionImpl.execute(ConnectionImpl.java:276)

  org.apache.geode.cache.client.internal.QueueConnectionImpl.execute(QueueConnectionImpl.java:167)

  org.apache.geode.cache.client.internal.OpExecutorImpl.executeWithPossibleReAuthentication(OpExecutorImpl.java:894)

  org.apache.geode.cache.client.internal.OpExecutorImpl.executeOnServer(OpExecutorImpl.java:387)

  org.apache.geode.cache.client.internal.OpExecutorImpl.executeOn(OpExecutorImpl.java:349)

  org.apache.geode.cache.client.internal.PoolImpl.executeOn(PoolImpl.java:827)

  org.apache.geode.cache.client.internal.PingOp.execute(PingOp.java:36)

  org.apache.geode.cache.client.internal.LiveServerPinger$PingTask.run2(LiveServerPinger.java:90)

  org.apache.geode.cache.client.internal.PoolImpl$PoolTask.run(PoolImpl.java:1338)

  java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)

  java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)

  org.apache.geode.internal.ScheduledThreadPoolExecutorWithKeepAlive$DelegatingScheduledFuture.run(ScheduledThreadPoolExecutorWithKeepAlive.java:271)

  java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)

  java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)

  java.lang.Thread.run(Thread.java:748)

 

This report and stacktrace is being continuously repeated by ThreadsMOnitor over time – just iteration count and “stuck for” values are increasing. From stacktrace it seems to be PingOperation initiated by client on VM “B” to Server of VM “A”. Due to packet drop between the nodes the response is not reaching caller client from the server and this thread remaines blocked for hours. In source I see that receiveWithHeaderReadTimeout receives NO_HEADER_READ_TIMEOUT as a timeout argument which means we will wait indefinitely. Is this reasonable? So the question is why PingOperation is executed without timeout?

 

Or could it be that this stacked thread will be interrupted by some monitoring logic at some moment?
{quote}

Commit 7536f2e56a73610c1c694b4c9648107405ed735a in geode's branch refs/heads/feature/GEODE-3948b from Bruce Schuchardt
[ https://gitbox.apache.org/repos/asf?p=geode.git;h=7536f2e ]

GEODE-3948 fixing handling of sotimeout in Message.receive()

Changes made for GEODE-3948 caused the Message.receive() method to block
indefinitely waiting for a response.  That wasn't the intent - it should
honor the current setting of sotimeout.


Commit 7536f2e56a73610c1c694b4c9648107405ed735a in geode's branch refs/heads/feature/GEODE-3948b from Bruce Schuchardt
[ https://gitbox.apache.org/repos/asf?p=geode.git;h=7536f2e ]

GEODE-3948 fixing handling of sotimeout in Message.receive()

Changes made for GEODE-3948 caused the Message.receive() method to block
indefinitely waiting for a response.  That wasn't the intent - it should
honor the current setting of sotimeout.


Commit 2758f58b9df310a79d7b77daa234398a1dbf8e0e in geode's branch refs/heads/develop from Bruce Schuchardt
[ https://gitbox.apache.org/repos/asf?p=geode.git;h=2758f58 ]

GEODE-3948 fixing handling of sotimeout in Message.receive()

Changes made for GEODE-3948 caused the Message.receive() method to block
indefinitely waiting for a response.  That wasn't the intent - it should
honor the current setting of sotimeout.


Commit 2758f58b9df310a79d7b77daa234398a1dbf8e0e in geode's branch refs/heads/develop from Bruce Schuchardt
[ https://gitbox.apache.org/repos/asf?p=geode.git;h=2758f58 ]

GEODE-3948 fixing handling of sotimeout in Message.receive()

Changes made for GEODE-3948 caused the Message.receive() method to block
indefinitely waiting for a response.  That wasn't the intent - it should
honor the current setting of sotimeout.


Commit 5d2b8d924e1b879fff6af72ed1d32e303aa8379a in geode's branch refs/heads/release/1.9.0 from Bruce Schuchardt
[ https://gitbox.apache.org/repos/asf?p=geode.git;h=5d2b8d9 ]

GEODE-3948 fixing handling of sotimeout in Message.receive()

Changes made for GEODE-3948 caused the Message.receive() method to block
indefinitely waiting for a response.  That wasn't the intent - it should
honor the current setting of sotimeout.

(cherry picked from commit 2758f58b9d)


Commit 5d2b8d924e1b879fff6af72ed1d32e303aa8379a in geode's branch refs/heads/release/1.9.0 from Bruce Schuchardt
[ https://gitbox.apache.org/repos/asf?p=geode.git;h=5d2b8d9 ]

GEODE-3948 fixing handling of sotimeout in Message.receive()

Changes made for GEODE-3948 caused the Message.receive() method to block
indefinitely waiting for a response.  That wasn't the intent - it should
honor the current setting of sotimeout.

(cherry picked from commit 2758f58b9d)


Cherry-picked to 1.9.0

