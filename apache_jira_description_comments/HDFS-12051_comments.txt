Upon a closer analysis of the problem, it looks like we will need to apply a very specialized byte[] array interning solution here.

What makes this case special is that the number of byte[] arrays is very high (~100M total arrays, ~25M unique arrays), but the average duplication factor is not very high (~4). Some byte[] arrays are replicated in an extremely high number, e.g. per the jxray report there are 3.5M copies of one 17-element array and so on. But that means that the vast majority of arrays actually don't have any duplicates. So if we use a standard dedupe solution, a WeakHashMap for all byte[] arrays, it will end up taking a lot of memory. A java.util.HashMap would use ~60 bytes per entry, a WeakHashMap even more, so this table will take at least 25M * 60 bytes = 1.5GB. That's comparable with the amount of memory that we try to save, and will result in multiple extra objects and the associated GC overhead - all because of the vast number of no-dupe arrays that the table would contain.

To address this problem, I suggest to use a solution that worked for me in the past in similar situations. It's a small (probably a few thousand elements in our case) fixed-size cache for byte[] arrays. It is organized as a simple hashmap. If a new element is added to it and its hashcode puts it into an already occupied slot, the old element is thrown away and replaced with the new one. In this way the cache stays fixed, but the elements that are duplicated most, have the highest chance to occupy its slots. This cache will not eliminate all the duplicates, but it will eliminate most of them, at a very small cost.

I've just discovered that this problem has apparently been known before, and {{org.apache.hadoop.hdfs.server.namenode.NameCache}} exists to address it. However, given the high degree of replication of 'name' byte[] arrays that we observe, this cache doesn't work very well. [~revans2] may I ask you if you have any comments on this? Looks like you were the last person who touched this code, and looks like your changes were supposed to address uncontrolled growth of the HashMap in NameCache. What I suggest above is a radically different way to address the same problem by using a simple "opportunistic" fixed-size cache. It won't guarantee elimination of all duplicates, but it should help to remove most of the worst of them.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 14s{color} | {color:blue} Docker mode activated. {color} |
| {color:green} 1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green} 1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green} 1{color} | {color:green} mvninstall {color} | {color:green} 13m 31s{color} | {color:green} trunk passed {color} |
| {color:green} 1{color} | {color:green} compile {color} | {color:green}  0m 49s{color} | {color:green} trunk passed {color} |
| {color:green} 1{color} | {color:green} checkstyle {color} | {color:green}  0m 47s{color} | {color:green} trunk passed {color} |
| {color:green} 1{color} | {color:green} mvnsite {color} | {color:green}  0m 58s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 46s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 10 extant Findbugs warnings. {color} |
| {color:green} 1{color} | {color:green} javadoc {color} | {color:green}  0m 41s{color} | {color:green} trunk passed {color} |
| {color:green} 1{color} | {color:green} mvninstall {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |
| {color:green} 1{color} | {color:green} compile {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |
| {color:green} 1{color} | {color:green} javac {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 41s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 8 new   627 unchanged - 17 fixed = 635 total (was 644) {color} |
| {color:green} 1{color} | {color:green} mvnsite {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |
| {color:green} 1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green} 1{color} | {color:green} findbugs {color} | {color:green}  1m 44s{color} | {color:green} the patch passed {color} |
| {color:green} 1{color} | {color:green} javadoc {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 86m 17s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green} 1{color} | {color:green} asflicense {color} | {color:green}  0m 20s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}112m  4s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.tools.TestHdfsConfigFields |
|   | hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HDFS-12051 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12875976/HDFS-12051.01.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 5294f01f06cd 3.13.0-123-generic #172-Ubuntu SMP Mon Jun 26 18:04:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 7576a68 |
| Default Java | 1.8.0_131 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/20179/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/20179/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20179/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20179/testReport/ |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20179/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



I've redesigned the new NameCache so that its size adjusts depending on the size of the input data, within user-specified limits.

It was tested using a synthetic workload simulating that of a big Hadoop installation. The result is an 8.5% reduction in the overhead due to duplicate byte[] arrays. Here are the results of the jxray analysis of the respective heap dumps:

Before

{code}
19. DUPLICATE PRIMITIVE ARRAYS

Types of duplicate objects:
     Ovhd         Num objs  Num unique objs   Class name

346,198K (12.6%)   12097893      3714559         byte[]
...
Total arrays: 12,101,111  Unique arrays: 3,716,791  Duplicate values: 371,424  Overhead: 346,322K (12.6%)

===================================================

20. REFERENCE CHAINS FOR DUPLICATE PRIMITIVE ARRAYS

  333,160K (12.1%), 8458874 (99%) dup arrays (368811 unique)
78925 of byte[14](112, 114, 111, 99, 95, 117, 110, 105, 116, 95, ...), 75981 of byte[14](112, 114, 111, 99, 95, 117, 110, 105, 116, 95, ...), 51638 of byte[12](99, 99, 108, 95, 117, 95, 102, 108, 97, 103, ...), 50010 of byte[14](112, 114, 111, 99, 95, 117, 110, 105, 116, 95, ...), 34126 of byte[15](112, 114, 111, 99, 95, 117, 110, 105, 116, 95, ...), 24951 of byte[14](112, 114, 111, 99, 95, 117, 110, 105, 116, 95, ...), 24394 of byte[12](99, 99, 108, 95, 117, 95, 102, 108, 97, 103, ...), 16851 of byte[15](112, 114, 111, 99, 95, 117, 110, 105, 116, 95, ...), 14746 of byte[26](118, 101, 114, 115, 105, 111, 110, 61, 50, 48, ...), 10900 of byte[14](112, 114, 111, 99, 95, 117, 110, 105, 116, 95, ...)
... and 8076342 more arrays, of which 368801 are unique
     <-- org.apache.hadoop.hdfs.server.namenode.INodeDirectory.name <-- org.apache.hadoop.util.LightWeightGSet$LinkedElement[] <-- org.apache.hadoop.util.LightWeightGSet.entries <-- org.apache.hadoop.hdfs.server.namenode.INodeMap.map <-- org.apache.hadoop.hdfs.server.namenode.FSDirectory.inodeMap <-- org.apache.hadoop.hdfs.server.namenode.FSNamesystem.dir <-- org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber.this$0 <-- Java Local@695acbb40 (org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber)

....
{code}

After:

{code}
19. DUPLICATE PRIMITIVE ARRAYS

Types of duplicate objects:
     Ovhd         Num objs  Num unique objs   Class name

100,440K (3.9%)   6208877      3855398         byte[]
...

Total arrays: 6,212,104  Unique arrays: 3,857,624  Duplicate values: 727,662  Overhead: 100,566K (3.9%)

===================================================

20. REFERENCE CHAINS FOR DUPLICATE PRIMITIVE ARRAYS

  56,568K (2.2%), 1575637 (96%) dup arrays (232009 unique)
52709 of byte[14](112, 114, 111, 99, 95, 117, 110, 105, 116, 95, ...), 50009 of byte[14](112, 114, 111, 99, 95, 117, 110, 105, 116, 95, ...), 16979 of byte[15](112, 114, 111, 99, 95, 117, 110, 105, 116, 95, ...), 10899 of byte[14](112, 114, 111, 99, 95, 117, 110, 105, 116, 95, ...), 4853 of byte[14](114, 112, 116, 95, 112, 114, 100, 61, 50, 48, ...), 4494 of byte[14](114, 112, 116, 95, 112, 114, 100, 61, 50, 48, ...), 4396 of byte[20](112, 97, 114, 116, 105, 116, 105, 111, 110, 115, ...), 3919 of byte[14](114, 112, 116, 95, 112, 114, 100, 61, 50, 48, ...), 3460 of byte[14](114, 112, 116, 95, 112, 114, 100, 61, 50, 48, ...), 3452 of byte[14](114, 112, 116, 95, 112, 114, 100, 61, 50, 48, ...)
... and 1420457 more arrays, of which 231999 are unique
     <-- org.apache.hadoop.hdfs.server.namenode.INodeDirectory.name <-- org.apache.hadoop.util.LightWeightGSet$LinkedElement[] <-- org.apache.hadoop.util.LightWeightGSet.entries <-- org.apache.hadoop.hdfs.server.namenode.INodeMap.map <-- org.apache.hadoop.hdfs.server.namenode.FSDirectory.inodeMap <-- org.apache.hadoop.hdfs.server.namenode.FSNamesystem.dir <-- org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.namesystem <-- Java Local@68a849e38 (org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer)
  28,192K (1.1%), 993579 (41%) dup arrays (494398 unique)
3308 of byte[15](48, 48, 48, 48, 48, 48, 95, 48, 95, 99, ...), 3308 of byte[15](48, 48, 48, 48, 48, 48, 95, 48, 95, 99, ...), 3308 of byte[15](48, 48, 48, 48, 48, 48, 95, 48, 95, 99, ...), 3308 of byte[15](48, 48, 48, 48, 48, 48, 95, 48, 95, 99, ...), 3308 of byte[16](48, 48, 48, 48, 48, 48, 95, 48, 95, 99, ...), 3308 of byte[15](48, 48, 48, 48, 48, 48, 95, 48, 95, 99, ...), 3308 of byte[15](48, 48, 48, 48, 48, 48, 95, 48, 95, 99, ...), 3308 of byte[15](48, 48, 48, 48, 48, 48, 95, 48, 95, 99, ...), 3307 of byte[16](48, 48, 48, 48, 48, 48, 95, 48, 95, 99, ...), 3286 of byte[16](48, 48, 48, 48, 48, 48, 95, 48, 95, 99, ...)
... and 960512 more arrays, of which 494388 are unique
     <-- org.apache.hadoop.hdfs.server.namenode.INodeFile.name <-- org.apache.hadoop.util.LightWeightGSet$LinkedElement[] <-- org.apache.hadoop.util.LightWeightGSet.entries <-- org.apache.hadoop.hdfs.server.namenode.INodeMap.map <-- org.apache.hadoop.hdfs.server.namenode.FSDirectory.inodeMap <-- org.apache.hadoop.hdfs.server.namenode.FSNamesystem.dir <-- org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.namesystem <-- Java Local@68a849e38 (org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer)
  13,074K (0.5%), 468403 (22%) dup arrays (468403 unique)
1 of byte[26](118, 101, 114, 115, 105, 111, 110, 61, 50, 48, ...), 1 of byte[27](50, 48, 49, 55, 45, 48, 53, 45, 48, 54, ...), 1 of byte[26](118, 101, 114, 115, 105, 111, 110, 61, 50, 48, ...), 1 of byte[29](50, 48, 49, 55, 45, 48, 53, 45, 48, 54, ...), 1 of byte[29](50, 48, 49, 55, 45, 48, 53, 45, 48, 54, ...), 1 of byte[18](117, 110, 105, 113, 117, 101, 95, 105, 100, 61, ...), 1 of byte[27](50, 48, 49, 55, 45, 48, 53, 45, 48, 54, ...), 1 of byte[29](50, 48, 49, 55, 45, 48, 53, 45, 48, 54, ...), 1 of byte[29](50, 48, 49, 55, 45, 48, 53, 45, 48, 54, ...), 1 of byte[29](50, 48, 49, 55, 45, 48, 53, 45, 48, 54, ...)
... and 468383 more arrays, of which 468393 are unique
     <-- byte[][] <-- org.apache.hadoop.hdfs.server.namenode.NameCache.cache <-- org.apache.hadoop.hdfs.server.namenode.FSDirectory.nameCache <-- org.apache.hadoop.hdfs.server.namenode.FSNamesystem.dir <-- org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.namesystem <-- Java Local@68a849e38 (org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer)
{code}

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 11s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 16m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 46s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 42s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 10 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 42s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 41s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 7 new + 627 unchanged - 17 fixed = 634 total (was 644) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 48s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 39s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 73m 31s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 20s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}102m 10s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.tools.TestHdfsConfigFields |
|   | hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy |
|   | hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HDFS-12051 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12876918/HDFS-12051.02.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux b9fe465b2600 3.13.0-123-generic #172-Ubuntu SMP Mon Jun 26 18:04:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / b628d0d |
| Default Java | 1.8.0_131 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/20246/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/20246/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20246/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20246/testReport/ |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20246/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



HI [~misha@cloudera.com],

Thanks for working on this issue.

I did a review and have the following high level comments:

1. The original NameCache works like this, when loading fsimage, it put names into a transient cache and remember the counts of each name, if the count of a name reachs a threshold (configurable with default 10), it promote the name to the permanent cache. After fsimage is loaded, it will clean up the transient cache and freeze the final cache.  The problem described here is about calculating snapshotdiff which happens after fsimage loading. Thus any new name, even if it appears many times, would not benefit from the NameCache. Let's call this solution1, your change is to always allow the cache to be updated, and let's call it solution2.

2.  If we modify solution1 to keep updating the cache instead of freezing it, we have chance to help the problem to solve here, however, depending on the threshold, the number of entries in the final cache of solution1 can be very different, thus memory footprint can be very different.

3. The cache size to be configured in solution2 would impact the final memory footprint too. If it's configured too small, we might end up many duplicates too. So having a reasonable default configuration would be important. It's so internal that we may not easily make good recommendation to users when to adjust it.

4. How much memory we are saving when saying "8.5% reduction"?

5. "In practice most of the time some names occur much more frequently than others". Wonder if you have examples from the case you studied, why some Names appear so much more than others, what patterns the names have? is it an artifact of snapshot implementation?

6. Solution2 might benefit some cases, but make other cases worse. If we decide to proceed, wonder if we can make both solution1 and solution2 available, and make it switchable when needed.

7. Suggest to add more comments in code. For example.  {{for (int colsnChainLen = 0; colsnChainLen < 5; colsnChainLen++) {}}, what this does, and why "5".

Thanks.






| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 36s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 19s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 39s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 47s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 35s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 7 new + 634 unchanged - 17 fixed = 641 total (was 651) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 27s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 45s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}122m 50s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 22s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}168m 18s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.TestFileAppend2 |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure170 |
|   | hadoop.fs.TestUnbuffer |
|   | hadoop.hdfs.web.TestWebHdfsTimeouts |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |
|   | hadoop.tools.TestHdfsConfigFields |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.TestDatanodeDeath |
|   | hadoop.hdfs.server.balancer.TestBalancerRPCDelay |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure040 |
|   | hadoop.hdfs.TestBlocksScheduledCounter |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HDFS-12051 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12876918/HDFS-12051.02.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux ce095bc4a720 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 333ef30 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22223/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22223/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22223/testReport/ |
| Max. process+thread count | 3783 (vs. ulimit of 5000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22223/console |
| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



Thank you for the review [~yzhangal] Here are the answers to your questions:

{quote}1. The original NameCache works like this, when loading fsimage, it put names into a transient cache and remember the counts of each name, if the count of a name reachs a threshold (configurable with default 10), it promote the name to the permanent cache. After fsimage is loaded, it will clean up the transient cache and freeze the final cache. The problem described here is about calculating snapshotdiff which happens after fsimage loading. Thus any new name, even if it appears many times, would not benefit from the NameCache. Let's call this solution1, your change is to always allow the cache to be updated, and let's call it solution2.{quote}

I would say that this solution may (or does) have problems even during fsimage loading. What if fsimage contains a very high number of different names? Then NameCache may grow to several million entries, and a java.util.HashMap of this size is very costly to operate, because, for one thing, a separate HashMap$Entry object is created for each key-value pair. This would become a big burden on the GC and a big overhead in terms of CPU cycles.

{quote}2. If we modify solution1 to keep updating the cache instead of freezing it, we have chance to help the problem to solve here, however, depending on the threshold, the number of entries in the final cache of solution1 can be very different, thus memory footprint can be very different.{quote}

See above, and also see my initial explanation in this ticket. If we allow the cache in solution1 to grow, its memory footprint may grow comparable to the memory savings that it achieves, while creating a lot of additional GC pressure as explained above.

{quote}3. The cache size to be configured in solution2 would impact the final memory footprint too. If it's configured too small, we might end up many duplicates too. So having a reasonable default configuration would be important. It's so internal that we may not easily make good recommendation to users when to adjust it.{quote}

Yes. Ideally, more measurements need to be done and a better algorithm for selecting its size should be devised. But let's do it incrementally. Right now, this cache consumes very little extra memory yet saves quite a lot of it. This is much better than what we had before.

{quote}4. How much memory we are saving when saying "8.5% reduction"?{quote}

In this particular case, see above for the two lines explaining the overhead of duplicate byte[] arrays from jxray memory reports before and after the change:

Types of duplicate objects:
     Ovhd         Num objs  Num unique objs   Class name

Before:
346,198K (12.6%)   12097893      3714559         byte[]
After
100,440K (3.9%)   6208877      3855398         byte[]

So, the overhead went down from ~333MB to ~100MB in this synthetic workload example. Note that in the original, production heap dump that I started with, the heap size and the overhead of duplicate byte[] arrays is much higher ~3GB:

3,220,272K (6.5%)   104749528      25760871         byte[]

{quote}
6. Solution2 might benefit some cases, but make other cases worse. If we decide to proceed, wonder if we can make both solution1 and solution2 available, and make it switchable when needed.
{quote}

For the use cases that I considered, it was a clear net benefit. I've also explained the very real problems with solution 1 in the answer to your question (1): it may create a lot of extra memory pressure, especially when the data is unscewed (i.e. the size of the resulting cache is comparable to the total number of names). And if a limit is put on the size of name cache in solution 1, it will have the same drawback as solution 2, while still requiring more memory.

{quote}7. Suggest to add more comments in code. For example. for (int colsnChainLen = 0; colsnChainLen < 5; colsnChainLen++) {, what this does, and why "5".{quote}

Certainly, will do.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 16m 30s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 25s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 49s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 43s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 4 new + 634 unchanged - 17 fixed = 638 total (was 651) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 46s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  0s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}112m 20s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}162m 59s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HDFS-12051 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12900092/HDFS-12051.03.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux fb27d2c05243 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / a409425 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22239/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22239/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22239/testReport/ |
| Max. process+thread count | 3152 (vs. ulimit of 5000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22239/console |
| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



In the most recent heap dump obtained from a very big HDFS installation we found yet another source of duplicate byte[] arrays: org.apache.hadoop.fs.XAttr.value data field. In that particular heap dump, there are over 24M duplicate byte[] arrays referenced by that field, collectively wasting 1.5GiB of memory. I will submit a new patch that addresses this problem, and also deals with potentially duplicate arrays in other classes in a more uniform way.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 20s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m  9s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 42s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 1 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 50s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 43s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 3 new + 1210 unchanged - 19 fixed = 1213 total (was 1229) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 15s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 48s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}120m 11s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 18s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}168m 11s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.web.TestWebHdfsTimeouts |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |
|   | hadoop.hdfs.server.namenode.TestEditLog |
|   | hadoop.hdfs.server.balancer.TestBalancerRPCDelay |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HDFS-12051 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12902148/HDFS-12051.04.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux b45b90df5dfc 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 37efa67 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/22406/artifact/out/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22406/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22406/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22406/testReport/ |
| Max. process+thread count | 3739 (vs. ulimit of 5000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22406/console |
| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



Test failures above (some with OOM) look rather strange. I doubt that they are related with my change.

I've fixed one checkstyle problem that I've introduced. The other two are about long lines, but in the file in question (DFSConfigKeys.java) all lines are long, so this is irrelevant.

The findbugs warning is about some code that I didn't write, that just happens to be in one of the files that I've touched.

I am now submitting one more patch with some comments fixed/improved.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 18m  4s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  5s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  5s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m  9s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 59s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 1 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 50s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 49s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 2 new + 1216 unchanged - 19 fixed = 1218 total (was 1235) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 57s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m  6s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 1 new + 1 unchanged - 0 fixed = 2 total (was 1) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 52s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}127m 51s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}181m 50s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |
|  |  Increment of volatile field org.apache.hadoop.hdfs.server.namenode.NameCache.size in org.apache.hadoop.hdfs.server.namenode.NameCache.put(byte[])  At NameCache.java:in org.apache.hadoop.hdfs.server.namenode.NameCache.put(byte[])  At NameCache.java:[line 117] |
| Failed junit tests | hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency |
|   | hadoop.hdfs.TestReadStripedFileWithMissingBlocks |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration |
|   | hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HDFS-12051 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12902438/HDFS-12051.05.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux af5d38c733e4 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 949be14 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/22423/artifact/out/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22423/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/22423/artifact/out/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22423/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22423/testReport/ |
| Max. process+thread count | 3108 (vs. ulimit of 5000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22423/console |
| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



There are some test failures again. They seem unrelated - some of them and/or some related fails also failed in the previous Hadoop Jenkins build.

Thanks for the updated version Misha.

Couple of minor comments, 

1. the const 5 is better defined as a constant in the class, 
{{for (int collisnChainLen = 0; collisnChainLen < 5; collisnChainLen++) {}}

2. The value in {{private final static int DEFAULT_CACHE_SIZE = 4 * 1024 * 1024;}} should be referencing DFS_NAMENODE_NAME_CACHE_SIZE_DEFAULT instead of hardcode again here.

Hi [~daryn] and [~kihwal],  

The fix [~misha@cloudera.com] did here is a good improvement. Probably slight concern is about run time computation cost. Prior to this change, all INode names go through this computation. Misha added some more for improving memory usage better. 

The patch looks good to me over all. Wonder if you guys have further thoughts?

Thanks.


Addressed Yongjun's comments and submitted a new patch.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 21s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 29s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 42s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 16s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 1 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  0s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 18s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 11s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m  2s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 2 new + 1234 unchanged - 19 fixed = 1236 total (was 1253) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 18s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 23s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m  1s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 1 new + 1 unchanged - 0 fixed = 2 total (was 1) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}112m 23s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 24s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}172m 22s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |
|  |  Increment of volatile field org.apache.hadoop.hdfs.server.namenode.NameCache.size in org.apache.hadoop.hdfs.server.namenode.NameCache.put(byte[])  At NameCache.java:in org.apache.hadoop.hdfs.server.namenode.NameCache.put(byte[])  At NameCache.java:[line 116] |
| Failed junit tests | hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HDFS-12051 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12903319/HDFS-12051.06.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 3f5c528716e5 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 826507c |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/22493/artifact/out/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22493/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/22493/artifact/out/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22493/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22493/testReport/ |
| Max. process+thread count | 3264 (vs. ulimit of 5000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22493/console |
| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



Thanks [~misha@cloudera.com] for the new rev and he commented:

{quote}
The FindBugs issue cannot be fixed per se. The 'volatile int size' field is there just as a rough estimate of the size of this table, and I intentionally don't use an AtomicInteger instead, to avoid a performance impact. I can just remove this field if we are really concerned about FindBugs, but I think it's still better to have some means of debugging here (and hence this findbugs warning).

Regarding test failures. Previously all test failures in this ticket seemed transient. I ran these two tests locally, and they passed.
{quote}
which makes sense to me.

I'm +1 on the changes, I have kicked off new build and will commit by noon next Monday if there is no objection.

Thanks.



| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 20s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 32s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 16s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 20s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 43s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 10s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 22s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  8s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  8s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m  8s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 2 new + 1234 unchanged - 19 fixed = 1236 total (was 1253) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 24s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m  8s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}116m 17s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 22s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}176m 48s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |
|  |  Increment of volatile field org.apache.hadoop.hdfs.server.namenode.NameCache.size in org.apache.hadoop.hdfs.server.namenode.NameCache.put(byte[])  At NameCache.java:in org.apache.hadoop.hdfs.server.namenode.NameCache.put(byte[])  At NameCache.java:[line 116] |
| Failed junit tests | hadoop.hdfs.TestRollingUpgrade |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HDFS-12051 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12903319/HDFS-12051.06.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux cde41a3547fa 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / a81144d |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22583/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/22583/artifact/out/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22583/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22583/testReport/ |
| Max. process+thread count | 3115 (vs. ulimit of 5000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22583/console |
| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



I am very surprise from the Summary and Description of this JIRA that the patch changes not only SnapshotCopy but also all other INode as well as FSImage/Edit.  Does this suppose to improve the performance of Namenode?  If yes, could you measure it?

Please hold on committing the patch.  It definitely needs more discussion.

The current summary and description sound like a minor change but the patch is a major change.  Please update them or restrict the patch to what is described here.  Thanks.

Hi [~szetszwo], it's nice to finally see someone other than Yongjun comment on this patch so many months after I first submitted it.

Yes, this patch improves performance of Namenode, namely its memory consumption. In one of the comments above I mentioned that memory was reduced by 8.5%. The savings depend very much on the user data - it can be more or it can be less.

The reason I changed several files is becase it turns out that duplicate byte[] arrays come from many sources in the Namenode code. I don't think it makes this a major change. Please keep in mind that it doesn't change any code functionality - it just improves performance by reducing data duplication.

> ... it's nice to finally see someone other than Yongjun comment on this patch so many months after I first submitted it.

It is probably because of the summary and description of this JIRA.

> ... I don't think it makes this a major change. ...

No, this is not true.  INode and FSImage/Edit are core components of Namenode.

> ... Please keep in mind that it doesn't change any code functionality - it just improves performance by reducing data duplication.

How about running time?  Does this patch also improves it?

>> ... it's nice to finally see someone other than Yongjun comment on this patch so many months after I first submitted it.
> It is probably because of the summary and description of this JIRA.

I believe the summary/description still match the code. I just added the calls to NameCache.intern() in a couple more files recently. In many applications a similar addition, like calls to String.intern(), have to be made in even more places to get rid of all duplicate objects.

>> ... I don't think it makes this a major change. ...
> No, this is not true. INode and FSImage/Edit are core components of Namenode.

I agree. What I meant is that this change doesn't affect the functionality and its impact is easy to understand. It's not like some complex change to the core logic of Namenode.

>> ... Please keep in mind that it doesn't change any code functionality - it just improves performance by reducing data duplication.
> How about running time? Does this patch also improves it?

The extra code on itself doesn't noticeably affect the running time. However, reducing the number of objects and heap size reduces GC pauses. So the net effect on running time should be an improvement.

> The extra code on itself doesn't noticeably affect the running time. ...

How do you qualify this statement?

> I agree. What I meant is that this change doesn't affect the functionality and its impact is easy to understand. It's not like some complex change to the core logic of Namenode.

No, the impact is non-trivial.  Also, how do we know that there are no bugs in the new NameCache?

> ... I mentioned that memory was reduced by 8.5% ...

Comparing to no cache at all?  It may be true for your example but it does not seem a generally true statement.

How about comparing it to the old NameCache?

>> The extra code on itself doesn't noticeably affect the running time. ...
> How do you qualify this statement?

In Cloudera Manager, there is an "RPC Queue and Processing Time" chart for NameNode. I've replaced the NN jar in our test cluster with my own jar containing the updates in this patch and verified that the processing time didn't increase.

>> I agree. What I meant is that this change doesn't affect the functionality and its impact is easy to understand. It's not like some complex change to the core logic of Namenode.
> No, the impact is non-trivial. Also, how do we know that there are no bugs in the new NameCache?

If you check this patch, you will see that there is a TestNameCache.java file there, containing several tests. Plus, again, I've verified that the patch works in a live cluster.

>> ... I mentioned that memory was reduced by 8.5% ...
> Comparing to no cache at all? It may be true for your example but it does not seem a generally true statement.
> How about comparing it to the old NameCache?

Yes, I compared the live heap size (as measured by analyzing heap dumps), obtained from NN running in a live cluster, before and after applying my patch. "Before" means that NN used the old NameCache, and "after" means that it used my new NameCache.

Hi [~szetszwo],

Thanks for chiming in and good comments made. Do you think [~misha@cloudera.com] addressed all your concerns?



No.

Do you think that it is appropriate to claim that this is a SnapshotCopy change in the summary and the description but the patch actually changes NameNode internal silently, [~yzhangal]?

BTW, I am still waiting for some numbers to support his arguments.  Thanks.

[~szetszwo] I have already provided you the numbers that you asked for. If you would like anything else, please specify what you would like.

If you are unhappy with the summary not exactly matching the changes, please keep this conversation constructive and suggest what you think would be a possible alternative summary.

[~szetszwo] I hope I've addressed all your concerns?

No.  I still have at least the following question unanswered.

{quote}
Do you think that it is appropriate to claim that this is a SnapshotCopy change in the summary and the description but the patch actually changes NameNode internal silently, [~yzhangal]?
{quote}

[~szetszwo] did you see my previous response, by any chance? If you want to change this description, could you please be so kind to suggest your variant? Otherwise, as I am really afraid based on the current experience interacting with you, we may spend a lot more time just me suggesting new names and you rejecting them.

I've just modified the ticket name and description.

HI [~szetszwo],

Thanks for your feedback. [~misha@cloudera.com] changed the summary and description to address your comments, so now they are consistent with the patch changes. Wold you please take a look to see if it works for you? Thanks.

 

 

Hi [~szetszwo],

I would like to commit by tomorrow if there is no objection. Thanks.

 

> ...  Otherwise, as I am really afraid based on the current experience interacting with you, we may spend a lot more time just me suggesting new names and you rejecting them.

[~misha@cloudera.com], I have clearly [commented on 05/Jan/18|https://issues.apache.org/jira/browse/HDFS-12051?focusedCommentId=16314331&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16314331] that the Summary and Description of this JIRA are misleading. They were not fixed until yesterday.

I also asked [~yzhangal] 6 days ago [a question|https://issues.apache.org/jira/browse/HDFS-12051?focusedCommentId=16321743&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16321743] but got no answer.

These are probably the reasons that we have spent a lot of time.

> ... I have already provided you the numbers that you asked for. ...

Where are those numbers?  Sorry that I was not able to find them.  Thanks.

> I would like to commit by tomorrow if there is no objection. ...

Is there a reason to hurry?

[~szetszwo] regarding the patch name: I believe your comments are not very constructive, because you repeatedly complain that the summary is misleading, but don't explain in more details what you would like to change. The summary cannot cover the details of all the things I changed in the code. If it was crucial for you that it just mentions "NameCache" (that's the change that you've just made), you could say so explicitly and/or make this change yourself right away. That would save both of us a lot of time.

Regarding the numbers. I would really appreciate if you spent some time reading the beginning of this thread, where I gave the numbers indicating the significance of the problem (how much memory was wasted by duplicate byte[] arrays despite the presence of the old NameCache), and how much savings my new NameCache provided. But if you insist that I do it once again, I am copying this here for your convenience.

"Analyzing one heap dump with jxray (www.jxray.com), we observed that duplicate byte[] arrays result in 6.5% memory overhead, and most of these arrays are referenced by {{org.apache.hadoop.hdfs.server.namenode.INodeFileAttributes$SnapshotCopy.name}} and {{org.apache.hadoop.hdfs.server.namenode.INodeFile.name}}"

"What makes this case special is that the number of byte[] arrays is very high (~100M total arrays, ~25M unique arrays), but the average duplication factor is not very high (~4). Some byte[] arrays are replicated in an extremely high number, e.g. per the jxray report there are 3.5M copies of one 17-element array and so on. But that means that the vast majority of arrays actually don't have any duplicates."

"I've redesigned the new NameCache so that its size adjusts depending on the size of the input data, within user-specified limits.

It was tested using a synthetic workload simulating that of a big Hadoop installation. The result is an 8.5% reduction in the overhead due to duplicate byte[] arrays. Here are the results of the jxray analysis of the respective heap dumps:

Before
{code:java}
19. DUPLICATE PRIMITIVE ARRAYS

Types of duplicate objects:
     Ovhd         Num objs  Num unique objs   Class name

346,198K (12.6%)   12097893      3714559         byte[]
...
Total arrays: 12,101,111  Unique arrays: 3,716,791  Duplicate values: 371,424  Overhead: 346,322K (12.6%)
{code}
After:
{code:java}
19. DUPLICATE PRIMITIVE ARRAYS

Types of duplicate objects:
     Ovhd         Num objs  Num unique objs   Class name

100,440K (3.9%)   6208877      3855398         byte[]
...

Total arrays: 6,212,104  Unique arrays: 3,857,624  Duplicate values: 727,662  Overhead: 100,566K (3.9%){code}
"

I hope very much that you will now spend some time and really read these numbers.

As for "reasons to hurry" - this is not a hurry, this is just a change that's desperately behind the schedule. I made it in August 2017, and now it's January 2018.

> ... I believe your comments are not very constructive, because you repeatedly complain that the summary is misleading, ...

I am sorry that you seems not understanding the confusion.  The JIRA only mentioned SnapshotCopy but not the INode, FSImage or NameCache in NameNode.  I am not sure if you aware: they are huge difference.  People not using snapshot won't look at this.  However, everyone has to start a NameNode to run HDFS.

If SnapshotCopy is broken, HDFS still works for many use cases.  However, it is fatal if INode, FSImage or/and NameCache are broken.

> As for "reasons to hurry" - this is not a hurry, this is just a change that's desperately behind the schedule. I made it in August 2017, and now it's January 2018.

To be fair, when did you post your last patch?

Now the summary is just updated.  Do we want to give some time for other people reviewing this?

> Now the summary is just updated. Do we want to give some time for other people reviewing this?

I've been waiting for constructive feedback for most of the 6 months since the first patch was published. My last patch is _relatively_ recent only because [~yzhangal] finally looked at this code and provided such a feedback.

If more people will come with feedback because of the updated summary, it would be great. However, this ticket already has 12 viewers, with no feedback from most of them. So I am not sure I will now get more. I would suggest a deadline of this Friday afternoon, after which we will stop waiting for more feedback and commit this change.

Good comments [~szetszwo], the summary is better than before. 

About your question earlier to me, I think [~misha@cloudera.com] has been quite responsive addressing,  so sorry I did not reply myself there.

Since I'm behind reviewing this, I will commit by next Monday if there is no further objection.

Thanks.

 

BTW [~szetszwo], I pinged some folks requesting review earlier and did not hear back, anyone you would like to recommend?

Thanks.

 

> ..., I pinged some folks requesting review earlier and did not hear back, anyone you would like to recommend?

[~daryn] probably is the best choice since he has done a lot of performance improvement in NN.  Thanks.

Sorry time expired, I have pinged [~daryn] long time ago. I'm committing it now. If anyone finds issues that [~misha@cloudera.com], [~szetszwo], and I have not found, we can fix it in new jira. Thanks.

 

> ..., If anyone finds issues that Misha Dmitriev, Tsz Wo Nicholas Sze, and I have not found, we can fix it in new jira. Thanks.

I only have discovered that the patch has also re-implemented NameCache in NameNode but have not fully reviewed the patch.

If anyone found an issue later, it probably would cause data corruption.  We may be able to fix the bug but may not be able to recover the data.  My suggestion is to test it more.  It is your decision to commit this patch.  Thanks.


Thanks for your comments [~szetszwo]. I thought you had reviewed the patch. 

Misha described his tests at:

https://issues.apache.org/jira/browse/HDFS-12051?focusedCommentId=16084471&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16084471

and

https://issues.apache.org/jira/browse/HDFS-12051?focusedCommentId=16329891&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16329891

I agree more testing is always a good thing.

I did another round of review and found one thing I did not point out earlier (I'm sorry about that). The patch obsoleted the old config 
{code}
public static final String DFS_NAMENODE_NAME_CACHE_THRESHOLD_KEY = "dfs.namenode.name.cache.threshold";
public static final int DFS_NAMENODE_NAME_CACHE_THRESHOLD_DEFAULT = 10;
{code}
and introduced new config 
{code}
public static final String  DFS_NAMENODE_NAME_CACHE_SIZE_KEY = "dfs.namenode.name.cache.size";
public static final int     DFS_NAMENODE_NAME_CACHE_SIZE_DEFAULT = 4 * 1024 * 1024;
{code}
We should make this visible to the user saying that the former is deprecated because of the implementation change, and the new one can be used to config the new implementation.

Would you please address this [~misha@cloudera.com]?

Since I'm the only one who has reviewed the patch, I'm inviting [~manojg] for a review (thanks Manoj). While he is reviewing, other folks are welcome to review.

Thanks.



Thank you [~yzhangal], I've addressed your comment and uploaded the new patch.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 26s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 33s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 54s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 46s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 34s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 49s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 42s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 2 new + 1235 unchanged - 18 fixed = 1237 total (was 1253) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m  9s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m  8s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 53m 53s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 19s{color} | {color:red} The patch generated 2 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}102m 20s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |
|  |  Increment of volatile field org.apache.hadoop.hdfs.server.namenode.NameCache.size in org.apache.hadoop.hdfs.server.namenode.NameCache.put(byte[])  At NameCache.java:in org.apache.hadoop.hdfs.server.namenode.NameCache.put(byte[])  At NameCache.java:[line 116] |
| Failed junit tests | hadoop.hdfs.TestModTime |
|   | hadoop.hdfs.TestDataTransferKeepalive |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure190 |
|   | hadoop.hdfs.TestReadStripedFileWithDecoding |
|   | hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy |
|   | hadoop.hdfs.TestEncryptionZonesWithKMS |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |
|   | hadoop.hdfs.TestHdfsAdmin |
|   | hadoop.cli.TestHDFSCLI |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure000 |
|   | hadoop.hdfs.TestDFSStorageStateRecovery |
|   | hadoop.cli.TestErasureCodingCLI |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure200 |
|   | hadoop.security.TestPermissionSymlinks |
|   | hadoop.hdfs.TestSetrepIncreasing |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure160 |
|   | hadoop.security.TestPermission |
|   | hadoop.tools.TestHdfsConfigFields |
|   | hadoop.hdfs.TestRollingUpgrade |
|   | hadoop.hdfs.qjournal.client.TestQJMWithFaults |
|   | hadoop.security.TestRefreshUserMappings |
|   | hadoop.hdfs.TestDatanodeStartupFixesLegacyStorageIDs |
|   | hadoop.cli.TestXAttrCLI |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure130 |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HDFS-12051 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12907365/HDFS-12051.07.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 52687e275098 4.4.0-89-generic #112-Ubuntu SMP Mon Jul 31 19:38:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / a72cdcc |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22781/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/22781/artifact/out/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22781/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22781/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/22781/artifact/out/patch-asflicense-problems.txt |
| Max. process+thread count | 2666 (vs. ulimit of 5000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22781/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



Hi [~misha@cloudera.com],

Thanks for the updated patch, my apology I did not point out earlier:

For the config change, we need to modify ./hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml file accordingly. 

1.  We need to specify that the old config is obsoleted and new config will be used in the old config section. Please see examples in the same file like this. for example
{code}
 <property>
  <name>dfs.web.ugi</name>
  <value></value>
  <description>
    dfs.web.ugi is deprecated. Use hadoop.http.staticuser.user instead.
  </description>
</property>
{code}
Suggest to describe there that the implementation is changed etc, as I mentioned earlier.

2. We need to add a new section in this file for the new config, with some good description what it means and how to use it.

Thanks.


{quote}
Misha described his tests at:

https://issues.apache.org/jira/browse/HDFS-12051?focusedCommentId=16084471&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16084471

and

https://issues.apache.org/jira/browse/HDFS-12051?focusedCommentId=16329891&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16329891
{quote}
[~yzhangal], these two comments seem actually the same test result.  Do you agree?

This is a problem in this JIRA that it only seems having this one test result.  Questions/comments:
- What is the data used in the test?
- Why not running tests with different data sets?
- Why no new results posted for the newer patches?
- No tests were run over FSImage loading?

Thanks for working on this [~misha@cloudera.com]. Few comments on HDFS-12051.07.patch

{{NameCache.java}}
 * line 97: {{cache = new byte[cacheSize][];}} Since this will take up a contiguous space, we need to restrict the cache size to much lesser size than your current MAX size of 1 << 30. Your thoughts?
 * {{#cache}} is now following the {{open addressing}} model. Any reasons why you moved to this model compared to your initial design?
 * {{#put()}} 
 ** line 118: the first time cache fill .. shouldn't it be a new byte array name constructed from the passed in name? Why use the same caller passed in name?
 ** With the {{open addressing}} model, when you overwrite the cache slot with new names,  there could be INodes which are already referring to this name and are cut from the cache. Though their references are still valid, want  to understand why the preference given to new names compared to the old one.
 * I don't see any cache invalidation even when the INodes are removed. This takes up memory. Though not huge, design wise its not clean to leave the cache with stale values and incur cache lookup penalty in the future put() 
 * {{#getSize()}} since there is no cache invalidation, and since this open addressing model, the size returned is not right.
 * line 149: {{cacheSizeFor}} is this roundUp or roundDown to the nearest 2 power. Please add the link to {{HashMap#tableSizeFor()}} in the comment to show where the code is inspired from.

Thank you for the review, [~manojg] See my responses inline below.

{{NameCache.java}}
 * _line 97: {{cache = new byte[cacheSize][];}} Since this will take up a contiguous space, we need to restrict the cache size to much lesser size than your current MAX size of 1 << 30. Your thoughts?_

As you can see from line 78, the cache size is always set from the configuration, which provides a reasonable default, which is much, much smaller than 1<<30. It's up to the customer to increase this value if they need. If they have a huge heap, like 120GB (I've already heard of users approaching this!), then with 1<<30 it will result in an 8GB contiguous array. With a huge heap already, it is nothing wrong, if they really need it. But, anyway, if they decide to change this number, I think it's reasonable to expect them to have some understanding of what they are doing.

_{{#cache}} is now following the {{open addressing}} model. Any reasons why you moved to this model compared to your initial design?_

My own design for this cache has always been open addressing. The reason is that this is the most economical model in terms of memory: it uses just one pointer per cache entry, which is 8 bytes at most. If you use a cache with collision chains, like in java.util.HashMap, then each entry requires a pointer and a separate object (HashMap$Entry) This separate object takes at least 32 bytes, so you end up with at least 40 bytes per entry - five times more!

Now, for a real HashMap, that needs to hold potentially very large number of objects, and needs to hold them all, the collision chain design may be justified in some cases. But for our specialized fixed-size cache, that strives to minimize its own memory overhead, the open addressing design is more appropriate.
 * _{{#put()}}_ 
 ** _line 118: the first time cache fill .. shouldn't it be a new byte array name constructed from the passed in name? Why use the same caller passed in name?_

The goal of this cache is to _avoid_ object duplication as much as possible. If the caller gave us a name X for which we don't have an existing copy, just remember X and return it. If on the next invocation they gave us Y and it turns out to be the same as X, return X again, and Y will be effectively lost and GCed soon.

 
 * _With the {{open addressing}} model, when you overwrite the cache slot with new names,  there could be INodes which are already referring to this name and are cut from the cache. Though their references are still valid, want  to understand why the preference given to new names compared to the old one._

The preference is given to new names simply because it's the lesser evil. We already discussed this with [~yzhangal] in the past. First, obviously when a cache entry is overwritten, the old INodes will just continue to refer to their old names, i.e. no information is lost. Second, all our solution details stem from the fact that we don't know in advance how many names we are going to have, and how many of them will be duplicate. Thus we want to have a fixed-size cache that will be guaranteed to not waste much memory if there is little duplication, but will provide a benefit and will save a lot of memory if there is considerable duplication.

Now, suppose we have a cache of size 3, and names come as follows: 'A', 'B', 'C', 'D', 'D', 'D', ... The cache would be full after the first 3 names. If after that we don't override one of the entries to accomodate 'D', we will not realize any savings from deduplicating all the subsequent 'D's. To be fair, if this cache receives something like 'A', 'B', 'C', 'D', 'E', 'F', 'A', 'B', 'C', 'D', 'E', 'F' - then it just gets rewritten all the time and provides no benefit. But in practice (and I have already implemented a similar cache in several other projects), I've never observed such a pathology. With a reasonable-size cache and real-life data, it always works.
 * _I don't see any cache invalidation even when the INodes are removed. This takes up memory. Though not huge, design wise its not clean to leave the cache with stale values and incur cache lookup penalty in the future put()_ 

This cache by default takes just 16MB, which is 0.1% of 16GB, which is on the smaller side of NN heap size spectrum. So any losses due to stale cache entries are pretty negligible. Furthermore, the above-mentioned overwriting of cache entries when new data is coming also helps to keep the cache reasonably "fresh".
 * _{{#getSize()}} since there is no cache invalidation, and since this open addressing model, the size returned is not right._

As the javadoc for this method explains, this method may return a slightly incorrect result because of races, and is intended to be used in tests (where it's required) and possibly for debugging/monitoring. I've renamed it to getSizeEstimate() and hope that this is ok now.
 * _line 149: {{cacheSizeFor}} is this roundUp or roundDown to the nearest 2 power. Please add the link to {{HashMap#tableSizeFor()}} in the comment to show where the code is inspired from._

Good observation. I've tested and it's always rounding up. Updated the javadoc per your suggestion.

Addressed the most recent comments by [~yzhangal] and [~manojg]

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 12m 30s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 33m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  2m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  2s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 20s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m  8s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 54s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 50s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 2 new + 1235 unchanged - 18 fixed = 1237 total (was 1253) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 28s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 10s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 91m 27s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 22s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}175m 26s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |
|  |  Increment of volatile field org.apache.hadoop.hdfs.server.namenode.NameCache.size in org.apache.hadoop.hdfs.server.namenode.NameCache.put(byte[])  At NameCache.java:in org.apache.hadoop.hdfs.server.namenode.NameCache.put(byte[])  At NameCache.java:[line 116] |
| Failed junit tests | hadoop.hdfs.TestDFSClientRetries |
|   | hadoop.hdfs.web.TestWebHdfsTimeouts |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HDFS-12051 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12907776/HDFS-12051.08.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux 1a0589f35cc2 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 16be42d |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22819/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/22819/artifact/out/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22819/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22819/testReport/ |
| Max. process+thread count | 4917 (vs. ulimit of 5000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22819/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



I've just updated this patch to make NameNode automatically set the cache size as a percentage of the total heap (by default 1/512th, or little less than 0.25%). I found in my testing that this works better than the previous fixed-size cache.

I ran another test in a cluster with ~30M HDFS files, where NameNode uses ~20GB of memory. The measurements, before my change:

*Types of duplicate objects:*
||  *Overhead* ||  *# objects* ||  *Unique objects* || *Class name* ||
| 745,343K (4.0%)| 28,746,601| 9,566,545|byte[]|
| 48,014K (0.3%)| 1,533,733| 1,438|int[]|

 

The same table after my change:
||  *Overhead* ||  *# objects* ||  *Unique objects* || *Class name* ||
| 48,014K (0.3%)| 1,533,702| 1,407|int[]|
| 4,906K (< 0.1%)| 9,611,557| 9,553,953|byte[]|

 

In other words, we have about the same number of unique byte[] arrays, but almost none of them have duplicates now. As a result, we saved ~0.6GB of memory. This is the removed overhead of duplicate byte[] arrays (approx. 740MB) minus the size of the cache (approx. 160MB)

 

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 13s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 16m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  2s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 35s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 49s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  9s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 29s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 21s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 21s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m  5s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 1 new + 1235 unchanged - 18 fixed = 1236 total (was 1253) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m  9s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m  3s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}136m 58s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 24s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}193m 32s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |
|  |  Increment of volatile field org.apache.hadoop.hdfs.server.namenode.NameCache.size in org.apache.hadoop.hdfs.server.namenode.NameCache.put(byte[])  At NameCache.java:in org.apache.hadoop.hdfs.server.namenode.NameCache.put(byte[])  At NameCache.java:[line 119] |
| Failed junit tests | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |
|   | hadoop.hdfs.server.namenode.TestMetaSave |
|   | hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HDFS-12051 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12908462/HDFS-12051.09.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux 3849f6cfea35 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 2e7331c |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22899/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/22899/artifact/out/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22899/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22899/testReport/ |
| Max. process+thread count | 3358 (vs. ulimit of 5000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22899/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



I've just attached the detailed document comparing the old and new NameCache design.

Hi [~misha@cloudera.com],

Thanks for the further tests and revision and a design doc. 

Did you try the previous test after you changed to " set the cache size as a percentage of the total heap"? 

Hi [~manojg] and [~szetszwo], would you please take a look again at the latest?

Thanks.


Thanks [~misha@cloudera.com], your results look good.  Could you also benchmark the running time for FSImage loading?

I tested my change in a relatively small cluster that simulates some customer's workload at a smaller scale. It contains about 15M HDFS files, NN heap oscillates between about 2.1 and 2.9GiB. Before the change, FSImage load time is 48 sec, and there was the following overhead due to duplicate byte[] arrays:
||  *Overhead* ||  *# objects* ||  *Unique objects* || *Class name* ||
| 336,794K (14.8%)| 11,309,068| 3,132,447|byte[]|

 

I first applied the current patch, where the NameCache size is set as 1/512th of the total heap size. It resulted in a cache with 1M entries, taking 4MiB of memory. It turns out that when the cache size is considerably smaller than the number of unique arrays (3M in the above case), it leaves behind some duplicate objects. We saved ~100MiB of memory:
||  *Overhead* ||  *# objects* ||  *Unique objects* || *Class name* ||
| 232,435K (10.7%)| 8,599,197| 3,132,367|byte[]|

 

Next, I changed my patch so that by default NameCache is set as 1/400 of the total heap size. This resulted in a cache with 2M entries, and it eliminated almost all duplicate objects and saved, compared to the original NameNode, more than 260MiB of memory. The FSImage load time was 50 sec.
||  *Overhead* ||  *# objects* ||  *Unique objects* || *Class name* ||
| 76,209K (3.8%)| 4,866,933| 3,132,450|byte[]|

In this patch, the default NameCache size is increased from 1/512th to 1/400 of the total heap size.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 10s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 58s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  6s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 54s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 58s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 51s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 1 new + 1235 unchanged - 18 fixed = 1236 total (was 1253) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  2s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m  5s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 24s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}147m 19s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 25s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}201m  5s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |
|  |  Increment of volatile field org.apache.hadoop.hdfs.server.namenode.NameCache.size in org.apache.hadoop.hdfs.server.namenode.NameCache.put(byte[])  At NameCache.java:in org.apache.hadoop.hdfs.server.namenode.NameCache.put(byte[])  At NameCache.java:[line 119] |
| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeUUID |
|   | hadoop.hdfs.web.TestWebHdfsTimeouts |
|   | hadoop.hdfs.server.blockmanagement.TestOverReplicatedBlocks |
|   | hadoop.hdfs.server.blockmanagement.TestNameNodePrunesMissingStorages |
|   | hadoop.hdfs.server.blockmanagement.TestPendingInvalidateBlock |
|   | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS |
|   | hadoop.hdfs.server.federation.router.TestRouterQuota |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration |
|   | hadoop.hdfs.server.balancer.TestBalancerWithEncryptedTransfer |
|   | hadoop.hdfs.server.blockmanagement.TestBlockManager |
|   | hadoop.hdfs.server.blockmanagement.TestBlocksWithNotEnoughRacks |
|   | hadoop.hdfs.server.blockmanagement.TestPendingReconstruction |
|   | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped |
|   | hadoop.hdfs.server.blockmanagement.TestBlockReportRateLimiting |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |
|   | hadoop.hdfs.server.blockmanagement.TestReconstructStripedBlocksWithRackAwareness |
|   | hadoop.hdfs.server.blockmanagement.TestRBWBlockInvalidation |
|   | hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA |
|   | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |
|   | hadoop.hdfs.server.blockmanagement.TestSortLocatedStripedBlock |
|   | hadoop.hdfs.server.blockmanagement.TestSequentialBlockGroupId |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient |
|   | hadoop.hdfs.server.federation.router.TestRouterRpcMultiDestination |
|   | hadoop.hdfs.server.blockmanagement.TestNodeCount |
|   | hadoop.hdfs.TestDFSClientRetries |
|   | hadoop.hdfs.server.blockmanagement.TestComputeInvalidateWork |
|   | hadoop.hdfs.server.balancer.TestBalancerRPCDelay |
|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HDFS-12051 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12909373/HDFS-12051.10.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux e29137798e75 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / a196ee9 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22944/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/22944/artifact/out/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22944/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22944/testReport/ |
| Max. process+thread count | 3003 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22944/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



[~szetszwo] I've done more benchmarking per your request. That was actually useful for tuning the default cache size. See the results above.

Thanks, [~misha@cloudera.com] for running benchmark.  

Thanks [~misha@cloudera.com] for the new revs and [~szetszwo] for the review.

Hi Misha,

Sorry I did not review your latest rev in time. One minor suggestion, the ratio config is more intuitive to be a floating point, like other ratio kind of config parameters in DFSConfigKeys.java. I noticed that the default value in the code and in hdfs-default.xml is not the same. We need to make them same.

Hi [~szetszwo], are you ok with setting the default cache ratio to 1/400 (0.0025)?  Given that the existing cache is not working well for some cases we examined, would you agree to push this forward?

Thanks.

 

> ... and Tsz Wo Nicholas Sze for the review.

I like to clarify one more time that I neither have reviewed the patch nor the results.  I do have taken quick looks on the results but, honestly, I have not checked the details.  Thanks.

> ... would you agree to push this forward?

I won't be able to comment on this.  Sorry.

Addressed the latest commment by [~yzhangal] regarding the cache size as a heap size ratio format (switched from int to float).

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 11s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 40s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 53s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 50s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 3 new + 1235 unchanged - 18 fixed = 1238 total (was 1253) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 55s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m  2s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 88m 30s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}140m 28s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |
|  |  Increment of volatile field org.apache.hadoop.hdfs.server.namenode.NameCache.size in org.apache.hadoop.hdfs.server.namenode.NameCache.put(byte[])  At NameCache.java:in org.apache.hadoop.hdfs.server.namenode.NameCache.put(byte[])  At NameCache.java:[line 119] |
| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HDFS-12051 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12909669/HDFS-12051.11.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux c995c1528d5b 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / b061215 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22985/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/22985/artifact/out/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22985/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22985/testReport/ |
| Max. process+thread count | 4047 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22985/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



I've taken a quick look at the patch and have some questions:

# Is there a way to disable the cache entirely, if we find that there's some bug in the implementation? e.g. if you set the ratio to 0, does everything behave correctly?
# How hard would it be to not make this class a static singleton, and instead have a single instance of it in the NN that can be referenced, perhaps as an instance variable of the {{FSNamesystem}}? That seems a bit less fragile if it's possible, and could allow for the class to be more easily tested.
# Have you done any verification of the correctness of this cache in any of your benchmarks? e.g. something that walked the file system tree to ensure that the names are identical with/without this cache I think would help allay correctness concerns.
# I'd really like to see some more tests of the actual cache implementation itself, e.g. in the presence of hash collisions, behavior at the boundaries of the main cache array, overlap of slots probed in the open addressing search, other edge cases, etc.
# I see that precommit raised some findbugs warnings and had some failed unit tests. Can we please address the findbugs warnings, and also confirm that those unit test failures are unrelated?
# Seems like this cache will have a somewhat odd behavior if an item hashes to a slot that's within {{MAX_COLLISION_CHAIN_LEN}} slots of the end of the array, in that it looks like we'll just probe the same slot over and over again up to {{MAX_COLLISION_CHAIN_LEN}} times. Is this to be expected?

[~misha@cloudera.com] - in general I share [~szetszwo]'s concern that we just need to be very careful with changes to this sort of code in the NN, because even a small bug could subtly result in very severe consequences. I realize that the length of time that this patch has been up is frustrating for you, but please understand that the concerns being raised are in good faith, and are just focused on trying to ensure that file system data is not ever put at risk. The more tests you can include in the patch, and the more correctness testing you can report having done on the patch, will help all reviewers feel more comfortable and confident in committing this very valuable change. The recent reviews that this patch have received demonstrate to me that we're moving in a good direction to getting this JIRA resolved.

I'd also like to ping [~daryn] and [~kihwal] to see if they have time to review this change, as I bet they'll be keenly interested in this improvement.

Thank you for the review [~atm] Please see my answers below.

_> Is there a way to disable the cache entirely, if we find that there's some bug in the implementation? e.g. if you set the ratio to 0, does everything behave correctly?_

It won't, but I can add this functionality.

_> How hard would it be to not make this class a static singleton, and instead have a single instance of it in the NN that can be referenced, perhaps as an instance variable of the {{FSNamesystem}}? That seems a bit less fragile if it's possible, and could allow for the class to be more easily tested._

As you can see, this class is not really a static singleton. Its public API is indeed a single static put() method, but inside there is a singleton _instance_ of NameCache, with its instance methods. Initially I didn't have this singleton at all, and it indeed was an instance variable of FSNamesystem. But later I found that there are several other places in the code where duplicate byte[] arrays are generated, and where it would be very hard to pass this instance variable. So I ended up with this static API, which makes it easier to use NameCache anywhere in the code. But ability to test it is not compromised.

_> Have you done any verification of the correctness of this cache in any of your benchmarks? e.g. something that walked the file system tree to ensure that the names are identical with/without this cache I think would help allay correctness concerns._

Well, I can try that, but honestly, how paranoid should we be? In my opinion, this code is simple enough to pass with a combination of unit tests and some runs in the cluster.

_> I'd really like to see some more tests of the actual cache implementation itself, e.g. in the presence of hash collisions, behavior at the boundaries of the main cache array, overlap of slots probed in the open addressing search, other edge cases, etc._

_>I see that precommit raised some findbugs warnings and had some failed unit tests. Can we please address the findbugs warnings, and also confirm that those unit test failures are unrelated?_

The single findbugs issue has been already explained. It's legitimate, but we intentionally do something that wouldn't be good in general (use a volatile field and increment it without synchronization) just to enable some information for testing without degrading performance in production. As for unit tests - well, every time some different unit test fails, which makes me think that they are flaky (I had same experience in the past with my other changes in HDFS). I looked at them but couldn't see any obvious signs that the problems are related to my code. There are timeouts and similar things that tend to happen in flaky tests. Here I think I really need help from someone else in the HDFS team.

_> Seems like this cache will have a somewhat odd behavior if an item hashes to a slot that's within {{MAX_COLLISION_CHAIN_LEN}} slots of the end of the array, in that it looks like we'll just probe the same slot over and over again up to {{MAX_COLLISION_CHAIN_LEN}} times. Is this to be expected?_

I don't think there is any problem here. We use the same formula to get the next slot, and it wraps around the array boundary correctly. Take a look at the test program below that uses the same formula, and its output:
{code:java}
public static void main(String args[]) {
  int capacity = 4;
  int slot = 0;
  for (int i = 0; i < 8; i++) {
    slot = (slot + 1) & (capacity - 1);             
    System.out.println("slot = " + slot);
  }
}

> java Test
slot = 1
slot = 2
slot = 3
slot = 0
slot = 1
slot = 2
slot = 3
slot = 0{code}
 

Thanks for the followup, [~misha@cloudera.com]. A few responses:

bq. It won't, but I can add this functionality.

Great, thanks.

bq. As you can see, this class is not really a static singleton. Its public API is indeed a single static put() method, but inside there is a singleton instance of NameCache, with its instance methods. Initially I didn't have this singleton at all, and it indeed was an instance variable of FSNamesystem. But later I found that there are several other places in the code where duplicate byte[] arrays are generated, and where it would be very hard to pass this instance variable. So I ended up with this static API, which makes it easier to use NameCache anywhere in the code. But ability to test it is not compromised.

Sorry, I shouldn't have said the class was a singleton, but I think the point remains. Especially in the context of tests, wherein we have potentially several HA or federated NNs running within a single process, I worry that using a singleton instance will cause some odd behavior. Passing it around may be difficult, but do all the places in the code where you're adding calls to {{NameCache}} perhaps have a reference to the {{FSNamesystem}}? If so, making the {{NameCache}} a member of the {{FSNamesystem}} may make that not so hard to deal with.

bq. Well, I can try that, but honestly, how paranoid should we be? In my opinion, this code is simple enough to pass with a combination of unit tests and some runs in the cluster.

I think we need to be diligent in confirming the correctness of this change, or any change like this, as the ramifications of a bug here are both potentially subtle and severe.

bq. The single findbugs issue has been already explained. It's legitimate, but we intentionally do something that wouldn't be good in general (use a volatile field and increment it without synchronization) just to enable some information for testing without degrading performance in production. As for unit tests - well, every time some different unit test fails, which makes me think that they are flaky (I had same experience in the past with my other changes in HDFS). I looked at them but couldn't see any obvious signs that the problems are related to my code. There are timeouts and similar things that tend to happen in flaky tests. Here I think I really need help from someone else in the HDFS team.

I think you're probably right that the failures are flaky tests - I just wanted to make sure you or someone had taken a look at them and confirmed that.

bq. I don't think there is any problem here. We use the same formula to get the next slot, and it wraps around the array boundary correctly. Take a look at the test program below that uses the same formula, and its output:<snip>

Gotcha, makes sense. This behavior would be a great thing to ensure is in a unit test.

[~atm] I've just submitted a patch where I've addressed your comments. I've added functionality to completely disable NameCache by specifying DFS_NAMENODE_NAME_CACHE_SIZE_RATIO_KEY = 0.0. I've added a test for this, plus a stress-test where the cache is exercised by multiple threads and the number of unique names exceeds the cache's capacity (this may happen in production). As we discussed, so far I cannot find a good way to pass around a "non-singleton" NameCache instance around all the code that needs it. On the other hand, I explained that I don't see problems if this singleton is used by multiple NameNode instances running within the same JVM.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 23s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 31s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 58s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 14s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 42s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 4 new + 1234 unchanged - 19 fixed = 1238 total (was 1253) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 24s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 52s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}135m  9s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 19s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}184m  4s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |
|  |  Increment of volatile field org.apache.hadoop.hdfs.server.namenode.NameCache.size in org.apache.hadoop.hdfs.server.namenode.NameCache.put(byte[])  At NameCache.java:in org.apache.hadoop.hdfs.server.namenode.NameCache.put(byte[])  At NameCache.java:[line 125] |
| Failed junit tests | hadoop.hdfs.web.TestWebHdfsTimeouts |
|   | hadoop.hdfs.server.namenode.TestReencryptionWithKMS |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HDFS-12051 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12910663/HDFS-12051.12.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux a62106be8c4b 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 8f66aff |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/23074/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/23074/artifact/out/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/23074/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/23074/testReport/ |
| Max. process+thread count | 3676 (vs. ulimit of 5500) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/23074/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



