production code changes

* HADOOP-13985

Testing improvements

* HADOOP-13589
* HADOOP-13995
* HADOOP-13876



Mmm




All of the dependencies for this have patches available for review.  I would like to start on empty directory handling improvements, but would prefer to merge the feature branch to trunk first to avoid having to maintain more S3AFileSystem diffs.

*I'm proposing we merge* HADOOP-13345 to trunk as soon as we get the dependent JIRAs linked here committed.  I'll provide a summary of where we are at below.  I look forward to feedback from [~stevel@apache.org], [~cnauroth], [~eddyxu], [~mackrorysd], and the rest of the community.

The main feature we want for the initial version is listing consistency, and we've accomplished that.

For testing, we have completed (off the top of my head):
- List consistency tests with failure injection.  (HADOOP-13793) This integration test forces a delay in visibility of certain files by wrapping the AWS S3 client. It asserts listing is consistent.  The test fails without S3Guard, and succeeds with it. 
- All existing S3 integration tests with and without S3Guard.  The filesystem contract tests have been invaluable here. (HADOOP-13589 makes these very easy to run).
- MetadataStore contract tests that ensure that the API semantics of the DynamoDB and in-memory reference implementations are correct.
- MetadataStore scale tests that can be used to force DynamoDB service throttling and ensure we are robust to that.
- Unit tests for different parts of the S3Guard logic.

In addition to this upstream testing, my colleagues have run a couple of our in-house test harnesses against S3Guard.  This includes Hive, Spark, and a number of other components.  All the testing is looking great so far.

Edit: Here is a [link to current s3guard documentation|https://github.com/apache/hadoop/blob/HADOOP-13345/hadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/s3guard.md]

Is the s3guard documentation actually linked from the main index?

[~aw] no.. thanks for noticing. I'll fix that (filed HADOOP-14051).

+1 for proceeding with a trunk merge vote after resolving the linked issues.  (I just added the HADOOP-14051 documentation fix mentioned in the last comment.)

Looking at this, what else do we need?

[~stevel@apache.org] probably merge in latest trunk, do a full round of testing, and resolve the documentation JIRA that this depends (haven't had time to do that yet).

FYI I'm currently working on HADOOP-13914, which will change a decent amount of code in S3AFileSystem and related tests.

Add: review key hashing so that we are confident it spreads the data widely, rather than biased towards a single shard in the database

Overall we're close to the merge. I link [HADOOP-14215] here as dependency for merging back to {{trunk}} (initial preview). Correct me if that is not critical. Thanks,

Hi [~liuml07], [~mackrorysd], [~stevel@apache.org] and others. Looking for your feedback here.

I'd like to start a DISCUSS thread on the email list to propose merging S3Guard to trunk if you guys feel like we are at a good point.

I think that active s3guard development will continue for a year or more, so we might also want to resolve HADOOP-13345 and create a new "phase 2" S3Guard JIRA to hold ongoing subtasks.  Thoughts?



I would generally support a merge where we are in development. I feel like things are generally sufficiently useful and stable.

At a finer-grained level though I'm adding HADOOP-14448 as a dependency. There are tests in trunk that don't play nice with S3Guard. I'm of the opinion that it's just a "ignore-the-tests-in-that-scenario-and-document-the-implications" scenario though, so it will probably be resolved soon.

I support to merge back to trunk if we agree there is no blockers. For basic listing and delete tracking, the core logic has been finished, reviewed and to some degree tested. There are other critical subtasks but developing in trunk is OK to me. As we chose to integrate the S3Guard feature in S3AFilesystem itself, it's better to let incoming S3A changes be aware of the fact that, there may be a metadata store.

it's time to merge in, as the branch is big enough we should merge in trunk to the branch again, have everything working nicely; the troublesome SSE-C test can be skipped and covered in docs/release notes.

Before then, last chance to do refactorings and renamings of options, etc, and review.

h3. Code
Need to look at code to see if
# perf on non-s3guard codepaths is impacted, e.g. by new requests
# config options look good before freezing their names
# all those places which have TODO in them: are they critical? If not, do they at least have JIRA coverage somewhere

h3. Docs
# docs: how well do they read for someone who hasn't worked on it (this can evolve, obviously)
# release notes. Maybe: make clear it's experimental, safe in non-auth, auth is more dangerous

h3. Testing!

what functional tests have people done?

I'm trying to do some downstream testing in my [spark cloud integration module|https://github.com/hortonworks-spark/cloud-integration] project, mostly on committer. But I've just moved the spark SQL Hive test suite {{org.apache.spark.sql.sources.HadoopFsRelationTest}} & its ORC subclass in so I can verify that the commit algorithms work there. I'm now trying to switch over to the inconsistent client to see if I can make it easy to observe inconsistencies in the classic "legacy" file commit algorithms. (ignoring Parquet for technical reasons; that'll need a fix in spark itself).

Other logistics
# get some review from [~cnauroth] if he has the time
# submit a single patch to cover the merge

linking to HADOOP-14423; need to stop a putObjectDirect with length of -1.

Thank you for the comments [~liuml07] and [~stevel@apache.org].

{quote}
what functional tests have people done?
{quote}

We've done quite a bit of functional testing.  We've run our standard downstream Hive, Spark, MR, Impala, scale, and performance tests.  For performance, we generally saw similar or better performance with S3Guard enabled (due to short circuit getFileStatus()).

{quote}
Need to look at ... perf on non-s3guard codepaths is impacted, e.g. by new requests
{quote}

This is a good point.  Do you prefer timing-based microbenchmarks, or S3 request statistics (counts)?


bq. We've run our standard downstream Hive, Spark, MR, Impala, scale, and performance tests

If these tests were working *before* you turned s3guard on then they weren't catching inconsistencies & so were lucky (as mine were). I'm running my spark committer tests with the inconsistent client turned on, and it is repeatedly failing the classic & magic committers without s3guard enabled: both depend on consistent listing. Also found a brittleness in path cleanup for the magic committer too; cleanup code *must* handle an FNFE if there's a file returned in the listing but which isn't there in the GET. This is why I'd like the  factory for the inconsistent client be in src/main: it lets anyone turn on inconsistency for their test runs

bq. This is a good point. Do you prefer timing-based microbenchmarks, or S3 request statistics (counts)?

the instrumentation ones are way less brittle; Ming has been fixing some nanotimer-assertion in WASB which was failing intermittently. I have some tests somewhere which call listFiles(recursive) against the amazon landsat store: that's the reference example of a deep and wide directory tree.



regarding tests, I'm seeing something up with the combination of (s3guard and the partition committer (and only it)): a newly created file is where it should be, but the parent dir is still tagged as missing. I  can GET the file, but if I try to list the parent I get rejected:
{code}
2017-06-02 18:19:10,709 [ScalaTest-main-running-S3ACommitDataframeSuite] INFO  s3.S3AOperations (Logging.scala:logInfo(54)) - s3a://hwdev-steve-new/cloud-integration/DELAY_LISTING_ME/S3ACommitDataframeSuite/dataframe-committer/partitioned/orc/part-00000-7573c876-38e5-4024-8a53-51fa1aa9c9c2-c000.snappy.orc size=384
2017-06-02 18:19:10,709 [ScalaTest-main-running-S3ACommitDataframeSuite] DEBUG s3a.S3AFileSystem (S3AFileSystem.java:innerGetFileStatus(1899)) - Getting path status for s3a://hwdev-steve-new/cloud-integration/DELAY_LISTING_ME/S3ACommitDataframeSuite/dataframe-committer/partitioned/orc/_SUCCESS  (cloud-integration/DELAY_LISTING_ME/S3ACommitDataframeSuite/dataframe-committer/partitioned/orc/_SUCCESS)
2017-06-02 18:19:10,710 [ScalaTest-main-running-S3ACommitDataframeSuite] DEBUG s3guard.MetadataStore (LocalMetadataStore.java:get(151)) - get(s3a://hwdev-steve-new/cloud-integration/DELAY_LISTING_ME/S3ACommitDataframeSuite/dataframe-committer/partitioned/orc/_SUCCESS) -> file  s3a://hwdev-steve-new/cloud-integration/DELAY_LISTING_ME/S3ACommitDataframeSuite/dataframe-committer/partitioned/orc/_SUCCESS 3400    UNKNOWN  false S3AFileStatus{path=s3a://hwdev-steve-new/cloud-integration/DELAY_LISTING_ME/S3ACommitDataframeSuite/dataframe-committer/partitioned/orc/_SUCCESS; isDirectory=false; length=3400; replication=1; blocksize=1048576; modification_time=1496423948811; access_time=0; owner=stevel; group=stevel; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false} isEmptyDirectory=FALSE
2017-06-02 18:19:10,710 [ScalaTest-main-running-S3ACommitDataframeSuite] DEBUG s3a.S3AFileSystem (S3AFileSystem.java:innerListStatus(1660)) - List status for path: s3a://hwdev-steve-new/cloud-integration/DELAY_LISTING_ME/S3ACommitDataframeSuite/dataframe-committer/partitioned/orc
2017-06-02 18:19:10,710 [ScalaTest-main-running-S3ACommitDataframeSuite] DEBUG s3a.S3AFileSystem (S3AFileSystem.java:innerGetFileStatus(1899)) - Getting path status for s3a://hwdev-steve-new/cloud-integration/DELAY_LISTING_ME/S3ACommitDataframeSuite/dataframe-committer/partitioned/orc  (cloud-integration/DELAY_LISTING_ME/S3ACommitDataframeSuite/dataframe-committer/partitioned/orc)
2017-06-02 18:19:10,711 [ScalaTest-main-running-S3ACommitDataframeSuite] DEBUG s3guard.MetadataStore (LocalMetadataStore.java:get(151)) - get(s3a://hwdev-steve-new/cloud-integration/DELAY_LISTING_ME/S3ACommitDataframeSuite/dataframe-committer/partitioned/orc) -> file  s3a://hwdev-steve-new/cloud-integration/DELAY_LISTING_ME/S3ACommitDataframeSuite/dataframe-committer/partitioned/orc 0       UNKNOWN  true  FileStatus{path=s3a://hwdev-steve-new/cloud-integration/DELAY_LISTING_ME/S3ACommitDataframeSuite/dataframe-committer/partitioned/orc; isDirectory=false; length=0; replication=0; blocksize=0; modification_time=1496423936532; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}
2017-06-02 18:19:10,719 [dispatcher-event-loop-6] INFO  spark.MapOutputTrackerMasterEndpoint (Logging.scala:logInfo(54)) - MapOutputTrackerMasterEndpoint stopped!
2017-06-02 18:19:10,727 [dispatcher-event-loop-3] INFO  scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint (Logging.scala:logInfo(54)) - OutputCommitCoordinator stopped!
2017-06-02 18:19:10,729 [ScalaTest-main-running-S3ACommitDataframeSuite] INFO  spark.SparkContext (Logging.scala:logInfo(54)) - Successfully stopped SparkContext
- Dataframe+partitioned *** FAILED ***
  java.io.FileNotFoundException: Path s3a://hwdev-steve-new/cloud-integration/DELAY_LISTING_ME/S3ACommitDataframeSuite/dataframe-committer/partitioned/orc is recorded as deleted by S3Guard
  at org.apache.hadoop.fs.s3a.S3AFileSystem.innerGetFileStatus(S3AFileSystem.java:1906)
  at org.apache.hadoop.fs.s3a.S3AFileSystem.getFileStatus(S3AFileSystem.java:1881)
  at org.apache.hadoop.fs.s3a.S3AFileSystem.innerListStatus(S3AFileSystem.java:1664)
  at org.apache.hadoop.fs.s3a.S3AFileSystem.listStatus(S3AFileSystem.java:1640)
  at com.hortonworks.spark.cloud.ObjectStoreOperations$class.validateRowCount(ObjectStoreOperations.scala:340)
  at com.hortonworks.spark.cloud.CloudSuite.validateRowCount(CloudSuite.scala:37)
  at com.hortonworks.spark.cloud.s3.commit.S3ACommitDataframeSuite.testOneFormat(S3ACommitDataframeSuite.scala:107)
  at com.hortonworks.spark.cloud.s3.commit.S3ACommitDataframeSuite$$anonfun$1$$anonfun$apply$2.apply$mcV$sp(S3ACommitDataframeSuite.scala:71)
  at com.hortonworks.spark.cloud.CloudSuiteTrait$$anonfun$ctest$1.apply$mcV$sp(CloudSuiteTrait.scala:66)
  at com.hortonworks.spark.cloud.CloudSuiteTrait$$anonfun$ctest$1.apply(CloudSuiteTrait.scala:64)
{code}
I don't know where the blame lies here, but its something I'd like to understand first. IT does not happen when s3guard is off; there the new committer works

{quote}If these tests were working before you turned s3guard on then they weren't catching inconsistencies & so were lucky (as mine were){quote}

Actually I believe a few of those tests had transient failures at a fairly consistent rate (something like 1 in 4 or 1 in 6 test runs if I remember correctly) that had always been assumed to be the result of inconsistency. They stopped failing entirely once the initial work for list-after-put consistency was incorporated.

[~stevel@apache.org] - regarding that test issue, that would happen if a directory was deleted and a file inside it was then created without correctly overwriting or removing the tombstone of the parent directories. If you're using the DynamoDB implementation, it should definitely be replacing the tombstone for the parent directory when the file is created. If you're using the Local implementation, I wonder if that's happening as a result of HADOOP-14457. I'll take a closer look at that again and see if I can reproduce, though I thought I had added test cases for that sequence.

bq. Actually I believe a few of those tests had transient failures at a fairly consistent rate (something like 1 in 4 or 1 in 6 test runs if I remember correctly) that had always been assumed to be the result of inconsistency. They stopped failing entirely once the initial work for list-after-put consistency was incorporated.

yes. That's why our docs on using s3 as a dest now say "dont". The big test runs fail as they have validation of the output and catch problems. Other people's apps may not do that validation, so end up getting bad data & not noticing

If I get it correctly, [HADOOP-14457] is the only blocker before this is merged to trunk, right?

As far as I can see.

-I'd actually like to get the S3A lambda and retry logic in there too, even though its going to be in the committer where it gets picked up.-

-maybe a few more side things too (json ser/deser). Why? I want them in trunk for general S3A work, such as implementing all retry error handling.-

This is not the committer itself. that I'd like to get into the 13345 branch once the preview is out.

Regarding  merge process: vote in commons, 2+ votes. Even though mingliang and I are quorate, be good to get some review from others, ideally cnauroth and others with experience in the area

Or, in the case of [~aw] somebody with no experience in the area but who cares about the support calls code will raise

Thanks Steve for the list, I'll review those related JIRAs.

Update: 

# I don't want to get those new things I mentioned in. Let's get the (fairly stable) preview out and then worry about the new features.
# That leaves only a couple of patches HADOOP-14505 and HADOOP-14633
# For the merge, a big single squashed s3guard patch should seem to be the best way, "everything in one go"
# I think I'll also do a 2.9 backport branch, which should just be java 7 anonymous classes in places of lambdas in the tests. We have a lot of that internally already. That'd be a followon to the merge


+1, [~stevel@apache.org]

Thanks Steve.

{quote}
For the merge, a big single squashed s3guard patch should seem to be the best way, "everything in one go"
{quote}
I'm OK with this as the code change will be simple and clear.

{quote}
I think I'll also do a 2.9 backport branch
{quote}
+1 for this. We had some internal effort and this seems very promising.

We are pretty much done here, down to those review-of-spelling nits. I'm about do do a merge into s3guard of trunk again, as I can see things have diverged (if I mix builds, I get errors about commons-lang3 missing)

Status: review nearly ready. Once In I'm going to create a full diff to see what Yetus says...this will list all our style/findbugs issues, so it's a big change to review or ignore things.

I'm also thinking of moving all tests from Lambdas to closures, so that a branch-2 will be nearly identical to this one. This will make integration easier, as well as aid backporting any phase II work.

Mingliang did this internally, which I've got as a starting base. But as intelliJ does it itself, it may be simplest to use it for that, leaving only any other 8 -> 7 migration issue. Mingliang: what were the other java 7 migration issues other than us using Lambda expressions in tests.

(FWIW, all the error handling in HADOOP-13786 uses L-exps in production code to wrap AWS SDK calls with retry logic, something we need to roll out across the FS to handle throttling and other transients. I really want to stay in java 8 there)

Patch 001; the diff from s3guard+doc review against trunk. I expect this to show up some issues

This is a chance to review all findbugs/checkstyle/javadoc issues which have accrued over the year and see if they can be cleaned up. I'm not going to worry about line length, be a bit more lax about things in tests than production.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 59 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 37s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 41s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m  5s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  9s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 55s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-project hadoop-assemblies {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 19s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 38s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 33s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 11s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 12m 11s{color} | {color:red} root generated 2 new + 1344 unchanged - 1 fixed = 1346 total (was 1345) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 16s{color} | {color:orange} root: The patch generated 31 new + 205 unchanged - 4 fixed = 236 total (was 209) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} shellcheck {color} | {color:green}  0m  1s{color} | {color:green} There were no new shellcheck issues. {color} |
| {color:green}+1{color} | {color:green} shelldocs {color} | {color:green}  0m 26s{color} | {color:green} There were no new shelldocs issues. {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  1s{color} | {color:red} The patch has 8 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  9s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-project hadoop-assemblies {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 38s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 36s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 29s{color} | {color:green} hadoop-project in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 29s{color} | {color:green} hadoop-assemblies in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 24s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 58s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 43s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}100m 26s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.TestKDiag |
|   | hadoop.net.TestDNS |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-13998 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12881618/HADOOP-13998-001.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  findbugs  checkstyle  shellcheck  shelldocs  |
| uname | Linux d5976498809b 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 8b242f0 |
| Default Java | 1.8.0_144 |
| shellcheck | v0.4.6 |
| findbugs | v3.1.0-RC1 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/13020/artifact/patchprocess/diff-compile-javac-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13020/artifact/patchprocess/diff-checkstyle-root.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/13020/artifact/patchprocess/whitespace-eol.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13020/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13020/testReport/ |
| modules | C: hadoop-project hadoop-assemblies hadoop-common-project/hadoop-common hadoop-tools/hadoop-aws U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13020/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



Patch 002; iff with the final merge of HADOOP-14749 in; no other changes

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 59 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 58s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m  6s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  8s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 57s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-project hadoop-assemblies {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 19s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 23s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 34s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 50s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 10m 50s{color} | {color:red} root generated 2 new + 1344 unchanged - 1 fixed = 1346 total (was 1345) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 11s{color} | {color:orange} root: The patch generated 19 new + 205 unchanged - 4 fixed = 224 total (was 209) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 14s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} shellcheck {color} | {color:green}  0m  0s{color} | {color:green} There were no new shellcheck issues. {color} |
| {color:green}+1{color} | {color:green} shelldocs {color} | {color:green}  0m 25s{color} | {color:green} There were no new shelldocs issues. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  8s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-project hadoop-assemblies {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 37s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 38s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 29s{color} | {color:green} hadoop-project in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 30s{color} | {color:green} hadoop-assemblies in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 18s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 59s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 44s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 96m 35s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.TestKDiag |
|   | hadoop.net.TestDNS |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-13998 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12881631/HADOOP-13998-002.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  findbugs  checkstyle  shellcheck  shelldocs  |
| uname | Linux 54f0bdac83ad 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 8b242f0 |
| Default Java | 1.8.0_144 |
| shellcheck | v0.4.6 |
| findbugs | v3.1.0-RC1 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/13022/artifact/patchprocess/diff-compile-javac-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13022/artifact/patchprocess/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13022/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13022/testReport/ |
| modules | C: hadoop-project hadoop-assemblies hadoop-common-project/hadoop-common hadoop-tools/hadoop-aws U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13022/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



Thanks, [~steve_l] - I'm reviewing (is a comitter +1 even binding on this? I seem to recall branch merges being PMC votes, but I don't see that in the by-laws). I ran tests locally as well and only got some typical S3N flakiness:

{code}
testListStatus(org.apache.hadoop.fs.s3native.ITestJets3tNativeS3FileSystemContract)  Time elapsed: 2.527 sec  <<< FAILURE!
java.lang.AssertionError: expected:<1> but was:<12>

testRenameDirectoryAsExistingFile(org.apache.hadoop.fs.s3native.ITestJets3tNativeS3FileSystemContract)  Time elapsed: 1.38 sec  <<< FAILURE!
java.lang.AssertionError: Source exists expected:<true> but was:<false>
{code}

# I want to do a checkstyle fix
# we do need to follow the full vote for a branch merge; I believe I can be one of the voters.

HADOOP-13998 patch 003
* checkstyle issues
* a bit more IDE cleanup (inc /** -> /* in top comment)
* TestPathMetadataDynamoDBTranslation -> callable from lambda
* TestS3GuardConcurrentOps made java 7 friendly

My IDE was confused and thought it was Java 7, which helped find a couple of java 8 bits of the test. Fixed them for ease of backporting this to 2.9.

Identified a couple of issues we should look at/clarify

# {{LocalMetadataStore.prune()}} is modifying the iterator of the dirhash during the iteration using put(). Is it safe to do that?. It may be better to build the list of entries to add, and do it after that initial iteration

# DynamoDbClientFactory should be able to pick up StringUtils.join, either the hadoop one or one of the commons-lang ones.


| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 59 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 27s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 56s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 10s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 59s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-project hadoop-assemblies {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 18s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 20s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 22s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 37s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m  2s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 13m  2s{color} | {color:red} root generated 2 new + 1316 unchanged - 1 fixed = 1318 total (was 1317) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 30s{color} | {color:orange} root: The patch generated 4 new + 205 unchanged - 4 fixed = 209 total (was 209) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 41s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} shellcheck {color} | {color:green}  0m  0s{color} | {color:green} There were no new shellcheck issues. {color} |
| {color:green}+1{color} | {color:green} shelldocs {color} | {color:green}  0m 24s{color} | {color:green} There were no new shelldocs issues. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  1s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m 10s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-project hadoop-assemblies {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m  5s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 40s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 27s{color} | {color:green} hadoop-project in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 30s{color} | {color:green} hadoop-assemblies in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  9m 30s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m  8s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 47s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}102m 38s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.TestRaceWhenRelogin |
|   | hadoop.ipc.TestRPC |
|   | hadoop.security.TestKDiag |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-13998 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12881953/HADOOP-13998-003.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  findbugs  checkstyle  shellcheck  shelldocs  |
| uname | Linux 218a6f194ca6 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / e3ae3e2 |
| Default Java | 1.8.0_144 |
| shellcheck | v0.4.6 |
| findbugs | v3.1.0-RC1 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/13034/artifact/patchprocess/diff-compile-javac-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13034/artifact/patchprocess/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13034/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13034/testReport/ |
| modules | C: hadoop-project hadoop-assemblies hadoop-common-project/hadoop-common hadoop-tools/hadoop-aws U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13034/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



patch 004

As 003, except
* compiles against java 7
* provides better diags in tests when the local DDB server doesn't come up, by not losing exception text

This makes it a lot closer to a branch-2 patch, which is essentially this+ classpath fixup —existing work by [~liuml07].

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 59 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 26s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m  8s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m  9s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 44s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-project hadoop-assemblies {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 11s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 10s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 41s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 41s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 57s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 13m 57s{color} | {color:red} root generated 2 new + 1316 unchanged - 1 fixed = 1318 total (was 1317) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  8s{color} | {color:orange} root: The patch generated 4 new + 205 unchanged - 4 fixed = 209 total (was 209) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 20s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} shellcheck {color} | {color:green}  0m  0s{color} | {color:green} There were no new shellcheck issues. {color} |
| {color:green}+1{color} | {color:green} shelldocs {color} | {color:green}  0m 22s{color} | {color:green} There were no new shelldocs issues. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m 11s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-project hadoop-assemblies {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m  1s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 30s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 23s{color} | {color:green} hadoop-project in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 25s{color} | {color:green} hadoop-assemblies in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 32s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 58s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 41s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}101m 18s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.net.TestDNS |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-13998 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12882003/HADOOP-13998-004.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  findbugs  checkstyle  shellcheck  shelldocs  |
| uname | Linux 6f33654d0e7c 4.4.0-43-generic #63-Ubuntu SMP Wed Oct 12 13:48:03 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / dadb0c2 |
| Default Java | 1.8.0_144 |
| shellcheck | v0.4.6 |
| findbugs | v3.1.0-RC1 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/13038/artifact/patchprocess/diff-compile-javac-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13038/artifact/patchprocess/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13038/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13038/testReport/ |
| modules | C: hadoop-project hadoop-assemblies hadoop-common-project/hadoop-common hadoop-tools/hadoop-aws U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13038/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



v4 applied cleanly.  S3A tests w/o S3guard all passed.  Added -Dparallel-tests and -Ds3guard and saw some failures (ITestS3AEncryptionSSEC stuff and a couple of  ITestS3AContractRootDir).  Rerunning w/o parallel mode then I'll run some tests with dynamo.

OK. Do we have any other showstoppers? 

Having played with the tool, I'd really like a "s3guard info URI" command to list the s3guard state of a bucket (is it protected, is it encrypted, endpoint, with some opts for the command to fail if no s3guard or encryption. Why? No easy way to verify that a bucket is protected, not once you have complex per-bucket setup. But that could go in after atop trunk easily enough; no reason not to hold this merge up.

*If everyone is happy with this patch, it's time to raise it as a vote in hadoop-common. I'll draw people's attention to it on the list now*

+I'll make a patch of the changes between HADOOP-13345 branch & the latest patch here for review/commit to that branch pre-vote

FYI -Ds3guard (local) tests all passed once I removed parallel-tests option. I think there are some lingering issues with root contract tests and encryption integration tests in parallel test mode.

I'm +1 (nonbinding) on this patch.

I'm happy with this patch. +1 to an 's3guard info' tool. I also made a few nit-picky comments about grouping S3Guard things together better in the config-related files. But other than that I've tested this to my satisfaction and reviewed the code with no concerns worth holding up a merge. I can address my nit-picky thoughts next time I'm editing one of those files.

I'm doing the info command along with a bit of a rework of the CLI code; just the aggregate set of niggles. I don't want to hold the vote up though as it'll need work and is non-critical

Patch 005: everything in 04 plus HADOOP-14809, which restores the hadoop-aws shell profile. This is what I'm going to apply to trunk in a single (large) patch

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 21m  1s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 59 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 57s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m  4s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 11s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 58s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-project hadoop-assemblies {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 18s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 37s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 35s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 25s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 11m 25s{color} | {color:red} root generated 2 new + 1283 unchanged - 1 fixed = 1285 total (was 1284) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 12s{color} | {color:orange} root: The patch generated 4 new + 205 unchanged - 4 fixed = 209 total (was 209) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 14s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} shellcheck {color} | {color:green}  0m  0s{color} | {color:green} There were no new shellcheck issues. {color} |
| {color:green}+1{color} | {color:green} shelldocs {color} | {color:green}  0m 24s{color} | {color:green} There were no new shelldocs issues. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  8s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-project hadoop-assemblies {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 36s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 38s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 29s{color} | {color:green} hadoop-project in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 30s{color} | {color:green} hadoop-assemblies in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 10m 17s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m  1s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 44s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}123m 52s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:71bbb86 |
| JIRA Issue | HADOOP-13998 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12884700/HADOOP-13998-005.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  findbugs  checkstyle  shellcheck  shelldocs  |
| uname | Linux 6f44c1bdf1c3 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / d4417da |
| Default Java | 1.8.0_144 |
| shellcheck | v0.4.6 |
| findbugs | v3.1.0-RC1 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/13146/artifact/patchprocess/diff-compile-javac-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13146/artifact/patchprocess/diff-checkstyle-root.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13146/testReport/ |
| modules | C: hadoop-project hadoop-assemblies hadoop-common-project/hadoop-common hadoop-tools/hadoop-aws U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13146/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



Applying and testing patch 005 now.

For Yetus results above:  Javac warnings are just the AmazonS3Client constructor deprecation:

{code}
     * @deprecated use {@link AmazonS3ClientBuilder#defaultClient()}
     */
    @Deprecated
    public AmazonS3Client() {
        this(new S3CredentialsProviderChain());
    }
{code}

Checkstyle issues are line length where we cannot break (e.g. javadoc link urls), method length (innerRename), and "more than 7 method parameters" on two functions.  They all seem like reasonable exceptions.

+1 on v5 patch (non-binding, see upstream VOTE).  Didn't re-read the whole thing carefully but  tested in us-west-2.  All S3A integration and unit tests passed w/ and w/o s3guard.

On the s3guard run, I noticed one failure which went away when I re-ran it:  {{ITestS3GuardToolDynamoDB#testPruneCommandCLI}}.  This is a sleep-based prune test case that may in rare cases fail (because your computer / network / dynamodb goes out to lunch for >1 second).  In the future, we should add a comment to the test case saying it may transiently fail.  These tests are still useful, kinda wish we had a way to mark them as flaky-but-useful.

Have to update the testing.md doc on that, maybe a list of "intermittently unreliable tests". And @flakytest attribute would be cute,,,yetus could generate a report and if it were a @flakytest then it could be less fussy about a veto. However, that'd potentially put us off tracking down problems.

Finishing off the commit today

patch 005 committed to trunk; all is good. Closing as fixed. I'm going to create a s3guard phase II JIRA and move all the open stuff on the phase I JIRA to it

see HADOOP-14838 for branch-2 backport

-Patch 001-

-tested against s3 ireland with  -Dscale, and all of localdynamo and dynamodb-

(wrong JIRA)

Re-opening to resolve as "Complete" or something, since this code change was attributed to the parent JIRA HADOOP-13345 in the commit message.

Re-resolving per above.

