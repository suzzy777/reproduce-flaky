Trying to run the failing test in a loop I noticed it wasn't cleaning the env properly opening the door to test method cross-talk. [~aholmber] I think you managed to repro locally so could you doublecheck my PR and see if it doesn't repro anymore please?

Unfortunately I am still seeing [this|https://ci-cassandra.apache.org/job/Cassandra-trunk/362/testReport/junit/org.apache.cassandra.db/ScrubTest/testSkipScrubCorruptedCounterRowWithTool_compression/] failure when looping on this branch. With a bit of instrumentation, I can see that the scrubber is hitting this when it fails in this way:

{noformat}
 Scrubbing BigTableReader(path='/home/vagrant/cassandra/build/test/cassandra/data/Keyspace2/Counter1-949374d48be711eb9202f742d2eeefb4/na-1-big-Data.db') (64.289KiB)
 WARNING: Error reading row org.apache.cassandra.io.sstable.CorruptSSTableException: Corrupted: /home/vagrant/cassandra/build/test/cassandra/data/Keyspace2/Counter1-949374d48be711eb9202f742d2eeefb4/na-1-big-Data.db
     at org.apache.cassandra.io.sstable.SSTableIdentityIterator.hasNext(SSTableIdentityIterator.java:138)
     at org.apache.cassandra.db.compaction.Scrubber$RowMergingSSTableIterator.hasNext(Scrubber.java:541)
     at org.apache.cassandra.db.compaction.Scrubber$OrderCheckerIterator.computeNext(Scrubber.java:654)
     at org.apache.cassandra.db.compaction.Scrubber$OrderCheckerIterator.computeNext(Scrubber.java:574)
     at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47)
     at org.apache.cassandra.db.transform.BaseRows.hasNext(BaseRows.java:133)
     at org.apache.cassandra.db.transform.UnfilteredRows.isEmpty(UnfilteredRows.java:74)
     at org.apache.cassandra.io.sstable.format.big.BigTableWriter.append(BigTableWriter.java:205)
     at org.apache.cassandra.io.sstable.SSTableRewriter.append(SSTableRewriter.java:125)
     at org.apache.cassandra.io.sstable.SSTableRewriter.tryAppend(SSTableRewriter.java:149)
     at org.apache.cassandra.db.compaction.Scrubber.tryAppend(Scrubber.java:343)
     at org.apache.cassandra.db.compaction.Scrubber.scrub(Scrubber.java:233)
     at org.apache.cassandra.tools.StandaloneScrubber.main(StandaloneScrubber.java:225)
     at org.apache.cassandra.tools.ToolRunner.runClassAsTool(ToolRunner.java:82)
     at org.apache.cassandra.tools.ToolRunner$2.get(ToolRunner.java:249)
     at org.apache.cassandra.tools.ToolRunner$2.get(ToolRunner.java:245)
     at org.apache.cassandra.tools.ToolRunner.invokeSupplier(ToolRunner.java:305)
     at org.apache.cassandra.tools.ToolRunner.invokeClass(ToolRunner.java:253)
     at org.apache.cassandra.tools.ToolRunner.invokeClass(ToolRunner.java:235)
     at org.apache.cassandra.db.ScrubTest.testSkipScrubCorruptedCounterRowWithTool(ScrubTest.java:811)
 Caused by: java.io.IOException: Error building row with data deserialized from RandomAccessReader:CachingRebufferer:CompressedChunkReader.Mmap(/home/vagrant/cassandra/build/test/cassandra/data/Keyspace2/Counter1-949374d48be711eb9202f742d2eeefb4/na-1-big-Data.db - SnappyCompressor, chunk length 16384, data length 65832)
     at org.apache.cassandra.db.rows.UnfilteredSerializer.deserializeRowBody(UnfilteredSerializer.java:646)
     at org.apache.cassandra.db.rows.UnfilteredSerializer.deserializeOne(UnfilteredSerializer.java:487)
     at org.apache.cassandra.db.rows.UnfilteredSerializer.deserialize(UnfilteredSerializer.java:443)
     at org.apache.cassandra.io.sstable.SSTableSimpleIterator$CurrentFormatIterator.computeNext(SSTableSimpleIterator.java:84)
     at org.apache.cassandra.io.sstable.SSTableSimpleIterator$CurrentFormatIterator.computeNext(SSTableSimpleIterator.java:62)
     at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47)
     at org.apache.cassandra.io.sstable.SSTableIdentityIterator.hasNext(SSTableIdentityIterator.java:126)
 Caused by: java.lang.AssertionError
     at org.apache.cassandra.cache.ChunkCache$Buffer.buffer(ChunkCache.java:122)
     at org.apache.cassandra.io.util.RandomAccessReader.reBufferAt(RandomAccessReader.java:66)
     at org.apache.cassandra.io.util.RandomAccessReader.reBuffer(RandomAccessReader.java:59)
     at org.apache.cassandra.io.util.RebufferingInputStream.read(RebufferingInputStream.java:90)
     at org.apache.cassandra.io.util.RebufferingInputStream.readFully(RebufferingInputStream.java:68)
     at org.apache.cassandra.io.util.RebufferingInputStream.readFully(RebufferingInputStream.java:62)
     at org.apache.cassandra.db.marshal.ByteArrayAccessor.read(ByteArrayAccessor.java:101)
     at org.apache.cassandra.db.marshal.ByteArrayAccessor.read(ByteArrayAccessor.java:38)
     at org.apache.cassandra.db.marshal.AbstractType.read(AbstractType.java:490)
     at org.apache.cassandra.db.rows.Cell$Serializer.deserialize(Cell.java:268)
     at org.apache.cassandra.db.rows.UnfilteredSerializer.readSimpleColumn(UnfilteredSerializer.java:655)
     at org.apache.cassandra.db.rows.UnfilteredSerializer.lambda$deserializeRowBody$2(UnfilteredSerializer.java:620)
     at org.apache.cassandra.utils.btree.BTree.applyValue(BTree.java:1294)
     at org.apache.cassandra.utils.btree.BTree.applyLeaf(BTree.java:1302)
     at org.apache.cassandra.utils.btree.BTree.apply(BTree.java:1317)
     at org.apache.cassandra.utils.btree.BTree.apply(BTree.java:1343)
     at org.apache.cassandra.db.Columns.apply(Columns.java:390)
     at org.apache.cassandra.db.rows.UnfilteredSerializer.deserializeRowBody(UnfilteredSerializer.java:612)
{noformat}

It only happens when compression is enabled, and when the whole test class is run (i.e.; not just one or a handful of methods).

Attempted to bisect flakiness, but found this error is encountered as far back as test introduction.

https://github.com/apache/cassandra/commit/a04ccf3297839febed68c314704db4d920b64413

I think I see what's happening. Reference counting for ChunkCache buffer is [allowed to go below zero|https://github.com/apache/cassandra/blob/bf96367f4d55692017e144980cf17963e31df127/src/java/org/apache/cassandra/cache/ChunkCache.java#L135]. Then, it is possible to [find a non-zero refCount, return a non-null reference incrementing from -1 --> 0, and arrive at {{buffer}} finding references is now zero|https://github.com/apache/cassandra/blob/bf96367f4d55692017e144980cf17963e31df127/src/java/org/apache/cassandra/cache/ChunkCache.java#L111-L122].


We're getting in this state while racing with an async task which is currently closing the file:

The file is being closed as part of the tidy task:
{noformat}
[junit-timeout] 	at org.apache.cassandra.cache.ChunkCache$Buffer.release(ChunkCache.java:158)
[junit-timeout] 	at org.apache.cassandra.cache.ChunkCache.onRemoval(ChunkCache.java:187)
[junit-timeout] 	at org.apache.cassandra.cache.ChunkCache.onRemoval(ChunkCache.java:41)
[junit-timeout] 	at com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$notifyRemoval$1(BoundedLocalCache.java:286)
[junit-timeout] 	at com.google.common.util.concurrent.DirectExecutor.execute(DirectExecutor.java:30)
[junit-timeout] 	at com.github.benmanes.caffeine.cache.BoundedLocalCache.notifyRemoval(BoundedLocalCache.java:292)
[junit-timeout] 	at com.github.benmanes.caffeine.cache.BoundedLocalCache.removeNoWriter(BoundedLocalCache.java:1731)
[junit-timeout] 	at com.github.benmanes.caffeine.cache.BoundedLocalCache.remove(BoundedLocalCache.java:1695)
[junit-timeout] 	at com.github.benmanes.caffeine.cache.LocalCache.invalidateAll(LocalCache.java:126)
[junit-timeout] 	at com.github.benmanes.caffeine.cache.LocalManualCache.invalidateAll(LocalManualCache.java:79)
[junit-timeout] 	at org.apache.cassandra.cache.ChunkCache.invalidateFile(ChunkCache.java:218)
[junit-timeout] 	at org.apache.cassandra.io.util.FileHandle$Cleanup.lambda$tidy$0(FileHandle.java:208)
[junit-timeout] 	at java.util.Optional.ifPresent(Optional.java:159)
[junit-timeout] 	at org.apache.cassandra.io.util.FileHandle$Cleanup.tidy(FileHandle.java:208)
[junit-timeout] 	at org.apache.cassandra.utils.concurrent.Ref$GlobalState.release(Ref.java:325)
[junit-timeout] 	at org.apache.cassandra.utils.concurrent.Ref$State.ensureReleased(Ref.java:203)
[junit-timeout] 	at org.apache.cassandra.utils.concurrent.Ref.ensureReleased(Ref.java:128)
[junit-timeout] 	at org.apache.cassandra.utils.concurrent.SharedCloseableImpl.close(SharedCloseableImpl.java:45)
[junit-timeout] 	at org.apache.cassandra.io.sstable.format.SSTableReader$InstanceTidier$1.run(SSTableReader.java:2058)
[junit-timeout] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
{noformat}

Which was scheduled by the previous scrub test:
{noformat}
[junit-timeout] 	at org.apache.cassandra.io.sstable.format.SSTableReader$InstanceTidier.tidy(SSTableReader.java:2020)
[junit-timeout] 	at org.apache.cassandra.utils.concurrent.Ref$GlobalState.release(Ref.java:325)
[junit-timeout] 	at org.apache.cassandra.utils.concurrent.Ref$State.release(Ref.java:224)
[junit-timeout] 	at org.apache.cassandra.utils.concurrent.Ref.release(Ref.java:118)
[junit-timeout] 	at org.apache.cassandra.db.compaction.Scrubber.lambda$scrub$0(Scrubber.java:303)
[junit-timeout] 	at java.util.ArrayList.forEach(ArrayList.java:1257)
[junit-timeout] 	at org.apache.cassandra.db.compaction.Scrubber.scrub(Scrubber.java:303)
[junit-timeout] 	at org.apache.cassandra.tools.StandaloneScrubber.main(StandaloneScrubber.java:226)
[junit-timeout] 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[junit-timeout] 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[junit-timeout] 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[junit-timeout] 	at java.lang.reflect.Method.invoke(Method.java:498)
[junit-timeout] 	at org.apache.cassandra.tools.ToolRunner.runClassAsTool(ToolRunner.java:82)
[junit-timeout] 	at org.apache.cassandra.tools.ToolRunner$2.get(ToolRunner.java:249)
[junit-timeout] 	at org.apache.cassandra.tools.ToolRunner$2.get(ToolRunner.java:245)
[junit-timeout] 	at org.apache.cassandra.tools.ToolRunner.invokeSupplier(ToolRunner.java:305)
[junit-timeout] 	at org.apache.cassandra.tools.ToolRunner.invokeClass(ToolRunner.java:253)
[junit-timeout] 	at org.apache.cassandra.tools.ToolRunner.invokeClass(ToolRunner.java:235)
[junit-timeout] 	at org.apache.cassandra.db.ScrubTest.testHeaderFixWithTool(ScrubTest.java:874)
{noformat}

I had hoped it would be sufficient to disallow negative numbers for the ref count, but at first blush that is revealing other issues. The work goes on.

Ok so the problem probably stems from the fact that {{StandaloneScrubber}} is to be used as a tool. That should be executed in it's own process hence all tidying would complete on exit with no possible races between calls.

I haven't managed to repro locally but with an internal multiplexing tool. The new push seems to solve that problem by using a different KS on each tool call hence there won't be any file races. Can you confirm if you can still repro or if it has been fixed?

Latest review comments pushed + I did trigger a new multiplexing run.

I'm still digging into it, but it seems that with the new commit I'm not able to reproduce the problem locally with compression enabled, as described by Adam (I was able before). I'm also running it in our internal multiplexer [here|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/725/], using [these changes|https://github.com/adelapena/cassandra/commit/4bf0c8424b4b3f8d5c85a001f28cb61c03a252bd] in {{ant testsome}} to use compression.

Yes, I see your point about the tool. After bisecting I made the mistake of going back to trunk so I was possibly diagnosing a problem that was already addressed by your changes. Back on this branch I'm still seeing fairly regular fails, not always with an AssertionError. I'll look into it a littler more, but maybe it's not worth holding this patch since I'm the only one getting failures and it's not corroborated in the multiplexer.

You are seeing fails like in the test run failing? or are you seeing exceptions around? bear in mind the test plays with corrupt sstables and does all sorts of things. So exceptions are ok, test failures are not.

[~adelapena] you can use ant target `test-compression` to the same effect and spare the build.xml changes #collaborating.

Latest review comment addressed and multiplexing again just in case

{quote}You are seeing fails like in the test run failing? or are you seeing exceptions around?
{quote}
I get actual failures. Since I seem to be the only one I don't want to hold things up here.

I'm afraid there are some {{assertNotReleased}} failures of {{testScrubOutOfOrder}} in the both the multiplexer run mentioned above and in [this other run|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/729/] using {{test-compression}}.

Yep I had noticed the {{testScrubOutOfOrder}} failures both in this branch _and_ in trunk. But notice how the failure for this ticket has gone away. I'd vote to merge this one and open a new ticket for {{testScrubOutOfOrder}}. I want to start merging fixes asap to see if ci-cass has indeed a problem of misreporting failures. If this failure goes away but the new one pops up then that'd be an indication it is so. Sounds ok?

On my part, I agree that merging known fixes and spinning out a different ticket is a good approach.

I suspect that those failures with {{testScrubOutOfOrder}} and compression are also related to the tests reusing the tables and calling {{clearUnsafe}}.

[In this commit|https://github.com/adelapena/cassandra/commit/b19711ac8d6f163113ba8f49762e2959996adfd7] I have tried to unify the two coexistent initialization methods ({{defineSchema}} and {{toolTestingSetup}}) into a single method annotated with JUnit's {{@Begin}}. This way every test uses its own dedicated keyspace and we don't need the calls to {{clearUnsafe}}. I have also done some minor cleaning to reduce the number of tables per keyspace and to get rid of most of the warnings across {{ScrubTest}}.

With these changes it seems that the test suite passes 400 runs in the multiplexer with compression ([here|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/737/] and [here|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/737/]), and 200 more runs without compression ([here|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/739/]).

Aha, good catch. So we just had the same problem in the other test cases as well: cross-talk at ks.cf level. I am +1 to merge everything in here specially after the 1000 runs!

[~adelapena] maybe we could merge this one before rc-1 is out?

[~Bereng] I guess we can, are you going to add my [last suggested commit|https://github.com/adelapena/cassandra/commit/b19711ac8d6f163113ba8f49762e2959996adfd7] into the PR? Also, I think we could move the calls to {{disableAutocompaction}} and the setting of {{ALLOW_TOOL_REINIT_FOR_TEST}} to the {{@BeforeClass}} method, as it's done [here|https://github.com/adelapena/cassandra/commit/f8a8e8c5c3fe66270bb49100cf86620392d9e7da]. Once we have all together we can rebase and run CI one last time before committing, wdyt? 

[~adelapena] I have squashed and rebased with your latest suggested commit. Unfortunately that removed your authorship info so add it back upon commit please. The multiplexing 200 runs returned green and CI runs are attached to the PR.

I have not changed location of {{disableAutocompaction}} or {{ALLOW_TOOL_REINIT_FOR_TEST}} as not all tests need it. Let me know wdyt.

{quote}I have not changed location of {{disableAutocompaction}} or {{ALLOW_TOOL_REINIT_FOR_TEST}} as not all tests need it. Let me know wdyt.
{quote}
I think there isn't a big difference between setting {{ALLOW_TOOL_REINIT_FOR_TEST}} before every test with {{@Begin}}, as it's currently done, or just once with {{@BeginClass}}. In both cases the property is set for all the tests, and not only for those tests that need it. I find using {{@BeginClass}} preferable because it saves some calls and it pairs more clearly with the {{@AfterClass}} method that resets it. If we wanted to set the property only for the tests that need it, we could restore the original {{testToolTestingEnvSetup}} initalization method [this way|https://github.com/adelapena/cassandra/commit/1db00fed784453a181ba42e09deb19686dbcafd5]. However, I think that setting it at the beginning of the class for all the tests is easier to read and it doesn't damage the tests that don't need it. Nevertheless, I don't think this is a very important detail and I'll be happy with the approach you prefer.

[~adelapena] scratch that. I was referring to a previous comment of yours about moving the per-test init of those 2 params to the {{Before}} which I was against as I preferred the per-test approach. Now I have re read your latest comment about moving them to {{BeforeClass}} I think we're splitting hairs: you can argue you need a {{Before/After}} pair if any test would alter those in between, you can argue {{BeforeClass/AfterClass}} are better bc no test is doing so _yet_, you can argue a per test approach is better as it doesn't add noise to the other tests that don't need it,... pick your poison lol.

I prefer the per test approach but I don't feel strongly about it. I'd say we merge as it is or I can do the {{BeforeClass}} one if you prefer.

[~Bereng] works for me as it is. [Here|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/543/pipeline] is a final CI round in ci-cassandra before committing, just in case. Can you commit once it finishes, or should I? 

I can't commit yet. I guess my iCLA will take some time to process being easter holidays :shrug:

Latest CI LGTM.

CI results look good to me too. I have prepared PRs for 3.0 and 3.11 since they are affected by the flakiness problems caused by reusing tables and {{clearUnsafe}}:
 * [3.0|https://github.com/apache/cassandra/pull/947] [(CI)|https://app.circleci.com/pipelines/github/adelapena/cassandra/248/workflows/bfa3c0d3-5f3b-4508-8d75-580ce634e62c]
 * [3.11|https://github.com/apache/cassandra/pull/948] [(CI)|https://app.circleci.com/pipelines/github/adelapena/cassandra/249/workflows/26407bc5-3fb2-4aba-a3d2-e702a505e933]

If these PRs look good to you I'll proceed to commit.
  

LGTM no failures. You should have asked me and I would have done it for you :-)

No worries, porting back the patch has been pretty straightforward. It seems that CI for {{ScrubTest.testScrubCorruptedCounterRow}} fails on 3.0 with compression, although that one was already marked as [72% flaky|https://ci-cassandra.apache.org/job/Cassandra-3.0/lastCompletedBuild/testReport/junit/org.apache.cassandra.db/ScrubTest/testScrubCorruptedCounterRow/] so my guess is that it fails due to a different reason, wdyt?

Mmm did you start that job later than the others? That failure wasn't there first time I looked. TBH being the only failure in 3K I would like to drill a bit more see if it repros without the fix... But I'll be off tomorrow & Monday. I guess it can wait.

{quote}Mmm did you start that job later than the others? That failure wasn't there first time I looked.
{quote}
Yes, I forgot to approve the job for {{utests_compression}} so it was paused.

{{ScrubTest.testScrubCorruptedCounterRow}} with compression doesn't work locally for me in 3.0, with and without the patch. It can also be seen failing [in CI|https://ci-cassandra.apache.org/job/Cassandra-3.0/lastCompletedBuild/testReport/junit/org.apache.cassandra.db/ScrubTest/testScrubCorruptedCounterRow/] without the fix. I suspect that's probably a different problem to what we have dealt with in this ticket, specific to 3.0, so I'll be fine if we address it here or in a separate ticket to not block 4.0, as you think it's best.

Hi [~adelapena] I agree with your assessment. I see the same. In any case I see that as a diff issue for a new ticket and I'd favor merging this one into 4.0 to get good CI on 4.0 asap to ease the rc work there atm. Wdyt? if you agree I can try commit this one to test my new commit permissions.

[~bereng] works for me. We probably should also create a follow up ticket for porting back the fix to 3.0 and 3.11, so we can fix the flakiness in those branches later. Alternatively we could also apply the patch here to 3.11 and trunk and let the investigation about 3.0 for the followup ticket, as you prefer. Let me know if you need any help with the commit procedure.

So... given I was testing the push privileges I went for the easy option and did 4.0 only. I opened CASSANDRA-16562. I owe you a few loc bc upon commit I forgot to add you as an author, sorry, so you can take the locs for 16562 under your name as compensation lol! :-)

Great, thanks for committing and creating the followup ticket. We can investigate there the additional failures in 3.0, which seem to happen with and without the patch so probably they have a different cause. Don't worry about the authorship, I feel recognised enough as reviewer :)

