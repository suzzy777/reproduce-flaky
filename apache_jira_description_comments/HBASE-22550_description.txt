It will inherit the ThreadGroup of the current thread, which is not necessary here but could introduce problems if the thread which creates the thread pool is dead. See this:

https://builds.apache.org/job/HBase-Flaky-Tests/job/HBASE-21512/1191/artifact/hbase-server/target/surefire-reports/org.apache.hadoop.hbase.master.procedure.TestTruncateTableProcedure-output.txt/*view*/

{noformat}
2019-06-07 00:58:47,175 ERROR [PEWorker-1] procedure2.ProcedureExecutor(1667): CODE-BUG: Uncaught runtime exception: pid=307, state=RUNNABLE:SPLIT_TABLE_REGION_UPDATE_META, hasLock=true; SplitTableRegionProcedure table=testTruncateWithPreserveAfterSplit, parent=bc630be809a91baf71d0a05051bd502b, daughterA=ce5cf8608cf97afcd09a33545d4169ab, daughterB=ec4d88471626f18b811bb6910f33a067
java.lang.IllegalThreadStateException
	at java.lang.ThreadGroup.addUnstarted(ThreadGroup.java:867)
	at java.lang.Thread.init(Thread.java:405)
	at java.lang.Thread.init(Thread.java:349)
	at java.lang.Thread.<init>(Thread.java:599)
	at org.apache.hadoop.hbase.util.Threads$2.newThread(Threads.java:220)
	at org.apache.hadoop.hbase.util.Threads$3.newThread(Threads.java:246)
	at java.util.concurrent.ThreadPoolExecutor$Worker.<init>(ThreadPoolExecutor.java:619)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:932)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367)
	at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:134)
	at org.apache.hadoop.hbase.client.TableOverAsyncTable.coprocssorService(TableOverAsyncTable.java:431)
	at org.apache.hadoop.hbase.client.TableOverAsyncTable.coprocessorService(TableOverAsyncTable.java:469)
	at org.apache.hadoop.hbase.client.Table.coprocessorService(Table.java:527)
	at org.apache.hadoop.hbase.MetaTableAccessor.multiMutate(MetaTableAccessor.java:1768)
	at org.apache.hadoop.hbase.MetaTableAccessor.multiMutate(MetaTableAccessor.java:1729)
	at org.apache.hadoop.hbase.MetaTableAccessor.splitRegion(MetaTableAccessor.java:1688)
	at org.apache.hadoop.hbase.master.assignment.RegionStateStore.splitRegion(RegionStateStore.java:237)
	at org.apache.hadoop.hbase.master.assignment.AssignmentManager.markRegionAsSplit(AssignmentManager.java:1643)
	at org.apache.hadoop.hbase.master.assignment.SplitTableRegionProcedure.updateMeta(SplitTableRegionProcedure.java:824)
	at org.apache.hadoop.hbase.master.assignment.SplitTableRegionProcedure.executeFromState(SplitTableRegionProcedure.java:304)
	at org.apache.hadoop.hbase.master.assignment.SplitTableRegionProcedure.executeFromState(SplitTableRegionProcedure.java:91)
	at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:194)
	at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:959)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1648)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1395)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$1100(ProcedureExecutor.java:78)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1964)
{noformat}
