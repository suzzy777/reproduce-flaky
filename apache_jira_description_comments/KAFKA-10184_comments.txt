Yeah, it's failing on the setup and hasn't even gotten to the real test at all cc/ [~vvcephei] seems like "500" was still too high :/

[~vvcephei] Could we maybe do something like "write as many records as you can in the 120000ms timeout"? Since as you said the whole point is just to make sure we have enough records to represent a "reasonably large" number, if it takes 2 minutes to write only 100 records then those 100 records represent a heavy load (apparently...)

Or instead (or in addition to the above) maybe we should wait for the streams to be in RUNNING before we start the timeout for writing records

What in the world... How can we not have processed even 500 records in two minutes?

I agree waiting for start up first would probably help. Do we have any logs that could confirm the hypothesis that the startup phase is eating up a bunch of our timeout?

We should probably decrease the size of the records down from a whopping 1kB. My intent was to bridge the integration and system test worlds by creating “realistic” data here, but maybe that was expecting too much of the CIT infrastructure. 

This is all pretty pathetic lol. Good 'ol Jenkins

Decreasing the message size might help though. I don't have any real evidence to back up the claim that startup might be occupying a large portion of this time, it just seems like good practice. Who knows what Jenkins is doing – maybe it's taking so long just to create topics?

