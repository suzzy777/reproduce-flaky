I may be missing something. I didn't yet look at this particular test function, but is this not the cause of the failure in the jenkins job you linked?

{code}
09:51:34 =================================== FAILURES ===================================
09:51:34 _____________________________ TestHS2.test_get_log _____________________________
09:51:34 [gw0] linux2 -- Python 2.6.6 /data/jenkins/workspace/impala-umbrella-build-and-test/repos/Impala/bin/../infra/python/env/bin/python
09:51:34 hs2/hs2_test_suite.py:45: in add_session
09:51:34     fn(self)
09:51:34 hs2/test_hs2.py:298: in test_get_log
09:51:34     assert "Error converting column" in log
09:51:34 E   assert 'Error converting column' in 'Query 9e43626414a7a000:a81335e22dda0c83: 0% Complete (0 out of 3)\n'
09:51:34 ---------------------------- Captured stderr setup -----------------------------
09:51:34 -- executing against localhost:21000
09:51:34 use default;
09:51:34 
09:51:34 SET sync_ddl=1;
09:51:34 -- executing against localhost:21000
09:51:34 drop database if exists `hs2_db` cascade;
09:51:34 
09:51:34  generated xml file: /data/jenkins/workspace/impala-umbrella-build-and-test/repos/Impala/logs/ee_tests/results/TEST-impala-parallel.xml 
09:51:34 =========================== short test summary info ============================
09:51:34 XFAIL metadata/test_explain.py::TestExplain::()::test_explain_level3[exec_option: {'disable_codegen': False, 'abort_on_error': 1, 'exec_single_node_rows_threshold': 0, 'batch_size': 0, 'num_nodes': 0} | table_format: text/none]
09:51:34   reason: [NOTRUN] The test for missing table stats fails for avro
09:51:34 XFAIL hs2/test_fetch.py::TestFetch::()::test_execute_select_v1
09:51:34   reason: IMPALA-558
09:51:34 XFAIL metadata/test_explain.py::TestExplain::()::test_explain_level0[exec_option: {'disable_codegen': False, 'abort_on_error': 1, 'exec_single_node_rows_threshold': 0, 'batch_size': 0, 'num_nodes': 0} | table_format: text/none]
09:51:34   reason: [NOTRUN] Expected per-host mem requirements inconsistent
09:51:34 XFAIL metadata/test_explain.py::TestExplain::()::test_explain_level1[exec_option: {'disable_codegen': False, 'abort_on_error': 1, 'exec_single_node_rows_threshold': 0, 'batch_size': 0, 'num_nodes': 0} | table_format: text/none]
09:51:34   reason: [NOTRUN] Expected per-host mem requirements inconsistent
09:51:34 XFAIL metadata/test_explain.py::TestExplain::()::test_explain_level2[exec_option: {'disable_codegen': False, 'abort_on_error': 1, 'exec_single_node_rows_threshold': 0, 'batch_size': 0, 'num_nodes': 0} | table_format: text/none]
09:51:34   reason: [NOTRUN] The test for missing table stats fails for avro
09:51:34 XFAIL query_test/test_mem_usage_scaling.py::TestTpchMemLimitError::()::test_low_mem_limit_q9[mem_limit: 450 | exec_option: {'disable_codegen': False, 'abort_on_error': 1, 'exec_single_node_rows_threshold': 0, 'batch_size': 0, 'num_nodes': 0} | table_format: parquet/none]
09:51:34   reason: IMPALA-3328: TPC-H Q9 memory limit test is flaky
09:51:34 XFAIL query_test/test_queries.py::TestQueries::()::test_subplans[exec_option: {'disable_codegen': False, 'abort_on_error': 1, 'exec_single_node_rows_threshold': 0, 'batch_size': 0, 'num_nodes': 0} | table_format: parquet/none]
09:51:34   reason: Disabled due to missing nested types functionality.
09:51:34 XFAIL query_test/test_queries.py::TestQueries::()::test_misc[exec_option: {'disable_codegen': False, 'abort_on_error': 1, 'exec_single_node_rows_threshold': 0, 'batch_size': 0, 'num_nodes': 0} | table_format: parquet/none]
09:51:34   reason: Failing on rc/snap/block despite resolution of IMP-624,IMP-503. Failing on parquet because tables do not exist
09:51:34 FAIL hs2/test_hs2.py::TestHS2::()::test_get_log
09:51:34 ======= 1 failed, 1001 passed, 82 skipped, 8 xfailed in 1915.17 seconds ========
{code}

If by summary page, you meant http://sandbox.jenkins.sf.cloudera.com/view/Impala/view/Evergreen-cdh5-trunk/job/impala-cdh5-trunk-core-local-filesystem/102/testReport/?

...then I agree that it should show some indication of failure.

Yes, that's the cause.  I have already updated the existing bug that the problem recurred.

The point is, in order to find it, I had to search through the console output.  The test error didn't show up in the jenkins test report.  I've also seen cases where the tests crashed before they could return the TEST_RET_CODE, so the jenkins job didn't get red, and you wouldn't know where to look in the console.  The test failures should be obvious, not just possible to find.

This is mostly about cloudera infrastructure. There was some recent work that helped with this like IMPALA-7399 and jenkins/finalize.sh

