Hadoop ShellCommandExecutor on timeout, destroys the process, and later checks the exit code. On windows, if process is destroyed, the exit code is non-zero, so ShellCommandExecutor.execute() throws ExitCodeException rather than generic IOException. However, in HealthChecker, on catching ExitCodeException we do not check the timeout. 

It is unfortunate that Hadoop does not throw an TimeoutException, but provides .isTimedOut() api. And it seems that on timeout on linux, the throwing of the IOException is coincidental:
{code}
2013-06-06 14:17:47,930 WARN  [main] hbase.HealthChecker(79): Caught exception : java.io.IOException: Stream closed
{code}
It may not be worth fixing Hadoop for this, but we have to do the correct check anyway. 