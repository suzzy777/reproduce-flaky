Not sure why this is happening, but the cause seems to be that the listOffsets request we make during the rebalance is failing:
{code:java}
[2023-01-20 23:34:28,256] WARN The listOffsets request failed. (org.apache.kafka.streams.processor.internals.ClientUtils:154)
java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)
	at org.apache.kafka.streams.processor.internals.ClientUtils.getEndOffsets(ClientUtils.java:152)
	at org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.populateClientStatesMap(StreamsPartitionAssignor.java:690) {code}
I see that in the beginning of the logs in all the failed runs so far and none of the passes. Unfortunately I haven't been able to reproduce locally so I have to go by the Jenkins build logs, which truncate everything in the middle and don't show what happens next. But presumably this call is failing repeatedly, or potentially other calls are failing as well – whatever is wrong happens for 10 minutes until the global timeout is triggered.

I also noticed that it seems to be almost always the stateUpdaterEnabled = true builds that fail, a parameter that was added just a few weeks before this ticket was filed. I doubt it's actually the state updater causing this, but I'm going to disable the `false` parameter temporarily to see if it's actually the "true" run that's broken or it has to do with the parametrization. Also because I need to get a clean build for the 3.4 release and this is failing at least once in almost every single build :/

First PR to disable the `false` build parameter: [https://github.com/apache/kafka/pull/13147]

Followup PR to re-enable it: [https://github.com/apache/kafka/pull/13155|https://github.com/apache/kafka/pull/13155]

FYI after disabling the `false` parameter I immediately saw another failure, which points to the state updater as the culprit after all.

 

I did one final PR to verify this by disabling the `true` build and enabling the `false` build again – https://github.com/apache/kafka/pull/13156

I'll give it a few more days before re-enabling both parameters, but so far I've got a few runs in with only the `false` parameter enabled and this seems to have fixed the flakiness.

Can't really envision why the state updater would/could the listOffsets request to fail in the way shown above, but it really does appear to be something about enabling this that so badly broke the SmokeTestDriverIntegrationTest

Definitely need to look into this before we consider publicly releasing the state updater feature cc [~cadonna] [~lbrutschy] [~guozhang] 

I took some time into this, also cannot find any clues leading state-updater to list-offset request failures on changelog topics.. nevertheless, I re-enabled the state-updater flag with finer-grained logging in assignor in https://github.com/apache/kafka/pull/13318, and hopefully jenkins could give me some more clues (like [~ableegoldman], I cannot reproduce this issue locally either with about 15 tries).

After some investigation I found the following:

1. In both successful and failed runs, the first `list-offset` request could fail if the topic creation is not yet completed; and that failure is actually not fatal since we would just fallback to the naive assignor behavior. So that one does not play a role here.
2. What's happening (as I found from both jenkins, as well as locally after about 25 runs, phew) is that the stateUpdater.shutdown(timeout) where the timeout value is default to `MAX.value` never completes, as the thread itself never exits, I have a PR (https://github.com/apache/kafka/pull/13318) that does not rely on interruptions to shutdown the thread. I think it could fix the never shutdown issue.

