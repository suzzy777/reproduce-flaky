This issue contributes to postsubmit flakiness, cc: [~udim].

Example manifestation of this error that we may be able to fix in the SDK:

poll_for_job_completion thread [1] encounters 503 :

{noformat}
16:55:27 root: INFO: 2019-07-14T23:38:13.223Z: JOB_MESSAGE_DETAILED: Workers have started successfully.
16:55:27 root: DEBUG: Response returned status 503, retrying
16:55:27 root: DEBUG: Retrying request to url https://dataflow.googleapis.com/v1b3/projects/apache-beam-testing/locations/us-central1/jobs/2019-07-14_16_36_07-9641014797750228421?alt=json after exception HttpError accessing <https://dataflow.googleapis.com/v1b3/projects/apache-beam-testing/locations/us-central1/jobs/2019-07-14_16_36_07-9641014797750228421?alt=json>: response: <{'vary': 'Origin, X-Origin, Referer', 'content-type': 'application/json; charset=UTF-8', 'date': 'Sun, 14 Jul 2019 23:39:25 GMT', 'server': 'ESF', 'cache-control': 'private', 'x-xss-protection': '0', 'x-frame-options': 'SAMEORIGIN', 'x-content-type-options': 'nosniff', 'transfer-encoding': 'chunked', 'status': '503', 'content-length': '102', '-content-encoding': 'gzip'}>, content <{
16:55:27   "error": {
16:55:27     "code": 503,
16:55:27     "message": "Deadline exceeded",
16:55:27     "status": "UNAVAILABLE"
16:55:27   }
16:55:27 }
16:55:27 >
{noformat}

Based on console logs, execution continues, and finishes successfully:

{noformat}
16:55:27 root: INFO: 2019-07-14T23:39:12.556Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-1 in us-central1-b.
16:55:27 root: INFO: 2019-07-14T23:41:30.701Z: JOB_MESSAGE_BASIC: Executing BigQuery import job "dataflow_job_9064238672948471335". You can check its status with the bq tool: "bq show -j --project_id=apache-beam-testing dataflow_job_9064238672948471335".
16:55:27 root: INFO: 2019-07-14T23:41:41.319Z: JOB_MESSAGE_BASIC: BigQuery import job "dataflow_job_9064238672948471335" done.
16:55:27 root: INFO: 2019-07-14T23:41:42.059Z: JOB_MESSAGE_BASIC: Finished operation create/Read+write/WriteToBigQuery/NativeWrite
16:55:27 root: INFO: 2019-07-14T23:41:42.137Z: JOB_MESSAGE_DEBUG: Executing success step success1
16:55:27 root: INFO: 2019-07-14T23:41:42.280Z: JOB_MESSAGE_DETAILED: Cleaning up.
16:55:27 root: INFO: 2019-07-14T23:41:42.337Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.
16:55:27 root: INFO: 2019-07-14T23:41:42.371Z: JOB_MESSAGE_BASIC: Stopping worker pool...
{noformat}

However, Dataflow runner believes that the job is in a failing state and attempts to cancel it, by this time job succeeds: 

{noformat}
16:55:27 root: WARNING: Cancel failed because job 2019-07-14_16_36_07-9641014797750228421 is already terminated in state DONE.
{noformat}

In this case we could retry with exponential backoff the 503 error a few more times. 

[1] https://github.com/apache/beam/blob/f7cbf88f550c8918b99a13af4182d6efa07cd2b5/sdks/python/apache_beam/runners/dataflow/dataflow_runner.py#L1315

Another example:  runner.dataflow_client.get_job(job_id) fails with 404, which causes Dataflow runner to fail:

{noformat}
16:57:22     response = runner.dataflow_client.get_job(job_id)
16:57:22 Found: https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2019-07-14_16_41_46-17942851702589150224?project=apache-beam-testing.
16:57:22   File "/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python3_Verify_PR/src/sdks/python/apache_beam/utils/retry.py", line 197, in wrapper
16:57:22     return fun(*args, **kwargs)
16:57:22   File "/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python3_Verify_PR/src/sdks/python/apache_beam/runners/dataflow/internal/apiclient.py", line 663, in get_job
16:57:22     response = self._client.projects_locations_jobs.Get(request)
16:57:22   File "/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python3_Verify_PR/src/sdks/python/apache_beam/runners/dataflow/internal/clients/dataflow/dataflow_v1b3_client.py", line 689, in Get
16:57:22     config, request, global_params=global_params)
16:57:22   File "/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python3_Verify_PR/src/build/gradleenv/-1734967052/lib/python3.7/site-packages/apitools/base/py/base_api.py", line 731, in _RunMethod
16:57:22     return self.ProcessHttpResponse(method_config, http_response, request)
16:57:22   File "/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python3_Verify_PR/src/build/gradleenv/-1734967052/lib/python3.7/site-packages/apitools/base/py/base_api.py", line 737, in ProcessHttpResponse
16:57:22     self.__ProcessHttpResponse(method_config, http_response, request))
16:57:22   File "/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python3_Verify_PR/src/build/gradleenv/-1734967052/lib/python3.7/site-packages/apitools/base/py/base_api.py", line 604, in __ProcessHttpResponse
16:57:22     http_response, method_config=method_config, request=request)
16:57:22 apitools.base.py.exceptions.HttpNotFoundError: HttpError accessing <https://dataflow.googleapis.com/v1b3/projects/apache-beam-testing/locations/us-central1/jobs/2019-07-14_16_38_18-18216836647829637555?alt=json>: response: <{'vary': 'Origin, X-Origin, Referer', 'content-type': 'application/json; charset=UTF-8', 'date': 'Sun, 14 Jul 2019 23:39:06 GMT', 'server': 'ESF', 'cache-control': 'private', 'x-xss-protection': '0', 'x-frame-options': 'SAMEORIGIN', 'x-content-type-options': 'nosniff', 'transfer-encoding': 'chunked', 'status': '404', 'content-length': '280', '-content-encoding': 'gzip'}>, content <{
16:57:22   "error": {
16:57:22     "code": 404,
16:57:22     "message": "(94573f72b4b58430): Information about job 2019-07-14_16_38_18-18216836647829637555 could not be found in our system. Please double check the id is correct. If it is please contact customer support.",
16:57:22     "status": "NOT_FOUND"
16:57:22   }
16:57:22 }
{noformat}

The flake due to a 404 error is a known issue that is being addressed on the service side, however dataflow runner could retry as well.

https://issues.apache.org/jira/browse/BEAM-7643 mentions a few other errors that may Dataflow runner could attempt to retry.

Here is an [issue BEAM-7733|http://issues.apache.org/jira/browse/BEAM-7733]Â with same problems but in Load Tests (with job run examples).

This issue is P2 but has been unassigned without any comment for 60 days so it has been labeled "stale-P2". If this issue is still affecting you, we care! Please comment and remove the label. Otherwise, in 14 days the issue will be moved to P3.

Please see https://beam.apache.org/contribute/jira-priorities/ for a detailed explanation of what these priorities mean.


This issue was marked "stale-P2" and has not received a public comment in 14 days. It is now automatically moved to P3. If you are still affected by it, you can comment and move it back to P2.

This Jira ticket has a pull request attached to it, but is still open. Did the pull request resolve the issue? If so, could you please mark it resolved? This will help the project have a clear view of its open issues.

This issue has been migrated to https://github.com/apache/beam/issues/19350

