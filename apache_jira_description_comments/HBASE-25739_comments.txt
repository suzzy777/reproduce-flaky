https://github.com/apache/hbase/pull/3067

Can you update the description since we are no longer using standard deviation in the current proposal?

Do you have any thoughts on the current default weight of TableSkewCostFunction? DEFAULT_TABLE_SKEW_COST = 35 - I wonder if this still makes sense given this change, or if it had this value due to the previous cost calculation. I don't really know myself... intuitively it makes sense to me to leave at 35, as it seems more important than most other cost functions, and less important than RegionCountSkewCostFunction. I was just curious if you had any thoughts.

Thanks for the nice improvement.

Thank you David. Description updated. Great that you called out the default weight. We changed it to similar weight as regionCountSkew CostFunction in production to get the full benefit. 

We also tested a few changes in production, also raising the weight of store file and lowered the weight of  dynamic loads to reduce chasing of ever changing load. Can I have a separate Jira to address this while closing this one? [~dmanning]

Yes [~clarax98007] that sounds good to me. I wasn’t suggesting any default weights need to change but was curious what you had found. Thanks for sharing.

The final cost in the description probably goes to 100/298 instead of 3.1/31, is that right?

Thank you for catching this. I need to update since standard deviation was not used. it is 100/198. 99 for the max node + 1*99 empty nodes.

oops yes! 198. Thanks [~claraxiong]

Results for branch master
	[build #264 on builds.a.o|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/master/264/]: (x) *{color:red}-1 overall{color}*
----
details (if available):

(/) {color:green}+1 general checks{color}
-- For more information [see general report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/master/264/General_20Nightly_20Build_20Report/]






(x) {color:red}-1 jdk8 hadoop3 checks{color}
-- For more information [see jdk8 (hadoop3) report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/master/264/JDK8_20Nightly_20Build_20Report_20_28Hadoop3_29/]


(x) {color:red}-1 jdk11 hadoop3 checks{color}
-- For more information [see jdk11 report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/master/264/JDK11_20Nightly_20Build_20Report_20_28Hadoop3_29/]


(/) {color:green}+1 source release artifact{color}
-- See build output for details.


(/) {color:green}+1 client integration test{color}


After merging this to master, {{TestStochasticLoadBalancerBalanceCluster.testBalanceCluster}} is now failing quite often. The error message says

{noformat}
java.lang.AssertionError: All servers should have load no less than 5. server=srv1609371185,56933,780219051392307383 , load=1
	at org.apache.hadoop.hbase.master.balancer.TestStochasticLoadBalancerBalanceCluster.testBalanceCluster(TestStochasticLoadBalancerBalanceCluster.java:68)
{noformat}

Reverting the patch for the time being.

Uploaded failed test logs from Jenkins.

Thank you, Nick. Let me investigate the flaky tests.

Results for branch master
	[build #265 on builds.a.o|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/master/265/]: (x) *{color:red}-1 overall{color}*
----
details (if available):

(/) {color:green}+1 general checks{color}
-- For more information [see general report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/master/265/General_20Nightly_20Build_20Report/]






(x) {color:red}-1 jdk8 hadoop3 checks{color}
-- For more information [see jdk8 (hadoop3) report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/master/265/JDK8_20Nightly_20Build_20Report_20_28Hadoop3_29/]


(/) {color:green}+1 jdk11 hadoop3 checks{color}
-- For more information [see jdk11 report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/master/265/JDK11_20Nightly_20Build_20Report_20_28Hadoop3_29/]


(/) {color:green}+1 source release artifact{color}
-- See build output for details.


(/) {color:green}+1 client integration test{color}


Hi, [~claraxiong], as we have discussed in [https://github.com/apache/hbase/pull/3260] , you have mentioned that you used the same aggregation as RegionCountSkewCostFunction for each table? If we set "hbase.master.loadbalance.bytable" be true, then I think the cost of RegionCountSkewCostFunction is for each table, do you think so?  For our production clusters, we set "hbase.master.loadbalance.bytable" be true, and from the balanced results until now, each table can be balanced well. So I'm confused of the question you have mentioned that byTable option doesn't work on your clusters, could you give a little more details? 

And when we do not use balance clusters by table, the cluster state may contains thousands of tables, your patch is aimed to resolve the problem that RegionCountSkewCostFunction is min but TableSkewCostFunction should max for several tables? Will the calculation of cost and generating for balance actions be of low efficiency? How can the balancer know which table is the most unbalanced? For example, 2/1000 tables are imbalanced. Will it balance the 2 tables just depending on a proper but smaller minCostNeedBalance?

 

 

Hi [~Xiaolin Ha], bytable doesn't work in our case because it doesn't consider other tables during the move and causes temporary imbalance on a cluster with current load very sensitive to locality and balance.

My patch is to aggregate the deviation by the sum of absolute deviation per node instead of max. It takes more calculation but bring the accuracy to the same level as region count skew.  As in my example, if half of the cluster is taking all the regions for table, the skew is calculated at very low level. It probably doesn't matter that much and takes a lot of time if you have many tables. but this can be turned off or run by table in that case. balancer looks at the max imbalance of all tables to try to balance them.  so even if only 2 tables out of 1000 are unbalance, it will still run until all table are under minCostNeedBalance.

There is another bug in the original tableSkew cost function for aggregation of the cost per table:

If we have 10 regions, one per table, evenly distributed on 10 nodes, the cost is scale to 1.0.

The more tables we have, the closer the value will be to 1.0. The cost function becomes useless.

All the balancer tests were set up with large numbers of tables with minimal regions per table. This artificially inflates the total cost and trigger balancer runs. With this fix on TableSkewFunction, we need to overhaul the tests too.
{code:java}
protected double cost() {
 double max = cluster.numRegions;
 double min = ((double) cluster.numRegions) / cluster.numServers;
 double value = 0;

 for (int i = 0; i < cluster.numMaxRegionsPerTable.length; i++) {
 value += cluster.numMaxRegionsPerTable[i];
 }
 LOG.info("min = {}, max = {}, cost= {}", min, max, value);
 return scale(min, max, value);
 }
}{code}

subtask created.

 

https://issues.apache.org/jira/browse/HBASE-26023

Because of the fix, the default 0.05 minCostNeedBalance will not quite work. As a gap-stopper before I check in auto-tuning threshold, should I just reduce the default value? So people won't be caught off guard? The broken TableSkewCostFunction artificially inflate the total cost. So if the fix is in and we don't change threshold, people will be badly surprised that balancer gets stuck.

bq. Because of the fix, the default 0.05 minCostNeedBalance will not quite work. As a gap-stopper before I check in auto-tuning threshold, should I just reduce the default value? So people won't be caught off guard? The broken TableSkewCostFunction artificially inflate the total cost. So if the fix is in and we don't change threshold, people will be badly surprised that balancer gets stuck.

This sounds like a case where we have to implement both changes together, nor neither of them. In that case, we have to leave them both out of any patch releases.

Yes. addressed by having both [~ndimiduk]

Merged to master. Want to make PRs for branch-2 [~clarax98007]  (I tried backport but failures)

Results for branch master
	[build #343 on builds.a.o|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/master/343/]: (x) *{color:red}-1 overall{color}*
----
details (if available):

(/) {color:green}+1 general checks{color}
-- For more information [see general report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/master/343/General_20Nightly_20Build_20Report/]






(/) {color:green}+1 jdk8 hadoop3 checks{color}
-- For more information [see jdk8 (hadoop3) report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/master/343/JDK8_20Nightly_20Build_20Report_20_28Hadoop3_29/]


(/) {color:green}+1 jdk11 hadoop3 checks{color}
-- For more information [see jdk11 report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/master/343/JDK11_20Nightly_20Build_20Report_20_28Hadoop3_29/]


(/) {color:green}+1 source release artifact{color}
-- See build output for details.


(/) {color:green}+1 client integration test{color}


Results for branch branch-2
	[build #300 on builds.a.o|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/branch-2/300/]: (x) *{color:red}-1 overall{color}*
----
details (if available):

(/) {color:green}+1 general checks{color}
-- For more information [see general report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/branch-2/300/General_20Nightly_20Build_20Report/]




(/) {color:green}+1 jdk8 hadoop2 checks{color}
-- For more information [see jdk8 (hadoop2) report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/branch-2/300/JDK8_20Nightly_20Build_20Report_20_28Hadoop2_29/]


(/) {color:green}+1 jdk8 hadoop3 checks{color}
-- For more information [see jdk8 (hadoop3) report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/branch-2/300/JDK8_20Nightly_20Build_20Report_20_28Hadoop3_29/]


(/) {color:green}+1 jdk11 hadoop3 checks{color}
-- For more information [see jdk11 report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/branch-2/300/JDK11_20Nightly_20Build_20Report_20_28Hadoop3_29/]


(/) {color:green}+1 source release artifact{color}
-- See build output for details.


(x) {color:red}-1 client integration test{color}
-- Something went wrong with this stage, [check relevant console output|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/branch-2/300//console].


Merged the branch-2 PR. 2.4 and 2.3 seem to have related test failures.

Resovling after merging PRs for branch-2.3+. Thanks for the patch [~clarax98007]  (and reviews [~busbey] and [~zhangduo] )

Results for branch branch-2.3
	[build #256 on builds.a.o|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/branch-2.3/256/]: (/) *{color:green}+1 overall{color}*
----
details (if available):

(/) {color:green}+1 general checks{color}
-- For more information [see general report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/branch-2.3/256/General_20Nightly_20Build_20Report/]




(/) {color:green}+1 jdk8 hadoop2 checks{color}
-- For more information [see jdk8 (hadoop2) report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/branch-2.3/256/JDK8_20Nightly_20Build_20Report_20_28Hadoop2_29/]


(/) {color:green}+1 jdk8 hadoop3 checks{color}
-- For more information [see jdk8 (hadoop3) report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/branch-2.3/256/JDK8_20Nightly_20Build_20Report_20_28Hadoop3_29/]


(/) {color:green}+1 jdk11 hadoop3 checks{color}
-- For more information [see jdk11 report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/branch-2.3/256/JDK11_20Nightly_20Build_20Report_20_28Hadoop3_29/]


(/) {color:green}+1 source release artifact{color}
-- See build output for details.


(/) {color:green}+1 client integration test{color}


Results for branch branch-2.4
	[build #162 on builds.a.o|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/branch-2.4/162/]: (x) *{color:red}-1 overall{color}*
----
details (if available):

(/) {color:green}+1 general checks{color}
-- For more information [see general report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/branch-2.4/162/General_20Nightly_20Build_20Report/]




(/) {color:green}+1 jdk8 hadoop2 checks{color}
-- For more information [see jdk8 (hadoop2) report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/branch-2.4/162/JDK8_20Nightly_20Build_20Report_20_28Hadoop2_29/]


(/) {color:green}+1 jdk8 hadoop3 checks{color}
-- For more information [see jdk8 (hadoop3) report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/branch-2.4/162/JDK8_20Nightly_20Build_20Report_20_28Hadoop3_29/]


(/) {color:green}+1 jdk11 hadoop3 checks{color}
-- For more information [see jdk11 report|https://ci-hadoop.apache.org/job/HBase/job/HBase%20Nightly/job/branch-2.4/162/JDK11_20Nightly_20Build_20Report_20_28Hadoop3_29/]


(/) {color:green}+1 source release artifact{color}
-- See build output for details.


(/) {color:green}+1 client integration test{color}


