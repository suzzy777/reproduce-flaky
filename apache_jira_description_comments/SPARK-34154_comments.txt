I also observed the hanged instance at branch-3.0 GitHub Action and added the link to the PR description. The affected version is all 3.x now.

User 'attilapiros' has created a pull request for this issue:
https://github.com/apache/spark/pull/31363

User 'attilapiros' has created a pull request for this issue:
https://github.com/apache/spark/pull/31363

I tried to reproduce this issue by running it locally 100 times but all of them was successful. 
So my next idea is to reproduce it by the PR builder (and getting the stack trace of the thread which got stuck):
https://github.com/apache/spark/pull/31363



In my PR the bug does not surfaced even after 200 runs.

I think the root cause could be something with the hostname lookup, I have checked and it is called from here:

{code:java}
	at org.apache.hadoop.net.NetUtils.normalizeHostName(NetUtils.java)
	at org.apache.hadoop.net.NetUtils.normalizeHostNames(NetUtils.java:585)
	at org.apache.hadoop.net.CachedDNSToSwitchMapping.resolve(CachedDNSToSwitchMapping.java:109)
	at org.apache.spark.deploy.yarn.SparkRackResolver.coreResolve(SparkRackResolver.scala:75)
	at org.apache.spark.deploy.yarn.SparkRackResolver.resolve(SparkRackResolver.scala:66)
	at org.apache.spark.deploy.yarn.LocalityPreferredContainerPlacementStrategy.$anonfun$localityOfRequestedContainers$3(LocalityPreferredContainerPlacementStrategy.scala:142)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)
	at org.apache.spark.deploy.yarn.LocalityPreferredContainerPlacementStrategy.localityOfRequestedContainers(LocalityPreferredContainerPlacementStrategy.scala:138)
	at org.apache.spark.deploy.yarn.LocalityPlacementStrategySuite.org$apache$spark$deploy$yarn$LocalityPlacementStrategySuite$$runTest(LocalityPlacementStrategySuite.scala:94)
	at org.apache.spark.deploy.yarn.LocalityPlacementStrategySuite$$anon$1.run(LocalityPlacementStrategySuite.scala:40)
	at java.lang.Thread.run(Thread.java:748)
{code}

To get more information I will modify my code a bit and make it mergeable. This way when it fails again in somebody's PR we will have at least the stack trace. In addition it will fail fast. It won't run for hour(s) just for 30 seconds.


Fixed in https://github.com/apache/spark/pull/31363

User 'attilapiros' has created a pull request for this issue:
https://github.com/apache/spark/pull/31397

