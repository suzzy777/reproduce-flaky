I think there are a combination of factors occurring here:
 # The test is effectively using a 10 second DDL timeout due to how the C++ client handles master RPC retries: [https://github.com/apache/kudu/blob/master/src/kudu/client/client-internal.cc#L185-L191]. It appears this isn't sufficient when running on our test infrastructure with TSAN.  The test is 25% flaky right now, with the majority being TSAN failures, but some are just plain timeout errors.
 # The notification log listener is using the [Synchronizer::WaitFor]([https://github.com/apache/kudu/blob/master/src/kudu/master/hms_notification_log_listener.cc#L121-L122)] API to wait for the notification log listener to catch up.  If this times out (after 10s), the stack-allocated {{Synchronizer}} instance is destructed as the stack pops.  At some later time the notification log listener thread completes the callback which holds a stale pointer to the stack.  This causes TSAN to issue errors.

So, the timeout needs to be adjusted, but it appears that this has also exposed a deeper issue with the {{WaitFor}} API.

Patch to make Synchronizer threadsafe in this scenario: [https://gerrit.cloudera.org/c/10783/.|https://gerrit.cloudera.org/c/10783/]  Still need to up the timeouts, which may require fixing the timeout handling of the c++ client.

The test is still 10% flaky, so here's a patch to bump the timeouts: [https://gerrit.cloudera.org/c/10833/.|https://gerrit.cloudera.org/c/10833/]  I punted on fixing the C++ client timeout behavior.

Dan merged this as 4479c20.

