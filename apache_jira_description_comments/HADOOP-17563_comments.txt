Sorry, Bouncy Castle 1.68 does not fix the vulnerability. There is not any fixed version for now.

The vulnerability may affect you only when you use BKS-V1. Therefore, most Hadoop user won't be affected.

This breaks spark builds downstream in the maven shade plugin (3.2.0)/3.2.4.

MSHADE-337 implies it's a .asm update, but  SPARK-29729 doesn't seem to address it locally.

Given this doesn't address the hash vulnerability, and that it breaks downstream builds, should we revert this for now?

 
{code:java}
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-shade-plugin:3.2.0:shade (default) on project spark-streaming-kafka-0-10-assembly_2.11: Error creating shaded jar: Problem shading JAR /Users/stevel/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.68/bcprov-jdk15on-1.68.jar entry META-INF/versions/15/org/bouncycastle/jcajce/provider/asymmetric/edec/SignatureSpi$EdDSA.class: java.lang.IllegalArgumentException: Unsupported class file major version 59 -> [Help 1]
[ERROR] 

 {code}
 

 

Sorry for the break, and thanks for reporting it, [~stevel@apache.org]. I agree to revert it. I'll create the PR. Should we backport it to 3.3.1-RC? (cc: [~weichiu] )

Created the revert PR: https://github.com/apache/hadoop/pull/3055

I found problems with bouncycastle 1.68 with HBase as well. HBase specifies bouncycastle 1.60 so at runtime it couldn't find some classes.

If 1.68 doesn't address the vulnerability, I am +1 to revert the change.

a bit more digging and its not core spark building, but something else downstream. I see hints online that bouncy castle now has multiple artifacts in for different java versions, and this is confusing maven shade. I see other hints that it's related to asm.jar versions, but even bumping things up to 7.2 that's failing.

So it's not a blocker. [~weichiu] is hbase explicitly looking for the jar by name? as that's trouble down the line, isn't it?

Merged the revert PR to trunk, and cherry-picked to branch-3.3 and branch-3.2.

[~weichiu] Please cherry-pick it to 3.3.1 if necessary.

I think the link to the vulnerability in the description is wrong? https://nvd.nist.gov/vuln/detail/CVE-2020-26939 and https://nvd.nist.gov/vuln/detail/CVE-2020-28052 and https://nvd.nist.gov/vuln/detail/CVE-2020-15522 could be correct?

At least CVE-2020-26939 applies to 1.60 and is fixed in 1.61 or later. CVE-2020-28052 applies to 1.65 and 1.66.

Based on https://snyk.io/vuln/maven:org.bouncycastle:bcprov-jdk15on 1.67 or later currently has no CVEs.

[~krisden] Yes, the description is wrong. I will update it based on your comment. Thanks for sharing it.

Reverted from branch-3.3.1. Resolve the jira.

Since the patch has been reverted, I've reopened and removed the fix versions.

Spark Asm has been updated in 2020  [SPARK-29729][BUILD] Upgrade ASM to 7.2 [PR-26373| https://github.com/apache/spark/pull/26373] 
I created [PR-3405| https://github.com/apache/spark/pull/3405] to upgrade bouncy to 1.69

trunk is at 1.68. given spark is updated, should we reapply this patch to 3.3. and 3.3.5?

steveloughran opened a new pull request, #5015:
URL: https://github.com/apache/hadoop/pull/5015

   
   Contributed by PJ Fanning
   
   <!--
     Thanks for sending a pull request!
       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute
       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.
   -->
   
   ### Description of PR
   
   
   ### How was this patch tested?
   
   
   ### For code changes:
   
   - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?
   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?
   - [X] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?
   - [X] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?
   
   




hadoop-yetus commented on PR #5015:
URL: https://github.com/apache/hadoop/pull/5015#issuecomment-1279636928

   :broken_heart: **-1 overall**
   
   
   
   
   
   
   | Vote | Subsystem | Runtime |  Logfile | Comment |
   |:----:|----------:|--------:|:--------:|:-------:|
   | +0 :ok: |  reexec  |   0m 52s |  |  Docker mode activated.  |
   |||| _ Prechecks _ |
   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |
   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |
   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |
   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |
   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |
   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |
   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |
   |||| _ branch-3.3 Compile Tests _ |
   | +0 :ok: |  mvndep  |  15m 16s |  |  Maven dependency ordering for branch  |
   | +1 :green_heart: |  mvninstall  |  26m 58s |  |  branch-3.3 passed  |
   | +1 :green_heart: |  compile  |  19m  6s |  |  branch-3.3 passed  |
   | +1 :green_heart: |  mvnsite  |  21m 20s |  |  branch-3.3 passed  |
   | +1 :green_heart: |  javadoc  |   7m  6s |  |  branch-3.3 passed  |
   | +1 :green_heart: |  shadedclient  |  32m 11s |  |  branch has no errors when building and testing our client artifacts.  |
   |||| _ Patch Compile Tests _ |
   | +0 :ok: |  mvndep  |   0m 31s |  |  Maven dependency ordering for patch  |
   | +1 :green_heart: |  mvninstall  |  24m 53s |  |  the patch passed  |
   | +1 :green_heart: |  compile  |  18m 33s |  |  the patch passed  |
   | +1 :green_heart: |  javac  |  18m 33s |  |  the patch passed  |
   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |
   | +1 :green_heart: |  mvnsite  |  21m  3s |  |  the patch passed  |
   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |
   | +1 :green_heart: |  javadoc  |   6m 56s |  |  the patch passed  |
   | +1 :green_heart: |  shadedclient  |  32m 54s |  |  patch has no errors when building and testing our client artifacts.  |
   |||| _ Other Tests _ |
   | -1 :x: |  unit  | 707m 41s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-5015/4/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |
   | +1 :green_heart: |  asflicense  |   2m  0s |  |  The patch does not generate ASF License warnings.  |
   |  |   | 926m 19s |  |  |
   
   
   | Reason | Tests |
   |-------:|:------|
   | Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade |
   |   | hadoop.hdfs.TestFileCreation |
   |   | hadoop.hdfs.tools.TestDFSAdmin |
   |   | hadoop.yarn.sls.appmaster.TestAMSimulator |
   
   
   | Subsystem | Report/Notes |
   |----------:|:-------------|
   | Docker | ClientAPI=1.41 ServerAPI=1.41 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-5015/4/artifact/out/Dockerfile |
   | GITHUB PR | https://github.com/apache/hadoop/pull/5015 |
   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs |
   | uname | Linux 96ba0915b1ba 4.15.0-191-generic #202-Ubuntu SMP Thu Aug 4 01:49:29 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux |
   | Build tool | maven |
   | Personality | dev-support/bin/hadoop.sh |
   | git revision | branch-3.3 / 98c7a56eabb8cffa9a3c3594894167bf692c22af |
   | Default Java | Private Build-1.8.0_342-8u342-b07-0ubuntu1~18.04-b07 |
   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-5015/4/testReport/ |
   | Max. process+thread count | 2718 (vs. ulimit of 5500) |
   | modules | C: hadoop-project . U: . |
   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-5015/4/console |
   | versions | git=2.17.1 maven=3.6.0 shellcheck=0.4.6 |
   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |
   
   
   This message was automatically generated.
   
   




steveloughran commented on PR #5015:
URL: https://github.com/apache/hadoop/pull/5015#issuecomment-1279753303

   flaky tests; ignoring




steveloughran merged PR #5015:
URL: https://github.com/apache/hadoop/pull/5015




merged all the way back to 3.3.5 as spark has had its build fix in, as should hive. those are both compile-time issues 

ok, i'm seeing some quirks with spark master and hadoop trunk with the sbt plugin missing bouncycastle.

{code}
[INFO] --- scala-maven-plugin:4.7.2:testCompile (scala-test-compile-first) @ spark-sql_2.12 ---
[INFO] Using incremental compilation using Mixed compile order
[INFO] Compiler bridge file: /Users/stevel/.sbt/1.0/zinc/org.scala-sbt/org.scala-sbt-compiler-bridge_2.12-1.7.1-bin_2.12.17__52.0-1.7.1_20220712T022208.jar
[INFO] compiler plugin: BasicArtifact(com.github.ghik,silencer-plugin_2.12.17,1.7.10,null)
[INFO] compiling 603 Scala sources and 51 Java sources to /Users/stevel/Projects/sparkwork/spark/sql/core/target/scala-2.12/test-classes ...
[WARNING] /Users/stevel/Projects/sparkwork/spark/sql/core/src/test/java/test/org/apache/spark/sql/MyDoubleAvg.java:25:39:  [deprecation] UserDefinedAggregateFunction in org.apache.spark.sql.expressions has been deprecated
[WARNING] /Users/stevel/Projects/sparkwork/spark/sql/core/src/test/java/test/org/apache/spark/sql/MyDoubleSum.java:25:39:  [deprecation] UserDefinedAggregateFunction in org.apache.spark.sql.expressions has been deprecated
[WARNING] /Users/stevel/Projects/sparkwork/spark/sql/core/src/test/java/test/org/apache/spark/sql/JavaBeanDeserializationSuite.java:593:16:  [rawtypes] found raw type: Tuple2
[WARNING] /Users/stevel/Projects/sparkwork/spark/sql/core/src/test/java/test/org/apache/spark/sql/JavaBeanDeserializationSuite.java:593:12:  [unchecked] unchecked call to Tuple2(T1,T2) as a member of the raw type Tuple2
[WARNING] /Users/stevel/Projects/sparkwork/spark/sql/core/src/test/java/test/org/apache/spark/sql/JavaBeanDeserializationSuite.java:592:62:  [unchecked] unchecked method invocation: method asList in class Arrays is applied to given types
[WARNING] /Users/stevel/Projects/sparkwork/spark/sql/core/src/test/java/test/org/apache/spark/sql/JavaColumnExpressionSuite.java:89:48:  [rawtypes] found raw type: HashMap
[WARNING] /Users/stevel/Projects/sparkwork/spark/sql/core/src/test/java/test/org/apache/spark/sql/JavaColumnExpressionSuite.java:89:44:  [unchecked] unchecked conversion
[WARNING] /Users/stevel/Projects/sparkwork/spark/sql/core/src/test/java/test/org/apache/spark/sql/JavaHigherOrderFunctionsSuite.java:67:29:  [varargs] Varargs method could cause heap pollution from non-reifiable varargs parameter objs
[WARNING] /Users/stevel/Projects/sparkwork/spark/sql/core/src/test/java/test/org/apache/spark/sql/JavaHigherOrderFunctionsSuite.java:74:15:  [varargs] Varargs method could cause heap pollution from non-reifiable varargs parameter ts
[WARNING] /Users/stevel/Projects/sparkwork/spark/sql/core/src/test/java/test/org/apache/spark/sql/MyDoubleAvg.java:36:33:  [deprecation] UserDefinedAggregateFunction in org.apache.spark.sql.expressions has been deprecated
[WARNING] /Users/stevel/Projects/sparkwork/spark/sql/core/src/test/java/test/org/apache/spark/sql/MyDoubleSum.java:35:33:  [deprecation] UserDefinedAggregateFunction in org.apache.spark.sql.expressions has been deprecated
[WARNING] /Users/stevel/Projects/sparkwork/spark/sql/core/src/test/java/test/org/apache/spark/sql/connector/JavaAdvancedDataSourceV2WithV2Filter.java:72:10:  [rawtypes] found raw type: Literal
[ERROR] ## Exception when compiling 654 sources to /Users/stevel/Projects/sparkwork/spark/sql/core/target/scala-2.12/test-classes
java.lang.NoClassDefFoundError: org/bouncycastle/jce/provider/BouncyCastleProvider
java.lang.Class.getDeclaredMethods0(Native Method)
java.lang.Class.privateGetDeclaredMethods(Class.java:2701)
java.lang.Class.privateGetPublicMethods(Class.java:2902)
java.lang.Class.getMethods(Class.java:1615)
sbt.internal.inc.ClassToAPI$.toDefinitions0(ClassToAPI.scala:173)
sbt.internal.inc.ClassToAPI$.$anonfun$toDefinitions$1(ClassToAPI.scala:125)
scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:454)
sbt.internal.inc.ClassToAPI$.toDefinitions(ClassToAPI.scala:125)
sbt.internal.inc.ClassToAPI$.$anonfun$process$1(ClassToAPI.scala:34)
scala.collection.immutable.List.foreach(List.scala:333)
sbt.internal.inc.ClassToAPI$.process(ClassToAPI.scala:34)
sbt.internal.inc.javac.AnalyzingJavaCompiler.readAPI$1(AnalyzingJavaCompiler.scala:185)
sbt.internal.inc.javac.AnalyzingJavaCompiler.$anonfun$compile$22(AnalyzingJavaCompiler.scala:215)
sbt.internal.inc.classfile.JavaAnalyze$.readInheritanceDependencies$1(JavaAnalyze.scala:186)
sbt.internal.inc.classfile.JavaAnalyze$.$anonfun$apply$16(JavaAnalyze.scala:193)
sbt.internal.inc.classfile.JavaAnalyze$.$anonfun$apply$16$adapted(JavaAnalyze.scala:108)
scala.collection.IterableOnceOps.foreach(IterableOnce.scala:563)
scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:561)
scala.collection.AbstractIterable.foreach(Iterable.scala:926)
scala.collection.IterableOps$WithFilter.foreach(Iterable.scala:896)
sbt.internal.inc.classfile.JavaAnalyze$.apply(JavaAnalyze.scala:108)
sbt.internal.inc.javac.AnalyzingJavaCompiler.$anonfun$compile$21(AnalyzingJavaCompiler.scala:215)
sbt.internal.inc.javac.AnalyzingJavaCompiler.$anonfun$compile$21$adapted(AnalyzingJavaCompiler.scala:207)
scala.collection.IterableOnceOps.foreach(IterableOnce.scala:563)
scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:561)
scala.collection.AbstractIterable.foreach(Iterable.scala:926)
scala.collection.IterableOps$WithFilter.foreach(Iterable.scala:896)
sbt.internal.inc.javac.AnalyzingJavaCompiler.$anonfun$compile$19(AnalyzingJavaCompiler.scala:207)
scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
sbt.internal.inc.javac.AnalyzingJavaCompiler.timed(AnalyzingJavaCompiler.scala:262)
sbt.internal.inc.javac.AnalyzingJavaCompiler.compile(AnalyzingJavaCompiler.scala:207)
sbt.internal.inc.MixedAnalyzingCompiler.$anonfun$compileJava$2(MixedAnalyzingCompiler.scala:103)
sbt.internal.inc.MixedAnalyzingCompiler.$anonfun$compileJava$2$adapted(MixedAnalyzingCompiler.scala:91)
sbt.internal.inc.JarUtils$.withPreviousJar(JarUtils.scala:239)
sbt.internal.inc.MixedAnalyzingCompiler.$anonfun$compileJava$1(MixedAnalyzingCompiler.scala:91)
scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
sbt.internal.inc.MixedAnalyzingCompiler.timed(MixedAnalyzingCompiler.scala:248)
sbt.internal.inc.MixedAnalyzingCompiler.compileJava(MixedAnalyzingCompiler.scala:61)
sbt.internal.inc.MixedAnalyzingCompiler.compileJava0$1(MixedAnalyzingCompiler.scala:198)
sbt.internal.inc.MixedAnalyzingCompiler.compile(MixedAnalyzingCompiler.scala:211)
sbt.internal.inc.IncrementalCompilerImpl.$anonfun$compileInternal$1(IncrementalCompilerImpl.scala:534)
sbt.internal.inc.IncrementalCompilerImpl.$anonfun$compileInternal$1$adapted(IncrementalCompilerImpl.scala:534)
sbt.internal.inc.Incremental$.$anonfun$apply$5(Incremental.scala:179)
sbt.internal.inc.Incremental$.$anonfun$apply$5$adapted(Incremental.scala:177)
sbt.internal.inc.Incremental$$anon$2.run(Incremental.scala:463)
sbt.internal.inc.IncrementalCommon$CycleState.next(IncrementalCommon.scala:116)
sbt.internal.inc.IncrementalCommon$$anon$1.next(IncrementalCommon.scala:56)
sbt.internal.inc.IncrementalCommon$$anon$1.next(IncrementalCommon.scala:52)
sbt.internal.inc.IncrementalCommon.cycle(IncrementalCommon.scala:263)
sbt.internal.inc.Incremental$.$anonfun$incrementalCompile$8(Incremental.scala:418)
sbt.internal.inc.Incremental$.withClassfileManager(Incremental.scala:506)
sbt.internal.inc.Incremental$.incrementalCompile(Incremental.scala:405)
sbt.internal.inc.Incremental$.apply(Incremental.scala:171)
sbt.internal.inc.IncrementalCompilerImpl.compileInternal(IncrementalCompilerImpl.scala:534)
sbt.internal.inc.IncrementalCompilerImpl.$anonfun$compileIncrementally$1(IncrementalCompilerImpl.scala:488)
sbt.internal.inc.IncrementalCompilerImpl.handleCompilationError(IncrementalCompilerImpl.scala:332)
sbt.internal.inc.IncrementalCompilerImpl.compileIncrementally(IncrementalCompilerImpl.scala:425)
sbt.internal.inc.IncrementalCompilerImpl.compile(IncrementalCompilerImpl.scala:137)
sbt_inc.SbtIncrementalCompiler.compile(SbtIncrementalCompiler.java:181)
scala_maven.ScalaCompilerSupport.incrementalCompile(ScalaCompilerSupport.java:364)
scala_maven.ScalaCompilerSupport.compile(ScalaCompilerSupport.java:122)
scala_maven.ScalaCompilerSupport.doExecute(ScalaCompilerSupport.java:89)
scala_maven.ScalaMojoSupport.execute(ScalaMojoSupport.java:310)
scala_maven.ScalaTestCompileMojo.execute(ScalaTestCompileMojo.java:51)
org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
org.apache.maven.lifecycle.internal.MojoExecutor.doExecute2(MojoExecutor.java:370)
org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:351)
org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:215)
org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:171)
org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:163)
org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:117)
org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)
org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
           

{code}


This class is in bcprov-jdk15on-1.60.jar and bcprov-jdk15on-1.68.jar.
org/bouncycastle/jce/provider/BouncyCastleProvider.class

Is it possible that the plugin needs to be updated to include bcprov-jdk15on-1.68.jar on the classpath?

makes sense. one bit of weirdness tho'; the 3.3.5 RC smoke build is happy and it has this patch, it is trunk that's failing.

