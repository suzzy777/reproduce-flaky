Taking a look at this while getting to know the project.

Hey [~baunsgaard],

this looks possible through the use of artifacts. However, I'd first like to know more about why the unit tests are split into separate jobs and why a whitelist is used instead of a blacklist for selecting the classes that should run. Do you not want to run all of the tests for each package (functions, component, applications, . . . )?

 

Edit: I've also seen the note on a commit that the splitting was done to fix some issues with RAM and to parallelize the tasks, but I'd like to know if there are any other motivations.

 

Best,

– Kyle

Hi Kyle!

Thanks for reaching out!

The main motivation is for each container to run tests for ~25 minutes, this gives us faster feedback, 
since if we were to run all tests in one container we would have to wait up to ~5 hours.
Each container is limited to 2 CPU cores and 8 GB ram, that is the second criteria. since some tests use more memory, 
and since we run all tests in parallel some mixes of tests run out.
Therefore finer granularity and spawning more jobs gives more stability in the testing.

We have had a manual process with whitelists that allow specific sub-parts of the tests to run in each container based on the string definitions.
Unfortunately this leads to tests sometimes not being added to the test suite when people add new things.
If you have a better suggestion i would love to discuss it.

Related to the task i am currently not aware of how these "artifacts" work in github actions, so if you know that would be a great help.
There are some extra challenges associated with this tho. because even if you can collect the individual tests code coverage i am not sure how they combine in jacoco, and you might (as the task suggest) have to look at other java code coverage tools.

best regards
Sebastian

If you want to pursue this, i suggest you first get familiar with the jacoco code coverage tool.


{code}
mvn test  -Dtest=org.apache.sysds.test.component.matrix.** -Djacoco.skip=false 
{code}


then the code coverage is in: target/site/jacoco

if you run multiple where each is covering a different subset of tests, then somehow we want to combine these.

I had ran the jacoco Maven plugin locally yesterday, and have not yet tried the combination is of results, but something along the lines of
`mvn jacoco:report-aggregate` 
had looked promising. I'll try it first locally.

Changing the nature of the whitelist for the different sets of java tests are something I'd keep for a second ticket. So, I'll stick with the manual whitelist for now but probably still combine all java tests into one workflow but separate jobs.

The limits of the containers are an important criteria for me. Even if we keep the sizing down, we could run into the concurrency limit of the jobs. Those are limited per account and not per workflow, what is the account type being used?

Hi Kyle

Sounds promising the thing i was missing when i tried it was the ability to have two different test runs logs

 The target folder is  empty between runs as it is in github actions. 

and then copying in he different JACOCO runs does not just work out of the box. 

I suggest trying to make the following work

run :

{code}
- mvn test  -Dtest=org.apache.sysds.test.component.matrix.** -Djacoco.skip=false 
- copy out the target folders jacoco content.
- mvn clean
- mvn test  -Dtest=org.apache.sysds.test.component.frame.** -Djacoco.skip=false 
- ... somehow combine the different runs results from your copied folder.
{code}

on : "Changing the nature of the whitelist for the different sets of java tests are something I'd keep for a second ticket. So, I'll stick with the manual whitelist for now but probably still combine all java tests into one workflow but separate jobs."

Please do not do this unless you verify and talk to me first that your alternative idea is beneficial i am not sure if i understand the differentiation of workflows and jobs you mean.

on: The limits of the containers are an important criteria for me. Even if we keep the sizing down, we could run into the concurrency limit of the jobs. Those are limited per account and not per workflow, what is the account type being used?

Apache special licenses... aka .... many many many parallel jobs are allowed i do not know the limit but at least over 35 parallel jobs with 2 cores and 8 GB ram. and Microsoft are giving them for free to Apache projects.

Best Regards
Sebastian 



Hi Sebastian,

 

Artifacts may be used to share files between jobs that belong to the same workflow. The API does not support sharing those artifacts between separate workflows. For this reason, I'd need to put all java tests for the test coverage report into the same workflow, at least not as far as I can tell, they even explicitly hint at it only working within one workflow. You can find the docs about this feature here: [https://docs.github.com/en/actions/using-workflows/storing-workflow-data-as-artifacts]

As for the number of parallel jobs, I guess I'll have to test that in a PR (I'm assuming github will have different limits within my fork).

 

Best,

– Kyle

Hi Kyle,

Okay if they cannot share across workflows so be it. then we combine all Java tests into one workflow, 
there is not much difference in the ones in each one. 

but before doing such a thing i suggest we concentrate on the smaller easier example to handle in our component tests.
Such that we can verify that the combining of test results work.

https://github.com/apache/systemds/blob/main/.github/workflows/componentTests.yml

On this task we have 4 different jobs run that once done can share their artifacts of jacoco and hopefully combine them.

I have not looked into the details of the tests running on forks lately, so i actually do not know how much they run.
but they have been limited to 1. main branches, 2. pull requests. 
So i would suggest you make your fork, then make a new branch on your fork and make a pull request from that to the apache main branch. This will make it such that it should not run the tests on your fork, but only on apache resources.

Do not worry about making an empty pull request ... or one that contain nothing, just mark it as a draft PR and add a comment of me in it.

Unfortunately until you make your first contribution it will not run automatically but i will have to approve it. 
No worries i will be on it as a hawk, and make sure it keeps running.
otherwise just text me if you have problems.

Br
Sebastian



Hi Sebastian,

no worries about the compute on my end, I'm just treating my main of the fork as the feature branch for now. I was curious if all the actions would still work without any secrets or special variables from the core project.

 

Yesterday I added the artifact upload for all of the matrix-jobs and ran into a flaky federated test. Is this failure common?

 

[https://github.com/kykrueger/systemds/actions/runs/4759533257/jobs/8466277359]

 

As for running a reduced test-set while testing the merge function of jacoco, good idea, I'll shrink the scope of the tests to a smaller group to speed up the iteration process. Might be able to take another look tonight or on the weekend.

 

Also, I'll open a PR to make the work a bit more transparent, but before I do that, what is the project philosophy on rebasing and resets in feature branches. Does the group prefer to have a lean commit history or should I rebase to get rid of any bugfix commits?

 

Best,

-- Kyle

On another note, did you have a type of test coverage in mind for displaying the results:
 * lines
 * classes
 * other?

 

 flaky federated test -- yes and no.
The test is flaky if you consider that it have to run together with a bunch of other tests, therefore the timing at which the different federated workers startup and such is flaky.
we have discussed this internally alot. and currently the way we handle it is by setting the repeat on the tests to 3 to allow the test not to fail, unless it does it 3 times. 

And thanks for opening the PR, i suggest we shift the conversation over there, for transparency with the other people.


>On another note, did you have a type of test coverage in mind for displaying the results:
  >  lines classes other?

lines would be the standard one. but we could consider branches.

Idealy, we need to:
1. Have some way of downloading the entire statistics / webpage of the combined jacoco.
2. Chose one of the metrics and include it in a dynamic updating badge on our main readme.

These are in prioritized order. 





 

> Also, I'll open a PR to make the work a bit more transparent, but before I do that, what is the project philosophy on rebasing and resets in feature branches. Does the group prefer to have a lean commit history or should I rebase to get rid of any bugfix commits?

Preferably, you make sure that your commit start on master at one place, and never never never merge master in again.

Instead fetch the master and rebase ontop of it with your commits. This makes it easier to merge later,

Feel free to rebase and squash all your commits into one as well, i prefer myself to split the commit into multiple smaller ones if i see it fit later.
 

About merging from master, I'd delete my fork after merge and just treat the fork as a branch since I'm not working on multiple features. If it is more of a problem for documentation or reporting, I could just rename my main branch to something else. I didn't see any branch naming conventions, did I miss something?

We try to avoid making any unnecessary rules, the last time we change a rule regarding branches was when we changed name of "master" to "main". In general we do not have many branches.

You can decided what to do with your fork after. but my workflow is as follows:

on my fork
main --- keep up to date with master on apache
anyOtherNamedBranch --- a checkout from my main branch

I do this because then if i make some mistake on my branch i can easily revert to my main, and not get confused when some changes happen on apache/main.

i typically call them by feature.



again... we should switch to your PR we can make it automatically report to JIRA via renaming the PR.
2 sec i will make it happen.

-- edit
nvm. you already did.

I think the Jira ticket might not be synchronised since my PR is marked as a draft, I'll change that.

Commit 7146c05d6b715a0e957ecf2ac1c9e5d8d61eb196 in systemds's branch refs/heads/main from Kyle Krueger
[ https://gitbox.apache.org/repos/asf?p=systemds.git;h=7146c05d6b ]

[SYSTEMDS-3428] Code coverage in GitHub Actions (Java)

This commit adds a code coverage task for the java tests in GitHub.
It is achieved by merging the individual sub test suites into one Java
workflow with multiple components that run Application, Function and
Component tests.

Also contained is a minor update of jacoco.

Closes #1806


