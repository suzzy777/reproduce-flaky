Stack. Could not replicate on 2x followups. Surfaced during a heavy-load parallel test run BTW.
{code}
[ERROR] testOpenFailOnRead(org.apache.hadoop.fs.s3a.ITestS3AInconsistency)  Time elapsed: 9.95 s  <<< FAILURE!
java.lang.AssertionError: S3Guard failed to handle fail-on-read
	at org.apache.hadoop.fs.contract.ContractTestUtils.fail(ContractTestUtils.java:528)
	at org.apache.hadoop.fs.s3a.ITestS3AInconsistency.doOpenFailOnReadTest(ITestS3AInconsistency.java:185)
	at org.apache.hadoop.fs.s3a.ITestS3AInconsistency.testOpenFailOnRead(ITestS3AInconsistency.java:162)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: java.io.FileNotFoundException: read(b, 0, 4) on key fork-0002/test/ancestor/file-to-read-DELAY_LISTING_ME failed: injecting error 51/100 for test.
	at org.apache.hadoop.fs.s3a.InconsistentS3Object.readFailpoint(InconsistentS3Object.java:158)
	at org.apache.hadoop.fs.s3a.InconsistentS3Object.access$200(InconsistentS3Object.java:39)
	at org.apache.hadoop.fs.s3a.InconsistentS3Object$InconsistentS3InputStream.read(InconsistentS3Object.java:227)
	at org.apache.hadoop.fs.s3a.S3AInputStream.lambda$read$3(S3AInputStream.java:451)
	at org.apache.hadoop.fs.s3a.Invoker.once(Invoker.java:109)
	at org.apache.hadoop.fs.s3a.Invoker.lambda$retry$3(Invoker.java:260)
	at org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:317)
	at org.apache.hadoop.fs.s3a.Invoker.retry(Invoker.java:256)
	at org.apache.hadoop.fs.s3a.Invoker.retry(Invoker.java:231)
	at org.apache.hadoop.fs.s3a.S3AInputStream.read(S3AInputStream.java:441)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.fs.s3a.ITestS3AInconsistency.doOpenFailOnReadTest(ITestS3AInconsistency.java:178)
	... 13 more
{code}

Interesting.. I'll try to take a look in spare time to see if I inadvertently created a flaky test here.

BTW, I'm still having problems with integration test failures due to multiple close(). fs.s3a.impl.disable.cache makes them go away so I think it has to do with FileSystem reuse across test cases on parallel runs (I usually test on OS X--wonder if test runner behaves differently).

Not seen this for a while; feel free to move to the 3.3 task list

closing as cannot reproduce

