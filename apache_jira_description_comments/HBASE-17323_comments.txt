{code}
grep 'Call queue is full' org.apache.hadoop.hbase.client.TestAsyncGetMultiThread-output.txt | wc
    3796   49348  614952
{code}

There were a lot of errors in the form:
{code}
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.NotServingRegionException): org.apache.hadoop.hbase.NotServingRegionException:       Region async,555,1481831095337.f8cfe8be90c3055f9abcb0c257ffdd6d. is not online on cn012.a.com,42921,1481830976137
  at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:3155)
  at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:1229)
  at org.apache.hadoop.hbase.regionserver.RSRpcServices.get(RSRpcServices.java:2263)
{code}
{code}
grep ' is not online on' org.apache.hadoop.hbase.client.TestAsyncGetMultiThread-output.txt | wc
    2131   20164  475147
{code}

Fails 50% of the time: https://builds.apache.org/job/HBASE-Find-Flaky-Tests/lastSuccessfulBuild/artifact/dashboard.html

Can repro fail about same rate locally.

Attached patch doesn't fix the issue (though seems to happen less w/ it in place).

I see this which seems wrong:

{code}
2016-12-16 13:56:41,709 DEBUG [Default-IPC-NioEventLoopGroup-12-16] client.AsyncRegionLocator(420): The actual exception when updating region=async,,1481925400233.c6b4c90d218018c1743fb8b6c7b4aee5., hostname=kalashnikov.att.net,59461,               1481925396418, seqNum=2
 org.apache.hadoop.hbase.CallQueueTooBigException: Call queue is full on kalashnikov.att.net,59461,1481925396418, too many items queued ?
     at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
     at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
     at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
     at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
     at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.instantiateException(RemoteWithExtrasException.java:95)
     at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.unwrapRemoteException(RemoteWithExtrasException.java:85)
     at org.apache.hadoop.hbase.client.ConnectionUtils.translateException(ConnectionUtils.java:289)
     at org.apache.hadoop.hbase.client.AsyncSingleRequestRpcRetryingCaller.onError(AsyncSingleRequestRpcRetryingCaller.java:135)
     at org.apache.hadoop.hbase.client.AsyncSingleRequestRpcRetryingCaller.lambda$call$5(AsyncSingleRequestRpcRetryingCaller.java:191)
     at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760)
     at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736)
     at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
     at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977)
     at org.apache.hadoop.hbase.client.RawAsyncTableImpl$1.run(RawAsyncTableImpl.java:123)
     at org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcUtil$1.run(RpcUtil.java:82)
     at org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcUtil$1.run(RpcUtil.java:73)
     at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:389)
     at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:94)
     at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:407)
     at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:403)
     at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:103)
     at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:118)
     at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.readResponse(NettyRpcDuplexHandler.java:159)
     at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.channelRead(NettyRpcDuplexHandler.java:189)
....
{code}


.. so [~Apache9] maybe HBASE-17282 Reduce the redundant requests to meta table  fixes this... let me finish my review there.

Code that checks for null and if we are stopping, just skips out. Also started to refactor the call queue too big exception to add more info which is nice but this not the locale of the exception pasted above... more to do.

I still see above exception even with HBASE-17282 in place. HBASE-17282 does not fix this issue either.

HBASE-17329 adds some info around exceptions thrown when Qs are full. Probably shouldn't be up against limit but doesn't seem to be the issue. We seem to misread randomly (HBASE-17329 added logging name of problem row) so something more substantial going on here I'd say. What you reckon [~Apache9] ? Thanks sir.

I think the queue full is in the setUp method where I put 1000 rows concurrently. This is what [~carp84] said, with async client we need to pay more attention on the pressure of RS. One simple solution is to use a separated sleep mechanism when call queue is full, and a more beautiful solution is to track the pressure of RS and give a reasonable sleep time when retrying. We have done some works before, see the classes under o.a.h.h.client.backoff package, but I haven't found a proper way to use them. But I do not think this is the reason why this test fails. It just wastes some time...

And the error posted by Ted is intenional. In this test I keep moving regions(include meta region) across RSes to test if there are data races which will lead to incorrect result. Let me dig more.

Thanks.

Yeah, on CallQueueTooBigException not being the issue because I got rid of exception by making Q massive and it still failed. Yeah, on pushback.

The NPE happens randomly. Could we be mis-reading? Dropping value. Seems to happen at random places doing Get of 1k. [~Apache9]

With HBASE-17081, the test fails in 2nd iteration.

With the commit prior to HBASE-17081, I haven't reproduced test failure.

Thanks for the information. Will take a look later today.

I can get the same result with [~tedyu]. If I update to the version before HBASE-17081
{noformat}
commit 401e83cee383508a2ccdf5b92e7c77a0be2e566a
Author: tedyu <yuzhihong@gmail.com>
Date:   Thu Dec 15 07:06:37 2016 -0800

    HBASE-17318 Increment does not add new column if the increment amount is zero at first time writing (Guangxu Cheng)
{noformat}

TestAsyncGetMultiThread have passed all the 10 runs.

If I update to HBASE-17081
{noformat}
commit a2a7618d261bfe121f05821d89242d770cd7b7ec
Author: Ramkrishna <ramkrishna.s.vasudevan@intel.com>
Date:   Thu Dec 15 22:02:05 2016 +0530

    HBASE-17081 Flush the entire CompactingMemStore content to disk (Anastasia
    Braginsky)
{noformat}

It failed 7 times out of 10 runs.

So I think the problem is HBASE-17081.

Resolving as 'Cannot Reproduce'.  It no longer shows in the flakey list: https://builds.apache.org/job/HBASE-Find-Flaky-Tests/lastSuccessfulBuild/artifact/dashboard.html

This test was failing because of an issue in inmemory compaction (HBASE-17294 + HBASE-17333) that this test exposed.

