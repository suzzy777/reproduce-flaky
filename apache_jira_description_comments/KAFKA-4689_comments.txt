Not sure yet, but we think this could be caused by KAFKA-4673. I looked at the test data and could not find any gaps in the data delivered to the consumer.

[~hachikuji] Any further thoughts on this since 4673 was resolved but we still saw a failure in the nightlies?

Actually, the error message in the latest version looks different:

{quote}
====================================================================================================
test_id:    kafkatest.tests.client.consumer_test.OffsetValidationTest.test_broker_failure.clean_shutdown=True.enable_autocommit=False
status:     FAIL
run time:   1 minute 17.051 seconds


    Timed out waiting for consumption
Traceback (most recent call last):
  File "/var/lib/jenkins/workspace/system-test-kafka-0.10.2/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.6.0-py2.7.egg/ducktape/tests/runner_client.py", line 123, in run
    data = self.run_test()
  File "/var/lib/jenkins/workspace/system-test-kafka-0.10.2/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.6.0-py2.7.egg/ducktape/tests/runner_client.py", line 176, in run_test
    return self.test_context.function(self.test)
  File "/var/lib/jenkins/workspace/system-test-kafka-0.10.2/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.6.0-py2.7.egg/ducktape/mark/_mark.py", line 321, in wrapper
    return functools.partial(f, *args, **kwargs)(*w_args, **w_kwargs)
  File "/var/lib/jenkins/workspace/system-test-kafka-0.10.2/kafka/tests/kafkatest/tests/client/consumer_test.py", line 221, in test_broker_failure
    self.await_consumed_messages(consumer, min_messages=1000)
  File "/var/lib/jenkins/workspace/system-test-kafka-0.10.2/kafka/tests/kafkatest/tests/verifiable_consumer_test.py", line 74, in await_consumed_messages
    err_msg="Timed out waiting for consumption")
  File "/var/lib/jenkins/workspace/system-test-kafka-0.10.2/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.6.0-py2.7.egg/ducktape/utils/util.py", line 36, in wait_until
    raise TimeoutError(err_msg)
TimeoutError: Timed out waiting for consumption
{quote}

So maybe the only failure remaining is actually a case of https://issues.apache.org/jira/browse/KAFKA-3513

0.10.1, which includes KAFKA-4673 and KAFKA-4547 failed with a slightly different message:

{code}
test_id:    2017-01-28--001.kafkatest.tests.client.consumer_test.OffsetValidationTest.test_broker_rolling_bounce
status:     FAIL
run time:   3 minutes 48.362 seconds


    Total consumed records did not match consumed position
Traceback (most recent call last):
  File "/var/lib/jenkins/workspace/system-test-kafka-0.10.1/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.5.3-py2.7.egg/ducktape/tests/runner.py", line 106, in run_all_tests
    data = self.run_single_test()
  File "/var/lib/jenkins/workspace/system-test-kafka-0.10.1/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.5.3-py2.7.egg/ducktape/tests/runner.py", line 162, in run_single_test
    return self.current_test_context.function(self.current_test)
  File "/var/lib/jenkins/workspace/system-test-kafka-0.10.1/kafka/tests/kafkatest/tests/client/consumer_test.py", line 113, in test_broker_rolling_bounce
    "Total consumed records did not match consumed position"
AssertionError: Total consumed records did not match consumed position
{code}

[~ewencp] I've looked into the two instances of the "Timed out waiting for consumption" test failures from the past week: one on 0.10.2, and one on (trunk) http://testing.confluent.io/confluent-kafka-system-test-results/?prefix=2017-01-25--001.1485335861--apache--trunk--abe19fe/. In both of these cases, the problem appears to be on the producer side. Before the timeout occurs, I see a long delay during which the consumer continues fetching, but during which the high watermark never advances. Unfortunately there are few logs from the producer to tell what is going on, but one possibility is that we're hitting the request timeout, which is 30s by default. This corresponds closely with the duration of the delay. The consumer times out after 20s of inactivity, so we probably just need to make these two timeouts consistent. I'll submit a patch, but it doesn't seem worth blocking the release for it.

[~ijuma] Can you link me to the test results for that failure?

[~hachikuji], https://jenkins.confluent.io/job/system-test-kafka-0.10.1/138/console and http://confluent-kafka-0-10-1-system-test-results.s3-us-west-2.amazonaws.com/2017-01-28--001.1485603818--apache--0.10.1--6ba7470/report.html

[~hachikuji] I kicked off https://jenkins.confluent.io/job/system-test-kafka-branch-builder/693/console to try to test this repeatedly for failure with --repeat 10 to see if the original failure would repeat. Didn't reproduce, so hard to say why we may be seeing this more frequently in the nightlies.

Shall we remove this as a blocker for 0.10.2.0? Not ideal to have a transiently failing test, but it sounds like it's partly the test just being flaky, not necessarily incorrectness.

[~ewencp] Yes, let's remove it from the blockers. The test case Ismael linked to from 0.10.1 is a little more troubling (there is an unexplained pause during shutdown of one of the consumers), but until we know more, I don't think it should block the release. I'll continue investigating.

Note I created KAFKA-4719 for the Timeout error we have seen a couple times. I think this is just a case of timeout adjustment.

This happened again in the system test run of 02/02/2017:

{noformat}

[INFO  - 2017-02-02 04:58:49,171 - runner_client - log - lineno:221]: RunnerClient: kafkatest.tests.client.consumer_test.OffsetValidationTest.test_consumer_bounce.clean_shutdown=False.bounce_mode=rolling: Summary: Current position greater than the total number of consumed records
Traceback (most recent call last):
  File "/var/lib/jenkins/workspace/system-test-kafka/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.6.0-py2.7.egg/ducktape/tests/runner_client.py", line 123, in run
    data = self.run_test()
  File "/var/lib/jenkins/workspace/system-test-kafka/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.6.0-py2.7.egg/ducktape/tests/runner_client.py", line 176, in run_test
    return self.test_context.function(self.test)
  File "/var/lib/jenkins/workspace/system-test-kafka/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.6.0-py2.7.egg/ducktape/mark/_mark.py", line 321, in wrapper
    return functools.partial(f, *args, **kwargs)(*w_args, **w_kwargs)
  File "/var/lib/jenkins/workspace/system-test-kafka/kafka/tests/kafkatest/tests/client/consumer_test.py", line 158, in test_consumer_bounce
    "Current position greater than the total number of consumed records"
AssertionError: Current position greater than the total number of consumed records

[INFO  - 2017-02-02 04:58:49,172 - runner_client - log - lineno:221]: RunnerClient: kafkatest.tests.client.consumer_test.OffsetValidationTest.test_consumer_bounce.clean_shutdown=False.bounce_mode=rolling: Data: None
{noformat}

Logs for this run are at http://confluent-kafka-system-test-results.s3-us-west-2.amazonaws.com/2017-02-02--001.1486027182--apache--trunk--3d9f34d/OffsetValidationTest/test_consumer_bounce/clean_shutdown=False.bounce_mode=rolling/46.tgz

This happened again last night. Logs are at: http://confluent-kafka-0-10-2-system-test-results.s3-us-west-2.amazonaws.com/2017-03-09--001.1489054973--apache--0.10.2--a05c541/OffsetValidationTest/test_consumer_bounce/clean_shutdown=False.bounce_mode=rolling/49.tgz

{noformat}
Current position 80172 greater than the total number of consumed records 80169
Traceback (most recent call last):
  File "/var/lib/jenkins/workspace/system-test-kafka-0.10.2/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.6.0-py2.7.egg/ducktape/tests/runner_client.py", line 123, in run
    data = self.run_test()
  File "/var/lib/jenkins/workspace/system-test-kafka-0.10.2/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.6.0-py2.7.egg/ducktape/tests/runner_client.py", line 176, in run_test
    return self.test_context.function(self.test)
  File "/var/lib/jenkins/workspace/system-test-kafka-0.10.2/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.6.0-py2.7.egg/ducktape/mark/_mark.py", line 321, in wrapper
    return functools.partial(f, *args, **kwargs)(*w_args, **w_kwargs)
  File "/var/lib/jenkins/workspace/system-test-kafka-0.10.2/kafka/tests/kafkatest/tests/client/consumer_test.py", line 159, in test_consumer_bounce
    (consumer.current_position(partition), consumer.total_consumed())
AssertionError: Current position 80172 greater than the total number of consumed records 80169
{noformat}

Happened again. Logs here http://confluent-kafka-0-10-2-system-test-results.s3-us-west-2.amazonaws.com/2017-03-28--001.1490697484--apache--0.10.2--1e4cab7/OffsetValidationTest/test_consumer_bounce/clean_shutdown%3DFalse.bounce_mode%3Drolling/49.tgz

<pre>
test_id:    kafkatest.tests.client.consumer_test.OffsetValidationTest.test_consumer_bounce.clean_shutdown=False.bounce_mode=rolling
status:     FAIL
run time:   3 minutes 32.756 seconds


    Current position 79302 greater than the total number of consumed records 79299
Traceback (most recent call last):
  File "/var/lib/jenkins/workspace/system-test-kafka-0.10.2/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.6.0-py2.7.egg/ducktape/tests/runner_client.py", line 123, in run
    data = self.run_test()
  File "/var/lib/jenkins/workspace/system-test-kafka-0.10.2/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.6.0-py2.7.egg/ducktape/tests/runner_client.py", line 176, in run_test
    return self.test_context.function(self.test)
  File "/var/lib/jenkins/workspace/system-test-kafka-0.10.2/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.6.0-py2.7.egg/ducktape/mark/_mark.py", line 321, in wrapper
    return functools.partial(f, *args, **kwargs)(*w_args, **w_kwargs)
  File "/var/lib/jenkins/workspace/system-test-kafka-0.10.2/kafka/tests/kafkatest/tests/client/consumer_test.py", line 159, in test_consumer_bounce
    (consumer.current_position(partition), consumer.total_consumed())
AssertionError: Current position 79302 greater than the total number of consumed records 79299
</pre>

I think I finally see what is happening here. I looked at this test case: http://confluent-systest.s3-website-us-west-2.amazonaws.com/confluent-kafka-0-10-2-system-test-results/?prefix=2017-03-30--001.1490888066--apache--0.10.2--2397269/. 

Here is the assertion error:
{code}
AssertionError: Current position 30897 greater than the total number of consumed records 30892
{code}

We are missing 5 records apparently. Looking in the test logs, I found this warning:
{code}
[WARNING - 2017-03-30 11:01:19,615 - verifiable_consumer - _update_global_position - lineno:222]: Expected next consumed offset of 20037 for partition TopicPartition(topic=u'test_topic', partition=0), but instead saw 20042
{code}

This suggests a gap in the consumed data. However, in the event output, we see clearly that these offsets were consumed:
{code}
{"timestamp":1490871669110,"count":5,"name":"records_consumed","partitions":[{"topic":"test_topic","partition":0,"count":5,"minOffset":20037,"maxOffset":20041}]}
{code}

And from the consumer log, we can see the offset is committed, though we do not see the offset commit in the event output:
{code}
[2017-03-30 11:01:09,110] TRACE Sending OffsetCommit request with {test_topic-0=OffsetAndMetadata{offset=20042, metadata=''}} to coordinator worker9:9092 (id: 2147483646 rack: null) for group test_group_id (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
{code}

We can conclude that both the "records_consumed" event and the "offsets_committed" event were not delivered to the test framework prior to the hard failure. In general, it seems difficult to write reliable hard failure test cases which depends on event output from the process experiencing the hard failure. There is always a delay between the occurrence of the event and its emission and delivery. We probably need to weaken the test assertions to deal with the possibility of having missed events, but it's possible that the test is longer be useful if we do so. For the time being, I think we should disable the hard failure scenarios.

GitHub user hachikuji opened a pull request:

    https://github.com/apache/kafka/pull/2771

    KAFKA-4689: Disable system tests for consumer hard failures

    See the JIRA for the full details. Essentially the test assertions depend on receiving reliable events from the consumer processes, but this is not generally possible in the presence of a hard failure (i.e. `kill -9`). Until we solve this problem, the hard failure scenarios will be turned off.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hachikuji/kafka KAFKA-4689

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/2771.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #2771
    
----
commit 55380bf623f2a5be489818fc5979d77fd7570047
Author: Jason Gustafson <jason@confluent.io>
Date:   2017-03-30T18:15:01Z

    KAFKA-4689: Disable system tests for consumer hard failures

----


Issue resolved by pull request 2771
[https://github.com/apache/kafka/pull/2771]

Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/2771


This is such a critical test, I understand why it's hard to guarantee the offsets though. Any chance we could turn it back on when exactly once lands?

[~enothereska], we filed a new issue for re-enabling. As [~hachikuji] said, the issue is in the test framework, so not sure that exactly once would help.

