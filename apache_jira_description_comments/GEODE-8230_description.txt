currently, we run Build, then all <x>Test jobs in parallel (which takes ~5 hours), then all Benchmark<x> jobs (which takes ~5 hours).

Presumably the benchmarks were run after all tests, on the premise that benchmarks are meaningless if the code is not correct. Â However, required PR checks now prevent incorrect code from getting into develop in the first place, and the remaining occasional failures are flaky, so it's rather arbitrary to gate benchmarks on a lottery.

However, faster feedback has clear benefits, and cutting our CI pipeline from 10 hours to 5 hours seems like low-hanging fruit.