[~mck] This is the POC I came up with. I tested it on a local jenkins and I can see it being effective:

{noformat}
16:56:29 forceDeviceListenAddress:
16:56:29      [exec] docker0: flags=4099<UP,BROADCAST,MULTICAST>  mtu 1500
16:56:29      [exec]         inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255
16:56:29      [exec]         inet6 fe80::42:26ff:fe25:c1e2  prefixlen 64  scopeid 0x20<link>
16:56:29      [exec]         ether 02:42:26:25:c1:e2  txqueuelen 0  (Ethernet)
16:56:29      [exec]         RX packets 78645  bytes 5621831 (5.6 MB)
16:56:29      [exec]         RX errors 0  dropped 0  overruns 0  frame 0
16:56:29      [exec]         TX packets 85630  bytes 1329098560 (1.3 GB)
16:56:29      [exec]         TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
16:56:29      [exec] 
16:56:29      [exec] lo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536
16:56:29      [exec]         inet 127.0.0.1  netmask 255.0.0.0
16:56:29      [exec]         inet6 ::1  prefixlen 128  scopeid 0x10<host>
16:56:29      [exec]         loop  txqueuelen 1000  (Local Loopback)
16:56:29      [exec]         RX packets 66296  bytes 21093416 (21.0 MB)
16:56:29      [exec]         RX errors 0  dropped 0  overruns 0  frame 0
16:56:29      [exec]         TX packets 66296  bytes 21093416 (21.0 MB)
16:56:29      [exec]         TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
16:56:29      [exec] 
16:56:29      [exec] wlp59s0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
16:56:29      [exec]         inet 192.168.1.131  netmask 255.255.255.0  broadcast 192.168.1.255
16:56:29      [exec]         inet6 fe80::9c8e:fcad:d881:ffda  prefixlen 64  scopeid 0x20<link>
16:56:29      [exec]         ether 18:1d:ea:b1:51:48  txqueuelen 1000  (Ethernet)
16:56:29      [exec]         RX packets 6031123  bytes 7766582727 (7.7 GB)
16:56:29      [exec]         RX errors 0  dropped 0  overruns 0  frame 0
16:56:29      [exec]         TX packets 2398356  bytes 1840272042 (1.8 GB)
16:56:29      [exec]         TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
16:56:29      [exec] 
16:56:29      [echo] ******************* 192.168.1.131
{noformat}

You'll notice that a device is being force upon calling {{ifconfig}}. This is bc many ips can match the regexp. On AWS the private ip is on eth0. So I'd suggest this course of action:
- Take a look at what I did and see if it makes sense at all
- If it does we'd need to run it against {{eth0}} on all agents and see we indeed get what we expect and tests run ok

wdyt?


Quick interjection while i keep looking… 

bq. If it does we'd need to run it against eth0 on all agents and see we indeed get what we expect and tests run ok

Not all the agents are AWS. Some are virtuals on-premise (e.g. iland). In fact I only know for certain that the Amazon agents are AWS  :shrug:



Back references:
- example failure stacktrace on [ci-cassandra.a.o|https://ci-cassandra.apache.org/job/Cassandra-trunk/150/testReport/(root)/_init_/org_apache_cassandra_locator_ReplicaCollectionTest/]
- dev ML [post|https://lists.apache.org/thread.html/r1a7bc49b0648ec3b4ab9245dc101dc7dfbec51048f83c7128e3989eb%40%3Cdev.cassandra.apache.org%3E] asking for help

After discussion with [~mck] it seems the underlying root cause is that some tests don't init the daemon. Hence the config/listen_address are never loaded and effective. We came up with the following course of action:
 * Make all ci-cass agents fail consistently, so any new tests will get reported.
 * Fix all current tests to init the daemon correctly
 * Once ci-cass is in good shape we can link the report for the commit into the Jira ticket
 * Explore ways to make that fail locally so you get the failure pre-push rather than post-commit/ci-cass run

[~mck] CI [runs|https://app.circleci.com/pipelines/github/bereng/cassandra/51/workflows/e5aeb0d3-9bc6-43d1-a45c-8c6f6c3412b1] seem ok & tests pass locally as well, besides the OOM but circle was on a partial outage today... Do you think you could run the PR against cassandra13 and see if the issue has been sorted?

bq. Do you think you could run the PR against cassandra13 and see if the issue has been sorted?

Running at https://ci-cassandra.apache.org/job/Cassandra-devbranch-test/153/

Mmmm they seem to failing already but let it run to get an updated list of failing tests. I'll start digging...

Ok the ones failing on the hostname resolution have gone down from 20-ish to 3 and they look like snowflakes: unsing reflection and other non-std stuff. I'll fix those tomorrow but looks like we're on track.

The latest run with the latest commit looks ok imo:
 * [CI j11|https://app.circleci.com/pipelines/github/bereng/cassandra/52/workflows/573ad5be-e34d-4668-a0af-2726d4b35568] Failure seems unrelated and passes locally
 * [CI j8|https://app.circleci.com/pipelines/github/bereng/cassandra/52/workflows/16e15155-7dce-4877-86f5-315c6a837d36] Seems to be a new flaky test but unrelated to the PR imo. It passes when ran locally but failed once locally on {{ant test}}
 * The [latest|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch-test/156/] ci-cassandra run looks much better but:
 ** ActiveRepairServiceTest could be a [legit|https://ci-cassandra.apache.org/job/Cassandra-trunk/199/testReport/org.apache.cassandra.service/ActiveRepairServiceTest/testQueueWhenPoolFullStrategy_cdc/history/] flaky
 ** ClearSpanshotTest passes locally and it failed with some weird VM error :shrug:
 ** Connection tests have given timeouts [before|https://ci-cassandra.apache.org/job/Cassandra-trunk/199/testReport/org.apache.cassandra.net/ConnectionTest/testMessageDeliveryOnReconnect_cdc/history/]

It would be good to have a second opinion here. But I think the failures we are hitting are legit flaky tests now that we've removed much of the noise. [~mck] would you be so kind to run the tests again but not on cassandra13 to see what happens? I think we can then move this to review if no weird stuff happens. Wdyt?

Agreed!
New run [here|https://ci-cassandra.apache.org/job/Cassandra-devbranch-test/157/] (on cassandra35)

The new run is successful. So I am starting to think that cassandra13 should have been named cassandra12+1 instead as things tend to go wrong over there lol. Anyway this is removing lots of noise from test reports so I am moving it forward to review. We need another committer besides you [~mck] to +1 it. Sounds good?

I'm not sure whether adding {{DatabaseDescriptor.daemonInitialization()}} to the tests is the right way here. Those tests do not need the daemon at all and adding these DD.daemonInit() makes those tests slower. The change to {{DatabaseDescriptorRefTest}} can actually break that test itself. The {{SSTable*Test.java}} tests test offline tools, so DD.daemonInit() feels wrong here.

[~snazy] Thanks for taking a look here! I replaced all daemon inits with a plain address load call and checked it still works locally. The {{SStable*Test}}s weren't using DD.daemonInit() but toolinit(). Still I have replaced those with plain address loads as well to avoid any other heavyweight lifting as you pointed out. Hope it looks better now?

Hm - maybe it's easier to change {{org.apache.cassandra.utils.FBUtilities#getJustLocalAddress}} and add a try-catch(UnknownHostException) around the {{InetAddress.getLocalHost()}} (_"Returns the address of the local host. This is achieved by retrieving the name of the host from the system, then resolving that name into an {{InetAddress}}."_) and use {{InetAddress.getLoopbackAddress()}} when that's thrown (to avoid a change of the current behavior). Guess, this affects all branches (and all other uses of {{InetAddress.getLocalHost()}}).

If I am following you correctly you're proposing returning {{InetAddress.getLoopbackAddress()}} when {{listen_address}} is null and not resolvable:
 * The original problem we are facing imo is that the specified {{listen_address}} in the yaml is not being loaded, hence is not effective and using a default fallback. I would argue here you want the {{listen_address}} you have in the test yaml to be effective rather than being resilient to a default fallback node mis-config? In fact it's actually good we found out we were not honoring the test yaml.
 * I played a bit on DD to try to load the address config sooner looking for alternatives, as you did, to the wall of test fixes. But some access the method well before the {{listen_address}} is loaded. So that didn't work.
 * On your proposed fix it sounds great but maybe orthogonal (iiuc). Also would we prefer to fail if we can't resolve the machine name?  I read a bit about {{{{getLoopbackAddress}}}} and you might have some ipv4 vs ipv6 lo address being returned apparently :thinking:...

So TLDR: we need to make the yaml effective, I wasn't able to find a smarter alternative & your proposal could be a new ticket instead. Wdyt makes sense?

bq.  I would argue here you want the listen_address you have in the test yaml to be effective rather than being resilient to a default fallback node mis-config? In fact it's actually good we found out we were not honoring the test yaml.

I agree with this. The test yaml needs to honoured. And it would be nice to solve this ticket without touching runtime code.
Finding a lighter way to just load the yaml makes sense.

Well, the most unintrusive way would be to add the hostname to the 127.0.0.1 (or even better the host's public IP) entry in /etc/hosts.

Mosts tests in question (e.g. the {{ReplicaCollectionTest}} or {{SEPExecutorTest}}) do not need a c-yaml at all (and didn't need it before), because those are "pure" unit tests (i.e. don't need a daemon or any configuration). Other tests (like the {{DatabaseDescriptorRefTest}}) are "allergic" to touching classes before the actual test. The next guy who comes along these tests, likely thinks that the DD call is unnecessary and removes it, because the test passes locally and e.g. in CircleCI.

The change to {{DatabaseDescriptorRefTest}} actually causes the test to not fully exercise the DD-init code being tested (and "silently pass" although it didn't test the whole init code or, if new changes get in, fail because some expectations aren't met). TL;DR it breaks that test.

The implemented default for {{broadcast_address}} (defaulting to {{listen_address}}, which in turn defaults to {{InetAddress.getLocalHost()}}), is correct (the yaml says: _"{{Leaving it blank leaves it up to InetAddress.getLocalHost(). This will always do the Right Thing *if the node is properly configured (hostname, name resolution, etc)*, and the Right Thing is to use the address associated with the hostname (it might not be).}}"_). I admit, it might be wrong to add a fallback to {{InetAddress.getLoopbackAddress()}}.

TL;DR I think it's much safer to fix the test environment (and not work around test environment issues by changing any existing code).

Side note (feel free to ignore this): I do think that using {{InetAddress.getLocalHost()}} is a mistake in general. It seems that (in practice) there is no guarantee that it {{IA.getLocalHost()}} deterministically return the same address - think: DHCP changes, interfaces going up or down, hostnames that resolve to multiple IPs, etc etc.

[~snazy] thx for the input.

{{toolInit}} isn't expected to have a loaded address config so the default behavior is what's expected. So adding an address load either from scratch or before the {{toolInit}} is wrong. Icwym.

On the other hand as discussed in CASSANDRA-15622 there can be problems on test C* nodes listening on public ips /ports and ASF regulations I am not aware of as mentioned there. Given this is a source of false failures on ci-cass jenkins runs atm, maybe the best way forward is to fix the config in cassandra-13. Then open a ticket to put the full ci-cassandra jenkins master/slave things under a more secured env compliant to whatever ASF and other regulations there might be.

What do you guys think? [~mck] is that even possible or am I talking nonsense?

bq. Well, the most unintrusive way would be to add the hostname to the 127.0.0.1 (or even better the host's public IP) entry in /etc/hosts.

These tests have also failed in the previous jenkins environment at builds.apache.org (long before circleci was introduced).

The jenkins agents  require public ip and a valid hostname. So there is a valid reason that these nodes are "not properly configured" (according to our definition for a runtime node). 

And, we don't have ssh access. So this may be un-intrusive to code changes, but involves either waiting a few weeks or months for the owner of the donated agents to re-configure them (to incorrectly let tests listen on public interfaces), or containerising all tests (bc inside containers hostname can always safely be the private interface, like circleci).

bq. … those are "pure" unit tests (i.e. don't need a daemon or any configuration)

I'm not sure I agree entirely with that statement. But those quotes imply you don't either. These unit tests are not really configuration free, the fault lies in the fact that the tests are looking up the configuration, and those that haven't defined the config then fall back onto an opinion that is incompatible with the "jenkins agents around the world but unlike normal C* don't listen on the public interface because this is tests" setup. A pure unit test shouldn't be resorting to either an opinion or an OS hostname lookup. A hardcoded default config would be more appropriate, in theory. But alas the C* is a bit too messy for the ideal :-(

Thanks for pushing back [~snazy].

So it seems after all the back and forth and given the current restrictions mainly:
 * Not providing a synthetic address load which the test actually doesn't need
 * Avoiding failing on mis-config nodes

Adding a 3rd fallback seems reasonable enough, moving from failing scenarios to a 'localhost' listen in a major release. Both {{getLocalHost()}} and {{getLoopbackAddress()}} may fail under some OS/ip configs so we're not anyway worse than we used to be.

The change has been pushed. It's undergoing review and an initial test run [fired|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch-test/161/]. Iirc at least the JMXAuth test is a legit failure I need to look into. Once that's done I'll run a full test suite as this is touching C* code: dtests, unit tests, jvm, etc...

 

[~snazy] I did accept your commits but for a single one on wording. Please take a look at it and the {{JMXAuthTest}} failure, which is a hostname resolution error in some library. Wdyt?

[~mck] could you be so kind to fire a run against cassandra13 please :-)?

I am running a full CI on circle as well. If all goes well that should be it.

Just the unit tests (on cassandra13) at https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch-test/165
Full devbranch pipeline (now that we're touching runtime code) at https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/196/

[~mck] the full pipeline failed on dtest [replica_side_filtering_test|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/196/testReport/] which passes locally and passes on circle-ci. Is there a chance to re-run that? I know this is an extra day of waiting before commit, but it'll be better than merging sthg broken, despite I have the intuition this is probably a legit flaky.

Committed as [4654ef09c1d3736e0b50e8d5756664cbf9e4ca84 |https://github.com/apache/cassandra/commit/4654ef09c1d3736e0b50e8d5756664cbf9e4ca84].

bq.  the full pipeline failed on dtest replica_side_filtering_test which passes locally and passes on circle-ci. Is there a chance to re-run that? 

this was a first-time-witnessed bug where the Jenkins pipeline copied the test report artefact from the wrong build. investigating this separately. 

Ok after some investigation [~mck] discovered the final jenkins report is collecting results from other runs! If you check the stages one by one and make sure commit id matches we see none of those failures. This is jenkins being broken.

