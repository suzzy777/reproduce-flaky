{noformat}
2019-05-26 17:10:31,195 ERROR [master/asf906:0:becomeActiveMaster] helpers.MarkerIgnoringBase(159): Failed to become active master
org.apache.hadoop.hbase.client.RetriesExhaustedException: Cannot get the location for replica0 of region for  in hbase:meta
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:335)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:153)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:58)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithoutRetries(RpcRetryingCallerImpl.java:192)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:263)
	at org.apache.hadoop.hbase.client.ClientScanner.loadCache(ClientScanner.java:405)
	at org.apache.hadoop.hbase.client.ClientScanner.nextWithSyncCache(ClientScanner.java:285)
	at org.apache.hadoop.hbase.client.ClientScanner.next(ClientScanner.java:564)
	at org.apache.hadoop.hbase.MetaTableAccessor.scanMeta(MetaTableAccessor.java:766)
	at org.apache.hadoop.hbase.MetaTableAccessor.scanMeta(MetaTableAccessor.java:734)
	at org.apache.hadoop.hbase.MetaTableAccessor.scanMeta(MetaTableAccessor.java:690)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScanRegions(MetaTableAccessor.java:220)
	at org.apache.hadoop.hbase.master.assignment.RegionStateStore.visitMeta(RegionStateStore.java:77)
	at org.apache.hadoop.hbase.master.assignment.AssignmentManager.loadMeta(AssignmentManager.java:1294)
	at org.apache.hadoop.hbase.master.assignment.AssignmentManager.joinCluster(AssignmentManager.java:1255)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:1100)
	at org.apache.hadoop.hbase.master.HMaster.startActiveMasterManager(HMaster.java:2375)
	at org.apache.hadoop.hbase.master.HMaster.lambda$run$0(HMaster.java:605)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Meta region is in state OPENING
	at org.apache.hadoop.hbase.client.ZKAsyncRegistry.lambda$getMetaRegionLocation$1(ZKAsyncRegistry.java:162)
	at org.apache.hadoop.hbase.util.FutureUtils.lambda$addListener$0(FutureUtils.java:70)
	at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760)
	at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
	at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1962)
	at org.apache.hadoop.hbase.client.ZKAsyncRegistry.lambda$getAndConvert$0(ZKAsyncRegistry.java:81)
	at org.apache.hadoop.hbase.util.FutureUtils.lambda$addListener$0(FutureUtils.java:70)
	at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760)
	at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
	at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1962)
	at org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$ZKTask$1.exec(ReadOnlyZKClient.java:174)
	at org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient.run(ReadOnlyZKClient.java:342)
	... 1 more
{noformat}

Seems something wrong when restarting the whole cluster. For these tests, I think a possible solution, is to only shutdown all the region servers, not the whole cluster. And we can open a new issue to addressing the above problem.

Pushed to master and branch-2.

Thanks [~zghaobac] for reviewing.

Results for branch master
	[build #1065 on builds.a.o|https://builds.apache.org/job/HBase%20Nightly/job/master/1065/]: (x) *{color:red}-1 overall{color}*
----
details (if available):

(/) {color:green}+1 general checks{color}
-- For more information [see general report|https://builds.apache.org/job/HBase%20Nightly/job/master/1065//General_Nightly_Build_Report/]




(/) {color:green}+1 jdk8 hadoop2 checks{color}
-- For more information [see jdk8 (hadoop2) report|https://builds.apache.org/job/HBase%20Nightly/job/master/1065//JDK8_Nightly_Build_Report_(Hadoop2)/]


(x) {color:red}-1 jdk8 hadoop3 checks{color}
-- For more information [see jdk8 (hadoop3) report|https://builds.apache.org/job/HBase%20Nightly/job/master/1065//JDK8_Nightly_Build_Report_(Hadoop3)/]


(/) {color:green}+1 source release artifact{color}
-- See build output for details.


(x) {color:red}-1 client integration test{color}
--Failed when running client tests on top of Hadoop 3. [see log for details|https://builds.apache.org/job/HBase%20Nightly/job/master/1065//artifact/output-integration/hadoop-3.log]. (note that this means we didn't check the Hadoop 3 shaded client)


Results for branch branch-2
	[build #1941 on builds.a.o|https://builds.apache.org/job/HBase%20Nightly/job/branch-2/1941/]: (x) *{color:red}-1 overall{color}*
----
details (if available):

(/) {color:green}+1 general checks{color}
-- For more information [see general report|https://builds.apache.org/job/HBase%20Nightly/job/branch-2/1941//General_Nightly_Build_Report/]




(/) {color:green}+1 jdk8 hadoop2 checks{color}
-- For more information [see jdk8 (hadoop2) report|https://builds.apache.org/job/HBase%20Nightly/job/branch-2/1941//JDK8_Nightly_Build_Report_(Hadoop2)/]


(x) {color:red}-1 jdk8 hadoop3 checks{color}
-- For more information [see jdk8 (hadoop3) report|https://builds.apache.org/job/HBase%20Nightly/job/branch-2/1941//JDK8_Nightly_Build_Report_(Hadoop3)/]


(/) {color:green}+1 source release artifact{color}
-- See build output for details.


(x) {color:red}-1 client integration test{color}
--Failed when running client tests on top of Hadoop 3. [see log for details|https://builds.apache.org/job/HBase%20Nightly/job/branch-2/1941//artifact/output-integration/hadoop-3.log]. (note that this means we didn't check the Hadoop 3 shaded client)


[~zhangduo] I've started running into this again. I was looking at your PR and you mentioned
{quote}The problem here is that we should only start one region server for the restarted cluster...
{quote}
What is the reason for this? Shouldn't it be the original number of region servers so that the recovered queues are evenly split at startup? Otherwise one region server gets all the recovered queues and there are asserts like the following.. (In testReplicationStatusSourceStartedTargetStoppedNewOp). These tests with sleeps are very racy.
{quote}testReplicationStatusSourceStartedTargetStoppedNewOp()
 ......
 ClusterMetrics metrics = hbaseAdmin.getClusterMetrics(EnumSet.of(Option.LIVE_SERVERS));
 List<ReplicationLoadSource> loadSources =
 metrics.getLiveServerMetrics().get(serverName).getReplicationLoadSourceList();
 assertEquals(1, loadSources.size());
{quote}

I think it is because the assertions. If we have multiple region servers then all the assertions should be rewritten.

