I think this is a great change.  sstables version number clash has always been an issue when backing up and restoring tables.  There was just a conversation the other day in the slack where a truncate of a table and then restart cause the sstables numbers to reset, which then messed up someone’s backups.

Without commenting on the patch overall, I have a preference not to proliferate new varieties of UUID-like concepts. We already have v1 time UUID, and v7 is in [draft|https://datatracker.ietf.org/doc/html/draft-peabody-dispatch-new-uuid-format#section-4.5] with the IETF. I think it would be preferable to either use v7 UUID, or to use v1 UUID but to serialise them to string so that they sort lexicographically (this is a pretty simple shuffle).

As part of CEP-14 I will be introducing a {{TimeUUID}} class to represent our v1 uses of UUID, that stores the data internally in its lexicographic order (this is intended primarily to ensure correctness, to avoid accidentally using the UUID format timestamp instead of unix), so it would be quite simple extend this and modify {{toString}} (and {{fromString}}). I would also be happy to extend this work to support v7 UUID as well, as these are probably superior.

I also anticipate that in the near future we will begin issuing nodes in the cluster a globally unique id, so that globally unique UUIDs may be issued without any probabilistic component, which should be strictly superior to ULID.

I assume this is already in use for supporting S3, but I think the aims of the patch can probably be achieved without necessarily adopting ULID within the Cassandra codebase?

Ah, this library you reference is also LGPL, so is anyway incompatible with the Apache 2.0 license.

https://www.apache.org/legal/resolved.html


Not a review, but a reminder: 

We removed windows support in trunk, but we've had issues with long paths in the past. Worth checking 
 CASSANDRA-6962 if we end up with a longer generation identifier. 

{quote}Ah, this library you reference is also LGPL, so is anyway incompatible with the Apache 2.0 license.
{quote}
It is dual licensed LGPL or ASLv2

[https://github.com/huxi/sulky/blob/master/sulky-ulid/src/main/java/de/huxhorn/sulky/ulid/ULID.java#L19-L33]

From [https://github.com/huxi/sulky]
{quote}sulky modules are licensed LGPLv3 & ASLv2.
{quote}
 

 

This patch is pretty flexible, it allows you to provide any generation ID factory, the changes make the usages agnostic to the format of the generation ID. Thus the only requirement is that it is sortable, generated in monotonic, growing order, and convertible to/from string and bytes. As such, switching to UUID v1 or v7 or whatever else is just a matter of providing another implementation. 

However:
- ULID has shorter default string representation (26 vs 36 characters) - obviously it is just the default representation and we can use represent UUID in the same form as both ids have 128 bits
- UUID v1 is not lexicographically sortable by default as you mentioned, so we would have to be forced to use a custom representation anyway
- AFAIK no UUID is guaranteed to generate monotonically growing identifiers when two are generated almost at the same time - this would probably never a problem in this context though

All in all, if we are forced wrap any UUID representation with some utilities to make its representation satisfy our needs, then I don't really know why not to use ULID as its implementation provides us everything we need



Thanks [~jjirsa] for pointing this out. IIUC that ticket, it was about the variable length of file names due to putting table name in it, where the table name can be lengthy. The ULID identifier indeed will make the name longer by around 20-25 characters but on the other hand its aim is to be globally unique - if there is a need for that, the table name could be hypothetically removed at all from the file name while keeping the file name globally unique.

bq. UUID v1 is not lexicographically sortable by default as you mentioned, so we would have to be forced to use a custom representation anyway

A custom parser only, which can delegate to {{Long.toString}} and {{Long.fromString}} for the same density of representation (i.e. base32, though a different form), so we're not talking about much effort here. We could implement Crockford's scheme also rather trivially.

bq. AFAIK no UUID is guaranteed to generate monotonically growing identifiers when two are generated almost at the same time - this would probably never a problem in this context though

We do guarantee this within Cassandra for all TimeUUID we generate, for reasons of correctness.

bq. All in all, if we are forced wrap any UUID representation with some utilities to make its representation satisfy our needs, then I don't really know why not to use ULID as its implementation provides us everything we need

Because having multiple ways of doing the same thing in the codebase leads to inconsistency and confusion, and unnecessarily bloats our dependencies. We should not introduce new ways of doing things that may be provided by _simple_ modifications to existing mechanisms. 

The only relevant difference as far as I can tell is the {{toString}} and {{fromString}} methods, which can be delegated to {{Long.toString}}. This also provides us greater flexibility: If the motive is shorter strings, we can make them even shorter for case sensitive file systems, where we could use base64 encoding, which would shrink the path to 16 chars (we might prefer to use a modified form that e.g. swaps / for , however), or a base60 encoding that has no special characters and would achieve 18 char lengths.

Additionally, if we want to reduce path sizes we can apply these improvements to our existing path specifications for directories that themselves use UUIDs, though this would obviously need to be handled with care.

Your points feel valid. I don't have strong preference for ULIDs over UUIDs so I can update PR. 

[~benedict] I've pushed a commit which replaces ULID with UUID v1 and use {{UUIDGen}} class.

I thing to note - we cannot use Base64 because it is not lexicographically sortable and it may not work well in non-case sensitive file systems. Thus I used {{Long.toString}} with radix 36, which gives 25 characters long ID

Thanks. 

bq. we cannot use Base64

We can use a custom Base64 that is lexicographic in ASCII (or alternatively lexicographic in the alphabet by interleaving lowercase and upper case):

{code}
for (int i=0;i<64;i+=8) {
  int ch = (v & 0xff);
  if (ch < 2) ch = ch == 0 ? '+' : '-';
  else if ((ch - = 2) < 10) ch = '0' + ch;
  else if ((ch -= 10) < 26) ch = 'A' + ch;
  else ch = 'a' + (ch - 26);
  builder.append((char)ch);
  v >>>= 8;
}
{code}

Or whatever your preferred encoding is.

That is, assuming short path strings is our goal! It would require some work to validate the file system is case insensitive, that might not be worth it.

Given the fact that many people develop on Mac OS, which often does not use a case sensitive file system, I think we should stay away from file names that require case sensitivity for uniqueness.

bq. I think we should stay away from file names that require case sensitivity for uniqueness

Even if all platforms we intend to run on support case sensitivity, I think it's a good idea to avoid any dependence on it, considering that this can also affect backups.

I'm also in favor of keeping it case-insensitive, thus we can use 36 symbols. It is not too bad, the id is 25 characters long in this case 25 vs 22 characters in case of 64 symbols, so we would just save 3 characters.


Sure, that works for me.

In future, when we have better globally unique TimeUUID, we can perhaps instead truncate the representation to the minimal unambiguous one.

I hope that in the future the path length will not be a problem for OSes any longer :D

I assumed in part this was for human legibility. The switch from integers to white noise isn't very operator friendly, but it's a tolerable cost for support for this deployment style.

If length was not a problem, we could encode UUID as human readable timestamp + that random part, which is constant each Cassandra run, that would be probably more operator friendly

I think human readable timestamps are actually pretty illegible when they are very long, which they probably would be here. But perhaps this would still be better. We could perhaps go for a human readable timestamp down to the seconds granularity, and base32/36 for the remainder? We could perhaps even decompose the date and intra-day timestamp, as this would make human parsing much easier.

If we do that we probably do not loose much, in particular, it would look like this:

{{xxxx_yyyy_zzzzzzzzzzzzzzzzz}}

where:

{{xxxx}} - 4 characters (base 36) denoting a day in the whole timestamp range
{{yyyy}} - 4 characters (base 36) denoting a second of a day (this is going to be useful part)
{{zzz...}} - 17 characters (base 36) denoting 100-ns + random

as you can see, we still have 25 characters total, and the only thing we need to add is two separators (underscores as dashes are forbidden)


That sounds good to me.

Done, 

one change from the previous comment - the last part is actually 18 chars long. I decided to encode nano part as separate 5 characters and random part as 13 characters for better readability - in this case the last 13 characters is not likely to change very often (just every restart of C* I suppose).

OTOH when nano and random are combined they take 17 characters but the whole part is different for every generated ID.

(y)

[~benedict] or [~jjirsa] - do any of you guys want to review the PR?


Hi Jacek,

I'd be willing to be a reviewer, but I'm not sure when time will become available for review as this patch isn't as trivial as it might first appear. So it depends how impatient you are for review.

I do have some initial comments though, regarding upgrades: 

* I would firstly prefer that we do not remove compatibility with upgrades from 3.0, at least as part of this patch. I think the project should expressly agree when we deprecate support for upgrades from a given version, and aim to be as permissive as possible while the maintenance burden is minimal.
* Relatedly, since we are aiming for a shippable trunk with live upgrades and patch compatibility (and for major users to be preferably deploying trunk into production as early as possible), the logical conclusion of this is support for live downgrades, i.e. ensuring incompatible changes like this do not prevent an operator from restarting the node with an earlier version of trunk. We have a goal of enabling this across major versions as well, to ensure smooth rollout of new versions of the software.

Both of these are items that have been touched upon in wider DISCUSS threads, but that I don't think we have a formal project-level policy on. Depending on your (and your colleague's) thoughts on this we might need to formulate such a policy before this patch is merged.

_Precisely_ how to do the second item when deprecating a system table is unclear, though there are a variety of options: 
# Provide some downgrade tool to migrate data back to the earlier table;
# Make the upgrade to a new system table user-initiated, so that nodes are easily downgradeable until this point; 
# Introduce a new {{SignedBytesType}} that is compatible with {{Int32Type}} and simply modify the schema of the existing table to use this type so that we do not need a new system table (and downgrade only becomes impossible when the new UUID format begins to be used)

Thoughts?

Basically I agree with you. Though, I don't understand the first point - the compatibility upgrades from 3.0 - what do you mean?

For mitigation options you mentioned, I think I like the option (1) the most. I don't know if we need to touch {{system}} keyspace during downgrading, the new table - {{sstable_activity_v2}} would just remain unused and the old stable {{sstable_activity}} would get repopulated. The tool would be super simple as it just needs to sort the sstables by generation ID and rename (perhaps snapshots as well). 

Option (2) feels tempting but without (1) it makes switching to the new scheme irreversible. Also it would introduce more complexity to the main code, while (1) keeps all the extra stuff needed for supporting downgrade in a separate tool.

I would not go for option (3) because of similar reasons the the mentioned above - extra complexity in the default path

For the patch complexity, git provides a bit misleading information that there is 100k+ changes - it is just because I added a new JMX dump. I'll rebase the PR and split it into reasonable chunks to make it more reviewer friendly.


bq. Though, I don't understand the first point - the compatibility upgrades from 3.0 - what do you mean?

It looks like you have deleted the code that upgrades system keyspace tables from 3.0 to 4.0 - perhaps this was unintentional?

bq. For the patch complexity
I'm not too worried about the LOC, more the implications of these changes to correctness for live upgrade and downgrade. Though whatever you can do to ease review burden would certainly be appreciated.

bq. I think I like the option (1) the most

I had been leaning towards a combination of (1) and (2), but it occurs to me there's an option (4): carry on writing to both system tables, even if we only read from one of them. This can be maintained for all SSTables that support the old generation. We can have a flag to disable the old system table so that downgrades become irrevocable, but I doubt this will be a significant burden. Or option (5): write the simple int generations to the old system table, and all new variants to the new system table, keeping both around indefinitely. 

With either of these options old versions can be started without any consideration to the new table - though this potentially introduces some complexity when we upgrade a _second_ time as we cannot decide if we populate based solely on the absence of the new system table. I think it makes sense to introduce a new system record: last booted version. This can be written at startup before touching other schema tables, so that the migration process to the new system table can be performed afresh each time, even if there was a temporary downgrade.

I think these approaches are probably much easier to implement, too. WDYT?

If we can agree that the upgrade is irrevocable after switching to the new scheme, then you are right, it is much easier to implement indeed. 

The question here from the usability pov - what is the default?

- if the default is to use the old scheme, we impose an additional operation for the typical path (just upgrade)
- if the default is to use the new scheme, it will be easy to miss switching that option and land in the place where downgrade is impossible

Implementing downgrader is far more complex that that though. We have to rename all the newly generated files, perhaps touch the snapshots which were created in the new version, perform modifications in system tables and eventually compact them.

The options without downgrader seem to be valid for other system tables as well. They do not seem to support downgrading though. 

TBH - I don't know which approach we should go for.

BTW. regarding 3.0 to 4.0 - I still cannot find the part which you meant - can you point it in the PR? I tried to just "rename" system keyspace migrator, but given to the amount of changes git decided to remove/add it. However, I just refactored the existing stuff (and added migration of sstable_activity). 


If we take option (5) I don't think we ever need a downgrader tool? Folk who begin using new sstable generation ids cannot downgrade past the point at which they enable the feature (which is probably fine, but also a downgrader for this would be a pretty easy tool to write in a pinch), but since all of the int generations continue to be written to the same system table there's essentially no effect for most users on upgrade?

bq. I tried to just "rename" system keyspace migrator, but given to the amount of changes git decided to remove/add it

Ah, that would explain it. I was just looking at the diff, not closely at the details just yet.

Yes, I know we do not need downgrader in that case - I just say that in case of 4 or 5 there is a risk to forget to make a switch, regardless which value is the default.


I've pushed downgrade support commit with the option to write to both tables. Please have a look if you have a moment.


Added a note to NEWS.txt and added JVM dtests to verify different scenarios when the node is restarted. From my pov the PR is ready to review


[~benedict] asked to add upgrade / downgrade verification but I need to wait until https://issues.apache.org/jira/browse/CASSANDRA-17050 is fixed to do that.


One problem I see is with the current patch is that the existing tests will not check the use of the new identifier but the use of the old one.
We also probably need to also check the transistion from the sequential one to the UUID one.


It seems that the patch breaks a bunch of tests: https://app.circleci.com/pipelines/github/adelapena/cassandra/1205/workflows/0358803c-a2a3-4335-a1d4-897f7cb77828

Here is a new round of CI for the last changes on the PR:
||PR||CI||
|[trunk|https://github.com/apache/cassandra/pull/1276]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1226/workflows/0ccfbbcd-08b0-4454-ba32-f3dc63b58f73] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/1226/workflows/517e03b4-466e-4270-b041-954fb736db93]​|
It seems that the patch is still breaking multiple tests.

||PR||CI||
|[trunk|https://github.com/apache/cassandra/pull/1276]|[j11 (!)|https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/173/workflows/e90fa232-9af4-4088-b12b-d3f7d71934e1/jobs/877]

The failure at {{testGetTemporaryFilesSafeAfterObsoletion}} is being addressed by CASSANDRA-17286, and the failure at {{test_atomic_writes}} has CASSANDRA-17289. As for the other dtest failures, the seem related to recent problems with Byteman scripts, and might have been fixed by CASSANDRA-17265. Here is a new CI round over the rebased patch, including j8's upgrade tests:
||Branch||CI||
|[trunk|https://github.com/adelapena/cassandra/tree/17048-trunk-review-rebase]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1275/workflows/e278b53d-09e5-430a-affd-416387c91007] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/1275/workflows/fb13e232-6021-4a19-b304-a51f004025b6]|

The last test fixes look good to me. Besides a couple of typos, my only remaining concern is that we are mixing terminology a bit by naming attributes and parameters of type {{SSTableId}} as {{{}generation{}}}, which might make the code a bit confusing, as it's mentioned [here|https://github.com/apache/cassandra/pull/1276#discussion_r768668771]. [~blerer] wdyt?

Thanks [~adelapena], and sorry for not responding - most of the last week I was on vacation. I've accepted your suggestions, squashed and rebased, though after rebasing I have quite bad looking test results: https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/177/workflows/7b6e1a32-fe40-4526-899f-4162a664e736


Thanks, I'll take a look at the changes.

CI is having some issues due to the recent changes on CASSANDRA-15234 and CCM retagging. The workaround is pointing to a dtest repo with [a patched CCM requirement|https://github.com/adelapena/cassandra-dtest/blob/b68cd7572f1114b5146b0841d85634e99791aa30/requirements.txt#L12]. I have run CI with this workaround, let's hope we have better luck this time:
||Branch||CI||
|[trunk|https://github.com/adelapena/cassandra/tree/17048-trunk-review]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1294/workflows/f26243ac-e63d-4e23-8aef-eee2cdc2d773] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/1294/workflows/401848c7-a492-4e21-b612-293786f9948a]|

The CircleCI config has been generated with:
{code:java}
.circleci/generate.sh -m \
  -e REPEATED_UTEST_TARGET=test-jvm-dtest-some \
  -e REPEATED_UTEST_COUNT=100 \
  -e REPEATED_UTEST_CLASS=org.apache.cassandra.distributed.test.SSTableIdGenerationTest \
  -e DTEST_REPO=https://github.com/adelapena/cassandra-dtest.git \
  -e DTEST_BRANCH=CASSANDRA-15234
{code}
Note that this includes some repeated runs for the new {{{}SSTableIdGenerationTest{}}}, since we have a history of flaky dtests.

[~adelapena] thank you for running those tests, are the results ok? Can this be merged?

Last changes look good to me, +1

One last CI run after squash+rebase:
||Commit||CI||
|[2c22d483d4e6bcb6da40f45b679a836707ef2762|https://github.com/adelapena/cassandra/commit/2c22d483d4e6bcb6da40f45b679a836707ef2762]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1409/workflows/3d3e26ec-c394-4a22-8597-efd7ad4016b9] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/1409/workflows/6125e0cb-e1c4-4864-9319-283a082eb400]|

Committed to {{trunk}} as [0040fea3797ea3e497691e9d1e2660711c60ac4d|https://github.com/apache/cassandra/commit/0040fea3797ea3e497691e9d1e2660711c60ac4d].

Thanks for the patch.

[~jlewandowski] [~blerer] Seems like this has made {{org.apache.cassandra.io.sstable.LegacySSTableTest.testStreamLegacyCqlTables}} flaky:

https://butler.cassandra.apache.org/#/ci/upstream/workflow/Cassandra-trunk/failure/org.apache.cassandra.io.sstable/LegacySSTableTest/testStreamLegacyCqlTables
https://ci-cassandra.apache.org/job/Cassandra-trunk/1039/testReport/org.apache.cassandra.io.sstable/LegacySSTableTest/testStreamLegacyCqlTables/

CircleCI shows a 4% flakiness:
https://app.circleci.com/pipelines/github/adelapena/cassandra/1421/workflows/916a4466-92e8-4115-b4e2-1a951722f409/jobs/14212

 

Created CASSANDRA-17482 for that test failure.

