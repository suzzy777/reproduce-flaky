One thing I've noticed from looking at more instances of this is that normally, we don't see any log lines from {{SharedState}} from the executor threads.  Normally we see this:

{noformat}
09:37:38.203 pool-1-thread-1-ScalaTest-running-ParquetQuerySuite INFO SharedState: Warehouse path is 'file:/Users/irashid/github/pub/spark/sql/core/spark-warehouse/'.
{noformat}

but in failures, we see

{noformat}
23:37:56.728 Executor task launch worker for task 48 INFO SharedState: Warehouse path is 'file:/home/jenkins/workspace/spark-branch-2.3-test-sbt-hadoop-2.6/sql/core/spark-warehouse'.
{noformat}

(notice the thread).  I don't understand why this happens yet.  Nor can I reproduce locally.

I think I understand what is happening here, but I don't know how to fix it.

Normally, there is no active spark session for the executor threads.  I added some debugging code to where an executor might call {{SQLConf.get}} to show the active session, and under my test runs, there isn't an active session:

{noformat}
12:49:35.801 dispatcher-event-loop-0 INFO Executor: Creating task runner thread with activeSession = None
...
getting conf, activeSession = None in Executor task launch worker for task 24
java.lang.Exception: getting conf in thread Executor task launch worker for task 23
        at org.apache.spark.sql.catalyst.plans.QueryPlan.conf(QueryPlan.scala:35)
        at org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.org$apache$spark$sql$execution$columnar$InMemoryTableScanExec$$createAndDecompressColumn(InMemoryTableScanExe
c.scala:84)
...
        at org.apache.spark.scheduler.Task.run(Task.scala:109)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
{noformat}

So how come sometimes its defined?  Note that activeSession is an *Inheritable* thread local.  Normally the executor threads are created before activeSession is defined, so they don't inherit anything.  But a threadpool is free to create more threads at any time.  And when they do, then suddenly the new executor threads will inherit the active session from their parent, a thread in the driver with the activeSession defined.

I'll submit a PR to defensively always clear the active session in the executor thread.

User 'squito' has created a pull request for this issue:
https://github.com/apache/spark/pull/21185

I believe this issue has existed since SPARK-10810 / https://github.com/apache/spark/commit/3390b400d04e40f767d8a51f1078fcccb4e64abd though originally the SQLContext is what was in the InheritableThreadLocal

After discussion in related PRs, SPARK-22938 should cover the main problem, and the PR for that will include the appropriate defensive checks preventing this in the future.

