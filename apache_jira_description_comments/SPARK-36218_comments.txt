cc [~maropu], [~cloud_fan], [~dongjoon] FYI.

Actually, I faced this issue in our internal repo a while ago, and just added a hacky fix by adding an explicit GC:

{code}
  if (tpcdsDataPath.nonEmpty) {
    tpcdsQueries
      .foreach { name =>
      val queryString = resourceToString(s"tpcds/$name.sql",
        classLoader = Thread.currentThread().getContextClassLoader)
      test(name) {
        + // SPARK-36218: workaround to prevent unexpected failure related to resource usage.
        + System.gc()
        val goldenFile = new File(s"$baseResourcePath/v1_4", s"$name.sql.out")
        runQuery(queryString, goldenFile)
      }
    }
    tpcdsQueriesV2_7_0
      .foreach { name =>
      val queryString = resourceToString(s"tpcds-v2.7.0/$name.sql",
        classLoader = Thread.currentThread().getContextClassLoader)
      test(s"$name-v2.7") {
        + // SPARK-36218: workaround to prevent unexpected failure related to resource usage.
        + System.gc()
        val goldenFile = new File(s"$baseResourcePath/v2_7", s"$name.sql.out")
        runQuery(queryString, goldenFile)
      }
    }
  } else {
    ignore("skipped because env `SPARK_TPCDS_DATA` is not set") {}
  }
}
{code}

Oh wait, let me take this back. TPC-DS became flaky now in our internal repo even with the fix ^.

Oh, thank you for sharing, [~hyukjin.kwon].

Sorry for my late work.., has anyone tried to makeÂ  `spark.driver.memory` larger, e.g.,, 1g? Spark might not have enough memory for running TPCDSQueryTestSuite. Anyway, I'll check this today.

Oh actually I think this is now fixed via SPARK-36270

Ah, okay. I got it now. Thanks.

