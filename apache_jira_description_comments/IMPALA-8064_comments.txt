Commit f8c3e4c0a44dbfa389c195c399e17a64d38a0824 in impala's branch refs/heads/master from Janaki Lahorani
[ https://git-wip-us.apache.org/repos/asf?p=impala.git;h=f8c3e4c ]

IMPALA-8064: Fix intermittent test failures from test_min_max_filters

test_min_max_filters and test_decimal_min_max_filters records the aggregated probe rows to
check whether min-max filter was exercised.  In the case of ASAN builds, the probe side
started processing before the filters reached the probe side, because ASAN builds are a
little slower.  The resolution is to increase RUNTIME_FILTER_WAIT_TIME_MS to accommodate ASAN.

This issue was also seen earlier on a runtime filter tests and fixed through IMPALA-6201.  This
fix mimics the same, by setting RUNTIME_FILTER_WAIT_TIME_MS to $RUNTIME_FILTER_WAIT_TIME_MS.

Change-Id: I111ed15947bd2812753ae68d3bbb8a9871e25b08
Reviewed-on: http://gerrit.cloudera.org:8080/12224
Reviewed-by: Tim Armstrong <tarmstrong@cloudera.com>
Tested-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>


[~janulatha] This is still happening on master in a downstream ASAN build+test. I confirmed it was at a Git hash that had the fix above and of course the correct {{RUNTIME_FILTER_WAIT_TIME_MS}} is evident.

{noformat}
query_test/test_runtime_filters.py:114: in test_min_max_filters
    test_file_vars={'$RUNTIME_FILTER_WAIT_TIME_MS': str(WAIT_TIME_MS)})
common/impala_test_suite.py:518: in run_test_case
    update_section=pytest.config.option.update_results)
common/test_result_verifier.py:612: in verify_runtime_profile
    % (function, field, expected_value, actual_value, actual))
E   AssertionError: Aggregation of SUM over ProbeRows did not match expected results.
E   EXPECTED VALUE:
E   643
E
E   ACTUAL VALUE:
E   661
E
{noformat}

The query in question:
{noformat}
USE functional_kudu;
SET RUNTIME_FILTER_WAIT_TIME_MS=100000;
select STRAIGHT_JOIN count(*) from decimal_rtf_tbl a
join [BROADCAST] decimal_rtf_tiny_tbl b
where a.d38_38 = b.d38_38 and b.d38_38 != 0;
{noformat}

Snippets from the profile which I'll upload in full show that 2/3 scan nodes did not receive the runtime filter in time.
{noformat}
      Instance 2b4a14d9933eb108:7565b86500000006 (host=downstream-jenkins-host:22001):(Total: 1m47s, non-child: 3.999ms, % non-child: 0.00%)
        HASH_JOIN_NODE (id=2):(Total: 172.996ms, non-child: 9.999ms, % non-child: 5.78%)
            Runtime filters: 1 of 1 Runtime Filter Published
        KUDU_SCAN_NODE (id=0):(Total: 162.996ms, non-child: 162.996ms, % non-child: 100.00%)
          Runtime filters: All filters arrived. Waited 0
      Instance 2b4a14d9933eb108:7565b86500000004 (host=downstream-jenkins-host:22000):(Total: 1m42s, non-child: 0.000ns, % non-child: 0.00%)
        HASH_JOIN_NODE (id=2):(Total: 13s819ms, non-child: 25.999ms, % non-child: 0.10%)
            Runtime filters: 1 of 1 Runtime Filter Published
        KUDU_SCAN_NODE (id=0):(Total: 11s359ms, non-child: 11s359ms, % non-child: 100.00%)
          Runtime filters: Not all filters arrived (arrived: [], missing [1]), waited for 11s337ms
      Instance 2b4a14d9933eb108:7565b86500000005 (host=downstream-jenkins-host:22002):(Total: 1m42s, non-child: 0.000ns, % non-child: 0.00%)
        HASH_JOIN_NODE (id=2):(Total: 39s251ms, non-child: 6.999ms, % non-child: 0.01%)
            Runtime filters: 1 of 1 Runtime Filter Published
        KUDU_SCAN_NODE (id=0):(Total: 36s812ms, non-child: 36s812ms, % non-child: 100.00%)
          Runtime filters: Not all filters arrived (arrived: [], missing [1]), waited for 36s768ms
{noformat}

Profile for above uploaded as {{profile.txt}}.

Something curious here as someone who doesn't know all the intricacies of profiles: If I'm setting RUNTIME_FILTER_WAIT_TIME_MS to 100,000 but then see that the waits for those runtime filters weren't that long, I'm going to be confused. Is the profile confusing and I'm misreading? Is there a bug in the reporting or a bug in actually waiting that long?

I think runtime_filter_wait_time_ms is the maximum time we'll wait. i.e., it's the deadline for the filters to show up. If they don't show up by then, then the query will proceed without the benefit of the runtime filters.

That's how I read that, too. My point is I didn't see evidence of waiting 100,000 ms according to my pastes above. Instead, according to the profile and the way I read it, the scan nodes waited 11,337 ms and 36,768 ms.

Commit e5af7f92926f94fd4c91a8c30089de142ea5f3ac in impala's branch refs/heads/master from Janaki Lahorani
[ https://gitbox.apache.org/repos/asf?p=impala.git;h=e5af7f9 ]

IMPALA-8064: Fix intermittent test failures from test_min_max_filters

test_min_max_filters and test_decimal_min_max_filters records the aggregated probe rows to
check whether min-max filter was exercised.  In the case of ASAN builds, the probe side
started processing before the filters reached the probe side, because ASAN builds are a
little slower.  The resolution was to increase RUNTIME_FILTER_WAIT_TIME_MS to accommodate ASAN.
After this patch was merged, https://gerrit.cloudera.org/#/c/12224/ the issue is still seen.

After further analysis, it was found from the profile that though RUNTIME_FILTER_WAIT_TIME_MS
was set to 100000, the probe side waited for much less than 100000.
-- Begin Profile Snippet where probe side waited for 36768 ms instead of 100000
      Instance 2b4a14d9933eb108:7565b86500000005 (host=downstream-jenkins-host:22002):(Total: 1m42s, non-child: 0.000ns, % non-child: 0.00%)
        HASH_JOIN_NODE (id=2):(Total: 39s251ms, non-child: 6.999ms, % non-child: 0.01%)
            Runtime filters: 1 of 1 Runtime Filter Published
        KUDU_SCAN_NODE (id=0):(Total: 36s812ms, non-child: 36s812ms, % non-child: 100.00%)
          Runtime filters: Not all filters arrived (arrived: [], missing [1]), waited for 36s768ms
-- End Profile Snippet

After analyzing the code we found that in ScanNode::WaitForRuntimeFilters, int32 was used for time.
But it should be using int64.  This is something that needs to be fixed.  There is some probability
that using 32 bit caused an overflow resulting in the actual wait time shown in profile to be less
than 100000.

This patch fixes the time variables in ScanNode::WaitForRuntimeFilters to int64.

Change-Id: I7d560adfb098be455a5a89c6de76ac1f17d1d3e3
Reviewed-on: http://gerrit.cloudera.org:8080/12269
Reviewed-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>
Tested-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>


Looks like the same test is still failing even after the latest commit. [~poojanilangekar], since [~janulatha] is unlikely to work on this in the near future, can you please look into it when you get a chance ? Thanks.

{noformat}
query_test/test_runtime_filters.py:116: in test_min_max_filters
    test_file_vars={'$RUNTIME_FILTER_WAIT_TIME_MS': str(WAIT_TIME_MS)})
common/impala_test_suite.py:522: in run_test_case
    update_section=pytest.config.option.update_results)
common/test_result_verifier.py:612: in verify_runtime_profile
    % (function, field, expected_value, actual_value, actual))
E   AssertionError: Aggregation of SUM over ProbeRows did not match expected results.
E   EXPECTED VALUE:
E   619
E   
E   ACTUAL VALUE:
E   684
{noformat}

Sure, taking a look at it right now. 

[~poojanilangekar] If you can get access to the profiles, see whether runtime filters were waited on for at least 100,000 ms. If you look at my comments above, in the profiles I looked at, they didn't seem to be waiting as long as directed. I can help take a look too if needed.

Commit e0aabddd573c204a780d3f5ff0af442cdb26b7c6 in impala's branch refs/heads/master from poojanilangekar
[ https://gitbox.apache.org/repos/asf?p=impala.git;h=e0aabdd ]

IMPALA-8064: Improve observability of wait times for runtime filters

This change is a diagnostic fix to improve the wait times logged
for runtime filters. The filter wait time counts against the
elapsed time since the filter's registration in ScanNode::Init()
while the duration logged in ScanNode::WaitForRuntimeFilters() is
the time spent in the function waiting for all the filters to
arrive. This could be misleading as it doesn't account for the
elapsed time spent between ScanNode::Init() and
ScanNode::WaitForRuntimeFilters(). This change logs the maximum
arrival delay for any runtime filter to arrive.

From my analysis of the logs of the failed tests, I believe the
filters are actually waiting for the specified time but logging
the duration incorrectly. The solution would be to increase the
wait time further. This change would help validate this
hypothesis.

Change-Id: I28fd45e75c773bc01d424f5a179ae186ee9b7469
Reviewed-on: http://gerrit.cloudera.org:8080/12401
Reviewed-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>
Tested-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>


I had a look at the most recent failure. The runtime filters didn't arrive in the specified 100000 ms limit. Instead on one of the fragment instance, the arrival time was 1m58s (this node was probably lucky because ScanNode::WaitForRuntimeFilters() was called later).  For two other fragment instances, the filters had not arrived after 1m40s. I think it might help to increase this wait time.  Or could there be other workarounds? 

[~tarmstrong] I looked at a few other failed instances. In all cases, the codegen time for F00 is about 2 minutes. In the worst case, the total codegen time spent was 2m36s and CodegenInvoluntaryContextSwitches: 289.66K. Also, I looked around the ASAN code, each allocation and free grabs a spinlock. So the slow down is most likely because of ASAN. Would it be okay to bump the wait time? 

Yeah it seems OK to bump it further.

Commit 59e1087d112df21d1ffe4d6f616d93da595036d7 in impala's branch refs/heads/master from poojanilangekar
[ https://gitbox.apache.org/repos/asf?p=impala.git;h=59e1087 ]

IMPALA-8064: Increase RUNTIME_FILTER_WAIT_TIME_MS for slow builds

Several ASAN runs of test_decimal_min_max_filters failed due to
the filters not arriving in time. This was because the codegen
time for the fragments was high and hence the scan node took long
to complete. This change increases the wait time from 100000ms to
200000ms.

Testing:
Executed the test 1000 times on an ASAN build without any failures.

Change-Id: Ib18075c2a480aad1331754cfd89a383dd58b0f2e
Reviewed-on: http://gerrit.cloudera.org:8080/12560
Reviewed-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>
Tested-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>


