Example output for job Hadoop-Common-0.23-Build
{code}
[yzhang@localhost jenkinsftf]$ ./determine-flaky-tests-hadoop.py -j Hadoop-Common-0.23-Build -n 8
****Recently FAILED builds in url: https://builds.apache.org//job/Hadoop-Common-0.23-Build
    THERE ARE 5 builds (out of 5) that have failed tests in the past 8 days, as listed below:

===>https://builds.apache.org/job/Hadoop-Common-0.23-Build/1059/testReport (2014-09-01 02:01:30)
    Failed test: org.apache.hadoop.io.compress.TestCodec.testSnappyCodec
===>https://builds.apache.org/job/Hadoop-Common-0.23-Build/1058/testReport (2014-08-31 02:01:30)
    Failed test: org.apache.hadoop.io.compress.TestCodec.testSnappyCodec
===>https://builds.apache.org/job/Hadoop-Common-0.23-Build/1057/testReport (2014-08-30 02:01:30)
    Failed test: org.apache.hadoop.io.compress.TestCodec.testSnappyCodec
===>https://builds.apache.org/job/Hadoop-Common-0.23-Build/1056/testReport (2014-08-29 02:01:30)
    Failed test: org.apache.hadoop.io.compress.TestCodec.testSnappyCodec
===>https://builds.apache.org/job/Hadoop-Common-0.23-Build/1055/testReport (2014-08-28 02:01:30)
    Failed test: org.apache.hadoop.io.compress.TestCodec.testSnappyCodec

All failed tests <#occurrences: testName>:
    5: org.apache.hadoop.io.compress.TestCodec.testSnappyCodec
{code}

Example output for Hadoop-Hdfs-trunk:
{code}
[yzhang@localhost jenkinsftf]$ ./determine-flaky-tests-hadoop.py -n 7
****Recently FAILED builds in url: https://builds.apache.org//job/Hadoop-Hdfs-trunk
    THERE ARE 7 builds (out of 8) that have failed tests in the past 7 days, as listed below:

===>https://builds.apache.org/job/Hadoop-Hdfs-trunk/1858/testReport (2014-09-01 04:31:30)
    Failed test: org.apache.hadoop.hdfs.web.TestWebHDFS.testWebHdfsDeleteSnapshot
===>https://builds.apache.org/job/Hadoop-Hdfs-trunk/1857/testReport (2014-08-31 04:31:30)
    Failed test: org.apache.hadoop.hdfs.web.TestWebHDFSForHA.testFailoverAfterOpen
    Failed test: org.apache.hadoop.hdfs.web.TestWebHDFSForHA.testSecureHAToken
===>https://builds.apache.org/job/Hadoop-Hdfs-trunk/1856/testReport (2014-08-30 09:46:54)
    Failed test: org.apache.hadoop.hdfs.TestDFSClientRetries.testIdempotentAllocateBlockAndClose
    Failed test: org.apache.hadoop.hdfs.TestDFSClientRetries.testFailuresArePerOperation
    Failed test: org.apache.hadoop.hdfs.TestDFSClientRetries.testRetryOnChecksumFailure
    Failed test: org.apache.hadoop.hdfs.TestDFSClientRetries.testWriteTimeoutAtDataNode
    Failed test: org.apache.hadoop.hdfs.TestDFSClientRetries.testDFSClientRetriesOnBusyBlocks
    Failed test: org.apache.hadoop.hdfs.TestDFSClientRetries.testClientDNProtocolTimeout
    Failed test: org.apache.hadoop.hdfs.TestDFSClientRetries.testGetFileChecksum
    Failed test: org.apache.hadoop.hdfs.TestDFSClientRetries.testNamenodeRestart
===>https://builds.apache.org/job/Hadoop-Hdfs-trunk/1855/testReport (2014-08-30 04:31:30)
    Failed test: org.apache.hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes.testBalancer
    Failed test: org.apache.hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes.testUnevenDistribution
===>https://builds.apache.org/job/Hadoop-Hdfs-trunk/1854/testReport (2014-08-29 04:31:30)
    Could not open testReport
===>https://builds.apache.org/job/Hadoop-Hdfs-trunk/1853/testReport (2014-08-28 09:37:18)
    Could not open testReport
===>https://builds.apache.org/job/Hadoop-Hdfs-trunk/1852/testReport (2014-08-28 09:28:48)
    Could not open testReport

All failed tests <#occurrences: testName>:
    1: org.apache.hadoop.hdfs.TestDFSClientRetries.testIdempotentAllocateBlockAndClose
    1: org.apache.hadoop.hdfs.web.TestWebHDFSForHA.testFailoverAfterOpen
    1: org.apache.hadoop.hdfs.web.TestWebHDFS.testWebHdfsDeleteSnapshot
    1: org.apache.hadoop.hdfs.TestDFSClientRetries.testFailuresArePerOperation
    1: org.apache.hadoop.hdfs.web.TestWebHDFSForHA.testSecureHAToken
    1: org.apache.hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes.testUnevenDistribution
    1: org.apache.hadoop.hdfs.TestDFSClientRetries.testRetryOnChecksumFailure
    1: org.apache.hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes.testBalancer
    1: org.apache.hadoop.hdfs.TestDFSClientRetries.testWriteTimeoutAtDataNode
    1: org.apache.hadoop.hdfs.TestDFSClientRetries.testDFSClientRetriesOnBusyBlocks
    1: org.apache.hadoop.hdfs.TestDFSClientRetries.testClientDNProtocolTimeout
    1: org.apache.hadoop.hdfs.TestDFSClientRetries.testGetFileChecksum
    1: org.apache.hadoop.hdfs.TestDFSClientRetries.testNamenodeRestart
{code}

Attached the tool, version 001.

Thanks for review, and welcome for comments.
 

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12665830/HADOOP-11045.001.patch
  against trunk revision 258c7d0.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4625//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4625//console

This message is automatically generated.

* Shouldn't DEFAULT_JOB_NAME be common?
* -Are we OK introducing a python dependency into the build tree, even if just for jenkins?- Forgot about relnotes.py. 

Thanks [~aw], good suggestion, I will make the change in next rev.


Hi [~aw], thanks for your earlier view. Attached rev 002 to address your comments. In addition, I moved the script to the same location as relnotes.py. Thanks.



{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12665958/HADOOP-11045.002.patch
  against trunk revision 59384df.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4631//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4631//console

This message is automatically generated.

Hi [~aw], would you please help taking a look at rev 002 and committing it if looks good to you? thanks a lot.



Hello [~aw], thanks for your earlier review and comment, would you mind take a look at the new rev? many thanks.


I don't know nearly enough about the Jenkins setup to give a yay or a nay.

Thanks [~aw], I will get help from some other folks. 


HI [~arpitagarwal],

It was nice to work with you on some of the test failures earlier and thanks for your help there. I wonder if you could take a look at the tool suggested here. Running it is pretty easy, and I hope you find it useful. Thanks.


I checked PreCommit-HDFS-Build, and here is the result. It says testPipelineRecoveryStress is the topmost (HDFS-6694), and without solving it, we might hide some real problem.

The second and the third tests in the list below failed for the similar reason "Too many open files...". It's suspicious because this is not the case before. Some code change might have introduced this problem recently (just filed HDFS-7070).

{code}
****Recently FAILED builds in url: https://builds.apache.org//job/PreCommit-HDFS-Build
    THERE ARE 18 builds (out of 20) that have failed tests in the past 3 days, as listed below:
......
Among 20 runs examined, all failed tests <#failedRuns: testName>:
    8: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover.testPipelineRecoveryStress
    6: org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract.testResponseCode
    2: org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract.testRenameDirToSelf
    2: org.apache.hadoop.ha.TestZKFailoverControllerStress.testExpireBackAndForth
    2: org.apache.hadoop.fs.contract.localfs.TestLocalFSContractOpen.testFsIsEncrypted
    2: org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract.testOverWriteAndRead
    2: org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract.testOutputStreamClosedTwice
    2: org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractOpen.testFsIsEncrypted
    2: org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer.testStored
    2: org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract.testSeek
    1: org.apache.hadoop.hdfs.TestDFSShell.testGet
    1: org.apache.hadoop.hdfs.TestDFSUpgrade.testUpgrade
    1: org.apache.hadoop.fs.TestFsShellCopy.testCopyNoCrc
    1: org.apache.hadoop.crypto.key.TestValueQueue.testgetAtMostPolicyALL
    1: org.apache.hadoop.hdfs.TestDFSShell.testCopyToLocal
......
{code}



Submitted 003 with improved reporting. 

Main change is that in the summary section, the total runs examined is now reported. In addition, for jobs that failed but not captured in the test report, produce more informative messages.



Results of recent  PreCommit-HDFS-Build run:

{code}
****Recently FAILED builds in url: https://builds.apache.org//job/PreCommit-HDFS-Build
     THERE ARE 44 builds (out of 52) that have failed tests in the past 3 days, as listed below:
...
Among 52 runs examined, all failed tests <#failedRuns: testName>:
    15: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication.testFencingStress
    3: org.apache.hadoop.hdfs.server.balancer.TestBalancer.testUnknownDatanode
    2: org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.testIsEncryptedMethod
    2: org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.testListEncryptionZonesAsNonSuperUser
    2: org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.testRenameFileSystem
    2: org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.testSnapshotsOnEncryptionZones
    1: org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.testBasicOperations
    1: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.testSnapshot
    1: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover.testFailoverRightBeforeCommitSynchronization
    1: org.apache.hadoop.fs.contract.hdfs.TestHDFSContractAppend.testAppendToEmptyFile
    1: org.apache.hadoop.hdfs.TestReplaceDatanodeOnFailure.testAppend
    1: org.apache.hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes.testAddVolumesDuringWrite
    1: org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.testFsckOnEncryptionZones
......
{code}




{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12673946/HADOOP-11045.003.patch
  against trunk revision 180afa2.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

        {color:red}-1 release audit{color}.  The applied patch generated 1 release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4888//testReport/
Release audit warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/4888//artifact/patchprocess/patchReleaseAuditProblems.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4888//console

This message is automatically generated.

Uploading rev 004, which added one more pattern of failed test to detect.


{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12681384/HADOOP-11045.004.patch
  against trunk revision 81dc0ac.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5080//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5080//console

This message is automatically generated.

Somehow the patch I submitted to HADOOP-11293 doesn't trigger jenkins run, upload it here for a trial.


Submitted rev 005 for better failure detection.


{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12690253/HADOOP-11045.005.patch
  against trunk revision 4cd66f7.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5366//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5366//console

This message is automatically generated.

Hi [~yzhangal], this is a nice tool. I have trivial comments:

* import re, string may be unnecessary.
* Sequential slashes appear in URL, like:
{code}
****Recently FAILED builds in url: https://builds.apache.org//job/Hadoop-Common-trunk
{code}
* For me, {code}b['result'] in ('UNSTABLE', 'FAILURE'){code} is simpler than {code}b['result'] == 'UNSTABLE' or b['result'] == 'FAILURE'{code}

I've tried to run the tool. Here are some comments:
* Would you change the permission from 644 to 755?
* I'm thinking it's better to add the URL of console output to the below message.
{code}
===>https://builds.apache.org/job/Hadoop-Hdfs-trunk/2005/testReport (2015-01-14 20:30:00)
    No failed tests in testReport, check job's Console Output for why it was reported failed
{code}
* (trivial) There are some trailing whitespaces.

Hi [~sekikn] and [~ajisakaa],

Thank you so much for the review and good comments! I'm attaching rev 006 to address all your comments. 




Thanks [~yzhangal] for updating the patch. Rev 006 looks good to me, +1.
If there are no further comments until this weekend, I'll commit it.

Thank you so much [~ajisakaa]!

When you commit, would you please include both [~tlipcon] and me as the contributer? Thanks.




bq. When you commit, would you please include both Todd Lipcon and me as the contributer?
Sure, thanks Todd for the initial work.

[~yzhangal] [~ajisakaa] do you know the version which this python script supports? We should validate python version with sys.version_info.

Thanks [~ozawa]!

I tested it against python 2.6.6 and 2.7.6. Assuming it's going to work with newer versions, I could try to get earlier python versions to see which is the lowest that works, and add the sys.version_info check. Would you please confirm that's what you meant? thanks.



[~yzhangal], yes, that is what I meant. How about python 3.0 or later in addition to older versions? 

Hi [~ozawa],

Thanks for confirming, it's very nice comments!

I did pretty extensive testing and I'm uploading rev 007 with the following changes:

* I found that it doesn't work with pre python2.6, so I added code to quit with  error message when the version is not at least 2.6.
* When testing with 3.x, I found that there is quite some difference between 2.x and 3.x, I made the code changes accordingly to support both 2.x and 3.x
* When testing against 3.0, I found a bug in 3.0, and the bug is fixed in 3.0.1, so I added code to issue a message and quit when the version is 3.0
* The latest version I tested is 3.4.2.

Many thanks to you all for the review and comments, would you please take a look at 007?





{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12694300/HADOOP-11045.007.patch
  against trunk revision 8f26d5a.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5470//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5470//console

This message is automatically generated.

[~yzhangal] Great work! One point: I prefer to use sys.version_info instead of sys.hexversion. We can use tuple comparison feature like this: 

{code}
>>> sys.version_info
sys.version_info(major=2, minor=7, micro=6, releaselevel='final', serial=0)
>>> sys.version_info > (2, 6, 0)
True
>>> sys.version_info > (3, 0, 0)
False
>>> sys.version_info < (3, 0, 0)
True
{code}

Please let me know if you have reason to use sys.hexversion.

Hi [~ozawa],

Thanks a lot for your feedback! I did do some study before deciding to use hexversion. Below is what I found:

* hexversion exists in as early version as Python 1.5.2, whereas version_info exists only from 2.0 on. 
* hexversion is described as "The version number encoded as a single integer. This is guaranteed to increase with each version, including proper support for non-production releases", however, per http://stackoverflow.com/questions/1093322/how-do-i-check-what-version-of-python-is-running-my-script, version_info may not, see " As long you do not endup comparing (3,3,0,'rc1','0') and (3,3,0,'beta','0') –  sorin Jun 5 '13 at 9:51 "

Based on this information, I chose to use hexversion. It's a bit harder to read, but not too bad. There is a detailed description of the format here: https://docs.python.org/2/library/sys.html#sys.hexversion. Please see that when I print out error messages, I do print a more readable version info.

What do you think?

Thanks.

--Yongjun




Make sense. Let me try it with multiple python versions.

Thanks Tsuyoshi!


[~yzhangal], +1, confirmed that this script works with python 2.x and python 3.x. Checking this in. I'll add you and Todd as the contributors as you mentioned.

Committing this to trunk and branch-2. Thanks [~yzhangal] and [~tlipcon]] for your contribution. Thanks [~ajisakaa] and [~sekikn] for your reviews. 

FAILURE: Integrated in Hadoop-trunk-Commit #6987 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6987/])
HADOOP-11045. Introducing a tool to detect flaky tests of hadoop jenkins testing job. Contributed by Yongjun Zhang and Todd Lipcon. (ozawa: rev 80705e034b7fc7ad384f1aa0bd15fc254ea06cf0)
* dev-support/determine-flaky-tests-hadoop.py
* hadoop-common-project/hadoop-common/CHANGES.txt


Hi [~ozawa], thanks a lot for reviewing, testing out and committing that patch!

Many thanks also to [~ajisakaa], [~aw], [~sekikn] for the review and feedback!

 

FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #94 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/94/])
HADOOP-11045. Introducing a tool to detect flaky tests of hadoop jenkins testing job. Contributed by Yongjun Zhang and Todd Lipcon. (ozawa: rev 80705e034b7fc7ad384f1aa0bd15fc254ea06cf0)
* dev-support/determine-flaky-tests-hadoop.py
* hadoop-common-project/hadoop-common/CHANGES.txt


FAILURE: Integrated in Hadoop-Yarn-trunk #828 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/828/])
HADOOP-11045. Introducing a tool to detect flaky tests of hadoop jenkins testing job. Contributed by Yongjun Zhang and Todd Lipcon. (ozawa: rev 80705e034b7fc7ad384f1aa0bd15fc254ea06cf0)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/determine-flaky-tests-hadoop.py


FAILURE: Integrated in Hadoop-Hdfs-trunk #2026 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2026/])
HADOOP-11045. Introducing a tool to detect flaky tests of hadoop jenkins testing job. Contributed by Yongjun Zhang and Todd Lipcon. (ozawa: rev 80705e034b7fc7ad384f1aa0bd15fc254ea06cf0)
* dev-support/determine-flaky-tests-hadoop.py
* hadoop-common-project/hadoop-common/CHANGES.txt


FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #91 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/91/])
HADOOP-11045. Introducing a tool to detect flaky tests of hadoop jenkins testing job. Contributed by Yongjun Zhang and Todd Lipcon. (ozawa: rev 80705e034b7fc7ad384f1aa0bd15fc254ea06cf0)
* dev-support/determine-flaky-tests-hadoop.py
* hadoop-common-project/hadoop-common/CHANGES.txt


FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #95 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/95/])
HADOOP-11045. Introducing a tool to detect flaky tests of hadoop jenkins testing job. Contributed by Yongjun Zhang and Todd Lipcon. (ozawa: rev 80705e034b7fc7ad384f1aa0bd15fc254ea06cf0)
* dev-support/determine-flaky-tests-hadoop.py
* hadoop-common-project/hadoop-common/CHANGES.txt


FAILURE: Integrated in Hadoop-Mapreduce-trunk #2045 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2045/])
HADOOP-11045. Introducing a tool to detect flaky tests of hadoop jenkins testing job. Contributed by Yongjun Zhang and Todd Lipcon. (ozawa: rev 80705e034b7fc7ad384f1aa0bd15fc254ea06cf0)
* dev-support/determine-flaky-tests-hadoop.py
* hadoop-common-project/hadoop-common/CHANGES.txt


My bad to have forgotten to mention, when we try to use this tool internally, [~andrew.wang] made very good suggestion about sorting. A late thanks to Andrew!


