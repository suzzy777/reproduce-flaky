[~blambov] overall looks awesome. I have a few suggestions from our testing of BoundedRead ([patch|https://github.com/jolynch/cassandra/commit/b2516af983930b3fe5bb016b5039c289ea396fd6#diff-447488af7557e6bb324a058fa442f009624d00ef8b4d12a18dcbf4f94950c1ec], [options|https://gist.github.com/jolynch/9118465f32ad5298b4e39d03ccd4370e#boundedreadcompactionstrategy]) that you might either want to incorporate now or later (I think the current proposal is a huge step forwards because of the sharding and density tiering, definitely don't want to hold it up). If you agree with some of these I would love to collaborate on getting some of them into your patch either now or after merge (I think these could be added later if you agree)
 * target_consolidate_interval_in_seconds (1 hour): When tiering in the lower levels (the T ones from your proposal) force a compaction if this amount of time passes.
 * Dynamic tier for lowest level: When data is being dumped into the lower tier would lead to redundant compaction than the consolidate interval (e.g. if you have a tier of 4 but you are getting a flush every minute meaning you'd compact more than once per 1 hour interval), autorange the tier up to ~4x the input. The combination of this plus target_consolidate_interval_in_seconds leads to significantly less compaction during data loads.
 * max_level_age_in_seconds (10 days): If a table hasn't participated in compaction (in your case a shard) in this amount of time do a full vertical compaction to ensure tombstones find their data. This would finally make C* guarantee that it has tombstones find data.
 * Breaking up full compaction: I think that the sharding technique does this, but when an operator does a full compaction if you instead just flip a timestamp to trigger normal background compactions of the shards, then you don't need double disk space (you only need the size of #compactions * shard size).

Generally density (and levels) are a proxy for time, and thus can provide some version of this. However, one thing it can't do that appears to be important for some workloads, is the ability to provide guarantees that deleted data will be actually removed from the sstable set within a specified amount of time.

UCS could allow for this if we introduce a time component to the strategy. It looks like the simplest option would be to additionally permit levelling based on elapsed time, which would enable both TWCS-like leave-old-sstables-alone behaviour (where old sstables move to higher levels of the hierarchy as they age and never meet), as well as compact-all-old-sstables as described (where old sstables stay in the same level and compaction is immediately triggered when a new sstable matures enough to enter their bucket). I think this is well worth doing, but I would prefer to do this after the current 5.0 push is over.

The pull request is ready for review.

Committed as [957eca2fb53477d56bdc9a97c612f1fbecfb5d41|https://github.com/apache/cassandra/commit/957eca2fb53477d56bdc9a97c612f1fbecfb5d41].

Many thanks to all the reviewers and co-authors of this patch.

