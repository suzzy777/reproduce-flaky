DataNode.shutdown will call [blockPoolManager.shutDownAll|https://github.com/apache/hadoop/blob/rel/release-3.3.1/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java#L2152] which eventually calls [BPServiceActor.stop|https://github.com/apache/hadoop/blob/rel/release-3.3.1/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java#L592] which will interrupt the command processing thread, which _is_ a daemon thread.

In the logs we see...

{noformat}
  2> 31835 ERROR (Command processor) [] o.a.h.h.s.d.DataNode Command processor encountered interrupt and exit.
  2> 31835 WARN  (Command processor) [] o.a.h.h.s.d.DataNode Ending command processor service for: Thread[Command processor,5,TGRP-HdfsBackupRepositoryIntegrationTest]
{noformat}
which despite error status looks like the normal mode of shutting things down. However... that's only one of the data nodes, and the second one is the one that got stuck. It would be great if the thread names were unique as that would have given us the hint faster.

Maybe we can try reducing to one datanode instead of our current default of 2 and see if that helps the tests? We're not really interested in testing HDFS resiliency here anyway, so I think it should be fine for test purposes. Additional bonus is that startup/shutdown times might reduce a bit?
 

 

The output from the two different data node shutdowns might be telling us something:

{noformat}
  2> 233391 INFO  (org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@622864f7) [] o.a.h.h.s.d.DataNode Closing all peers.
  2> 233395 WARN  (BP-2039008531-127.0.0.1-1645493950129 heartbeating to localhost/127.0.0.1:55316) [] o.a.h.h.s.d.DataNode Ending block pool service for: Block pool BP-2039008531-127.0.0.1-1645493950129 (Datanode Uuid 20c3c955-3e3b-43c4-a6c8-26417ae3ea96) service to localhost/127.0.0.1:55316
  2> 233395 INFO  (BP-2039008531-127.0.0.1-1645493950129 heartbeating to localhost/127.0.0.1:55316) [] o.a.h.h.s.d.DataNode Removed Block pool BP-2039008531-127.0.0.1-1645493950129 (Datanode Uuid 20c3c955-3e3b-43c4-a6c8-26417ae3ea96)
  2> 233395 INFO  (BP-2039008531-127.0.0.1-1645493950129 heartbeating to localhost/127.0.0.1:55316) [] o.a.h.h.s.d.f.i.FsDatasetImpl Removing block pool BP-2039008531-127.0.0.1-1645493950129
  2> 233404 INFO  (Listener at localhost/55365) [] o.a.h.h.s.d.DataNode Waiting up to 30 seconds for transfer threads to complete
  2> 233404 INFO  (Listener at localhost/55365) [] o.a.h.i.Server Stopping server on 55351
  2> 233407 INFO  (IPC Server listener on 0) [] o.a.h.i.Server Stopping IPC Server listener on 0
  2> 233407 INFO  (IPC Server Responder) [] o.a.h.i.Server Stopping IPC Server Responder
  2> 233408 INFO  (Listener at localhost/55365) [] o.a.h.h.s.d.DataNode Shutdown complete.
  
  2> 233408 INFO  (org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@61d48b09) [] o.a.h.h.s.d.DataNode Closing all peers.
  2> 233422 INFO  (Listener at localhost/55365) [] o.a.h.h.s.d.DataNode Waiting up to 30 seconds for transfer threads to complete
  2> 233422 INFO  (Listener at localhost/55365) [] o.a.h.i.Server Stopping server on 55365
  2> 233426 INFO  (IPC Server listener on 0) [] o.a.h.i.Server Stopping IPC Server listener on 0
  2> 233426 ERROR (Command processor) [] o.a.h.h.s.d.DataNode Command processor encountered interrupt and exit.
  2> 233426 INFO  (IPC Server Responder) [] o.a.h.i.Server Stopping IPC Server Responder
  2> 233426 WARN  (BP-2039008531-127.0.0.1-1645493950129 heartbeating to localhost/127.0.0.1:55316) [] o.a.h.h.s.d.IncrementalBlockReportManager IncrementalBlockReportManager interrupted
  2> 233426 WARN  (Command processor) [] o.a.h.h.s.d.DataNode Ending command processor service for: Thread[Command processor,5,TGRP-HdfsDirectoryTest]
  2> 233426 WARN  (BP-2039008531-127.0.0.1-1645493950129 heartbeating to localhost/127.0.0.1:55316) [] o.a.h.h.s.d.DataNode Ending block pool service for: Block pool BP-2039008531-127.0.0.1-1645493950129 (Datanode Uuid a7783809-4beb-4df0-b349-0e44cdaa3719) service to localhost/127.0.0.1:55316
  2> 233426 INFO  (BP-2039008531-127.0.0.1-1645493950129 heartbeating to localhost/127.0.0.1:55316) [] o.a.h.h.s.d.DataNode Removed Block pool BP-2039008531-127.0.0.1-1645493950129 (Datanode Uuid a7783809-4beb-4df0-b349-0e44cdaa3719)
  2> 233427 INFO  (BP-2039008531-127.0.0.1-1645493950129 heartbeating to localhost/127.0.0.1:55316) [] o.a.h.h.s.d.f.i.FsDatasetImpl Removing block pool BP-2039008531-127.0.0.1-1645493950129
  2> 233430 INFO  (Listener at localhost/55365) [] o.a.h.h.s.d.DataNode Shutdown complete.
{noformat}

For one of them, the block pool service looks like it is naturally terminated, for the other the command processor thread is interrupted and _then_ the block pool service can finally stop. Unfortunately, without a little bit better logging I don't have an easy way to tell which Command Processor is the one that is actually leaking.

Big thanks to [~mdrob] for the debugging here. We chatted on Slack and think this might address the issue: https://github.com/apache/solr/pull/686

So sadly this PR doesn't seem to fully address the problem.

I ran

{code:java}
./gradlew beast -Ptests.dups=10 --tests "*hdfs*" --tests "*Hdfs*" --tests "*HDFS*" --tests "*Hadoop*" -Ptests.jvms=4 -Ptests.jvmargs=-XX:TieredStopAtLevel=1 -Ptests.nightly=true -Ptests.awaitsfix=false -Ptests.badapples=false -Ptests.file.encoding=UTF-8
{code}

and on the 7/10 iteration:

{code:java}
  2> INFO: Starting to interrupt leaked threads:
  2>    1) Thread[id=425, name=Command processor, state=WAITING, group=TGRP-HdfsBackupRepositoryIntegrationTest]
  2> 23747 ERROR (Command processor) [] o.a.h.h.s.d.DataNode Command processor encountered interrupt and exit.
  2> 23747 WARN  (Command processor) [] o.a.h.h.s.d.DataNode Ending command processor service for: Thread[Command processor,5,TGRP-HdfsBackupRepositoryIntegrationTest]
  2> Feb 22, 2022 2:37:28 PM com.carrotsearch.randomizedtesting.ThreadLeakControl tryToInterruptAll
  2> INFO: All leaked threads terminated.
   >     com.carrotsearch.randomizedtesting.ThreadLeakError: 1 thread leaked from SUITE scope at org.apache.solr.core.backup.repository.HdfsBackupRepositoryIntegrationTest:
   >        1) Thread[id=425, name=Command processor, state=WAITING, group=TGRP-HdfsBackupRepositoryIntegrationTest]
   >             at java.base@17.0.2/jdk.internal.misc.Unsafe.park(Native Method)
   >             at java.base@17.0.2/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
   >             at java.base@17.0.2/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
   >             at java.base@17.0.2/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3463)
   >             at java.base@17.0.2/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3434)
   >             at java.base@17.0.2/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1623)
   >             at java.base@17.0.2/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
   >             at app//org.apache.hadoop.hdfs.server.datanode.BPServiceActor$CommandProcessingThread.processQueue(BPServiceActor.java:1331)
   >             at app//org.apache.hadoop.hdfs.server.datanode.BPServiceActor$CommandProcessingThread.run(BPServiceActor.java:1315)
   >         at __randomizedtesting.SeedInfo.seed([EBD3DB97F02CC2C5]:0)
  2> NOTE: test params are: codec=Asserting(Lucene90): {}, docValues:{}, maxPointsInLeafNode=777, maxMBSortInHeap=5.859417284434442, sim=Asserting(RandomSimilarity(queryNorm=false): {}), locale=chr-US, timezone=America/Boise
  2> NOTE: Mac OS X 10.15.7 x86_64/Eclipse Adoptium 17.0.2 (64-bit)/cpus=8,threads=36,free=32429088,total=268435456
  2> NOTE: All tests run in this JVM: [TestHdfsBackupRestoreCore, HdfsBackupRepositoryIntegrationTest]
  2> NOTE: reproduce with: gradlew test --tests HdfsBackupRepositoryIntegrationTest -Dtests.seed=EBD3DB97F02CC2C5 -Dtests.nightly=true -Dtests.slow=true -Dtests.locale=chr-US -Dtests.timezone=America/Boise -Dtests.asserts=true -Dtests.file.encoding=UTF-8

:solr:modules:hdfs:test_7 (FAILURE): 29 test(s), 1 failure(s), 2 skipped

29 tests completed, 1 failed, 2 skipped

> Task :solr:modules:hdfs:test_7 FAILED

ERROR: The following test(s) have failed:
  - org.apache.solr.core.backup.repository.HdfsBackupRepositoryIntegrationTest.classMethod (:solr:modules:hdfs)
    Test output: /Users/risdenk/repos/apache/solr/solr/modules/hdfs/build/test-results/test_7/outputs/OUTPUT-org.apache.solr.core.backup.repository.HdfsBackupRepositoryIntegrationTest.txt
    Reproduce with: gradlew :solr:modules:hdfs:test --tests "org.apache.solr.core.backup.repository.HdfsBackupRepositoryIntegrationTest.classMethod" -Ptests.jvms=4 -Ptests.jvmargs=-XX:TieredStopAtLevel=1 -Ptests.seed=910A386A7CBF4B02 -Ptests.nightly=true -Ptests.awaitsfix=false -Ptests.badapples=false -Ptests.file.encoding=UTF-8 -Ptests.dups=10
{code}

The full log from the run is here:  [^OUTPUT-org.apache.solr.core.backup.repository.HdfsBackupRepositoryIntegrationTest.txt.gz] 

Confirmed separately that daemon threads can still count as leaking and fail the tests. [~dweiss] - was that an intentional decision or did we run into an unfortunate edge case?

{code}
  @Test
  public void test() throws Exception {
    CountDownLatch testLatch = new CountDownLatch(1);
    CountDownLatch latch = new CountDownLatch(1);
    new Thread(() -> {
      try {
        testLatch.countDown();
        latch.await();
      } catch (InterruptedException e) {

      }
    }) {{
       setDaemon(true);
    }}.start();
    testLatch.await();
  }
{code}

Some observations - I have a patched/hacked version of hdfs libs that I'm using locally to test this, not much progress so far. I think that decreasing the number of data nodes makes this less likely to happen because the problem is a datanode shutdown problem and not really a solr problem. It still occurs, but it's less flaky for us on the surface.

If adding the command processor to the thread leak filter solves this problem for now, then I'm ok with that approach. We can revisit it later after HDFS fixes it eventually?

Updated https://github.com/apache/solr/pull/686 to include "Command processor" in thread leak exceptions for now.

The framework by default detects all leaked threads - the filters can be configured manually. A set of "defaults" is also provided but it does not include daemon threads.

 

[https://github.com/randomizedtesting/randomizedtesting/blob/master/randomized-runner/src/main/java/com/carrotsearch/randomizedtesting/ThreadLeakControl.java#L281-L336]

 

The daemon threads are merely a flag - I wouldn't rely on these to be "innocent"... If you know something can be passed through, add the detection/ filtering to the custom filter impl, as in here:

 

https://github.com/apache/lucene/blob/main/lucene/test-framework/src/java/org/apache/lucene/tests/util/LuceneTestCase.java#L224-L226

Commit 10cc0c01aa3f1886542dc90ec4d0cb3a749f2854 in solr's branch refs/heads/main from Kevin Risden
[ https://gitbox.apache.org/repos/asf?p=solr.git;h=10cc0c0 ]

SOLR-16043: Simplify HDFS tests

Simplifies HDFS tests by:
* defaulting to 1 datanode instead of 2
* Calling only dfsCluster.shutdown(true);


Commit 06a37775cb8d8d3f0b9cfb3fe1614858a303581d in solr's branch refs/heads/main from Kevin Risden
[ https://gitbox.apache.org/repos/asf?p=solr.git;h=06a3777 ]

SOLR-16043: Add Command processor to BadHdfsThreadsFilter


Commit d33ce08aa748eecf5a87d979ef71133b680f74cd in solr's branch refs/heads/branch_9x from Kevin Risden
[ https://gitbox.apache.org/repos/asf?p=solr.git;h=d33ce08 ]

SOLR-16043: Simplify HDFS tests

Simplifies HDFS tests by:
* defaulting to 1 datanode instead of 2
* Calling only dfsCluster.shutdown(true);


Commit 80338aacebbcc1e71b435db84b3bfaa2853f9c89 in solr's branch refs/heads/branch_9x from Kevin Risden
[ https://gitbox.apache.org/repos/asf?p=solr.git;h=80338aa ]

SOLR-16043: Add Command processor to BadHdfsThreadsFilter


Commit 65bbd98f1e67de22dbfc28ef48ffc3b6a6b1d6c5 in solr's branch refs/heads/branch_9_0 from Kevin Risden
[ https://gitbox.apache.org/repos/asf?p=solr.git;h=65bbd98 ]

SOLR-16043: Simplify HDFS tests

Simplifies HDFS tests by:
* defaulting to 1 datanode instead of 2
* Calling only dfsCluster.shutdown(true);


Commit cd7fc3a22f23b9a7c53d44b826feb044d312f121 in solr's branch refs/heads/branch_9_0 from Kevin Risden
[ https://gitbox.apache.org/repos/asf?p=solr.git;h=cd7fc3a ]

SOLR-16043: Add Command processor to BadHdfsThreadsFilter


For completeness, the simplifying HDFS tests reduced the likelyhood of this error happening it seems. However, the datanode shutdown doesn't fully shutdown the "Command processor" thread so added to BadHdfsThreadsFilter. [~mdrob] had some HDFS potential fixes to chase down to make sure the thread is cleaned up.

Closing after the 9.0.0 release

