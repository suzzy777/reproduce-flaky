{{IgniteClientDisconnectedException}} should also behave consistently, regardless of whether the client was reconnected within network timeout or after it with a new ID. 

Now after client reconenct we check that cache still exists and have the same deploymentId (GridCacheProcessor.onReconnected). So even when client reconnects with new ID old caches should work if they were not re-created while client was disconnected. Maybe it can be improved and after reconnect we should ignore deploymentId, but check that cache have the same configuration.

The issue description refers to "special logic" but does not mention how this logic would be implemented. Is there a "known workaround" to this problem that users of Ignite 1.5.x can deploy?

GitHub user alamar opened a pull request:

    https://github.com/apache/ignite/pull/2816

    IGNITE-2766 Essais: Opportunistic reopen cache.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/gridgain/apache-ignite ignite-2766

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/ignite/pull/2816.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #2816
    
----
commit 3e8d3e8d756290e749a3f2d2a1a4deba97743a26
Author: Ilya Kasnacheev <ilya.kasnacheev@gmail.com>
Date:   2017-10-06T17:19:56Z

    IGNITE-2766 Essais: Opportunistic reopen cache.

----


When operation hits a closed cache proxy, instead of throwing exception we should try to retrieve cache with the same name from KernalContext.
If that it successful, we update internal state and serve the operation as if the cache is always open.

Obviously it means that there was a period of time when this cache object won't be valid, we're teaching bad habits a bit, but with common try-catch-wait-retry loops it should work OK.

https://ci.ignite.apache.org/project.html?projectId=Ignite20Tests&branch_Ignite20Tests=pull%2F2816%2Fhead

[~sboikov] please take a look

GitHub user alamar opened a pull request:

    https://github.com/apache/ignite/pull/2870

    IGNITE-2766 Deterministically reopen cache after client reconnect.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/gridgain/apache-ignite ignite-2766ex

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/ignite/pull/2870.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #2870
    
----
commit 843566b74b3afdf78d3ede1a46adc927878c89e2
Author: Ilya Kasnacheev <ilya.kasnacheev@gmail.com>
Date:   2017-10-17T12:53:05Z

    IGNITE-2766 Deterministically reopen cache after client reconnect bis.

----


GitHub user alamar opened a pull request:

    https://github.com/apache/ignite/pull/3077

    IGNITE-2766 Ensure that cache is available after client ID changes.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/gridgain/apache-ignite ignite-2766test

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/ignite/pull/3077.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #3077
    
----

----


I cannot reproduce the original problem - cache stays opened and operational after client reconnects with new ID.

I have improved test to check this behavior. Please review.

[~ntikhonov]

[~ilyak],
I've checked and merged your test improvment. Thank you for your contribution!

Github user alamar closed the pull request at:

    https://github.com/apache/ignite/pull/3077


Github user alamar closed the pull request at:

    https://github.com/apache/ignite/pull/2816


Github user alamar closed the pull request at:

    https://github.com/apache/ignite/pull/2870


I can reproduce the issue with the following test:

 
{code:java}
import java.util.Arrays;
import org.apache.ignite.Ignite;
import org.apache.ignite.IgniteCache;
import org.apache.ignite.Ignition;
import org.apache.ignite.configuration.CacheConfiguration;
import org.apache.ignite.configuration.IgniteConfiguration;
import org.apache.ignite.spi.discovery.tcp.TcpDiscoverySpi;
import org.apache.ignite.spi.discovery.tcp.ipfinder.vm.TcpDiscoveryVmIpFinder;
import org.jetbrains.annotations.NotNull;

public class ReconnectClient {
    private static int id;

    public static void main(String[] args) throws InterruptedException {
        Ignition.setClientMode(false);

        Ignite server = Ignition.start(getConfiguration());

        Ignition.setClientMode(true);
        Ignite client = Ignition.start(getConfiguration());

        IgniteCache<String, String> cache = client.cache("TEST");

        cache.put("Hello", "World");

        server.close();

        Thread.sleep(2_000);

        Ignition.setClientMode(false);
        server = Ignition.start(getConfiguration());

        Thread.sleep(4_000);

        System.out.println(cache.get("Hello"));
        cache.put("Ping", "Pong");

        System.out.println("DONE");
    }

    @NotNull private static IgniteConfiguration getConfiguration() {
        IgniteConfiguration cfg = new IgniteConfiguration();

        TcpDiscoveryVmIpFinder finder = new TcpDiscoveryVmIpFinder(true);
        finder.setAddresses(Arrays.asList("localhost:47500..47600"));

        cfg.setIgniteInstanceName("test" + id++);

        cfg.setCacheConfiguration(new CacheConfiguration("TEST"));

        cfg.setDiscoverySpi( new TcpDiscoverySpi().setIpFinder(finder));
        return cfg;
    }
}
{code}
 

Yes, now I can see what is the real issue. It is as follows:
{code:java}
Exception in thread "main" java.lang.IllegalStateException: class org.apache.ignite.internal.processors.cache.CacheStoppedException: Failed to perform cache operation (cache is stopped): TEST
    at org.apache.ignite.internal.processors.cache.GridCacheGateway.enter(GridCacheGateway.java:164)
    at org.apache.ignite.internal.processors.cache.GatewayProtectedCacheProxy.onEnter(GatewayProtectedCacheProxy.java:1656)
    at org.apache.ignite.internal.processors.cache.GatewayProtectedCacheProxy.get(GatewayProtectedCacheProxy.java:659)
    at ReconnectClient.main(ReconnectClient.java:36)
Caused by: class org.apache.ignite.internal.processors.cache.CacheStoppedException: Failed to perform cache operation (cache is stopped): TEST
    ... 4 more{code}
while IgniteClientDisconnectedException is expected!

No, I still don't get it.

-New Ignite cluster just doesn't have the 'TEST' cache.-

Even if it did, it would be a different cache (if not for persistence). Eventually with a different cache config. I will try to update the test with a working example.

"Client node was reconnected after it was already considered failed by the server topology (this could happen after all servers restarted or due to a long network outage between the client and servers). All continuous queries and remote event listeners created by this client will be unsubscribed, consider listening to EVT_CLIENT_NODE_RECONNECTED event to restore them."

I guess that means cache proxies are no longer good either.

[~ilyak], I believe that if cache with corresponding name still exists after restart (either because it's configured statically on server startup, or because persistence is used), proxy should continue to provide access to this cache. Configuration will be changed rarely in this case, but even if it does change, I don't see much harm. If there are any specific scenarios that would not work properly with this approach, can you please share them?

If cache doesn't exist after restart, exception is obviously correct behavior, although the message should be more clear I think.

GitHub user alamar opened a pull request:

    https://github.com/apache/ignite/pull/3417

    IGNITE-2766 Opportunistically reopen cache after client reconnect.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/gridgain/apache-ignite ignite-2766

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/ignite/pull/3417.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #3417
    
----
commit a70620ca6398ba151541b5ff92c7f941eea07527
Author: Ilya Kasnacheev <ilya.kasnacheev@...>
Date:   2018-01-22T15:29:36Z

    IGNITE-2766 Opportunistically reopen cache after client reconnect.

----


[~vkulichenko] So I have this commit stashed already (see above), I was hesistant to push it thru due to unclear requirements.

You can merge it to master if tests pass.

https://ci.ignite.apache.org/project.html?projectId=IgniteTests24Java8&branch_IgniteTests24Java8=pull%2F3417%2Fhead

[~ilyak], is there a test for the case discussed here?

[~vkulichenko] you can note that [ClientReconnectAfterClusterRestartTest.java|https://github.com/apache/ignite/pull/3417/files#diff-1e38a182668eb3491803ab6ce69e7262] test is changed in my commit, so it becomes test case for current issue.

Current patch is postponed due to IGNITE-7603 scenario failing every time. Should incorporate fix.

[~vkulichenko] please review amended fix

Merged to {{master}} and {{ignite-2.5}}. [~ilyak], thanks for contribution!

Github user asfgit closed the pull request at:

    https://github.com/apache/ignite/pull/3417


Folks, please pay attention to failure: [https://ci.ignite.apache.org/project.html?projectId=IgniteTests24Java8&testNameId=5567963579403368730&branch=%3Cdefault%3E&tab=testDetails]

Seems this is related. [~ilyak], could you please check?

GitHub user alamar opened a pull request:

    https://github.com/apache/ignite/pull/3853

    IGNITE-2766 Fix .net test.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/gridgain/apache-ignite ignite-2766net

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/ignite/pull/3853.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #3853
    
----
commit 5fbed1f4e48b9666a983d23ce22c5d51bebede7d
Author: Ilya Kasnacheev <ilya.kasnacheev@...>
Date:   2018-04-17T15:09:20Z

    IGNITE-2766 Fix .net test.

----


Github user asfgit closed the pull request at:

    https://github.com/apache/ignite/pull/3853


[~ilyak], [~dpavlov]

Due to changes of this issue, we've broked muted flaky test. I've created JIRA for fixing it.
 Please, see my changes an PR with my small fix
 https://issues.apache.org/jira/browse/IGNITE-8301

Hello [~ilyak], [~vkulichenko].
I'm faced with the fact that now IgniteCacheRestartingException can be thrown after IgniteCache#destroy method was called on the server node when we continue working with this cache asynchronously. Seems it's not right because we destroying cache.
How do yout think - is it ok to change GatewayProtectedCacheProxy#onEnter from
{code:java}
checkProxyIsValid(gate(), true) // tryRestart = true
{code}
to something like
{code:java}
checkProxyIsValid(gate(), context().localNode().isClient()) // tryRestart = true only on client node
{code}
?

I checked tests ClientReconnectAfterClusterRestartTest, IgniteCacheQueryCacheDestroySelfTest and they works well with such change.


[~xtern] You can definitely do that. Shame on me it isn't implemented this way in the first place.

