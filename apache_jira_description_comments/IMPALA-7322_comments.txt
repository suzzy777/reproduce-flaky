Commit 2fd795cf56e65a43087375867dcc9890e3a27330 in impala's branch refs/heads/master from Yongzhi Chen
[ https://gitbox.apache.org/repos/asf?p=impala.git;h=2fd795c ]

IMPALA-7322: Add storage wait time to profile

Add metrics to record storage wait time for operations with
metadata load in catalog for hdfs, kudu and hbase tables.
Pass storage wait time from catalog to fe through thrift and log
total storage load time in query profile.
Storage-load-time is the amount of time spent loading
metadata from the underlying storage layer (e.g. S3, HDFS,
Kudu, HBase), which does not  include the amount of time
spending loading data from HMS.

Testing:
Ran queries that can trigger all of, none of or some of the related
tables loading. Check query profile for each query. Check catalog
metrics for each table.
Add unit tests to test_observability.py
Ran all core tests.

Sample output:
Profile:(storage-load-time is the added property):
After ran a hbase query (Metadata load finished is divided into
several lines because of limitation of commit message):
Query Compilation: 4s401ms
  - Metadata load started: 661.084us (661.084us)
  - Metadata load finished. loaded-tables=1/1
      load-requests=1 catalog-updates=3
      storage-load-time=233ms: 3s819ms (3s819ms)
 - Analysis finished: 3s820ms (763.979us)
 - Value transfer graph computed: 3s820ms (63.193us)
Catalog metrics(this sample is from a hdfs table):
storage-metadata-load-duration:
   Count: 1
   Mean rate: 0.0085
   1 min. rate: 0.032
   5 min. rate: 0.1386
   15 min. rate: 0.177
   Min (msec): 111
   Max (msec): 111
   Mean (msec): 111.1802
   Median (msec): 111.1802
   75th-% (msec): 111.1802
   95th-% (msec): 111.1802
   99th-% (msec): 111.1802
Change-Id: I6dde7e394b7c1c396d835ef6aa0a55930c0a8660
Reviewed-on: http://gerrit.cloudera.org:8080/12940
Reviewed-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>
Tested-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>


Commit d750d884e5fc28117c051ba29b73cdc51e698cea in impala's branch refs/heads/master from Tim Armstrong
[ https://gitbox.apache.org/repos/asf?p=impala.git;h=d750d88 ]

Revert "IMPALA-7322: Add storage wait time to profile"

This reverts commit 2fd795cf56e65a43087375867dcc9890e3a27330.

The test added has some issues:
* Fails with the local catalog enabled
* Is flaky if run concurrently with other tests that touch the same
  tables.

Change-Id: I8fc33db75c21973d209d518c1fb02bd5f9728aee
Reviewed-on: http://gerrit.cloudera.org:8080/13738
Reviewed-by: Tim Armstrong <tarmstrong@cloudera.com>
Tested-by: Tim Armstrong <tarmstrong@cloudera.com>


[~ychena] since these tests run {{invalidate metadata}} onÂ shared tables they either (1) need to run serially rather than in parallel with tests that also might touch the {{alltypes}} table, or (2) the test should create a private table and use that instead of {{alltypes}}.

I'm in favor of approach #2 since running tests already takes a long time, so adding more serial tests is not ideal unless it is really necessary.

Not sure what the failures with local catalog were, can you take a look?

Commit 7136e8b965bd0df974dccd1419ea65d42c494c06 in impala's branch refs/heads/master from Yongzhi Chen
[ https://gitbox.apache.org/repos/asf?p=impala.git;h=7136e8b ]

IMPALA-7322: Add storage wait time to profile

Add metrics to record storage wait time for operations with
metadata load in catalog for hdfs, kudu and hbase tables.
Pass storage wait time from catalog to fe through thrift
and log total storage load time in query profile.
Storage-load-time is the amount of time spent loading metadata
from the underlying storage layer (e.g. S3, HDFS, Kudu, HBase),
which does not include the amount of time spending loading data
from HMS.

Testing:
* Ran queries that can trigger all of, none of or
  some of the related tables loading.
* Check query profile for each query.
* Check catalog metrics for each table.
* Add unit tests to test_observability.py
* Ran all core tests.

Sample output:

Profile for Catalog V1: (storage-load-time is the added property and
it is part of Metadata load in Query Compilation):
After ran a hbase query (Metadata load finished is divided into
several lines because of limitation of commit message):

Query Compilation: 4s401ms
  - Metadata load started: 661.084us (661.084us)
  - Metadata load finished. loaded-tables=1/1
      load-requests=1 catalog-updates=3
      storage-load-time=233ms: 3s819ms (3s819ms)
  - Analysis finished: 3s820ms (763.979us)
  - Value transfer graph computed: 3s820ms (63.193us)

Profile for Catalog V2: (StorageLoad.Time is the added property and it
is in CatalogFetch):

    Frontend:
       - CatalogFetch.ColumnStats.Misses: 1
       - CatalogFetch.ColumnStats.Requests: 1
       - CatalogFetch.ColumnStats.Time: 0
       - CatalogFetch.Config.Misses: 1
       - CatalogFetch.Config.Requests: 1
       - CatalogFetch.Config.Time: 3ms
       - CatalogFetch.DatabaseList.Hits: 1
       - CatalogFetch.DatabaseList.Requests: 1
       - CatalogFetch.DatabaseList.Time: 0
       - CatalogFetch.PartitionLists.Misses: 1
       - CatalogFetch.PartitionLists.Requests: 1
       - CatalogFetch.PartitionLists.Time: 4ms
       - CatalogFetch.Partitions.Hits: 2
       - CatalogFetch.Partitions.Misses: 1
       - CatalogFetch.Partitions.Requests: 3
       - CatalogFetch.Partitions.Time: 1ms
       - CatalogFetch.RPCs.Bytes: 1.01 KB (1036)
       - CatalogFetch.RPCs.Requests: 4
       - CatalogFetch.RPCs.Time: 93ms
       - CatalogFetch.StorageLoad.Time: 68ms
       - CatalogFetch.TableNames.Hits: 2
       - CatalogFetch.TableNames.Requests: 2
       - CatalogFetch.TableNames.Time: 0
       - CatalogFetch.Tables.Misses: 1
       - CatalogFetch.Tables.Requests: 1
       - CatalogFetch.Tables.Time: 91ms

Catalog metrics(this sample is from a hdfs table):

    storage-metadata-load-duration:
       Count: 1
       Mean rate: 0.0085
       1 min. rate: 0.032
       5 min. rate: 0.1386
       15 min. rate: 0.177
       Min (msec): 111
       Max (msec): 111
       Mean (msec): 111.1802
       Median (msec): 111.1802
       75th-% (msec): 111.1802
       95th-% (msec): 111.1802
       99th-% (msec): 111.1802

Change-Id: I7447f8c8e7e50eb71d18643859d2e3de865368d2
Reviewed-on: http://gerrit.cloudera.org:8080/13786
Tested-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>
Reviewed-by: Sahil Takiar <stakiar@cloudera.com>


Commit 65198faa3beeea13aec905f8cda8f644e99af960 in impala's branch refs/heads/master from Jiawei Wang
[ https://gitbox.apache.org/repos/asf?p=impala.git;h=65198fa ]

IMPALA-9110: Add table loading time break-down metrics for HdfsTable

A. Problem:
Catalog table loading currently only records the total loading
time. We will need some break-down times, i.e. more detailed
time recording on each loading function. Also, the table schema
loading is not taken into account for load-duration. We will need
to add some more metrics for that.

B. Solution:
- We added "hms-load-tbl-schema", "load-duration.all-column-stats",
"load-duration.all-partitions.total-time",
"load-duration.all-partitions.file-metadata".
Also, we logged the loadValidWriteIdList() time. So now we have
a more detailed breakdown time for table loading info.

The table loading time metrics for HDFS tables are in the following hierarchy:
- Table Schema Loading
- Table Metadata Loading - total time
    - all column stats loading time
    - ValidWriteIds loading time
    - all partitions loading time - total time
        - file metadata loading time
    - storage-metadata-loading-time(standalone metric)

1. Table Schema Loading:
* Meaning: The time for HMS to fetch table object and the real schema loading time.
Normally, the code path is "msClient.getHiveClient().getTable(dbName, tblName)"
* Metric : hms-load-tbl-schema

2. Table Metadata Loading -- total time
* Meaning: The time to load all the table metadata.
The code path is load() function in HdfsTable.load() function.
* Metric: load-duration.total-time

2.1 Table Metadata Loading -- all column stats
* Meaning: load all column stats, this is part of table metadata loading
The code path is HdfsTable.loadAllColumnStats()
* Metric: load-duration.all-column-stats

2.2 Table Metadata Loading -- loadValidWriteIdList
* Meaning: fetch ValidWriteIds from HMS
The code path is HdfsTable.loadValidWriteIdList()
* Metric: no metric recorded for this one. Instead, a debug log is
generated.

2.3 Table Metadata Loading -- storage metadata loading(standalone metric)
* Meaning: Storage related to file system operations during metadata
loading.(The amount of time spent loading metadata from the underlying storage layer.)
* Metric: we rename it to load-duration.storage-metadata. This is a metric introduced by
IMPALA-7322

2.4 Table Metadata Loading -- load all partitions
* Meaning: Load all partitions time, including fetching all partitions
from HMS and loading all partitions. The code path is
MetaStoreUtil.fetchAllPartitions() and HdfsTable.loadAllPartitions()
* Metric: load-duration.all-partitions

2.4.1 Table Metadata Loading -- load all partitions -- load file metadata
* Meaning: The file metadata loading for all all partitions. (This is
part of 2.4). Code path: loadFileMetadataForPartitions() inside
loadAllPartitions()
* Metric: load-duration.all-partitions.file-metadata

C. Extra thing in this commit:
1. Add PrintUtils.printTimeNs for PrettyPrint time in FrontEnd
2. Add explanation for table loading manager

D. Test:
1. Add Unit tests for PrintUtils.printTime() function
2. Manual describe table and verify the table loading metrics are
correct.

Change-Id: I5381f9316df588b2004876c6cd9fb7e674085b10
Reviewed-on: http://gerrit.cloudera.org:8080/14611
Reviewed-by: Vihang Karajgaonkar <vihang@cloudera.com>
Tested-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>


