Thanks [~ayushtkn] for opening this.
Can you give an overview of what the fix is?
* Why is {{getInstanceStorageDir()}} not working and you have to use the full method?
* Why you create the file later now?

Thanx [~elgoiri] for the comment.
 Regarding the overview : IIUC The test was basically aiming that if we fail a volume in a datanode containing a replica of block the block would get into the state of UnderReplicated and this we were checking whether it is underReplicated or not in the assertion.The reason for it failing here if we analyze by the logs was the since this file creation was above the assertion check.By the time this file is created and we wait for it to get its 3 replicas.In that time this under replicated gets replicated and this is the catch.Now when we check the assertion it says no underReplicated blocks since that block got replicated.So to counter this I placed this creation of file below this check to eliminate the time to get the block replicated.
 * InstanceStorageDir() works perfect in most cases but I encountered a scenario in my local not here in jenkins that that the block was not in storage dir that we failed. So to make sure that the volume that we fail is for sure the volume that has the replica.I moved to  the alternative used here.
 * File Creation was done earlier too.One Context I thought was it was to make the disk report error and get the block reports and identify the block that we are aiming as underReplicated.For sure it can be removed.I didn't remove it completely just because of one doubt that isn't there any other purpose being checked by this file creation like whether we are able add file after volume failure or not.Though it seems to be unrelated to the scenario which we are checking . If agreed that it has now in the present situation no relation with the test we can remove it. :)

Thanks for the explanation.
Did this ever pass then? Can you link the JIRAs that introduced the issue?

For the new InstanceStorageDir approach, we should make it into a function and potentially in one of the utils classes.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 44s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 23m 10s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  4s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 26s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m  2s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 24s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 54s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 17s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 11s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 55s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 6 new + 57 unchanged - 0 fixed = 63 total (was 57) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 15s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 57s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 31s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}101m 50s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 30s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}170m 15s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.TestLeaseRecovery2 |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:4b8c2b1 |
| JIRA Issue | HDFS-13945 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12941624/HDFS-13945-02.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 2ec31c6c8f1e 3.13.0-153-generic #203-Ubuntu SMP Thu Jun 14 08:52:28 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 5c8d907 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_181 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/25157/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/25157/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/25157/testReport/ |
| Max. process+thread count | 2976 (vs. ulimit of 10000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/25157/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 22s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 39s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 59s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  9s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m  9s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  7s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 49s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  6s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  4s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 21s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  0s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}110m 39s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}169m  4s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.TestReconstructStripedFile |
|   | hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics |
|   | hadoop.hdfs.server.namenode.TestFSImage |
|   | hadoop.hdfs.client.impl.TestBlockReaderLocal |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:4b8c2b1 |
| JIRA Issue | HDFS-13945 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12941675/HDFS-13945-03.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux e88f39d5c7bd 3.13.0-153-generic #203-Ubuntu SMP Thu Jun 14 08:52:28 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 7093afd |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_181 |
| findbugs | v3.1.0-RC1 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/25164/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/25164/testReport/ |
| Max. process+thread count | 2621 (vs. ulimit of 10000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/25164/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



The reason for failing supposedly was not actually it being replicated.It was the RedundancyMonitor that in 3 seconds after acknowledging the under replicated block changes it status to pendingReconstruction.which in turn during our wait in the supplier replicated that too.
 Yes it passes when we check the status within this window.

So are we going with  [^HDFS-13945-03.patch] where we just check for the right number of blocks?

As far as I think the reason of failure was this only here the conversion to pendingReconstruction in 3 seconds by the RedundancyMonitor thread. Ensuring the volume I guess is not required because there are two blocks being written so one will go in the first volume for sure. I concluded that it was not there as it was not underReplicated and even not the replica for that in that vol was present so I thought it killed nothing but it was pendingReconstruction .If you feel there can be some other concerns other than this then we can add that too. :) 

Thanks [~ayushtkn] for working on this!

Before this patch, heartbeatCheck was invoked in the test before checking if there is any under replicated block, why is that not needed anymore?

Thanx [~knanasi] for the comment.
 IIUC The heartbeat check function has much to do with the scenario of dead or decommissioning datanodes and doesn't seems to be serving as such any good purpose in favor of our test even before.As what we require is the reporting of disk error which would be done as part of the write process and the count which we would get as part of the next heart beat and this much will solve our purpose and to deal with the heartbeat interval we were here already very well equipped with the supplier which would provide us the liberty to wait for the correct heartbeat.So I don't think there was or is any need of the heartbeatCheck() function
 If there seems to be any other related purpose being handled by it which I might have missed.We can for sure add it back. :)

[~ayushtkn], thanks for clarifying!

Looking into the git history of the test, it looks like, the heartbeatCheck() function was used instead of checking the metric periodically (implemented in HDFS-7208) and it seemed to be flaky that way. So you are right, that is not needed anymore, because we wait for the heartbeat with the periodic checking anyway.

bq. As far as I think the reason of failure was this only here the conversion to pendingReconstruction in 3 seconds by the RedundancyMonitor thread. Ensuring the volume I guess is not required because there are two blocks being written so one will go in the first volume for sure. I concluded that it was not there as it was not underReplicated and even not the replica for that in that vol was present so I thought it killed nothing but it was pendingReconstruction
Thanks [~ayushtkn] for the deep dive. Analysis looks good.
+1, fix looks good to me.
Will commit later today.

Committed to trunk, branch-3.2 and branch-3.1

SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #15190 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/15190/])
HDFS-13945. TestDataNodeVolumeFailure is Flaky. Contributed by Ayush (vinayakumarb: rev 6e0e6daaf3215213c32cdffa79f3730d40e981ea)
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailure.java


