Started to work on this.

I've made the intended modification in the following branch: https://github.com/gaborgsomogyi/spark/blob/5598ce9227a3835a3e5de7279d27d89208815c4e/external/kafka-0-10-sql/src/test/scala/org/apache/spark/sql/kafka010/KafkaDelegationTokenSuite.scala#L53-L58

The new way is to move all the setup code into the retry area. The main problem is that Kafka is unable to do authentication in the second attempt:
{code:java}
20/05/11 06:54:03 INFO Selector: [AdminClient clientId=adminclient-2] Failed authentication with localhost/127.0.0.1 (Authentication failed during authentication due to invalid credentials with SASL mechanism GSSAPI)
20/05/11 06:54:03 INFO HadoopDelegationTokenManager: Attempting to login to KDC using principal: client/localhost@EXAMPLE.COM
20/05/11 06:54:03 INFO HadoopDelegationTokenManager: Successfully logged into KDC.
20/05/11 06:54:03 ERROR NetworkClient: [AdminClient clientId=adminclient-2] Connection to node -1 (localhost/127.0.0.1:54492) failed authentication due to: Authentication failed during authentication due to invalid credentials with SASL mechanism GSSAPI
{code}

I think this would be the bulletproof way but somehow it's not working. JVM is somehow caching obtained TGTs which I've discovered here: https://github.com/apache/spark/pull/27877#issuecomment-597554402
The new approach may suffer from this issue.


I've tried to reproduce the issue where the following exception comes {quote}Client not found in Kerberos database{quote} without success.
The only thing what I can imagine is the following:
* KDC started and sets it's kdc.conf
* KDC adds user
* Test starts
* Another KDC starts which overwrites kdc.conf
* Test tries to authenticate but it connects to the second KDC which doesn't have the user

I think it would be good to print out the actual kdc.conf when test failed. This way we can conclude on this possibility.

Hmmm, I've taken a look at the log and found only 2 type of kdc.conf set entry:

Initially:
{code:java}
Java config name: null
{code}

Later multiple times:
{code:java}
Java config name: /home/jenkins/workspace/SparkPullRequestBuilder@3/external/kafka-0-10-sql/target/tmp/org.apache.spark.sql.kafka010.KafkaDelegationTokenSuite/spark-ee403853-36d2-4c22-a84b-4c6ae8c016b0/1588824578912/krb5.conf
{code}

This tells to me that the krb5.conf is probably not changed (at least not through API).


As I see there are no artifacts for previous jenkins executions which blocks further investigation.
Without logs can't really tell what has happened with KDC.

[~srowen] [~dongjoon] is it possible to reach previous jenkins execution artifacts somehow?


They get removed after a certain period of time; if it's not accessible any more I think it's just gone.

Ah, as I see only the successful build have artifacts for certain time. Where it's not really helpful :)
I think I'm stuck here because of not available logs...


AFAIK, both successful build and failure build have the same life time, [~gsomogyi].Â 

Usually, the flaky test, we can search the result by the test. However, it's `SuiteSelector` issue in this case. :(
{code}
Failed
 org.apache.spark.sql.kafka010.KafkaDelegationTokenSuite.(It is not a test it is a sbt.testing.SuiteSelector)
{code}

