I have some WiP work here, [this is the spec document|https://github.com/steveloughran/hadoop/blob/s3/HADOOP-13327-outputstream-spec/hadoop-common-project/hadoop-common/src/site/markdown/filesystem/outputstream.md]

Patch 001 of an output stream specification; covering what is meant to happen, and what really does.

There's no tests for this, really the tests should be looking to see what the FS does on flush/hflush and hsync and verify that it matches whatever the declared behaviour is; we'll add contract test options for inconsistent metadata, writeback in chunks and flush-when-closed as options.

And of course, we'll need to have a test which probes the dest FS for data being written without relying on just the getFileStatus() length, because of course, HDFS under-reports there while the file is open. It'll need a stream.hflush() followed by open(path).read() != -1 as the check for a file not being empty

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 13m 37s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m  8s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  5m 47s{color} | {color:green} branch-2 passed with JDK v1.8.0_131 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 37s{color} | {color:green} branch-2 passed with JDK v1.7.0_121 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 26s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 16s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 40s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 41s{color} | {color:green} branch-2 passed with JDK v1.8.0_131 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 51s{color} | {color:green} branch-2 passed with JDK v1.7.0_121 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 40s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  5m 33s{color} | {color:green} the patch passed with JDK v1.8.0_131 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  5m 33s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 34s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 34s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 25s{color} | {color:green} hadoop-common-project/hadoop-common: The patch generated 0 new + 3 unchanged - 4 fixed = 3 total (was 7) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 15s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 21 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 54s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 42s{color} | {color:green} the patch passed with JDK v1.8.0_131 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 51s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 25s{color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_121. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 74m 59s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:8515d35 |
| JIRA Issue | HADOOP-13327 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12865793/HADOOP-13327-branch-2-001.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux a13191b3b9c0 3.13.0-106-generic #153-Ubuntu SMP Tue Dec 6 15:44:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | branch-2 / 5ca4f0f |
| Default Java | 1.7.0_121 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_131 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_121 |
| findbugs | v3.0.0 |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/12218/artifact/patchprocess/whitespace-eol.txt |
| JDK v1.7.0_121  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/12218/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12218/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



HADOOP-13327 OutputStream. Syncable and StreamCapabilities

* The docs state that you must rely on StreamCapabilities.hasCapability() as the cue as to whether Syncable methods are supported; tests are there to see what goes on The Azure and ADL streams now support this interface.
* Issues with FSOutputSummer are documented. It needs to make close() at-most-once idempotent & check for it being closed in write(int); explicitly downgrade flush() to no-op.
* Object store semantics listed

I don't think we've looked at `FSOutputSummer` hard enough to see what it does wrong, not for a while. This does need fixing, but I'd rather delay that until Hadoop 3.1; something, somewhere, will be using it wrong.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 6 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 57s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 24s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  6s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  4m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 53s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 32s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 32s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 32s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  4s{color} | {color:orange} root: The patch generated 3 new + 38 unchanged - 3 fixed = 41 total (was 41) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  4m  5s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 40 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  4s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 50s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m  1s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m  8s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 65m 44s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 36s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 17s{color} | {color:green} hadoop-azure in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 43s{color} | {color:green} hadoop-azure-datalake in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 36s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}178m 46s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.TestKDiag |
|   | hadoop.net.TestDNS |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-13327 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12882859/HADOOP-13327-002.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |
| uname | Linux ac211ceacc06 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 267e19a |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13080/artifact/patchprocess/diff-checkstyle-root.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/13080/artifact/patchprocess/whitespace-eol.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13080/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13080/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13080/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-tools/hadoop-aws hadoop-tools/hadoop-azure hadoop-tools/hadoop-azure-datalake U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13080/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



Thanks, cleaning up the specification and requirements for Filesystem is very helpful!

Some general feedback:

1) Is it too late to combine StreamCapabilities and Syncable?  StreamCapabilities and Syncable should be one interface.  It should have methods canHFlush, canHSync, hFlush, and hSync.  Users would then check if a stream implements the interface, call canHFlush/canHSync, and then hFlush/hSync if supported.  The fact that we're creating a helper for this (FSImplementationUtils.supportsSyncable) indicates an issue with the interface design, so I'm wondering if it is too late to update existing interfaces, maybe a new interface should be defined (Syncable2) and all the implementations gradually updated.

2) FSImplementationUtils.CloseChecker.  This class provides validation and synchronization for managing the stream state. The synchronization support is lacking though, for example, if one thread is in a flush or write call and another thread calls close(). I'm not sure how helpful it is to have a common class like this versus everyone
doing it their own way, but for a helper class, I'd prefer something along the lines of:


{code:java}
// Stream has three states: open, error, close
class StreamState {
  // Change state to close
  // @return - true iff state transitions from open or error to close
  boolean setStateClosed();

  // Change state to error and stores first error so it can be re-thrown.
  // @return - null if state transitions from open to error
  // @return - non-null if state is error or close.
  IOException setStateError(IOException);

  // Validate state is open.  Throws if not in open state.
  void checkState() throws IOException;

  // acquire exclusive lock
  void acquireLock() throws IOException;

  // release lock
  void releaseLock();
}
{code}


Specific feedback:

FSImplementationUtils.java:
 L26 - import specific classes instead of using '*'
 L45-46 - Preconditions.checkNotNull(capability) or reverse the comparisons
 L102 - I recommend removing isOpen since it is redundant next to IsClosed.

filesystem.md
 L612 - Object stores can create (overwrite=false) an empty file as a
 marker. However, object stores which have overwrite=true sematics
 cannot implement this easily.

outputstream.md
 L23 - "sp" should be "so"
 L53-142 - Generally speaking, I think the message is better delivered
 thru clear descriptions.  The notation is somewhat ambiguous to me.
 L149 - If close() fails, subsequent calls should re-throw the IOException.

AbstractContractCreateTest.java
 L350-352 This could be reduced to out.canFlush() with some
 refactoring of the interfaces.  It is too much code as-is.

S3ABlockOutputStream.java
 L320 - Since S3ABlockOutputStream.close is not synchronized, it is
 possible for a thread to be in a call to flush or write at the same
time the stream is being closed by another thread.

Thanks, I'll look at these. I thought I'd made the new close util atomic by way of AtomicBoolean, but perhaps not

b1q. L53-142 - Generally speaking, I think the message is better delivered thru clear descriptions. The notation is somewhat ambiguous to me.

Ah, you've entered the world of "how do we define the semantics of our FS API in a way which can be used for implmentors, users and people writing tests". Which is where I must respecfully disagree


h3. Notation 

The notation [is essentially python|https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/site/markdown/filesystem/notation.md] working on the state of the inputs, S and, if the conditions are met producing a new state, S', describing the updated state of the system. 

Why Python? It lets us call "functions" maps, and people are happy with new items being added to maps, and concepts like "kesy" and "values" the way they wouldn't be if terms like "domain" and "range" of a function. It also lets us use Python list selection to work on the domain and range of functions the way we could otherwise do in set-theory notation with upside-down As, backward Es and the like . We want something to be broadly used, rather to scare people away.

h3. Model 

The [Core FS model|https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/site/markdown/filesystem/model.md]. It's incomplete, probably got bugs in, but it deliberately tries to describe a filesystem at its most abstract: a list of path elements mapping to files or directories; directories can have children but no data, files can have data but no children, delete makes things go away, rename moves stuff, etc. The output stream is essentially the rounding off the earlier work with the bit we'd always avoid.

If we were going to change the spec, I'd rather go the other way, to something more rigorous, specifically TLA+ specs: more standard, capable of modelling concurrency requirements, the TLA+ toolkit can validate specs, [in use elsewhere|http://lamport.azurewebsites.net/tla/formal-methods-amazon.pdf]. The problem here is that when I do put up a bit of TLA+, such as for [a consistent blobstore|https://issues.apache.org/jira/secure/attachment/12865161/objectstore.pdf] nobody every finds bugs in it. Which means that people aren't reading it that rigorously. 

I know we could do with strictness in what is essentially the core API definitions for what is the open source stack for some of the largest applications in the world, but really, short term, my main concern is trying to make sure the HDFS team actually keep what we have up to date with public methods and interfaces they add, so that more users than one or two know to call it,  other FS implementations know what to do (Hello CanUnbuffer!) (HADOOP-14748, HADOOP-14747,...), and we have some tests which actually test which tries to break those implementations.

So no, not going to change. Sorry

The notation documentation makes sense.  We hadn't been properly introduced, so I saw your patch and didn't understand.  Thanks for the links!

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  5s{color} | {color:red} HADOOP-13327 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HADOOP-13327 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12882859/HADOOP-13327-002.patch |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13683/console |
| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



Reviewing this again. 

[~tmarquardt] : regarding your proposal that Stream.close() rethrows whichever exception was thrown earlier, I could add that to the {{CloseChecker}} . If it had a setter of an IOE, that could be served and subsequent close attempts would rethrow it.

I'm curious about what we *should* do here. What it does do is at least consistently say "this upload failed", so avoids giving the false impression that you can implement your own retry logic around close().






| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  6s{color} | {color:red} HADOOP-13327 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HADOOP-13327 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12882859/HADOOP-13327-002.patch |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14357/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



Patch 003.

in sync with trunk, with more on the locking, including trying to keep flush() involved here.

I think I'm going to split that out into its own code, and have an initial patch here purely of spec & tests, leaving the S3A changes to one side. Why? That lock stuff is complex and needs review on its own...and that shouldn't hold up having our syncable/output stream spec written down.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 21s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 7 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 20s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 25m 42s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 28m  9s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 59s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} shadedclient {color} | {color:red}  6m 18s{color} | {color:red} branch has errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 40s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m  4s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  3m 32s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 28m  5s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 28m  5s{color} | {color:red} root generated 2 new + 1536 unchanged - 0 fixed = 1538 total (was 1536) {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 21s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  4m  2s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 41 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  4s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:red}-1{color} | {color:red} shadedclient {color} | {color:red}  1m 59s{color} | {color:red} patch has errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  6m 42s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m 12s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 25s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}101m  5s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  4m 45s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 17s{color} | {color:green} hadoop-azure in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 57s{color} | {color:green} hadoop-azure-datalake in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 42s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}238m 14s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped |
|   | hadoop.hdfs.server.datanode.TestDataNodeUUID |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HADOOP-13327 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12928014/HADOOP-13327-003.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux cf64bb1b1e81 3.13.0-137-generic #186-Ubuntu SMP Mon Dec 4 19:09:19 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 43d994e |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_171 |
| findbugs | v3.1.0-RC1 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/14784/artifact/out/diff-compile-javac-root.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/14784/artifact/out/whitespace-eol.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/14784/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14784/testReport/ |
| Max. process+thread count | 2868 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-tools/hadoop-aws hadoop-tools/hadoop-azure hadoop-tools/hadoop-azure-datalake U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14784/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m 30s{color} | {color:red} HADOOP-13327 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HADOOP-13327 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12928014/HADOOP-13327-003.patch |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15425/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



Bulk update: moved all 3.2.0 non-blocker issues, please move back if it is a blocker.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m 10s{color} | {color:red} https://github.com/apache/hadoop/pull/532 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| GITHUB PR | https://github.com/apache/hadoop/pull/532 |
| JIRA Issue | HADOOP-13327 |
| Console output | https://builds.apache.org/job/hadoop-multibranch/job/PR-532/1/console |
| Powered by | Apache Yetus 0.9.0 http://yetus.apache.org |


This message was automatically generated.



| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  7s{color} | {color:red} HADOOP-13327 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HADOOP-13327 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12928014/HADOOP-13327-003.patch |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15997/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



There's a PR up for this: https://github.com/apache/hadoop/pull/575

This patch has been sitting around neglect for a long time. I know, this tightening down of "What things do" is a part time activity for all of us, but its important and once it's in people will appreciated it. Can I get some more reviews please? Thanks

I did my initial review and commented on the PR.

[~stevel@apache.org], thanks for working on this.

I have some feedback of contract tests after I applied [https://github.com/apache/hadoop/pull/575.patch] .

testHSync against pseudo-distributed HDFS worked fine.

testHSync against WASB failed. hadoop-tools/hadoop-azure/src/test/resources/abfs.xml should be fixed too.
{code:java}
[INFO] Running org.apache.hadoop.fs.azurebfs.contract.ITestAbfsFileSystemContractCreate
[ERROR] Tests run: 12, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 4.267 s <<< FAILURE! - in org.apache.hadoop.fs.azurebfs.contract.ITestAbfsFileSystemContractCreate
[ERROR] testHSync(org.apache.hadoop.fs.azurebfs.contract.ITestAbfsFileSystemContractCreate)  Time elapsed: 0.119 s  <<< FAILURE!
java.lang.AssertionError: hflush support expected:<false> but was:<true>
        at org.junit.Assert.fail(Assert.java:88)
        at org.junit.Assert.failNotEquals(Assert.java:834)
        at org.junit.Assert.assertEquals(Assert.java:118)
        at org.apache.hadoop.fs.contract.AbstractContractCreateTest.testHSync(AbstractContractCreateTest.java:355)
        ...
{code}
Splitting the patch by project-wise (common, aws, azure) would make reviewing easier if you like.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  6s{color} | {color:red} HADOOP-13327 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HADOOP-13327 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12928014/HADOOP-13327-003.patch |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/16395/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  8s{color} | {color:red} HADOOP-13327 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HADOOP-13327 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12928014/HADOOP-13327-003.patch |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/16684/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



Bulk update: moved all 3.3.0 non-blocker issues, please move back if it is a blocker.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m 12s{color} | {color:red} HADOOP-13327 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HADOOP-13327 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12928014/HADOOP-13327-003.patch |
| Console output | https://ci-hadoop.apache.org/job/PreCommit-HADOOP-Build/76/console |
| versions | git=2.17.1 |
| Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |


This message was automatically generated.



