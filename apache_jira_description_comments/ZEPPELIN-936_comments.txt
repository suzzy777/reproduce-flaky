Github user Leemoonsoo commented on the issue:

    https://github.com/apache/zeppelin/pull/1078
  
    I think the reason SparkRTest() failing was because of resource.
    pySpark() test creates 33 python processes (num core + 1) and that seems make unable to run SparkRTest().
    
    I have changed `spark.core.max` property to 2 for CI test, so now only 3 python processes are created. Triggered CI couple of times with these changes. I still see some CI failure by network fault or the other flaky tests, but can not see SparkRTest() failure anymore.
    
    I'm merging it into master and branch-0.6 as a hotfix.


Github user asfgit closed the pull request at:

    https://github.com/apache/zeppelin/pull/1078


