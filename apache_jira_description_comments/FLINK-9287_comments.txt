Yes, indeed there is such bug. The problem boils down to {{org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer011#abort}} being used for both aborting transactions and closing them at the end of the operator's lifecycle. For EXACTLY_ONCE in both cases we should be closing {{FlinkKafkaProducer}} but for AT_LEAST_ONCE and NONE we should be closing them only during operator close - which is not happening.

I'm not sure, but maybe we should split EXACTLY_ONCE and NON-EXACTLY_ONCE implementations, instead of trying to squeeze in both of them at the same time into one class. 

CC:
[~tzulitai]  [~gjy]

GitHub user pnowojski opened a pull request:

    https://github.com/apache/flink/pull/5952

    [FLINK-9287][kafka] Properly clean up resources in non EXACTLY_ONCE FlinkKafkaProducer011

    Previously FlinkKafkaProducer was not being closed for AT_LEAST_ONCE and NONE Semantics when closing FlinkKafkaProducer011. This was leading to resources leaking (for example increasing number of active threads). 
    
    ## Verifying this change
    
    This bug fix might be hard to test automatically. This PR adds a new test proposal in separate commit, however it might be flaky if there are other tests being executed in parallel.
    
    ## Does this pull request potentially affect one of the following parts:
    
      - Dependencies (does it add or upgrade a dependency): (yes / **no**)
      - The public API, i.e., is any changed class annotated with `@Public(Evolving)`: (yes / **no**)
      - The serializers: (yes / **no** / don't know)
      - The runtime per-record code paths (performance sensitive): (yes / **no** / don't know)
      - Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: (yes / **no** / don't know)
      - The S3 file system connector: (yes / **no** / don't know)
    
    ## Documentation
    
      - Does this pull request introduce a new feature? (yes / **no**)
      - If yes, how is the feature documented? (**not applicable** / docs / JavaDocs / not documented)


You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/pnowojski/flink f9287

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/flink/pull/5952.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #5952
    
----
commit c9139a90dd6a2afb25a4eb3102e1abedf90d8f5f
Author: Piotr Nowojski <piotr.nowojski@...>
Date:   2018-05-03T13:50:53Z

    [FLINK-9287][kafka] Properly clean up resources in non EXACTLY_ONCE FlinkKafkaProducer011
    
    Previously FlinkKafkaProducer was not being closed for AT_LEAST_ONCE and NONE Semantics
    when closing FlinkKafkaProducer011. This was leading to resources leaking (for example
    increasing number of active threads)

commit 5a1d0962f3fb92a87ee809b5a09106f5c4d05caf
Author: Piotr Nowojski <piotr.nowojski@...>
Date:   2018-05-03T13:53:40Z

    [FLINK-9287][kafka] Ensure threads count do not grow in FlinkKafkaProducer011

----


Github user tzulitai commented on the issue:

    https://github.com/apache/flink/pull/5952
  
    Would filtering the thread count by thread name be helpful here?
    
    Another possible approach to test this:
    Maybe we can simply verify that the current transaction producer is closed after the cleanup?
    This would require making the `getCurrentTransaction()` method visible for tests, though. We'll also need to have a `isClosed()` method on the `FlinkKafkaProducer`.


Github user tzulitai commented on the issue:

    https://github.com/apache/flink/pull/5952
  
    As discussed offline, both approaches I mentioned wouldn't seem to work.
    I'll merge as is, let's keep an eye on it to see if the test is flaky.


Github user asfgit closed the pull request at:

    https://github.com/apache/flink/pull/5952


Merged.

1.6.0: c8657bf9dee23bc13a281423284644013de9b850
1.5.0: a1ca628a031d658c1cc33037ede7aa92d93814f7

