Hi [~CodingCat], thanks a lot for your reporting, mainly the problem is caused in here:

{code}
    eventually(timeout(1000 milliseconds), interval(100 milliseconds)) {
      assert(
        server.apis.leaderCache.keySet.contains(TopicAndPartition(topic, partition)),
        s"Partition [$topic, $partition] metadata not propagated after timeout"
      )
    }
{code}

which trying to verify if topic is created and propagated accordingly, currently the longest timeout is 1000 ms, which might be fine for local test, but probably it will be timeout if the machine is in high load. Actually I've tested in my local machine for several rounds, this issue is hard to reproduce.

I think a possible way is to increase the timeout (1000 ms) to a large value.



[~saisai_shao], yeah, I got up early to check whether the test case can pass in a lightly loaded jenkins, 

Same code, just rebased

https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/25323/consoleFull

It passed...

So I agree with you that it's just caused by the overloaded server

but I'm not sure prolonging the timeout duration is the right way to do...as it's still possible to have a "super overloaded" server to make that timeout again...


Yes, I agree with you that increasing the timeout may not be an elegant solution, always have chance to meet the timeout. Actually this code is referred to Kafka's unit test, I will try to dig into the Kafka code to see if I can find a better solution.

[~jerryshao] Any elegant solution for this? Or should we ust increase the timeout?

User 'tdas' has created a pull request for this issue:
https://github.com/apache/spark/pull/4342

I increased timeout to reduce flakiness. If you can think of a better solution, please send a PR

Hi TD, thanks a lot for your PR, currently I've no better solution instead of increasing the timeout threshold, as I remembered in the Kafka unit test, it also deal with this way, I will check again to see if we can solve this with elegant way.

