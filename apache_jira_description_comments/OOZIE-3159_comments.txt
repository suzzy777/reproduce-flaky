[~satishsaley] a couple of questions that makes reproduction more easy:
* did you set {{oozie.action.mapreduce.needed.for.spark}} to {{true}}?
* what other classpath collisions did you encounter while trying to submit a Spark action?
* can you please attach {{workflow.xml}} of the Spark action? Submission mode {{standalone}} / {{yarn client}} / {{yarn cluster}} would be of extreme interest
* can you please tell the exact Spark version you want to submit the workflow?

[~satishsaley] thanks for spotting this!

Spark relies on a lot of hadoop classes that are in hadoop-common (for example Configuration). Without those dependencies, it simply cannot work with Yarn / HDFS. For example, look at Spark documentation and source code:
[Documentation|https://github.com/apache/spark/blob/39e2bad6a866d27c3ca594d15e574a1da3ee84cc/docs/hadoop-provided.md]
[HadoopFileLinesReader|https://github.com/apache/spark/blob/b03b4adf6d8f4c6d92575c0947540cb474bf7de1/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/HadoopFileLinesReader.scala#L23]

I have seen similar issues earlier.

I tested with pseudo Hadoop {{2.6.0}} that setting {{oozie.action.mapreduce.needed.for.spark}} to {{true}} in {{oozie-site.xml}} and submitting spark example workflow 
- with {{master}} set to {{local\[*]}} succeeds
- with {{master}} set to {{yarn}}. Executor job fails
{code}
Exception in thread "main" java.lang.NoClassDefFoundError: org/apache/spark/Logging
        at java.lang.ClassLoader.defineClass1(Native Method)
        at java.lang.ClassLoader.defineClass(ClassLoader.java:763)
        at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
        at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)
        at java.net.URLClassLoader.access$100(URLClassLoader.java:73)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:368)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:362)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:361)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
        at org.apache.spark.deploy.yarn.ExecutorLauncher$.main(ApplicationMaster.scala:674)
        at org.apache.spark.deploy.yarn.ExecutorLauncher.main(ApplicationMaster.scala)
Caused by: java.lang.ClassNotFoundException: org.apache.spark.Logging
        at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
        ... 14 more
{code}

Looking at the {{launcher_container.sh}}  of the executor:
{code}
export CLASSPATH="$PWD:$PWD/__spark_conf__:$PWD/__spark__.jar:$HADOOP_CONF_DIR:$HADOOP_COMMON_HOME/share/hadoop/common/*:$HADOOP_COMMON_HOME/share/hadoop/common/lib/*:$HADOOP_HDFS_HOME/share/hadoop/hdfs/*:$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*:$HADOOP_YARN_
HOME/share/hadoop/yarn/*:$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOM
E/share/hadoop/mapreduce/lib/*"
{code}

files in the container directory of the executor:
{code}
__spark__.jar -> /tmp/hadoop-asasvari/nm-local-dir/usercache/asasvari/filecache/11/spark-yarn_2.10-1.6.1.jar
__spark_conf__ -> /tmp/hadoop-asasvari/nm-local-dir/usercache/asasvari/filecache/10/__spark_conf__2056190651119303721.zip
{code}
As you see there are not too many file and {{spark-yarn_2.10-1.6.1.jar}} does not contain  {{org.apache.spark.Logging}} (it is included in {{spark-core_2.10-1.6.1.jar}} but that jar is not localized in the executor container's dir).
In {{spark_conf}} I can see {{spark_conf__.properties}} where a lot of properties are set, but some of them might not take any effect (runtime properties?).  [~gezapeti] can this be related to OOZIE-3112? I was unable to add extra dependencies or set classpath (tried "spark.executor.extraClassPath" and also "spark.executor.extraLibraryPath".

{quote}
 Satish Subhashrao Saley a couple of questions that makes reproduction more easy:
did you set oozie.action.mapreduce.needed.for.spark to true?
{quote}

Yes. I tried setting {{oozie.action.mapreduce.needed.for.spark}}, but we read this property from launcherConf 
https://github.com/apache/oozie/blob/branch-5.0.0-beta1/core/src/main/java/org/apache/oozie/action/hadoop/JavaActionExecutor.java#L1578
{code}
        final boolean configuredValue = ConfigurationService.getBooleanOrDefault(launcherConf, configurationKey, defaultValue);
{code}
This is not available in launcherConf. To make it available in launcherConf, it has to be prefixed with {{oozie.launcher.}}
After I set {{oozie.launcher.oozie.action.mapreduce.needed.for.spark}} to {{true}} (or {{oozie.launcher.oozie.action.mapreduce.needed.for}} to {{true}} like I mentioned in jira description). Then it put mapreduce jars in classpath. 

We need to fix this as well.

bq. what other classpath collisions did you encounter while trying to submit a Spark action?

After I did above, there was collision due to servlet-api-2.5.jar.

{quote}can you please attach workflow.xml of the Spark action? Submission mode standalone / 
yarn client / yarn cluster would be of extreme interest
{quote}
I used the out of box example with yarn-cluster mode. https://github.com/apache/oozie/tree/master/examples/src/main/apps/spark

bq. can you please tell the exact Spark version you want to submit the workflow?
Spark version is spark-1.6.1-bin-hadoop2.6

{quote}
Spark relies on a lot of hadoop classes that are in hadoop-common (for example Configuration). Without those dependencies, it simply cannot work with Yarn / HDFS. For example, look at Spark documentation and source code:
Documentation
HadoopFileLinesReader
{quote}
True. But hadoop-common is already available via $HADOOP_COMMON_HOME/share/hadoop/common/*
Following is from launch_container.sh (without adding mapreduce jars)
{code} 
 export CLASSPATH="$PWD:$PWD/*:$HADOOP_CONF_DIR:$HADOOP_COMMON_HOME/share/hadoop/common/*:$HADOOP_COMMON_HOME/share/hadoop/common/lib/*:$HADOOP_HDFS_HOME/share/hadoop/hdfs/*:$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*:$HADOOP_YARN_HOME/share/hadoop/ya    rn/*:$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*"
{code}

[~satishsaley]: If you set {{oozie.action.mapreduce.needed.for.spark}} to true in {{oozie-site.xml}}, the [defaultValue|https://github.com/apache/oozie/blob/branch-5.0.0-beta1/core/src/main/java/org/apache/oozie/action/hadoop/JavaActionExecutor.java#L1571] will be true and MR jars will be added.

Regarding the actual MapReduce dependency in [SparkArgsExtractor|https://github.com/apache/oozie/blob/9038fbc9592995f1bd538502126bc380cdebaec5/sharelib/spark/src/main/java/org/apache/oozie/action/hadoop/SparkArgsExtractor.java#L309], DistributedCache is required because of
{code}
SparkMain.fixFsDefaultUrisAndFilterDuplicates(DistributedCache.getCacheFiles(actionConf));
{code}

This specific line was introduced by {{OOZIE-2923 Improve Spark options parsing}}. However, if I look at the history of the Spark sharelib, DistirbutedCache was present from the beginning: see {{OOZIE-1983 Add spark action executor}}, then OOZIE-2547 introduced fixFsDefaultUris.

It might be better to only add hadoop-mapreduce-client-core & hadoop-mapreduce-client-common jar instead of hadoop-common jar that brings too many things and causes issues like the one you described (and added to the classpath by the launcher script anyway). So I uploaded MR jars, removed hadoop common this, updated sharelib and the Spark workflow succeeded.

However, in an earlier release, 4.2.0, Oozie required the spark-assembly jar to be present in the Spark ShareLib (see https://oozie.apache.org/docs/4.2.0/DG_SparkActionExtension.html). That assembly includes a lot of hadoop related classes.

You are also right that HADOOP_COMMON_HOME is referenced when CLASSPATH is set in the launcher script.

[~satishsaley], [~andras.piros], [~gezapeti] can you take a look at the attached patch?

Testing done:
- {{mvn  clean install assembly:single -DskipTests -Denforcer.skip=true -Dcheckstyle.skip=true -Dfindbugs.skip=true   -DtargetJavaVersion=1.8 -DjavaVersion=1.8   -Dhadoop.version-2.6.0  -Puber}}
- configured Oozie so that is talks with pseudo hadoop 2.6.
- modified {{examples/apps/spark/workflow.xml}} so that it also includes {{<mode>}}
{code:xml}
<workflow-app xmlns='uri:oozie:workflow:0.5' name='SparkFileCopy'>
    <start to='spark-node' />
    <action name='spark-node'>
        <spark xmlns="uri:oozie:spark-action:0.1">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <prepare>
                <delete path="${nameNode}/user/${wf:user()}/${examplesRoot}/output-data/spark"/>
            </prepare>
            <master>${master}</master>
            <mode>${mode}</mode>
            <name>Spark-FileCopy</name>
            <class>org.apache.oozie.example.SparkFileCopy</class>
            <jar>${nameNode}/user/${wf:user()}/${examplesRoot}/apps/spark/lib/oozie-examples.jar</jar>
            <arg>${nameNode}/user/${wf:user()}/${examplesRoot}/input-data/text/data.txt</arg>
            <arg>${nameNode}/user/${wf:user()}/${examplesRoot}/output-data/spark</arg>
        </spark>
        <ok to="end" />
        <error to="fail" />
    </action>
    <kill name="fail">
        <message>Workflow failed, error
            message[${wf:errorMessage(wf:lastErrorNode())}]
        </message>
    </kill>
    <end name='end' />
</workflow-app>
{code}
- CLUSTER mode with YARN: {{bin/oozie job -oozie http://localhost:11000/oozie   -config examples/apps/pyspark/job.properties  -run -DnameNode=hdfs://localhost:9000 -DjobTracker=localhost:8032 -Dmaster=yarn -Dmode=cluster}}, workflow succeeded
- CLIENT mode with YARN: {{bin/oozie job -oozie http://localhost:11000/oozie   -config examples/apps/pyspark/job.properties  -run -DnameNode=hdfs://localhost:9000 -DjobTracker=localhost:8032 -Dmaster=yarn -Dmode=client}}, workflow succeeded
- executed example workflows all except hive related ones, pyspark failed first because I have not uploaded required dependencies to Spark sharelib. After I set it up correctly, workflow succeeded.

Note: If you do not specify mode in the Spark workflow when {{master}} set to {{yarn}}, executor will fail. 

[Precommit build|https://builds.apache.org/job/PreCommit-OOZIE-Build/321/] finished, but results were not reported here:
{code}
Testing JIRA OOZIE-3159

Cleaning local git workspace

----------------------------

+1 PATCH_APPLIES
+1 CLEAN
-1 RAW_PATCH_ANALYSIS
    +1 the patch does not introduce any @author tags
    +1 the patch does not introduce any tabs
    +1 the patch does not introduce any trailing spaces
    +1 the patch does not introduce any line longer than 132
    -1 the patch does not add/modify any testcase
+1 RAT
    +1 the patch does not seem to introduce new RAT warnings
+1 JAVADOC
    +1 the patch does not seem to introduce new Javadoc warnings
+1 COMPILE
    +1 HEAD compiles
    +1 patch compiles
    +1 the patch does not seem to introduce new javac warnings
+1 There are no new bugs found in total.
 +1 There are no new bugs found in [docs].
 +1 There are no new bugs found in [sharelib/distcp].
 +1 There are no new bugs found in [sharelib/hive].
 +1 There are no new bugs found in [sharelib/spark].
 +1 There are no new bugs found in [sharelib/hive2].
 +1 There are no new bugs found in [sharelib/hcatalog].
 +1 There are no new bugs found in [sharelib/streaming].
 +1 There are no new bugs found in [sharelib/pig].
 +1 There are no new bugs found in [sharelib/sqoop].
 +1 There are no new bugs found in [sharelib/oozie].
 +1 There are no new bugs found in [examples].
 +1 There are no new bugs found in [client].
 +1 There are no new bugs found in [core].
 +1 There are no new bugs found in [tools].
 +1 There are no new bugs found in [server].
+1 BACKWARDS_COMPATIBILITY
    +1 the patch does not change any JPA Entity/Colum/Basic/Lob/Transient annotations
    +1 the patch does not modify JPA files
+1 TESTS
    Tests run: 2086
    Tests failed at first run:
TestJavaActionExecutor#testCredentialsSkip
    For the complete list of flaky tests, see TEST-SUMMARY-FULL files.
+1 DISTRO
    +1 distro tarball builds with the patch
{code}

Regarding the failure to adding commend to JIRA - it is in the build log:
{code}
Adding comment to JIRA
Unable to log in to server: https://issues.apache.org/jira/rpc/soap/jirasoapservice-v2 with user: hadoopqa.
 Cause: (404)404

test-patch exit code: 1
{code}

[~asasvari] thanks for the patch!

Couple of reflections:
* I think inside {{core/pom.xml}} the second {{hadoop-mapreduce-client-core}} dependency w/ {{version}} element should go to parent {{pom.xml}}
* I'm wondering whether w/ this patch OOZIE-3161 is also resolved ({{servlet-api-2.5.jar}} discrepancy)

[~andras.piros] thanks for the review. Are you looking at the second patch?
 https://issues.apache.org/jira/secure/attachment/12906130/OOZIE-3159-002.patch ? It changes:
{code}
pom.xml
sharelib/spark/pom.xml
{code}

I am not sure about the second remark. {{mvn dependency:tree}} shows {{mapreduce-client-core jar}} transitively pulls in {{servlet-api-2.5.jar}} via {{hadoop-yarn-common}}:
{code}
2254 [INFO] +- org.apache.hadoop:hadoop-mapreduce-client-core:jar:2.6.0:compile
2255 [INFO] |  +- org.apache.hadoop:hadoop-yarn-common:jar:2.6.0:compile
2256 [INFO] |  |  +- org.apache.hadoop:hadoop-yarn-api:jar:2.6.0:compile
...
2262 [INFO] |  |  +- javax.servlet:servlet-api:jar:2.5:compile
{code}

and also via the {{oozie-core}} jar via {{jetty-server}}:
{code}
[INFO] |  +- org.eclipse.jetty:jetty-server:jar:9.2.19.v20160908:provided
[INFO] |  |  +- javax.servlet:javax.servlet-api:jar:3.1.0:provided
{code}

These dependencies shall be excluded to avoid conflicts like OOZIE-3161 (where servlet-api is also pulled in via oozie-core). So yes, fixing this should resolve OOZIE-3161 too.

As a next step: I will exclude servlet-api and upload a new patch. 

Andras: Do you see other dependencies that might collide with Spark at runtime?

In the attached patch 003, I excluded javax-servlet servlet api in Spark sharelib (exclusion added to oozie-core, spark-streaming-flume)

Tests done:
 * Uploaded sharelib. Verified servlet api in HDFS:
hdfs://localhost:9000/user/asasvari/share/lib/lib_20180116150723/spark/javax.servlet-3.0.0.v201112011016.jar
 * executed test workflow -> succeeded

[~asasvari] thanks for the new patch! It seems to me that right now after a {{bin/mkdistro}} there is only one file w/ {{javax.servlet.FilterRegistration.class}} inside {{oozie-sharelib-spark}}.

Looks good to me +1

Now only javax.servlet-3.0.0.v201112011016.jar is present in Spark sharelib jars:

{code:java}
find share/lib/spark -name "*.jar" -exec sh -c '(jar -tvf {} | grep FilterRegistration 1>/dev/null && echo {})' \; 

share/lib/spark/javax.servlet-3.0.0.v201112011016.jar{code}
[~satishsaley] can you take a look? It shall solve OOZIE-3161 too. Spark example workflows succeeded on pseudo Hadoop 2.6.0.

Exclusion of {{<groupId>javax.servlet</groupId><artifactId>servlet-api</artifactId>}} is no op for {{<artifactId>spark-streaming-flume_${spark.scala.binary.version}</artifactId>}} as it is not fetching servlet-api. Please remove it from there. 

Exclusion of  {{<groupId>javax.servlet</groupId><artifactId>servlet-api</artifactId>}} is no op for {{<artifactId>oozie-core</artifactId>}} as it is a provided dependency. Please remove it from there.

bq.It shall solve OOZIE-3161 too. 
That issue is with {{jetty:servlet-api-2.5:jar}} which is fetched by {{org.mortbay.jetty:jetty:jar}}. So there I excluded it from {{<artifactId>spark-streaming-flume_${spark.scala.binary.version}</artifactId>}}
In master branch as well as 5.0.0-beta branch, we already excluded {{org.mortbay.jetty:jetty:jar}} from {{<artifactId>spark-streaming-flume_${spark.scala.binary.version}</artifactId>}}.
So, I will commit OOZIE-3161 only on branch-4.3.


I've built a distro with and without the patch and the new sharelib looks better. I'm glad it fixed Spark execution on a pseudodistributed Hadoop

+1

 

[~gezapeti] thanks for the review, committed to master

Closing issue; Oozie 5.0.0-beta1 is released

