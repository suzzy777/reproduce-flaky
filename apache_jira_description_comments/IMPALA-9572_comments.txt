[~norbertluksa] do you have any time to investigate this crash?

{noformat}
hadoopZeroCopyRead: ZeroCopyCursor#read failed error:
ReadOnlyBufferException: java.nio.ReadOnlyBufferException
	at java.nio.DirectByteBufferR.put(DirectByteBufferR.java:350)
	at org.apache.hadoop.crypto.CryptoInputStream.decrypt(CryptoInputStream.java:660)
	at org.apache.hadoop.crypto.CryptoInputStream.read(CryptoInputStream.java:728)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:193)
hadoopZeroCopyRead: ZeroCopyCursor#read failed error:
ReadOnlyBufferException: java.nio.ReadOnlyBufferException
	at java.nio.DirectByteBufferR.put(DirectByteBufferR.java:350)
	at org.apache.hadoop.crypto.CryptoInputStream.decrypt(CryptoInputStream.java:660)
	at org.apache.hadoop.crypto.CryptoInputStream.read(CryptoInputStream.java:728)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:193)
hadoopZeroCopyRead: ZeroCopyCursor#read failed error:
ReadOnlyBufferException: java.nio.ReadOnlyBufferException
	at java.nio.DirectByteBufferR.put(DirectByteBufferR.java:350)
	at org.apache.hadoop.crypto.CryptoInputStream.decrypt(CryptoInputStream.java:660)
	at org.apache.hadoop.crypto.CryptoInputStream.read(CryptoInputStream.java:728)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:193)
hadoopZeroCopyRead: ZeroCopyCursor#read failed error:
ReadOnlyBufferException: java.nio.ReadOnlyBufferException
	at java.nio.DirectByteBufferR.put(DirectByteBufferR.java:350)
	at org.apache.hadoop.crypto.CryptoInputStream.decrypt(CryptoInputStream.java:660)
	at org.apache.hadoop.crypto.CryptoInputStream.read(CryptoInputStream.java:728)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:193)
hadoopZeroCopyRead: ZeroCopyCursor#read failed error:
ReadOnlyBufferException: java.nio.ReadOnlyBufferException
	at java.nio.DirectByteBufferR.put(DirectByteBufferR.java:350)
	at org.apache.hadoop.crypto.CryptoInputStream.decrypt(CryptoInputStream.java:660)
	at org.apache.hadoop.crypto.CryptoInputStream.read(CryptoInputStream.java:728)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:193)
hadoopZeroCopyRead: ZeroCopyCursor#read failed error:
ReadOnlyBufferException: java.nio.ReadOnlyBufferException
	at java.nio.DirectByteBufferR.put(DirectByteBufferR.java:350)
	at org.apache.hadoop.crypto.CryptoInputStream.decrypt(CryptoInputStream.java:660)
	at org.apache.hadoop.crypto.CryptoInputStream.read(CryptoInputStream.java:728)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:193)
hadoopZeroCopyRead: ZeroCopyCursor#read failed error:
ReadOnlyBufferException: java.nio.ReadOnlyBufferException
	at java.nio.DirectByteBufferR.put(DirectByteBufferR.java:350)
	at org.apache.hadoop.crypto.CryptoInputStream.decrypt(CryptoInputStream.java:660)
	at org.apache.hadoop.crypto.CryptoInputStream.read(CryptoInputStream.java:728)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:193)
hadoopZeroCopyRead: ZeroCopyCursor#read failed error:
ReadOnlyBufferException: java.nio.ReadOnlyBufferException
	at java.nio.DirectByteBufferR.put(DirectByteBufferR.java:350)
	at org.apache.hadoop.crypto.CryptoInputStream.decrypt(CryptoInputStream.java:660)
	at org.apache.hadoop.crypto.CryptoInputStream.read(CryptoInputStream.java:728)
	at org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:193)
hadoopZeroCopyRead: ZeroCopyCursor#read failed error:
ReadOnlyBufferException: java.nio.ReadOnlyBufferException
	at java.nio.DirectByteBufferR.put(DirectByteBufferR.java:350)
	at org.apache.hadoop.crypto.CryptoInputStream.decrypt(CryptoInputStream.java:660)
	at org.apache.hadoop.crypto.CryptoInputStream.read(CryptoInputStream.java:728)
	at org.apache.hadoop.fs.FSDataIF0328 10:09:57.204267 17011 mem-util.h:40] d449a8a667d2bad3:d70ced0400000002] Check failed: current != nullptr 
*** Check failure stack trace: ***
    @          0x4e98fac  google::LogMessage::Fail()
    @          0x4e9a851  google::LogMessage::SendToLog()
    @          0x4e98986  google::LogMessage::Flush()
    @          0x4e9bf4d  google::LogMessageFatal::~LogMessageFatal()
    @          0x2c07534  impala::StrideWriter<>::StrideWriter()
    @          0x2c008d2  impala::BaseScalarColumnReader::FillPositionsInCandidateRange()
    @          0x2c731f6  impala::ScalarColumnReader<>::MaterializeValueBatchRepeatedDefLevel()
    @          0x2c54db0  impala::ScalarColumnReader<>::ReadValueBatch<>()
    @          0x2c1cde6  impala::ScalarColumnReader<>::ReadValueBatch()
    @          0x2bb4144  impala::HdfsParquetScanner::AssembleRows()
    @          0x2baefe4  impala::HdfsParquetScanner::GetNextInternal()
    @          0x2bacf5c  impala::HdfsParquetScanner::ProcessSplit()
    @          0x27dfa6a  impala::HdfsScanNode::ProcessSplit()
    @          0x27ded80  impala::HdfsScanNode::ScannerThread()
    @          0x27de0d3  _ZZN6impala12HdfsScanNode22ThreadTokenAvailableCbEPNS_18ThreadResourcePoolEENKUlvE_clEv
    @          0x27e054f  _ZN5boost6detail8function26void_function_obj_invoker0IZN6impala12HdfsScanNode22ThreadTokenAvailableCbEPNS3_18ThreadResourcePoolEEUlvE_vE6invokeERNS1_15function_bufferE
    @          0x1fc7d8d  boost::function0<>::operator()()
    @          0x258a886  impala::Thread::SuperviseThread()
    @          0x2592b0a  boost::_bi::list5<>::operator()<>()
    @          0x2592a2e  boost::_bi::bind_t<>::operator()()
    @          0x25929f1  boost::detail::thread_data<>::run()
    @          0x3dbf2e9  thread_proxy
    @     0x7f6f2e739e24  start_thread
    @     0x7f6f2b29d34c  __clone
{noformat}

from the impalad.ERROR



I think that there is a quite straightforward bug in the code that can occur with nested Parquet + page filtering:
https://github.com/apache/impala/blob/5ff7c6a7de76aac2623710b3e43ceed8ce7424c8/be/src/exec/parquet/parquet-column-readers.cc#L1315

pos_slot is only non-NULL if pos_slot_desc_  is non-NULL (so the query asks for the position of the collection), but we try to read the positions anyway, which leads to a DCHECK in StrideWriter.

Testing is a harder question - it is surprising if this a flaky test, as the same query in the same file should always hit this issue. My guess is that Hive created a bit different file that lead page filtering kicking in.

Yeah, I think Csaba is correct. Hopefully (and probably) the code would work fine without the DCHECK. Note that we cannot avoid callingÂ FillPositionsInCandidateRange because it also counts how many elements we can consume until the end of the "current candidate range" (it is a range not filtered by page statistics).

This query reproduces it:
{noformat}
select l_partkey from tpch_nested_parquet.customer.c_orders.o_lineitems where l_partkey < 10{noformat}

https://gerrit.cloudera.org/#/c/15598/

Commit e8f604a2139be2ee3f011e6f2ce71fa0dde26492 in impala's branch refs/heads/master from Csaba Ringhofer
[ https://gitbox.apache.org/repos/asf?p=impala.git;h=e8f604a ]

IMPALA-9572: Fix DCHECK in nested Parquet scanning

The issue occurred when there were skipped pages and a column
inside a collection was scanned, but its position was not needed.
The repetition level still needs to be read in this case, as the
skipped ranges are set in top level rows, so collection items
need to know which top level row do they belong to.

A DCHECK in StrideWriter's constructor was hit, otherwise the
code ran correctly in release mode. The DCHECK is moved to
functions where the condition would actually cause problems.

Testing:
- added and ran a regression test

Change-Id: I5e8ef514ead71f732c73f910af7fd1aecd37bb81
Reviewed-on: http://gerrit.cloudera.org:8080/15598
Reviewed-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>
Tested-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>


[~csringhofer] can we close this? Looks like a code fix went in.

[~tarmstrong]thanks, I forgot to close it.

