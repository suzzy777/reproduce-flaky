[~tsteinmaurer] you sure you don't see this in 3.11? looks like we ignore {{initialCapacity}} in 3.0 here: https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/utils/btree/BTree.java#L752 but not in 3.11: https://github.com/apache/cassandra/blob/cassandra-3.11/src/java/org/apache/cassandra/utils/btree/BTree.java#L777

[~marcuse], yes I think so. :-) TRUNK, locally checked out, calling hierarchy from {{BatchUpdatesCollector.getPartitionUpdateBuilder}} up to {{PartitionUpdate.Builder.rowBuilder}}

 !screenshot-2.png|width=100%! 

Thanks again.

Can you describe the workload used?  Work has been done to lower the heap usage so possible trunk is already fixed (but not in a beta release); would be good to try to replicate the reported issue 

[~dcapwell], code screen above is from local TRUNK, thus not strictly Beta2. [~marcuse] already contacted me via Slack. Thanks for your attention

In {{BatchStatement}} we have {{updatedRows()}} which is simply the number of statements in the batch - then we pre-size each partition update with that initial capacity. If the batch touches many different partitions we still use {{initialCapacity = statements.size()}} for each partition update which is what causes this. I'll work on a patch. 

Affects 3.11 and 4.0 but not earlier, before that we [ignored|https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/utils/btree/BTree.java#L752] {{initialCapacity}} 

[~marcuse], looking at CASSANDRA-15430 it looks like {{initialCapacity}} (CASSANDRA-13929) needs to be back-ported to 3.0, and this ticket also applied to 3.0. wdyt?

4.0: [patch|https://github.com/krummas/cassandra/commits/marcuse/16201-4.0-new], [cci|https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16201-4.0-new]
3.11: [patch|https://github.com/krummas/cassandra/commits/marcuse/16201-3.11-new], [cci|https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16201-3.11-new]
3.0: [patch|https://github.com/krummas/cassandra/commits/marcuse/16201-3.0-new], [cci|https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16201-3.0-new]

this focuses only on getMutations as that is where the OOM happened - there is much more to do, but I think these fixes are fairly safe and make performance slightly more acceptable


[~marcuse], first impression from our comparison infrastructure regarding the 3.0, 3.11 and 4.0 patches.

When having a look on 2 high-level metrics:
* JVM suspension, marked as "1" in the dashboard below
* Cassandra dropped messages, marked as "2" in the dashboard below

 !screenshot-3.png|width=100%! 

* Cassandra 3.0: No positive impact on suspension
* Cassandra 3.11: Huge positive impact on suspension
* Cassandra 4.0: Huge positive impact on suspension + no dropped messages with the patch

I will keep that running over the night and provide another set of JFR files for 3.0, 3.11 and 4.0 with the patch.

Thanks for your efforts!


Just went over the 40 patch. It looks good to me overall. Listing the nits/feedbacks below.
 * {{BatchStatement#updatedRows}} is no longer used. Please remove it
 * Maybe change the single table update detection from "{{!stmt.metadata.equals(metadata)"}} to "{{metadata != null && !stmt.metadata.equals(metadata)"}} in order to avoid the unnecessary comparison, although the cost of comparing with null should be negligible.
 * Please update the comments for {{perPartitionKeyCounts}} in both {{BatchUpdatesCollector}} and {{SingleTableUpdatesCollector}}, since the count is no longer an estimation.
 * Maybe remove the comment in {{ModificationStatement#requiresRead}} since the original implementation is removed.
 * The new implementation of {{BatchUpdatesCollector#getMutationBuilder}} is essentially the same as the previous {{computeIfAbsent}} except calling dk.getKey() twice. In the case of NativeDecoratedKey, the new implementation is slightly more expensive.
 * Similarly, the new implementation of {{BatchUpdatesCollector#keyspaceMap}} is equivalent to the previous {{computeIfAbsent}} except the supplied map being different. I think the {{computeIfAbsent}} approach looks more elegant. But it is just a style thing.

{quote}
I will keep that running over the night and provide another set of JFR files for 3.0, 3.11 and 4.0 with the patch.
{quote}

[~mck], in my provided OneDrive share provided on Oct 12, 2020 to you, there is now an additional sub-directory called {{_perffixes_jfr_20201027}}, which contains a new set of JFR files for all versions (including 2.1), with the patch applied to 3.0, 3.11 and 4.0.

[~marcuse], let me know if/how I could share the new JFR files with you as well.

Thank you [~tsteinmaurer]. I will take a look straight away.

Re-doing the screenshots as done in CASSANDRA-15430 for comparison.

h4. 2.1.18
Skipping these results as its based on the same C* code as in 15430, and I've confirmed the allocation counts and object sizes proportionally match. 


h4. 3.0.23
Allocations

* BatchMessage.execute - 1926411 
 ** BatchStatement.getMutations => 1008170 == 52% ( previously 60%)
 ** BatchStatement.executeWithoutConditions => 692322 == 36% ( previously 30%)
 !16201_jfr_3023_alloc.png|width=1000! 
Sizes by object under {{BatchStatement.getMutations}}
 !16201_jfr_3023_obj.png|width=600! 
With the invocation count only a 1%  decrease, the {{Object[]}} size has gone from 29.8GB down to 18.7GB, or 37% reduction. 

h4. 3.11.9
Allocations

* BatchMessage.execute - 1210873
 ** BatchStatement.getMutations => 396645 == 33% ( previously 62%)
 ** BatchStatement.executeWithoutConditions => 664650 == 55% ( previously 30%)
 !16201_jfr_3118_alloc.png|width=1000! 
Sizes by object under {{BatchStatement.getMutations}}
 !16201_jfr_3118_obj.png|width=600! 
The {{Object[]}} size has gone from 116GB down to 8.14GB. With the invocation count 40% that from CASSANDRA-15430, proportionally this is a 82% reduction.

h4. 4.0-beta3
Allocations

* BatchMessage.execute - 969189
 ** BatchStatement.getMutations => 410739  ==  42% ( previously 70%)
 ** BatchStatement.executeWithoutConditions => 425337 == 44% ( previously 23%)
 !16201_jfr_40b3_alloc.png|width=1000! 
Sizes by object under {{BatchStatement.getMutations}}
 !16201_jfr_40b3_obj.png|width=600! 
The {{Object[]}} size has gone from 129GB down to 8.52GB. With the invocation count 30% that from CASSANDRA-15430, proportionally this is a 78% reduction.



Similar to the metrics shown above from [~tsteinmaurer], 3.11 and 4.0 patches show the most improvement. From my understanding of 15430 and this patch, this makes sense.

[~marcuse], can you check these^ numbers and see if they align with your expectations.

[~mck], thanks a lot for the extensive follow-up. In our tests, from where the actual JFR files come from, we now see, that Cassandra 3.11 and Cassandra 4.0 is basically on the same level than 3.0 again, or even slightly better than 3.0, but 2.1 unbeaten :-)

Do you see any further improvements in regard to 2.1 vs. 3.0/3.11/4.0? Following chart is an AVG for last 24hrs on a bunch of metrics, for all versions with the patch applied for 3.0/3.11/4.0, processing the same ingest. The only main difference here is, that 2.1 is using STCS for our timeseries tables, whereas 3.0+ is using TWCS.
 !screenshot-4.png|width=100%! 

So, in short:
|| ||Cassandra 2.1||Cassandra 3.0 Patched (Rel. diff to 2.1)||Cassandra 3.11 Patched (Rel. diff to 2.1)||Cassandra 4.0 Patched (Rel. diff to 2.1)||
|AVG CPU|52,86%|61,43% (+16,2%)|61,04% (+15,5%)|75,06% (+42%)|
|AVG Suspension|3,76%|6,13% (+63%)|5,74% (+52,7%)|5,60% (+48,9%)|

But for *Cassandra 3.11* and *Cassandra 4.0*, this was a huge step forward! Thanks a lot!

The numbers make sense, we should file a followup ticket for more improvement but given the obvious bug fix for the multi-partition batch statement case, I think we should get these patches reviewed and committed

Out of the ticket scope… why are the microbench classes all in the {{org.apache.cassandra.test.microbench}} ? They are already separate under {{src/testmicrobench/}}, and by re-packaging them like this it means accessed methods: eg {{bs.getMutations(..)}} ; have to be made public instead of package-protected. It would be nice to keep methods package-protected where possible.

AFAIK we also don't CI run the microbench classes anywhere, so there's no guarantee they remain runnable over time. I could add them to the ci-cassandra pipeline, though ideally a dedicated bare-metal server would be needed to make [use|https://plugins.jenkins.io/jmh-report/] of the runtime [reports|https://www.jenkins.io/blog/2019/06/21/performance-testing-jenkins/].

+1 on all branch patches (including [~yifanc] review comments above).

Do we have an ETA for the patch being included/merged?

I'll try to get back to this next week

rebased the branches and fixed Yifans comments (not all, but the non-style ones)

Also pushed another commit to the branches improving this a bit more - in the 3.0 case it is a slightly smaller backport of CASSANDRA-12153 to avoid allocating the LinkedHashSet every time we iterate the restrictions. [~blerer] - any chance you have time to review this?

[~marcuse] I guessed that you just wanted me to review the last commit in the 3.0 branch. 
I let some minor comments on the commit. Otherwise, I am +1 with the change.  

+1 

I am able to run the benchmark and also observe the improvement with the change, especially when using uniquePartitions. However, I have to change the memory allocation to 1GB ({{@Fork(value = 1,jvmArgsAppend = "-Xmx1g")}}) in order to avoid OOME when using uniquePartitions and w/o the change. 

Any ideas if this will make it into 3.0.24?

I haven't seen any plans to cut 3.0.24 soon, so yes, most likely

+1 on all branches. 

Rebased the branch to the head of each branch and kicked off CI

trunk: [https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=r%2Fkrummas_marcuse%2F16201-4.0-new]

3.11: [https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=r%2Fkrummas_marcuse%2F16201-3.11-new]

3.0: [https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=r%2Fkrummas_marcuse%2F16201-3.0-new]

 

EDIT: update the CI result

The test 'testIndexMemtableSwitching - org.apache.cassandra.index.sasi.SASIIndexTest' has been failed. It is tracked already in CASSANDRA-15995

There are bunch of dtest failures. Scanned the failures and they do not look relevant to the change. [https://app.circleci.com/pipelines/github/yifan-c/cassandra/176/workflows/a6c6eaaf-b627-40e6-8af8-851f7a0174c6/jobs/923]

There are failures from 2 jvm dtest, 'org.apache.cassandra.distributed.test.SimpleReadWriteTest' and 'org.apache.cassandra.distributed.test.CASTest', all due to 'java.lang.OutOfMemoryError: Java heap space'. I am able to run the test successfully from my local. So the failures do not look relevant. Some flaky tests in the 'CASTest' are tracked in CASSANDRA-16355 and CASSANDRA-16317.

[~marcuse] I did not have the time to go through all the branches yet.
For the 4.0 branch I got a few comments:
* Would it not make sense to use an {{HashMultiset<ByteBuffer>}} rathen than a {{Map<ByteBuffer, Integer>}}? according to the [guava documentation|https://github.com/google/guava/wiki/NewCollectionTypesExplained#multiset] they seems to have been developped with that scenario in mind.
* In {{BatchStatement.getMutations}}:
    {code}
            partitionCounts.computeIfAbsent(stmt.metadata.id, k -> new HashMap<>());
            Map<ByteBuffer, Integer> perKeyCounts = partitionCounts.get(stmt.metadata.id);
    {code}
   Should be:
    {code}
            Map<ByteBuffer, Integer> perKeyCounts = partitionCounts.computeIfAbsent(stmt.metadata.id, k -> new HashMap<>());
    {code}
    Will it make sense to extract {{k -> new HashMap<>()}} in a variable initialized before the loop ?
*  Regarding the  single table update detection, I wonder if it will not be more efficient to do the comparison on the {{TableId}} rather than the metadata.

I went to the other branches today. 
I just have the following small nit: Rather than having {{(int) (createdAt / 1000)}} at several places in the code, should we not create a {{toSeconds}} method in {{FBUtilities}} and use it for the conversions?

+1 for the patches
  

And committed, thanks everyone

Decided to not merge the 3.0 patch as the improvement there was quite small - if anyone has a benchmark showing big 3.0 improvements I'd be happy to commit it as well.

