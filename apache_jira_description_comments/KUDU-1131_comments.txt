{code}
I0911 15:02:31.424937 37508 tablet.cc:1266] Flush: entering phase 2 (starting to duplicate updates in new rowsets)
I0911 15:02:31.425278 37508 tablet.cc:1321] Flush Phase 2: carrying over any updates which arrived during Phase 1
I0911 15:02:31.425287 37508 tablet.cc:1322] Phase 2 snapshot: MvccSnapshot[committed={T|T < 5906247479400488960 or (T in {5906247479798980608})}]
I0911 15:02:31.437552 37508 tablet.cc:1355] Flush successful on 40118 rows (7764749 bytes)
I0911 15:02:31.437984 37508 maintenance_manager.cc:340] Time spent running FlushMRSOp(705a24f0676e4f3292c2d059dab92e59): real 0.218s    user 0.090s     sys 0.041s
I0911 15:02:31.473562 37508 tablet.cc:1377] Compaction: stage 1 complete, picked 2 rowsets to compact
I0911 15:02:31.473603 37508 compaction.cc:578] Selected 2 rowsets to compact:
I0911 15:02:31.473608 37508 compaction.cc:581] RowSet(790)(current size on disk: ~9484691 bytes)
I0911 15:02:31.473616 37508 compaction.cc:581] RowSet(791)(current size on disk: ~7117852 bytes)
I0911 15:02:31.473623 37508 tablet.cc:1176] Compaction: entering phase 1 (flushing snapshot). Phase 1 snapshot: MvccSnapshot[committed={T|T < 5906247479400488960 or (T in {5906247479798980608})}]
F0911 15:02:31.473812 37508 delta_tracker.cc:281] Check failed: !dfr->IsRelevantForSnapshot(snap) Invalid snapshot MvccSnapshot[committed={T|T < 5906247479400488960 or (T in {5906247479798980608})}] does not come after undo file 0000368d2f90d9b2 with stats: ts range=[5906246988388700160, 5906247479798980608], update_counts_by_col_id=[)
{code}

He's probably hitting this issue because his cluster's running very slowly due to some weird fileblockmanager issues. But, it's clear we have some kind of error in our logic here when transactions commit out-of-order.

We're hitting this semi-regularly on precommit runs under mt-tablet-test on RELEASE mode, now. I'll loop it a bit and try to fix.

I'm upgrading this to Blocker, this would really be a good thing to have in 0.8.0.

I see this occasionally on the flaky dashboard for alter_table-randomized-test as well. I'll try to work on this this week.

Here's a log where we hit it. Interestingly a particular write was stuck in flight for over a minute and a half:

{code}
I0301 01:02:38.998479  9226 tablet.cc:1165] Flush: entering phase 1 (flushing snapshot). Phase 1 snapshot: MvccSnapshot[committed={T|T < 5967146793304829952 or (T in {5967146793304829952})}]
I0301 01:02:53.615841 10177 tablet.cc:1165] Flush: entering phase 1 (flushing snapshot). Phase 1 snapshot: MvccSnapshot[committed={T|T < 5967146793304829952 or (T in {5967146793304829952})}]
I0301 01:03:13.208626 11415 tablet.cc:1165] Flush: entering phase 1 (flushing snapshot). Phase 1 snapshot: MvccSnapshot[committed={T|T < 5967146793304829952 or (T in {5967146793304829952})}]
I0301 01:03:26.035773 12706 tablet.cc:1165] Flush: entering phase 1 (flushing snapshot). Phase 1 snapshot: MvccSnapshot[committed={T|T < 5967146793304829952 or (T in {5967146793304829952})}]
I0301 01:03:38.797785 13965 tablet.cc:1165] Flush: entering phase 1 (flushing snapshot). Phase 1 snapshot: MvccSnapshot[committed={T|T < 5967146793304829952 or (T in {5967146793304829952})}]
I0301 01:03:56.999855 16288 tablet.cc:1165] Flush: entering phase 1 (flushing snapshot). Phase 1 snapshot: MvccSnapshot[committed={T|T < 5967146793304829952 or (T in {5967146793304829952})}]
I0301 01:04:16.210322 22134 tablet.cc:1165] Flush: entering phase 1 (flushing snapshot). Phase 1 snapshot: MvccSnapshot[committed={T|T < 5967146793304829952 or (T in {5967146793304829952})}]
{code}

Talking to Todd, he's focusing on something else and won't have time for this in 0.8.0. It seems we're not seeing the issue as often either. Moving to 0.9.0.

Lowering the priority since it isn't a burning issue anymore.

fixed in 3512b1ac68f92ebe1e4e632d9c9dd11396edf1b3

