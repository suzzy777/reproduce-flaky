Also showing up with a different failure.
https://builds.apache.org/job/beam_PostCommit_Java_ValidatesRunner_PortabilityApi_Dataflow/381/
{code}
java.lang.AssertionError: Expected error message from PAssert with substring matching Expected: iterable over \[((<4>|<7>|<3>|<2>|<1>)(, )?){5}\] in any order but the message was "Dataflow job 2018-12-26_10_45_00-2709959779043569844 terminated in state UNKNOWN but did not return a failure reason."
{code}

The ExecutableStage test should be disabled for now: https://github.com/apache/beam/blob/master/.test-infra/jenkins/job_PostCommit_Java_ValidatesRunner_DataflowPortabilityExecutableStage.groovy#L53

The [testContainsInAnyOrderFalse](https://github.com/apache/beam/blob/master/sdks/java/core/src/test/java/org/apache/beam/sdk/testing/PAssertTest.java#L439) expects the pipeline fails and returns an error msg like "Expected: iterable over \\[((<4>|<7>|<3>|<2>|<1>)(, )?)\{5}\\] in any order")". According the harness log, the pipeline behaved correctly and there is the right error msg in harness log. The only problem is, this log didn't get populated into pipeline exception. I'll re-assign it to Scott, who may be more familiar with logging issues.

Hey Scott, for this error, the pipeline worked fine. So maybe it's the logging issue or something wrong with the testing framework. Could you please help take a look at this since I don't have too much content on this.

Yes, I can take a look.

https://builds.apache.org/job/beam_PostCommit_Java_ValidatesRunner_PortabilityApi_Dataflow/415/

I believe there are different root causes for the multiple job failures in the comments.

For the job in the description:

The job failure message ("Job 2018-12-26_16_45_48-1113656764334597924 failed with status FAILED.") is expected, as the test [PAssertTest.testContainsInAnyOrderFalse()|https://github.com/apache/beam/blob/5cdf3a79d603decd28ef4006370f6310ce1cae98/sdks/java/core/src/test/java/org/apache/beam/sdk/testing/PAssertTest.java#L439] validates that PAssert properly throws in this case.

The actual cause of the Jenkins failure is visible in the [Gradle scan|https://scans.gradle.com/s/djsp26uelzeuw/console-log?task=:beam-runners-google-cloud-dataflow-
java:validatesRunnerFnApiWorkerExecutableStageTest], showing the JVM ran out of memory:

{code}
Java HotSpot(TM) 64-Bit Server VM warning: 
INFO: os::commit_memory(0x00000005d0a00000, 311427072, 0) failed; error='Cannot allocate memory' (errno=12)
{code}

Investigating the OOM further..

The [jenkins job|https://builds.apache.org/job/beam_PostCommit_Java_ValidatesRunner_PortabilityApi_Dataflow/385/] executed on node [beam15|https://builds.apache.org/computer/beam15] on Dec 27, 2018 12:09:20 AM for 1h0m, and seems to start hitting memory issues around 12:14:24. 

[beam_PostCommit_Java_PVR_Flink_Batch|https://builds.apache.org/job/beam_PostCommit_Java_PVR_Flink_Batch/276/] and [beam_PreCommit_Python_Cron|https://builds.apache.org/job/beam_PreCommit_Python_Cron/752/] were executing concurrently on the same machine, which both failed or were aborted. I don't yet see any memory issues in those logs, but the Flink job seems to be doing a lot of work.

Still investigating

Looking into beam_PostCommit_Java_ValidatesRunner_PortabilityApi_Dataflow [#415|https://builds.apache.org/job/beam_PostCommit_Java_ValidatesRunner_PortabilityApi_Dataflow/415/]:

Test failure was [PAssertTest.testAssertionSiteIsCapturedWithMessage()|https://scans.gradle.com/s/qa3owj6zcdr3c/tests/qtn2jrvmf3g24-gflsxg36tbugi] ([source|https://github.com/apache/beam/blob/4b039e4bb36f2a59a0ac8f0ff0548ce6f772d012/sdks/java/core/src/test/java/org/apache/beam/sdk/testing/PAssertTest.java#L502]) with failure message:

{code}
Expected: a string containing "Should be empty"
     but: was "Dataflow job 2018-12-30_16_03_43-10058308512329988619 terminated in state UNKNOWN but did not return a failure reason."
{code}

This test verifies that PAssert failures contain the correct failure message. It seems here that the Dataflow runner wasn't able to capture the termination status, so that failure was included instead of the assertion failure.

The Dataflow job is [here|https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2018-12-30_16_03_43-10058308512329988619?project=apache-beam-testing], and on the website shows failed the correct failure reason ("org.apache.beam.sdk.util.UserCodeException: java.lang.AssertionError: Should be empty: Expected: [..]"

Tracing through the code, it appears that [TestDataflowRunner.waitForBatchJobTermination()|https://github.com/apache/beam/blob/master/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/TestDataflowRunner.java#L118] returned false, meaning that [DataflowPipelineJob.waitUntilFinish()|https://github.com/apache/beam/blob/master/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowPipelineJob.java#L282] failed to retrieve the job status from Dataflow service. 

This seems like a temporary failure from Dataflow service. This method already has retry logic (11 retries, exponential backoff). This seems reasonable; I don't think we should hang the test longer on Dataflow service issues.

This was failed due to flakiness in Dataflow service. The test already has retries built in; I don't believe there's anything to fix here.

