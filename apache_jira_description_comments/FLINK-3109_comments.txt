After implement this feature, nothing changed with any old API. 
We just need add one operator under package org.apache.flink.streaming.api.operators, and do some modification in the class org.apache.flink.streaming.api.datastream.JoinedStreams

https://github.com/apache/flink/compare/master...wangyangjun:master


[~yangjun.wang90@gmail.com] How is your experience with that implementation? Do you think it is in a state that it could be contributed?

During last month, this implementation worked well in my work. I think the feature could be contributed. 

GitHub user wangyangjun opened a pull request:

    https://github.com/apache/flink/pull/1527

    [FLINK-3109]Join two streams with two different buffer time -- Java iâ€¦

    Java implementation of jira [FLINK-3109](https://issues.apache.org/jira/browse/FLINK-3109)

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/wangyangjun/flink master

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/flink/pull/1527.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1527
    
----
commit a521c83eb31b653f0a4bfc9da58837a587a378c4
Author: Yangjun Wang <yangjun.wang90@gmail.com>
Date:   2015-12-05T01:16:49Z

    [FLINK-3109]Join two streams with two different buffer time -- Java implementation

----


Github user tillrohrmann commented on a diff in the pull request:

    https://github.com/apache/flink/pull/1527#discussion_r50288042
  
    --- Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamJoinOperator.java ---
    @@ -0,0 +1,305 @@
    +/*
    + * Licensed to the Apache Software Foundation (ASF) under one or more
    + * contributor license agreements.  See the NOTICE file distributed with
    + * this work for additional information regarding copyright ownership.
    + * The ASF licenses this file to You under the Apache License, Version 2.0
    + * (the "License"); you may not use this file except in compliance with
    + * the License.  You may obtain a copy of the License at
    + *
    + *    http://www.apache.org/licenses/LICENSE-2.0
    + *
    + * Unless required by applicable law or agreed to in writing, software
    + * distributed under the License is distributed on an "AS IS" BASIS,
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    + * See the License for the specific language governing permissions and
    + * limitations under the License.
    + */
    +
    +package org.apache.flink.streaming.api.operators;
    +
    +import org.apache.flink.api.common.functions.JoinFunction;
    +import org.apache.flink.api.common.typeutils.TypeSerializer;
    +import org.apache.flink.api.java.functions.KeySelector;
    +import org.apache.flink.core.memory.DataInputView;
    +import org.apache.flink.runtime.state.StateBackend;
    +import org.apache.flink.runtime.state.StateHandle;
    +import org.apache.flink.streaming.api.watermark.Watermark;
    +import org.apache.flink.streaming.runtime.operators.windowing.buffers.HeapWindowBuffer;
    +import org.apache.flink.streaming.runtime.streamrecord.MultiplexingStreamRecordSerializer;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
    +import org.apache.flink.streaming.runtime.tasks.StreamTaskState;
    +import org.slf4j.Logger;
    +import org.slf4j.LoggerFactory;
    +
    +import static java.util.Objects.requireNonNull;
    +
    +
    +public class StreamJoinOperator<K, IN1, IN2, OUT>
    +		extends AbstractUdfStreamOperator<OUT, JoinFunction<IN1, IN2, OUT>>
    +		implements TwoInputStreamOperator<IN1, IN2, OUT> {
    +
    +	private static final long serialVersionUID = 8650694601687319011L;
    +	private static final Logger LOG = LoggerFactory.getLogger(StreamJoinOperator.class);
    +
    +	private HeapWindowBuffer<IN1> stream1Buffer;
    +	private HeapWindowBuffer<IN2> stream2Buffer;
    +	private final KeySelector<IN1, K> keySelector1;
    +	private final KeySelector<IN2, K> keySelector2;
    +	private long stream1WindowLength;
    +	private long stream2WindowLength;
    +
    +	protected transient long currentWatermark1 = -1L;
    +	protected transient long currentWatermark2 = -1L;
    +	protected transient long currentWatermark = -1L;
    +
    +	private TypeSerializer<IN1> inputSerializer1;
    +	private TypeSerializer<IN2> inputSerializer2;
    +	/**
    +	 * If this is true. The current processing time is set as the timestamp of incoming elements.
    +	 * This for use with a {@link org.apache.flink.streaming.api.windowing.evictors.TimeEvictor}
    +	 * if eviction should happen based on processing time.
    +	 */
    +	private boolean setProcessingTime = false;
    +
    +	public StreamJoinOperator(JoinFunction<IN1, IN2, OUT> userFunction,
    +					KeySelector<IN1, K> keySelector1,
    +					KeySelector<IN2, K> keySelector2,
    +					long stream1WindowLength,
    +					long stream2WindowLength,
    +					TypeSerializer<IN1> inputSerializer1,
    +					TypeSerializer<IN2> inputSerializer2) {
    +		super(userFunction);
    +		this.keySelector1 = requireNonNull(keySelector1);
    +		this.keySelector2 = requireNonNull(keySelector2);
    +
    +		this.stream1WindowLength = requireNonNull(stream1WindowLength);
    +		this.stream2WindowLength = requireNonNull(stream2WindowLength);
    +
    +		this.inputSerializer1 = requireNonNull(inputSerializer1);
    +		this.inputSerializer2 = requireNonNull(inputSerializer2);
    +	}
    +
    +	@Override
    +	public void open() throws Exception {
    +		super.open();
    +		if (null == inputSerializer1 || null == inputSerializer2) {
    +			throw new IllegalStateException("Input serializer was not set.");
    +		}
    +
    +		this.stream1Buffer = new HeapWindowBuffer.Factory<IN1>().create();
    +		this.stream2Buffer = new HeapWindowBuffer.Factory<IN2>().create();
    +	}
    +
    +	/**
    +	 * @param element record of stream1
    +	 * @throws Exception
    +	 */
    +	@Override
    +	public void processElement1(StreamRecord<IN1> element) throws Exception {
    +		if (setProcessingTime) {
    +			element.replace(element.getValue(), System.currentTimeMillis());
    +		}
    +		stream1Buffer.storeElement(element);
    +
    +		if (setProcessingTime) {
    +			IN1 item1 = element.getValue();
    +			long time1 = element.getTimestamp();
    +
    +			int expiredDataNum = 0;
    +			for (StreamRecord<IN2> record2 : stream2Buffer.getElements()) {
    +				IN2 item2 = record2.getValue();
    +				long time2 = record2.getTimestamp();
    +				if (time2 < time1 && time2 + this.stream2WindowLength >= time1) {
    +					if (keySelector1.getKey(item1).equals(keySelector2.getKey(item2))) {
    +						output.collect(new StreamRecord<>(userFunction.join(item1, item2)));
    +					}
    +				} else {
    +					expiredDataNum++;
    +				}
    +			}
    +			// clean data
    +			stream2Buffer.removeElements(expiredDataNum);
    +		}
    +	}
    +
    +	@Override
    +	public void processElement2(StreamRecord<IN2> element) throws Exception {
    +		if (setProcessingTime) {
    +			element.replace(element.getValue(), System.currentTimeMillis());
    +		}
    +		stream2Buffer.storeElement(element);
    +
    +		if (setProcessingTime) {
    +			IN2 item2 = element.getValue();
    +			long time2 = element.getTimestamp();
    +
    +			int expiredDataNum = 0;
    +			for (StreamRecord<IN1> record1 : stream1Buffer.getElements()) {
    +				IN1 item1 = record1.getValue();
    +				long time1 = record1.getTimestamp();
    +				if (time1 <= time2 && time1 + this.stream1WindowLength >= time2) {
    +					if (keySelector1.getKey(item1).equals(keySelector2.getKey(item2))) {
    +						output.collect(new StreamRecord<>(userFunction.join(item1, item2)));
    +					}
    +				} else {
    +					expiredDataNum++;
    +				}
    +			}
    +			// clean data
    +			stream1Buffer.removeElements(expiredDataNum);
    +		}
    +	}
    +
    +	/**
    +	 * Process join operator on element during [currentWaterMark, watermark)
    +	 * @param watermark
    +	 * @throws Exception
    +	 */
    +	private void processWatermark(long watermark) throws Exception{
    +		System.out.println("Watermark:" + String.valueOf(watermark));
    --- End diff --
    
    `System.out` is not good here. Maybe using logger if you want to log something.


Github user tillrohrmann commented on a diff in the pull request:

    https://github.com/apache/flink/pull/1527#discussion_r50288200
  
    --- Diff: flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/windowing/CoGroupJoinITCase.java ---
    @@ -234,6 +234,109 @@ public void invoke(String value) throws Exception {
     		Assert.assertEquals(expectedResult, testResults);
     	}
     
    +
    +	// TODO: design buffer join test
    --- End diff --
    
    TODO still unresolved?


Github user wangyangjun commented on a diff in the pull request:

    https://github.com/apache/flink/pull/1527#discussion_r50318008
  
    --- Diff: flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/windowing/CoGroupJoinITCase.java ---
    @@ -234,6 +234,109 @@ public void invoke(String value) throws Exception {
     		Assert.assertEquals(expectedResult, testResults);
     	}
     
    +
    +	// TODO: design buffer join test
    --- End diff --
    
    As you can see in the code, the test case is implemented. I forgot to remove this comment.


Github user wangyangjun commented on a diff in the pull request:

    https://github.com/apache/flink/pull/1527#discussion_r50318034
  
    --- Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamJoinOperator.java ---
    @@ -0,0 +1,305 @@
    +/*
    + * Licensed to the Apache Software Foundation (ASF) under one or more
    + * contributor license agreements.  See the NOTICE file distributed with
    + * this work for additional information regarding copyright ownership.
    + * The ASF licenses this file to You under the Apache License, Version 2.0
    + * (the "License"); you may not use this file except in compliance with
    + * the License.  You may obtain a copy of the License at
    + *
    + *    http://www.apache.org/licenses/LICENSE-2.0
    + *
    + * Unless required by applicable law or agreed to in writing, software
    + * distributed under the License is distributed on an "AS IS" BASIS,
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    + * See the License for the specific language governing permissions and
    + * limitations under the License.
    + */
    +
    +package org.apache.flink.streaming.api.operators;
    +
    +import org.apache.flink.api.common.functions.JoinFunction;
    +import org.apache.flink.api.common.typeutils.TypeSerializer;
    +import org.apache.flink.api.java.functions.KeySelector;
    +import org.apache.flink.core.memory.DataInputView;
    +import org.apache.flink.runtime.state.StateBackend;
    +import org.apache.flink.runtime.state.StateHandle;
    +import org.apache.flink.streaming.api.watermark.Watermark;
    +import org.apache.flink.streaming.runtime.operators.windowing.buffers.HeapWindowBuffer;
    +import org.apache.flink.streaming.runtime.streamrecord.MultiplexingStreamRecordSerializer;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
    +import org.apache.flink.streaming.runtime.tasks.StreamTaskState;
    +import org.slf4j.Logger;
    +import org.slf4j.LoggerFactory;
    +
    +import static java.util.Objects.requireNonNull;
    +
    +
    +public class StreamJoinOperator<K, IN1, IN2, OUT>
    +		extends AbstractUdfStreamOperator<OUT, JoinFunction<IN1, IN2, OUT>>
    +		implements TwoInputStreamOperator<IN1, IN2, OUT> {
    +
    +	private static final long serialVersionUID = 8650694601687319011L;
    +	private static final Logger LOG = LoggerFactory.getLogger(StreamJoinOperator.class);
    +
    +	private HeapWindowBuffer<IN1> stream1Buffer;
    +	private HeapWindowBuffer<IN2> stream2Buffer;
    +	private final KeySelector<IN1, K> keySelector1;
    +	private final KeySelector<IN2, K> keySelector2;
    +	private long stream1WindowLength;
    +	private long stream2WindowLength;
    +
    +	protected transient long currentWatermark1 = -1L;
    +	protected transient long currentWatermark2 = -1L;
    +	protected transient long currentWatermark = -1L;
    +
    +	private TypeSerializer<IN1> inputSerializer1;
    +	private TypeSerializer<IN2> inputSerializer2;
    +	/**
    +	 * If this is true. The current processing time is set as the timestamp of incoming elements.
    +	 * This for use with a {@link org.apache.flink.streaming.api.windowing.evictors.TimeEvictor}
    +	 * if eviction should happen based on processing time.
    +	 */
    +	private boolean setProcessingTime = false;
    +
    +	public StreamJoinOperator(JoinFunction<IN1, IN2, OUT> userFunction,
    +					KeySelector<IN1, K> keySelector1,
    +					KeySelector<IN2, K> keySelector2,
    +					long stream1WindowLength,
    +					long stream2WindowLength,
    +					TypeSerializer<IN1> inputSerializer1,
    +					TypeSerializer<IN2> inputSerializer2) {
    +		super(userFunction);
    +		this.keySelector1 = requireNonNull(keySelector1);
    +		this.keySelector2 = requireNonNull(keySelector2);
    +
    +		this.stream1WindowLength = requireNonNull(stream1WindowLength);
    +		this.stream2WindowLength = requireNonNull(stream2WindowLength);
    +
    +		this.inputSerializer1 = requireNonNull(inputSerializer1);
    +		this.inputSerializer2 = requireNonNull(inputSerializer2);
    +	}
    +
    +	@Override
    +	public void open() throws Exception {
    +		super.open();
    +		if (null == inputSerializer1 || null == inputSerializer2) {
    +			throw new IllegalStateException("Input serializer was not set.");
    +		}
    +
    +		this.stream1Buffer = new HeapWindowBuffer.Factory<IN1>().create();
    +		this.stream2Buffer = new HeapWindowBuffer.Factory<IN2>().create();
    +	}
    +
    +	/**
    +	 * @param element record of stream1
    +	 * @throws Exception
    +	 */
    +	@Override
    +	public void processElement1(StreamRecord<IN1> element) throws Exception {
    +		if (setProcessingTime) {
    +			element.replace(element.getValue(), System.currentTimeMillis());
    +		}
    +		stream1Buffer.storeElement(element);
    +
    +		if (setProcessingTime) {
    +			IN1 item1 = element.getValue();
    +			long time1 = element.getTimestamp();
    +
    +			int expiredDataNum = 0;
    +			for (StreamRecord<IN2> record2 : stream2Buffer.getElements()) {
    +				IN2 item2 = record2.getValue();
    +				long time2 = record2.getTimestamp();
    +				if (time2 < time1 && time2 + this.stream2WindowLength >= time1) {
    +					if (keySelector1.getKey(item1).equals(keySelector2.getKey(item2))) {
    +						output.collect(new StreamRecord<>(userFunction.join(item1, item2)));
    +					}
    +				} else {
    +					expiredDataNum++;
    +				}
    +			}
    +			// clean data
    +			stream2Buffer.removeElements(expiredDataNum);
    +		}
    +	}
    +
    +	@Override
    +	public void processElement2(StreamRecord<IN2> element) throws Exception {
    +		if (setProcessingTime) {
    +			element.replace(element.getValue(), System.currentTimeMillis());
    +		}
    +		stream2Buffer.storeElement(element);
    +
    +		if (setProcessingTime) {
    +			IN2 item2 = element.getValue();
    +			long time2 = element.getTimestamp();
    +
    +			int expiredDataNum = 0;
    +			for (StreamRecord<IN1> record1 : stream1Buffer.getElements()) {
    +				IN1 item1 = record1.getValue();
    +				long time1 = record1.getTimestamp();
    +				if (time1 <= time2 && time1 + this.stream1WindowLength >= time2) {
    +					if (keySelector1.getKey(item1).equals(keySelector2.getKey(item2))) {
    +						output.collect(new StreamRecord<>(userFunction.join(item1, item2)));
    +					}
    +				} else {
    +					expiredDataNum++;
    +				}
    +			}
    +			// clean data
    +			stream1Buffer.removeElements(expiredDataNum);
    +		}
    +	}
    +
    +	/**
    +	 * Process join operator on element during [currentWaterMark, watermark)
    +	 * @param watermark
    +	 * @throws Exception
    +	 */
    +	private void processWatermark(long watermark) throws Exception{
    +		System.out.println("Watermark:" + String.valueOf(watermark));
    --- End diff --
    
    Thanks for your suggestion.


Github user wangyangjun commented on a diff in the pull request:

    https://github.com/apache/flink/pull/1527#discussion_r50318604
  
    --- Diff: flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/windowing/CoGroupJoinITCase.java ---
    @@ -234,6 +234,109 @@ public void invoke(String value) throws Exception {
     		Assert.assertEquals(expectedResult, testResults);
     	}
     
    +
    +	// TODO: design buffer join test
    --- End diff --
    
    @tillrohrmann Do you know why the checks have failed? There are 5 build jobs, only 3 of them passed. This is my first time to commit to an open source project. I have no idea how my code affects the failed tests.


Github user chiwanpark commented on a diff in the pull request:

    https://github.com/apache/flink/pull/1527#discussion_r50360393
  
    --- Diff: flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/windowing/CoGroupJoinITCase.java ---
    @@ -234,6 +234,109 @@ public void invoke(String value) throws Exception {
     		Assert.assertEquals(expectedResult, testResults);
     	}
     
    +
    +	// TODO: design buffer join test
    --- End diff --
    
    @wangyangjun Don't worry. Failing tests seems unrelated to your changes. There are some flaky tests in Flink.


Github user aljoscha commented on the pull request:

    https://github.com/apache/flink/pull/1527#issuecomment-176869415
  
    Hi @wangyangjun,
    sorry for the long wait but I think we can get this PR in after some modifications. I'd like to change the API a bit to separate it from the other Join implementation since that class is already quite crowded. What I would propose is to add a method `timeJoin()` on DataStream and a new class `TimeJoinedStreams` that is similar to `JoinedStreams` but specific to the two-buffer time join.
    
    Could you also please add support for the Scala API, we try to keep the two APIs in sync. If you need help with that, please let me know.


Github user wangyangjun commented on the pull request:

    https://github.com/apache/flink/pull/1527#issuecomment-176912402
  
    Hello, @aljoscha ,
    Thanks for your comment and suggestion. I will update the API. During my benchmark tests of timeJoin, the feature of this implementation is quite good, but the performance is bad. I will reimplement it with [Guava](http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/collect/MapMaker.html).
    
    Yes, I could add support for the Scala API.
    
    Thanks


Github user wangyangjun commented on the pull request:

    https://github.com/apache/flink/pull/1527#issuecomment-177007794
  
    Hello @aljoscha , 
    As I mentioned in last comment, I will reimplement it with [Guava CacheBuilder](http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/cache/CacheBuilder.html). One question is about Flink self-memory management, does CacheBuilder get memory from Flink or JVM directly? As I understand, HeapWindowBuffer allocates memory from Flink. Is there any data structure like cachedMap in Flink?


Github user StephanEwen commented on the pull request:

    https://github.com/apache/flink/pull/1527#issuecomment-177599020
  
    Concerning the data management: @aljoscha and me are currently heavily reworking that.
    All window operations need to go onto the "state" interfaces. Before we merge this one, we should also do that, so please do not spend much time on optimizing how the buffers for the two inputs are implemented.
    
    The interfaces for that will go into the code in a few days (they are in this pull request: https://github.com/apache/flink/pull/1562)
    
    For now, I would focus on the API and we look into the buffers in a few days.
    
    BTW: how exactly the buffered data is held (managed memory, external databases, etc) depends on the "state backend" of the job. Memory behavior can be changed that way and the operators need not worry about that.


Github user StephanEwen commented on the pull request:

    https://github.com/apache/flink/pull/1527#issuecomment-181922703
  
    @wangyangjun We actually merged all the changes concerning the state abstraction.
    
    To make this window join work seamlessly on Flink's state backends (memory, or key/value stores, managed memory, ...) you would need to implement it against the key/value state. That means that whenever you store data in the operator, the data should go into the partitioned state that you can obtain from the `AbstractStreamOperator` or the `RuntimeContext`.
    
    I think that for this window operator, the `ListState` is a good choice, where you can add values to a key and retrieve the list as a whole once the windows are evaluated.
    
    Please write back if you need some more pointers on the state abstraction.



Github user StephanEwen commented on the pull request:

    https://github.com/apache/flink/pull/1527#issuecomment-195495184
  
    I just saw that you updated this pull request (actually a few weeks ago already)
    
    A lot of it looks very good, some things we need to check a bit deeper (like how triggers actually behave on the two separate windows, how windows are matched).
    
    Can you give a high level summary of how this should behave?
    Especially given that you allow for custom triggers and window assigners here, how are windows matched against each other (to determine that their elements should be joined/co-grouped).
    For tumbling time windows, the behavior is well defined and like discussed in the JIRA issue, but for generic windows and triggers, how is it defined?


Github user wangyangjun commented on the pull request:

    https://github.com/apache/flink/pull/1527#issuecomment-199043205
  
    Hi StephanEwen, sorry for replying this late.
    
    This will join two window streams as long as slide size of these two windows are equal. It can be two SlidingTimeWindows, one SlidingTimeWindow and one TumblingTimeWindow. If slide size of windows are not equal, an exception will be threw. 
    
    It doesn't support generic windows and triggers yet. Only TimeWindow is allowed in the API.  



Hi [~yangjunpro], [~sewen] has this issue a relevance ?

Subsumed by FLINK-8478

