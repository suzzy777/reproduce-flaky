Attaching the patch

[~mitdesai],
   checkStopOnFailure currently throws an exception which makes it exit early. So it ends up skipping cleanupOnFailure, printing "Job Stats" information, etc. i.e all code starting from MRScriptState.get().emitProgressUpdatedNotification(100);. 

  So instead of throwing exception and exiting early and relying on system shutdown hook to kill the remaining jobs, you will have to call failJob(message) on JobControl.getReadyJobsList() and  JobControl.getRunningJobList() in checkStopOnFailure. That will kill all jobs and will then follow the regular code path.

Oh.
I will update the patch.

Updated the patch.

It should still be assertFalse(server.existsFile("done")); . With this change it is still not stopping execution of the script when it is compiled in two phases due to fs statements. Will have to make checkStopOnFailure return true instead of void, and throw new ExecException(msg.toString(), errCode, PigException.REMOTE_ENVIRONMENT); instead of return pigStats at the end in launchPig if checkStopOnFailure returned true. 

Thanks for the Review [~rohini]. Updated the patch.

In the ExecException, the message used to be "job_id Job Failed!". I have changed it to "Some jobs failed. stop.on.failure set true. Stopping execution". What job failed can now be easily found out by looking at the Script Status which will look something like this:
{noformat}
Error: org.apache.pig.backend.executionengine.ExecException: ERROR 2055: Received Error while processing the map plan: 'false (stdin-org.apache.pig.builtin.PigStreaming/stdout-org.apache.pig.builtin.PigStreaming)' failed with exit status: 1
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapBase.runPipeline(PigGenericMapBase.java:307)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapBase.map(PigGenericMapBase.java:274)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapBase.map(PigGenericMapBase.java:64)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:784)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

2015-09-20 16:44:56,874 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: org.apache.pig.backend.executionengine.ExecException: ERROR 2055: Received Error while processing the map plan: 'false (stdin-org.apache.pig.builtin.PigStreaming/stdout-org.apache.pig.builtin.PigStreaming)' failed with exit status: 1
2015-09-20 16:44:56,874 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
2015-09-20 16:44:56,875 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.6.0	0.16.0-SNAPSHOT	mitdesai	2015-09-20 16:44:38	2015-09-20 16:44:56	STREAMING

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1442785471589_0001	A,B	STREAMING,MAP_ONLY	Message: Job failed!	hdfs://localhost:63266/user/mitdesai/bar,

Input(s):

Output(s):
Failed to produce result in "hdfs://localhost:63266/user/mitdesai/bar"

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1442785471589_0001	->	null,
null


2015-09-20 16:44:56,875 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
2015-09-20 16:44:56,876 [IPC Server handler 8 on 63266] INFO  org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit  - allowed=true	ugi=mitdesai (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/mitdesai/bar	dst=null	perm=null	proto=rpc
2015-09-20 16:44:56,878 [IPC Server handler 9 on 63266] INFO  org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit  - allowed=true	ugi=mitdesai (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/mitdesai/bar	dst=null	perm=null	proto=rpc
2015-09-20 16:44:56,879 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: stop.on.failure set true. Some jobs failed. Stopping Execution
2015-09-20 16:44:56,879 [main] WARN  org.apache.pig.tools.grunt.Grunt  - There is no log file to write to.
2015-09-20 16:44:56,879 [main] ERROR org.apache.pig.tools.grunt.Grunt  - org.apache.pig.backend.executionengine.ExecException: ERROR 6017: stop.on.failure set true. Some jobs failed. Stopping Execution
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.launchPig(MapReduceLauncher.java:546)
	at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.launchPig(HExecutionEngine.java:304)
	at org.apache.pig.PigServer.launchPlan(PigServer.java:1390)
	at org.apache.pig.PigServer.executeCompiledLogicalPlan(PigServer.java:1375){noformat}

The ExecException message is different in the log here. I forgot to rerun the test after modifying the error message.

Updated the patch.

With the attached patch, it display job stats when stop on failure is set as below in mapreduce.

{code}
2017-03-28 14:15:04,580 [main] ERROR org.apache.pig.tools.pigstats.PigStats - ERROR 0: org.apache.pig.backend.executionengine.ExecException: ERROR 2055: Received Error while processing the map plan: 'false (stdin-org.apache.pig.builtin.PigStreaming/stdout-org.apache.pig.builtin.PigStreaming)' failed with exit status: 1
2017-03-28 14:15:04,580 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil - 2 map reduce job(s) failed!
2017-03-28 14:15:04,580 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics:

HadoopVersion   PigVersion      UserId  StartedAt       FinishedAt      Features
2.7.3   0.17.0-SNAPSHOT rohinip 2017-03-28 14:14:41     2017-03-28 14:15:04     STREAMING

Failed!

Failed Jobs:
JobId   Alias   Feature Message Outputs
job_1490735309298_0017  A,B     STREAMING,MAP_ONLY      Message: Job failed!    hdfs://localhost:56480/bar,
job_1490735309298_0018  A1      MAP_ONLY        Message: Failing running job for -stop_on_failure: job_1490735309298_0018       hdfs://localhost:56480/bar1,

Input(s):

Output(s):
Failed to produce result in "hdfs://localhost:56480/bar"
Failed to produce result in "hdfs://localhost:56480/bar1"

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1490735309298_0017  ->      null,
null
job_1490735309298_0018
{code}

+1

Committed to trunk. Thanks for the review Daniel.

The test was flaky based on the order of jobs launched. Fixed the assert statements for that in PIG-4677-fixflakytest.patch.

+1 on PIG-4677-fixflakytest.patch.

Committed  PIG-4677-fixflakytest.patch to trunk. Thanks Daniel for the review.

