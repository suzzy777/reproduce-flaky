This is a starting working point: https://github.com/apache/cassandra-builds/compare/trunk...thelastpickle:cassandra-builds:mck/17869 

Looking at the diff, i'm wondering if all this would be simpler if we brought these* scripts  in-tree, and introduced variables in build.xml
{code}
<property name="java.default" value="11" />
<property name="java.supported" value="11,17" />
{code}

Questions…
* For the {{jvm-dtest-upgrade}} I presume we would then only support the default (implied that's the JDK that overlaps with the previous major).
* Can we remove JAVA8_HOME and JAVA11_HOME from dtests script and image?
* Can we avoid introducing any CASSANDRA_USE_JDK17 ? 





bq. i'm wondering if all this would be simpler if we brought these* scripts in-tree
I've been asking myself this same question. Having them separate has some real costs in terms of visibility and folks on the project being familiar with it, but versioning the build scripts separately and having a single repo that has multi-version support makes some logical sense that we'd lose if we put it in-tree.

Would the idea be to have build scripts that are targeted per-branch rather than all the scripts on trunk supporting all previous supported branches? Or the latter?

bq. Having them separate has some real costs in terms of visibility and folks on the project being familiar with it.
In my all honesty, I disagree considering how we have CircleCI config in-tree, docs etc and:
 - people still do not get involved mostly because they do not have the time
 - I feel it is more prone to bugs if we have it in a few versions. 

bq. Would the idea be to have build scripts that are targeted per-branch rather than all the scripts on trunk supporting all previous supported branches?

I understood it being per version.

If we want to challenge and educate more people about the cassandra-builds repo - docs and some nice session should be enough refreshment in my opinion.

bq. For the jvm-dtest-upgrade I presume we would then only support the default (implied that's the JDK that overlaps with the previous major).

I think that is what we also do with the python upgrade tests?

bq. This is a starting working point: https://github.com/apache/cassandra-builds/compare/trunk...thelastpickle:cassandra-builds:mck/17869
[~mck], so just to confirm - this is one that covers trunk j11 and j17, right? This one we can use for preliminary testing with arm, as we talked last week, right? And thanks for pushing it!

bq. Can we remove JAVA8_HOME and JAVA11_HOME from dtests script and image?
What is your idea?

bq. CASSANDRA_USE_JDK17
Isn't this a substitution of CASSANDRA_USE_JDK11 from previous versions for the next 5.0 one?
So you won't have both applicable in one version. Or did I misunderstand the question?




bq. If we want to challenge and educate more people about the cassandra-builds repo - docs and some nice session should be enough refreshment in my opinion.
Honestly, people will probably learn about it when they have to, i.e. in a hypothetical future where folks are using these scripts to run on either ASF CI or a clone of it on private cloud.

Same thing w/the circle config; people learn things when they need to but are content to have them be black-box if they satisfy most of their needs.

bq. Honestly, people will probably learn about it when they have to, i.e. in a hypothetical future where folks are using these scripts to run on either ASF CI or a clone of it on private cloud.
bq. Same thing w/the circle config; people learn things when they need to but are content to have them be black-box if they satisfy most of their needs.

Totally agree with you here. The suggestion about docs and session was only to satisfy the concern that people do not know of those when they are in a separate repo. 

bq. versioning the build scripts separately and having a single repo that has multi-version support makes some logical sense that we'd lose if we put it in-tree.

This is a current pain-point. Different JDK versions, different test types, etc, is overhead in complexity that has no value that I'm aware of? There's also a lot of {{`git clone --depth 1 --single-branch …cassandra-builds }} we could be avoiding… 

The idea is per-branch scripts. Put in the {{.build/}} folder. 

bq. I think that is what we also do with the python upgrade tests?

Both upgrade test types already have in-place definitions of what versions can be, and are to be, upgraded from and to. So it makes sense to not enforce the JDK used at the test level, but via the build.xml (so we actually verify that there's a JDK in common that all upgrade paths can operate on).

{quote}
bq. Can we remove JAVA8_HOME and JAVA11_HOME from dtests script and image?
What is your idea?
{quote}

Well, in ci-cassandra.a.o there are no jdk11 python dtests run… (AFAIK?)

But… it's unclear to what the purpose of the JAVA8_HOME and JAVA11_HOME variables are for? Given the jdk used for the tests comes down the JAVA_HOME variable anyway, and building bc JAVA11_HOME doesn't happen anymore…

bq. So you won't have both applicable in one version. Or did I misunderstand the question?

Why have anything in trunk ? (There was a discussion about it recently, but i can't find it…)


{quote}Both upgrade test types already have in-place definitions of what versions can be, and are to be, upgraded from and to. So it makes sense to not enforce the JDK used at the test level, but via the build.xml (so we actually verify that there's a JDK in common that all upgrade paths can operate on)
{quote}
+1
{quote}But… it's unclear to what the purpose of the JAVA8_HOME and JAVA11_HOME variables are for? Given the jdk used for the tests comes down the JAVA_HOME variable anyway, and building bc JAVA11_HOME doesn't happen anymore…
{quote}
I was thinking we need to dig a bit also in CCM what it uses, how and why. There were some recent concerns brought while looking into running CQLSHLIB tests in CI and that is what made me think about that but I didn't have the chance to do it so far. I think we probably need separate ticket. I will open one now.
{quote}Why have anything in trunk ? (There was a discussion about it recently, but i can't find it…) 
{quote}
Honestly, I cannot remember which discussion you are referring to.

I just opened CASSANDRA-18106 for CCM. Feel free to correct me or comment on what I said there. 

{quote}
bq. Why have anything in trunk ? (There was a discussion about it recently, but i can't find it…) 

Honestly, I cannot remember which discussion you are referring to.
{quote}
In trunk we will remove {{CASSANDRA_USE_JDK11}} and {{-Duse.jdk11=true}}, as that becomes the default JDK. My question is, let's avoid adding {{CASSANDRA_USE_JDK17}} and {{-Duse.jdk17=true}}, there are not needed AFAIK.

The way I did it so far in the POC/WIP branch is only switching the current strategy from JDK8/JDK11 to JDK11/JDK17 as that was what we discussed when this whole migration to JDK17 conversation started. So I am not opposed to other ideas but so far I remove in trunk {{CASSANDRA_USE_JDK11}} and {{-Duse.jdk11=true and switch to }}{{CASSANDRA_USE_JDK17}} and {{-Duse.jdk17=true}}

I guess what you are looking for is automated detection of JDK version and logging - "you use this version" and "version 7 (for example) is detected, it is not supported"? Now while looking into that we realized we do not officially test non-LTS versions between 8 and 11 and the same will be between 11 and 17, but some people may be testing etc and those are not prohibited for usage at the moment. I guess that encourages early testing with new JDKs too. 

Now the big question on my mind is:

Do we keep the old cassandra branches as is with cassandra-builds still in place and initiate a change only for trunk (bringing scripts to .build)? Then we introduce for trunk that new way of handling things as you suggested? I guess we need to come up with exact plan/suggestion around that and bring it to the mailing list as it might be disruptive for certain people? (though if it is only trunk so far, it should be less disruptive but still awareness needed). Does it make sense what I am saying here? 

 

 

bq. switch to CASSANDRA_USE_JDK17 and -Duse.jdk17=true

yes, but what's the purpose or value of these variables? 
to prevent you from compiling with a version of java you didn't intend but that is still supported? sounds like a layer7 problem to me, that the build doesn't need to care about – you build with the version you have, end of story.

bq. I guess what you are looking for is automated detection of JDK version and logging 

detection and logging is already automatic.
and enforcing it to the two LTS happens with the {{<property name="java.supported" value="11,17" />}} (which can be overridden for those wanting to experiment with other JDKs).

bq. Do we keep the old cassandra branches as is with cassandra-builds still in place and initiate a change only for trunk (bringing scripts to .build)? 

my first thoughts was only trunk. so if the scripts were not found in .build/ fallback to the clone cassandra-builds approach.

So I think I found in ASF the [discussion|https://the-asf.slack.com/archives/CK23JSY2K/p1668014106184579] you were referring to (I guess that is the one, you will correct me if I am wrong and there was something more :)).

It seems the argument so far is "so there are some differences in the build process for both, and I agree that you should be explicit about building with a jvm that is not the same one the release binaries will be built with" or as long as that is the case and next time the release binaries will be j11, I guess we need to default to it and have flag for 17?
{quote}my first thoughts was only trunk. so if the scripts were not found in .build/ fallback to the clone cassandra-builds approach.
{quote}
If we are going to anyway still have the logic in cassandra-builds for fallback, I would suggest we focus here on doing that and have another ticket for improvement for adding build scripts for trunk in .build. What do you think?

bq. It seems the argument so far is "so there are some differences in the build process for both, and I agree that you should be explicit about building with a jvm that is not the same one the release binaries will be built with"

The release scripts will ensure releases are only built with the default. CI will check both for you.
We can add a warning if you are building with the non-default, I'm not sure of the real value of doing more than that.

Thanks for find the slack reference, I'll bring that discussion back to here.

bq. If we are going to anyway still have the logic in cassandra-builds for fallback, I would suggest we focus here on doing that and have another ticket for improvement for adding build scripts for trunk in .build. What do you think?

It adds complexity to the existing scripts that I am hoping to avoid. 

{quote}It adds complexity to the existing scripts that I am hoping to avoid.
{quote}
I guess I misunderstood you initially, I am all in for not adding more complexity if that will be the case. 

Another question: updating build.xml and other scripts should be also handled as part of this ticket I guess?

Or at least I have to open a ticket and rework what I already have I guess *after* this ticket lands so we have the final decision on what we want. Until then I should just use the current scripts I have in the WIP branch for testing while cleaning issues around JDK17

On another topic - I just looked at CCM and it will also require changes, I have the preliminary changes for it too but I guess now we need to wait on things to get more clear here and then revisit any changes in CASSANDRA-18106

I need this to go in before CASSANDRA-18133, because the compatibility required has to work in both directions between both git repos. It makes sense to start first and isolate the cassandra-builds patch, making it forward-compatible to the in-tree patch in 18133.

Patch is ready for review: https://github.com/apache/cassandra-builds/compare/trunk...thelastpickle:cassandra-builds:mck/17869 

({{prepare_release.sh}} i need to finish)
 

Patch ready. Am testing it.

Dummy Jenkins set up with the groovy DSL jobs created @ http://13.48.137.17:8080/ 

Only trunk has the jdk11+17 matrix, so each job still needs to be switched to [~e.dimitrova]'s branch… (working on that…)

I will be looking into it later today (meetings until early afternoon). I think that with the changes in build.xml for trunk we might need CCM changes for discovering JDK in order to run Python DTests? (I assume you were testing with those). I didn't manage to log into Jenkins to see the jobs/builds. I assume we need to use our Apache accounts, I. will try again later in case I just messed my passwords or so but just wanted to confirm I am trying the right account here. 

i'm testing your in-tree branch. (each jobs needs to be configured to update it as such, both in the scm and the build sections.)

This is a custom single-node jenkins (i'll DM you the creds).

artifacts, stress-test, fqltool-test are working. (jobs will appear as unstable only because the post-stage stuff fails, it not being ASF infra and not having the slack/smtp/nightlies secrets in place)

For the record, while testing both JDK11 and 17 we caught a bug in my branch, that was fixed. Thanks [~mck] 

Things shifted during rebase and I was focused on the Java 17 tests so I didn't notice earlier. (it was visible when we run CI with JDK 11 and my branch)

I left a few questions/comments in the PR but overall it looks good to me!

I think the main question is do we want to commit this now with a toggle that will switch later when we switch trunk from J8+J11 to J11+J17, or just have it ready for when the time comes. I leave It up to you Mick to decide. If we commit it now we will need to test all branches. If we leave it for later, that also seems ok to me because I do not expect cassandra-builds to get many change in the meantime. 

I just got reminded of something - CASSANDRA-18000

[~adelapena] mentioned we can use it in the splits in Jenkins. Thoughts? If we can benefit of that flag, do we want this added here while we are on top of the build scripts or a separate ticket?

CASSANDRA-18017 was created for that, it would be great if the flag is added here.

Thanks [~adelapena] , I missed CASSANDRA-18017 was created already. I will link it here and to the original ticket so we don't forget about it as it is a great improvement.

bq. CASSANDRA-18017 …

There's currently no shared/stashed files between stages and splits in jenkins. The flag would be useful for repeated runs, but for the existing test stages it requires them first to be brought on-tree and then the stash and unstash functionality to be implemented. For example stash is being tested here: https://github.com/apache/cassandra/compare/trunk...thelastpickle:cassandra:mck/17869/trunk#diff-917491029f94ac1ce6c114a542d2a8738ce1f2d1e866eaffe7189d2139250200R236-R238 

Patch needs some small updates post CASSANDRA-18179

Will wait til CASSANDRA-1824 lands for this, so folk can do their circleci jdk17 testing pre-commit, and we have a firm idea  of failing tests.

Patch [updated|https://github.com/apache/cassandra-builds/compare/trunk...thelastpickle:cassandra-builds:mck/17869].
Custom CI runs [here|http://13.49.102.201:8080/].

{quote}Patch updated.
{quote}
I am not sure what is the new part as I see one squashed commit and some time passed since I looked at this work. Can you advise, please?
{quote}Custom CI runs [here|http://13.49.102.201:8080/].
{quote}
Looking there I guess current trunk being tested with the proposed patch was the goal? Unfortunately I think something went wrong?

I see aborted runs if I am looking at the right place.

So we do not expect 17 to be able to run CI properly as we cannot start Cassandra at this point, only compile.

The aborted part I see is for 8 and 11

bq. I am not sure what is the new part as I see one squashed commit and some time passed since I looked at this work. Can you advise, please?

Apologies (I can avoid further squashes on next update).

Not much changed …
– the `export CASSANDRA_USE_JDK17=true` lines were removed, 
– three jdks are in the matrix for trunk temporarily, see [here|https://github.com/apache/cassandra-builds/compare/trunk...thelastpickle:cassandra-builds:mck/17869#diff-1f760d89dfb81ea05a11d862007a4e4e586b38aac7ae87f62c5b2e86571809c0R112]
– how jdk17 support is detected was updated [here|https://github.com/apache/cassandra-builds/compare/trunk...thelastpickle:cassandra-builds:mck/17869#diff-f458d745bb6227c4f9161c75ffed2a98d0ee3cd7da734afe7e759670c5969b3cR45-R50]

bq. Looking there I guess current trunk being tested with the proposed patch was the goal? Unfortunately I think something went wrong?

No aborts related to this ticket.

The pipeline isn't working because there are post-build steps in the artifacts stage job that are marked "unstable" and the pipeline will fail on that (and I aborted the build when I saw it before it got to finish). I've deleted the pipeline job to avoid confusion. Other stage jobs there are still running… 

CI
- artifacts: http://13.50.248.249:8080/job/Cassandra-trunk-artifacts/21/
- cqlsh-tests: http://13.50.248.249:8080/job/Cassandra-trunk-cqlsh-tests/11/
- unit: http://13.50.248.249:8080/job/Cassandra-trunk-test/4/
- jvm-dtest: http://13.50.248.249:8080/job/Cassandra-trunk-jvm-dtest/5/
- jvm-dtest-upgrade: http://13.50.248.249:8080/job/Cassandra-trunk-jvm-dtest-upgrade/3/
- dtest: http://13.50.248.249:8080/job/Cassandra-trunk-dtest/17/
- dtest-upgrade: http://13.50.248.249:8080/job/Cassandra-trunk-dtest-upgrade/6/

Failures are similar to CircleCI: https://app.circleci.com/pipelines/github/michaelsembwever/cassandra?branch=mck%2Ftrunk 



I figured that the JDK17 build doesn't start at the moment because of this (as expected we do not have too much storage locally and in CI available so we trigger the below warning), the main issue is initializing the partitioner and jamm hitting JDK internals:

 
{code:java}
WARN  [main] 2023-04-05 10:46:25,361 DatabaseDescriptor.java:675 - Only 44.801GiB free across all data volumes. Consider adding more capacity to your cluster or removing obsolete snapshots
Exception (java.lang.ExceptionInInitializerError) encountered during startup: null
java.lang.ExceptionInInitializerError
at org.apache.cassandra.dht.Murmur3Partitioner.<clinit>(Murmur3Partitioner.java:54)
at java.base/java.lang.Class.forName0(Native Method)
at java.base/java.lang.Class.forName(Class.java:375)
at org.apache.cassandra.utils.FBUtilities.classForName(FBUtilities.java:721)
at org.apache.cassandra.utils.FBUtilities.instanceOrConstruct(FBUtilities.java:737)
at org.apache.cassandra.utils.FBUtilities.newPartitioner(FBUtilities.java:642)
at org.apache.cassandra.utils.FBUtilities.newPartitioner(FBUtilities.java:628)
at org.apache.cassandra.config.DatabaseDescriptor.applyPartitioner(DatabaseDescriptor.java:1342)
at org.apache.cassandra.config.DatabaseDescriptor.applyPartitioner(DatabaseDescriptor.java:1328)
at org.apache.cassandra.config.DatabaseDescriptor.applyAll(DatabaseDescriptor.java:403)
at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:216)
at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:200)
at org.apache.cassandra.service.CassandraDaemon.applyConfig(CassandraDaemon.java:817)
at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:760)
at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:888)
Caused by: java.lang.reflect.InaccessibleObjectException: Unable to make field private final transient java.net.InetSocketAddress$InetSocketAddressHolder java.net.InetSocketAddress.holder accessible: module java.base does not "opens java.net" to unnamed module @536dbea0
at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:354)
at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297)
at java.base/java.lang.reflect.Field.checkCanSetAccessible(Field.java:178)
at java.base/java.lang.reflect.Field.setAccessible(Field.java:172)
at org.github.jamm.MemoryMeter.addFieldChildren(MemoryMeter.java:330)
at org.github.jamm.MemoryMeter.measureDeep(MemoryMeter.java:269)
at org.apache.cassandra.utils.ObjectSizes.measureDeep(ObjectSizes.java:221)
at org.apache.cassandra.utils.ObjectSizes.<clinit>(ObjectSizes.java:45)
... 15 more
ERROR [main] 2023-04-05 10:46:26,007 CassandraDaemon.java:910 - Exception encountered during startup
java.lang.ExceptionInInitializerError: null
at org.apache.cassandra.dht.Murmur3Partitioner.<clinit>(Murmur3Partitioner.java:54)
at java.base/java.lang.Class.forName0(Native Method)
at java.base/java.lang.Class.forName(Class.java:375)
at org.apache.cassandra.utils.FBUtilities.classForName(FBUtilities.java:721)
at org.apache.cassandra.utils.FBUtilities.instanceOrConstruct(FBUtilities.java:737)
at org.apache.cassandra.utils.FBUtilities.newPartitioner(FBUtilities.java:642)
at org.apache.cassandra.utils.FBUtilities.newPartitioner(FBUtilities.java:628)
at org.apache.cassandra.config.DatabaseDescriptor.applyPartitioner(DatabaseDescriptor.java:1342)
at org.apache.cassandra.config.DatabaseDescriptor.applyPartitioner(DatabaseDescriptor.java:1328)
at org.apache.cassandra.config.DatabaseDescriptor.applyAll(DatabaseDescriptor.java:403)
at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:216)
at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:200)
at org.apache.cassandra.service.CassandraDaemon.applyConfig(CassandraDaemon.java:817)
at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:760)
at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:888)
Caused by: java.lang.reflect.InaccessibleObjectException: Unable to make field private final transient java.net.InetSocketAddress$InetSocketAddressHolder java.net.InetSocketAddress.holder accessible: module java.base does not "opens java.net" to unnamed module @536dbea0
at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:354)
at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297)
at java.base/java.lang.reflect.Field.checkCanSetAccessible(Field.java:178)
at java.base/java.lang.reflect.Field.setAccessible(Field.java:172)
at org.github.jamm.MemoryMeter.addFieldChildren(MemoryMeter.java:330)
at org.github.jamm.MemoryMeter.measureDeep(MemoryMeter.java:269)
at org.apache.cassandra.utils.ObjectSizes.measureDeep(ObjectSizes.java:221)
at org.apache.cassandra.utils.ObjectSizes.<clinit>(ObjectSizes.java:45)
... 15 common frames omitted
 
{code}
Until Jamm maintenance is finished we can do add-opens temporarily to work around it. (I will test and provide a patch soon)

Now, I asked myself why now everywhere we can see this issue.

My bisecting landed me at CASSANDRA-17199

On my machine I can see we add about 4-5GiB so we started measuring something more which also triggers jamm somewhere? Probably it is ok but just in case - ping [~dcapwell] as he was working last on CASSANDRA-17199. Is this ok or is there anything we will need to follow up on?
{code:java}
WARN  [main] 2023-04-05 10:58:15,260 DatabaseDescriptor.java:677 - Only 40.798GiB free across all data volumes. Consider adding more capacity to your cluster or removing obsolete snapshots{code}
 

 

So there are two things. On startup I see more storage consumption reported.

With the new measurements added when we initialize the Murmur3Partitioner it hits those internals mentioned in the stack trace which is jamm problem triggered by new measuring added in CASSANDRA-17199

{quote}On startup I see more storage consumption reported.
{quote}
That is actually interesting, now I see different numbers when I switched back to latest trunk.

Might be just my setup and cleaning between branches/commits playing me

[~e.dimitrova] I am not sure the relationship to CASSANDRA-17199.  Your message shows that we failed to create DD and that we get a log saying we are out of disk space... The patch you linked (CASSANDRA-17199) adds logs to streaming to know why a sub-stream failed; not sure the relationship to this work?

{code}
Caused by: java.lang.reflect.InaccessibleObjectException: Unable to make field private final transient java.net.InetSocketAddress$InetSocketAddressHolder java.net.InetSocketAddress.holder accessible: module java.base does not "opens java.net" to unnamed module @536dbea0
{code}

Oh, I see that looks to be caused by

{code}
public static final long IPV6_SOCKET_ADDRESS_SIZE = ObjectSizes.measureDeep(new InetSocketAddress(getIpvAddress(16), 42));
{code}

In some code paths we use hard coded values from JOL, so if this is an issue I am 100% making this a constant based off JOL as well...  The intent is for memory tracking, so if we are off we store more or less streams than the ideal state... so if we are good-enough it's fine.

On JDK8 I get 168, so 100% cool with replacing the RHS with "168"

{quote}Oh, I see that looks to be caused by
{code:java}
public static final long IPV6_SOCKET_ADDRESS_SIZE = ObjectSizes.measureDeep(new InetSocketAddress(getIpvAddress(16), 42));{code}
{quote}
Yes, that is the problem. measureDeep is crawling the JDK internals and hits something. That kind of issues are that [~b.lerer@gmail.com] is working around during his jamm maintenance. When we get the new version of jamm things will be ok. Until then I can do probably just add-opens. If it doesn't start eagerly to ask me for more and more and it is a matter of adding just 1-2 in order to get through it I will go for that. If not we can go with your suggestion until the new jamm release is in and it fixes this type of issues.

I will open another ticket now to fix it. Thanks for looking into that!

Problem fixed in CASSANDRA-18431. JDK17 CI runs should be back to what they were last week. 

Thanks! I've updated the CI links above.

I will take a look, thanks, I need to remember the details as time passed and a bunch of stuff happened in the meantime...

Immediate question on my end though:
{quote}I think the main question is do we want to commit this now with a toggle that will switch later when we switch trunk from J8+J11 to J11+J17, or just have it ready for when the time comes. I leave It up to you Mick to decide. If we commit it now we will need to test all branches. If we leave it for later, that also seems ok to me because I do not expect cassandra-builds to get many change in the meantime. 
{quote}
What's the plan? In your runs we see currently 8+11+17. Were all three triggered just to check everything works with all JDK versions but we will have in Cassandra a toggle and switch from 8+11 to 11+17 runs when we are done with everything else required from CASSANDRA-16895?

Took a quick look at the few commits from the past few days. Looking good, left just a few questions on the commits primarily for my understanding.

I will check now the CI runs you posted

I tried to verify we have the right amount of tests running with every suite published; being run with the right JDK version and final results matching what we already know about without new surprises.

Feedback:
 * I will open a ticket for EmptyValuesTest class(unit tests) - I've seen it before failing with JDK17 but not in the past month so I guess it did not disappear but it is probably flaky with JDK17.
 * The links posted for in-jvm tests return 404 error. I just navigated myself from the main page to the latest runs available
 * I had some confusion with the Java distributed tests until I found CASSANDRA-18008. (we do not have them running with vnodes as in CircleCI). Also, Jenkins skips to run different tests sometimes in different runs. I have no clue why. Further to the @Ignore annotations do we have any custom way to check and decide if we want to skip some tests running with JUnit? Like we have for the Python tests for example to skip certain resource-intensive tests. Also, I think we also skip some tests in CircleCI but it just reports total number of test runs and total number of failures, no total number of skipped tests. Number of tests run seems similar so I _guess_ things are ok but it is hard to reason.
 * It seems JDK11 Python DTests are not currently run in Jenkins, do we plan now to enable both 11 and 17? This will raise significantly the build times and the infra will suffer. I am not sure whether this was the rationality or they were just not added as other suites we are missing.
 * Some Python upgrade tests are failing because we try to compile older Cassandra versions with JDK17 as far as I can tell from the logs. (I seen complaints about Nashorn)
 * Not all suites were run with the latest changes applied in Cassandra. 
 * I guess intentionally you did not run yet the cdc, compression enabled etc unit tests?

 

bq. do we want to commit this now with a toggle that will switch later when we switch trunk from J8+J11 to J11+J17

It's a manual switch here: https://github.com/apache/cassandra-builds/compare/trunk...thelastpickle:cassandra-builds:mck/17869#diff-1f760d89dfb81ea05a11d862007a4e4e586b38aac7ae87f62c5b2e86571809c0R90 ;that will be done as part of dropping JDK8 (CASSANDRA-18255).

The matrix generation (e.g. jdk axes here) will be done in a completely different manner with the in-tree scripts: https://github.com/michaelsembwever/cassandra/compare/mck/18179/trunk...thelastpickle:cassandra:mck/18133/trunk#diff-917491029f94ac1ce6c114a542d2a8738ce1f2d1e866eaffe7189d2139250200R207-R215 

bq. The links posted for in-jvm tests return 404 error

oh, those builds didn't kick in. they should appear soon.

bq. I had some confusion with the Java distributed tests until I found CASSANDRA-18008.

I suggest we look closer into this with CASSANDRA-18133, because we will fold these types of test types into the matrix for that general test type.

bq. It seems JDK11 Python DTests are not currently run in Jenkins, do we plan now to enable both 11 and 17?

Again, that's an existing problem that can be considered out of scope for this ticket. I suggest again that we tackle it as part of CASSANDRA-18133.

bq. Some Python upgrade tests are failing because we try to compile older Cassandra versions with JDK17 as far as I can tell from the logs.

any links to these errors? 

bq. I guess intentionally you did not run yet the cdc, compression enabled etc unit tests?

Correct. Rather minimal risk there.

{quote}It's a manual switch here: [https://github.com/apache/cassandra-builds/compare/trunk...thelastpickle:cassandra-builds:mck/17869#diff-1f760d89dfb81ea05a11d862007a4e4e586b38aac7ae87f62c5b2e86571809c0R90] ;that will be done as part of dropping JDK8 (CASSANDRA-18255).
{quote}
I am a bit confused. What is the order of commits this ticket and CASSANDRA-18255. Also, the link posted does not point to the switch but to the whole diff. 
{quote}oh, those builds didn't kick in. they should appear soon.
{quote}
Did those get stuck? I still do not see anything
{quote}I suggest we look closer into this with CASSANDRA-18133, because we will fold these types of test types into the matrix for that general test type.
{quote}
Agreed
{quote}Again, that's an existing problem that can be considered out of scope for this ticket. I suggest again that we tackle it as part of CASSANDRA-18133.
{quote}
Agreed
{quote}any links to these errors?
{quote}
There are 35 failures and all of them fail with the same issue. Example:

[http://13.50.248.249:8080/job/Cassandra-trunk-dtest-upgrade/3/jdk=jdk_11_latest,label=cassandra-dtest,split=2/testReport/junit/dtest-upgrade.upgrade_tests.storage_engine_upgrade_test/TestBootstrapAfterUpgrade/test_upgrade_with_wide_partition_reversed/]

On a deeper look - we see those were the Nashorn warnings, the failures are different compilation errors as pre-4.0 versions of cassandra were build with JDK11, instead of 8. 

FYI - ticket opened for EmptyValuesTest class(unit tests) - CASSANDRA-18436

bq. It's a manual switch here: https://github.com/apache/cassandra-builds/compare/trunk...thelastpickle:cassandra-builds:mck/17869#diff-1f760d89dfb81ea05a11d862007a4e4e586b38aac7ae87f62c5b2e86571809c0R90 ;that will be done as part of dropping JDK8 (CASSANDRA-18255).

This ticket first. That means ci-cassandra.a.o will be running 8, 11, and 17 on trunk.
Then 18255, which will remove 8.


bq. The links posted for in-jvm tests return 404 error

Really weird. I see those jobs start, and then disappear… am investigating… 

bq. On a deeper look - we see those were the Nashorn warnings, the failures are different compilation errors as pre-4.0 versions of cassandra were build with JDK11, instead of 8. 

Good catch.

The intention is that ci-cassandra.a.o does not do cross-jdk. That is, the same jdk is used for compilation and running, including upgrade tests.

So the fix here is to prevent (in trunk) ccm trying to compile versions that it won't be using anyway. (Any version of C* that cannot be compiled with jdk11 will no be included in the upgrade tests.)
Working on it… 

bq. The links posted for in-jvm tests return 404 error

Those jobs are complete now.

{quote}Those jobs are complete now.
{quote}
Thanks!
 - jvm-dtest-upgrade - the same amount of tests run as in current trunk. I took a look at a few tests and stumbled into 
simpleUpgradeWithNetworkAndGossipTest for example. It explicitly has a call to [.upgradesToCurrentFrom(v3X)|https://github.com/apache/cassandra/blob/trunk/test/distributed/org/apache/cassandra/distributed/upgrade/UpgradeTest.java#L37] so it seems the current matrix correctly ignores this call when it sees JDK which is not supported by the respective Cassandra version we are trying to build. But I am thinking we should probably change the method _upgradesToCurrentFrom(version)_ to maybe _upgradesToCurrent()_ or so? And document that the versions we upgrade from are detected based on the JDK version supported or so? Otherwise it looks confusing at the moment.
 - jvm-dtest - The number of tests run seems close to what we would expect. Test failures:
_- org.apache.cassandra.distributed.test.repair.ForceRepairTest.force_ - new timeout I haven't seen recently, we can keep an eye on it whether it was just random
_org.apache.cassandra.distributed.test.InternodeEncryptionEnforcementTest.testOutboundConnectionsAreRejectedWhenAuthFails_ - timeout in a class that is known to have failures already. 

The rest of the failures match what we already know about. 

bq.  It explicitly has a call to .upgradesToCurrentFrom(v3X) so it seems the current matrix correctly ignores this call when it sees JDK which is not supported by the respective Cassandra version we are trying to build. But I am thinking we should probably change the method upgradesToCurrentFrom(version) to maybe upgradesToCurrent() or so? And document that the versions we upgrade from are detected based on the JDK version supported or so? Otherwise it looks confusing at the moment.

Some tests have valid reason to explicitly define the upgrade path.
upgradesToCurrentFrom(_) makes sense as it is intentionally from an explicit minimum version.

The apidocs are:
{code}
        /** performs all supported upgrade paths that exist in between from and CURRENT (inclusive) **/
        public TestCase upgradesToCurrentFrom(Semver from) {…}

        /**
         * performs all supported upgrade paths to the "to" target; example
         * {@code upgradesTo(3.0, 4.0); // produces: 3.0 -> 4.0, 3.11 -> 4.0}
         */
        public TestCase upgradesTo(Semver from, Semver to) {…}

        /**
         * performs all supported upgrade paths from the "from" target; example
         * {@code upgradesFrom(4.0, 4.2); // produces: 4.0 -> 4.1, 4.0 -> 4.2}
         */
        public TestCase upgradesFrom(Semver from, Semver to) {…}

        /**
         * performs all supported upgrade paths that exist in between from and to that include the current version.
         * This call is equivilent to calling {@code upgradesTo(from, CURRENT).upgradesFrom(CURRENT, to)}.
         **/
        public TestCase upgrades(Semver from, Semver to) {…}

        /** Will test this specific upgrade path **/
        public TestCase singleUpgradeToCurrentFrom(Semver from) {…}
{code}

But we do have the overhead of when {{CURRENT}} changes (replaced with a specific version, e.g. {{v50X}}) we then need to scan the tests and fix it. The same problem exists in dtest-upgrades.

We could add an assert in these methods to prevent illegal (unsupported) upgrade paths.

The method does not need to change name, but all such calls should be replaced with `{{. upgrades(V3X, v41)}}`




bq. On a deeper look - we see those were the Nashorn warnings, the failures are different compilation errors as pre-4.0 versions of cassandra were build with JDK11, instead of 8.

Fix: https://github.com/apache/cassandra-dtest/compare/trunk...thelastpickle:cassandra-dtest:mck/17869
CI (running) UPDATED
 dtest: http://13.50.248.249:8080/job/Cassandra-trunk-dtest/17/
 dtest-upgrade: http://13.50.248.249:8080/job/Cassandra-trunk-dtest-upgrade/6/

I will start working on the similar fix for jvm-dtest, addressing your previous comment.

bq. But we do have the overhead of when CURRENT changes (replaced with a specific version, e.g. v50X) we then need to scan the tests and fix it. The same problem exists in dtest-upgrades. We could add an assert in these methods to prevent illegal (unsupported) upgrade paths.

My bad, all the methods are already doing this (and the apidoc says so as well).

{quote}Some tests have valid reason to explicitly define the upgrade path.
{quote}
Agreed
{quote}The method does not need to change name, but all such calls should be replaced with
{quote}
I was looking for a way not to have to change those calls in all tests. As then every time we move forward with branches and JDK versions we need to modify the lower/upper bound for upgrading in each test. And considering we keep on adding more tests, it sounds more time consuming and easy to forget... :( Though we are at least covered from the matrix we will run only what we support. It is just confusing and more checks around versions in the background

Looking one more time into the upgrade tests methods actually we have two issues with upgrade tests:
 * the matrix fixes the lower bound (If we start/got through a version which does not build with specific JDK version we skip it). So not an issue per se, the matrix is checking that but it is confusing when reading tests why we have mentioned start versions for paths we will not support upgrades at all.
 * upper bound of a version to upgrade to should be changed on branching new major, that part is for another ticket IMO but we should not forget to consider it. If it is not already a part of any of the other tickets for CI/release management, I can open one so we do not forget about this (knowing myself I will forget if I do not write it down :( )

 

 

bq. As then every time we move forward with branches and JDK versions we need to modify the lower/upper bound for upgrading in each test. And considering we keep on adding more tests, it sounds more time consuming and easy to forget...  

We won't forget if we put in asserts. That way it must be done when branching/bumping the version. IMHO this is a good start, and will ensure things move in the right direction, without the need of a jira ticket (that is usually only on the reporter's radar and otherwise all too easily forgotten).


I've added such an assert to dtests here:
https://github.com/apache/cassandra-dtest/commit/824c90c4d8b606d3beffc57f99c666d41828bca8#diff-16fb32b744845ae88f5f9638516d36b89d7ff14b2215779c3dc8959e567c8ab2R262

bq. confusing when reading tests why we have mentioned start versions for paths we will not support upgrades at all.

parameter names are a bit overloaded.
they could be:
{code}
upgradesToCurrentFrom(startingFrom)
upgradesTo(startingFrom, to)
upgradesFrom(from, endingTo)
upgrades(startingFrom, endingTo)
{code}
That is, "from" and "to" are fixed edges, while startingFrom and endingTo are bounds applied against the matrix of supported upgrade paths.

bq. upper bound of a version to upgrade to should be changed on branching new major

this is not needed. all non-supported upgrade paths are excluded, and if a test ends up with no upgrade paths at all it will fail.

DTests are looking good now. So are dtest-upgrades.

Patches:
- [cassandra-builds|https://github.com/apache/cassandra-builds/compare/trunk...thelastpickle:cassandra-builds:mck/17869]
- [cassandra-dtest|https://github.com/apache/cassandra-dtest/compare/trunk...thelastpickle:cassandra-dtest:mck/17869]
- [cassandra|https://github.com/apache/cassandra/compare/trunk...thelastpickle:cassandra:mck/17869_v2/trunk]

Test runs look way better now, I left some questions on your commits.

Most of them are about how we select what upgrade path to run.

Main ones that bother me:
 * now we run many more tests for Python upgrade tests and I do not understand certain changes. Maybe it's just me. I left questions on the commits
 * In-jvm upgrade tests run the same amount of tests we were running with JDK8 and they all pass? I would have expected there were certain paths from 3, 3.11 that we skip now? Where do we check the JDK version for them, similar to what you did for python dtests here:  [https://github.com/apache/cassandra-dtest/commit/824c90c4d8b606d3beffc57f99c666d41828bca8#diff-16fb32b744845ae88f5f9638516d36b89d7ff14b2215779c3dc8959e567c8ab2R262]
The only check I find for JDK is in cassandra-builds to identify for which JDK to run upgrade tests

bq. now we run many more tests for Python upgrade tests and I do not understand certain changes.

Extra dtest-upgrade tests come from the addition of this: https://github.com/apache/cassandra-dtest/compare/trunk...thelastpickle:cassandra-dtest:mck/17869#diff-31d0989c90471274d54ccce871e5ea977ba477d1b55ee13be6f399fd844c16cfR190 

We weren't previously doing upgrade tests from 4.1 releases (to 4.1 dev and to trunk), i.e. the manifest map `{{current_4_1_x}}`

bq. In-jvm upgrade tests run the same amount of tests we were running with JDK8 and they all pass? I would have expected there were certain paths from 3, 3.11 that we skip now? 

Should be the same number of tests, the change to upgrade paths happened already with the version bump: https://github.com/apache/cassandra/commit/7ca806c60a3e080d740fb163c639bb76a520f6ab#diff-b04a7dc5d2948794698a86fc8df005db9cf8c94d9dbc900f7613b13b0b7d1649

Of note

bq. Patches … cassandra

Since JDK15 biased locking is disabled by default, and the flag `-XX:-UseBiasedLocking` does nothing (except print a deprecation warning). This is why the cassandra patch removes it from the common jvm-server.options file and adds it back to only the jvm8-server.options and jvm11-server.options files.

Thank you for explaining. Now it clicked. It seems in-jvm and python upgrade paths were in different state in regards to the new major so that confused me.
 * When I run(we do this in CircleCI and as far as I recall same in Jenkins):
{{./run_dtests.py --execute-upgrade-tests-only --upgrade-target-version-only --upgrade-version-selection all --dtest-print-tests-only --dtest-print-tests-output=/tmp/all_dtest_tests_j8_upgradetests --cassandra-dir=/cassandra}}
I can see a few upgrade tests from 3.x versions. It seems we need some additional filtering for those if I am not missing anything. Left comment in the dtest branch with details
 * cassandra-builds changes will affect also previous branches so I guess when the time to commit anything comes, we should test them that nothing shifted. 
 * I also left a few comments in the cassandra-builds commits. I fear there might be places where we still want to consider CASSANDRA_USE_JDK11 for 4.0 and 4.1 but I guess we should test.
 * Also, aren't we going to add upgrade tests with JDK 11 also for 4.0 to 4.1? It occurs to me that the current patch considers only 4.0 to trunk and 4.1 to trunk and nothing changes in regards to upgrade tests for 4.0 and 4.1. Those will continue to be run only with JDK8. 

bq. I can see a few upgrade tests from 3.x versions.

Strictly speaking I think this is out-of-scope. Will look if it is easy to fix…

bq. cassandra-builds changes will affect also previous branches so I guess when the time to commit anything comes, we should test them that nothing shifted. 

Yes, most are already run on the custom jenkins.

bq. … fear there might be places where we still want to consider CASSANDRA_USE_JDK11 for 4.0 and 4.1

This is not a problem, the grep against java.version.11 works on past code too.

bq. aren't we going to add upgrade tests with JDK 11 also for 4.0 to 4.1?

No. Upgrade tests will use the lowest (default) JDK that is in common. 4.0 and 4.1 share JDK8 so that will be used for that path. I don't see the ROI in testing additional JDKs here.

{quote}Strictly speaking I think this is out-of-scope
{quote}
I am confused. When I asked for a separate ticket for upgrade tests you said you will handle them here and you also initiated updating the upgrade paths. With that said, I don't mind if you pull in a follow up ticket all upgrade paths changes and we focus on bringing upgrade tests J11 to what we see currently with J8. Please let me know.
{quote}This is not a problem, the grep against java.version.11 works on past code too.
{quote}
(y)
{quote}No. Upgrade tests will use the lowest (default) JDK that is in common. 4.0 and 4.1 share JDK8 so that will be used for that path. I don't see the ROI in testing additional JDKs here.
{quote}
(y)

Do we need to keep proliferating RUN_STATIC_MATRIX?  As I recall it only makes things break by running incompatible upgrades, so even though we aren't setting the env var it seems like keeping a sharp edge around.

Maybe in case anyone use it in their environment and we break people if we just remove it?

{quote}
bq. Strictly speaking I think this is out-of-scope. Will look if it is easy to fix…

I am confused. When I asked for a separate ticket for upgrade tests you said you will handle them here and you also initiated updating the upgrade paths. With that said, I don't mind if you pull in a follow up ticket all upgrade paths changes and we focus on bringing upgrade tests J11 to what we see currently with J8. Please let me know.
{quote}

Fixed here: https://github.com/apache/cassandra-dtest/commit/274865a2526c4f267b0ff0552d286573a395d4ad#r109607751

Here are the latest CI runs:
* trunk, no failures http://16.16.124.107:8080/job/Cassandra-trunk-dtest-upgrade/13/
* 2.2, same as ci-cassandra.a.o http://16.16.124.107:8080/job/Cassandra-2.2-dtest-upgrade/9
* 4.1, one failure (fixed in next run) http://16.16.124.107:8080/job/Cassandra-4.1-dtest-upgrade/12/

I had to bounce the ip (previous got ASF denylisted). all history to previous CI runs is there (same jenkins install, just ec2 instance rebooted).  The denylist was from ccm git cloning gitbox.a.o , we should in a separate ticket  change ccm to clone from github instead.

The last commit 9c71991d7c on cassandra-dtest was to fix the last remaining failure on 4.1, success can be seen here: http://16.16.124.107:8080/job/Cassandra-4.1-dtest-upgrade/jdk=jdk_1.8_latest,label=cassandra-dtest,split=55/13/testReport/dtest-upgrade.upgrade_tests.drop_compact_storage_upgrade_test/TestDropCompactStorage/test_drop_compact_storage_mixed_cluster/

Additional trivially dtest commit b4c79c8649 that fixes two dtest-upgrade failures on 2.2

Everything looks good to me or is being handled in another ticket, so I am +1.

+1, thank you

Cleaning up squash commits…

Committed
[33d1c4315cec2925f704a36d4ef364d9aeafe1cd |https://github.com/apache/cassandra/commit/33d1c4315cec2925f704a36d4ef364d9aeafe1cd], [29ed31542bc7503c7c5695ce8012a555b4b3fb6f |https://github.com/apache/cassandra/commit/29ed31542bc7503c7c5695ce8012a555b4b3fb6f], [52053200e75d3e6718c03bfa68232dfb94f9a566 |https://github.com/apache/cassandra-dtest/commit/52053200e75d3e6718c03bfa68232dfb94f9a566], [7e205252a001b9316efe98da329d26e3b62c1df9 |https://github.com/apache/cassandra-builds/commit/7e205252a001b9316efe98da329d26e3b62c1df9].

No jdk17 installed on cassandra-arm agents. I have ninja-fixed disabled arm on ci-cassandra.a.o until INFRA-24508 gets done.

git cloning in the docker containers was also broken, fixed by restarting docker daemons.
and debian stretch no longer found, switched to sid.
neither these problems were related to this ticket.

Follow on fix here: https://github.com/apache/cassandra-dtest/commit/d0e435304d5b04ebc782fc58ac38eed8720f4e51

The 2.1 to 3.x upgrade path needed to be added back, as we have some valid tests there (run when on 3.x branches). And the upgrade_manifest.CONFIG needs to be now set when running normal dtests as the upgrade paths we assert against are those found in upgrade_manifest.

Pre-commit CI was
 - 2.2 https://app.circleci.com/pipelines/github/michaelsembwever/cassandra/155/workflows/88ba46a7-f09f-4eff-b7f9-ff365f630769
 - 3.0 https://app.circleci.com/pipelines/github/michaelsembwever/cassandra/149/workflows/8f2d2153-e02f-4532-9aaf-a0495601fe22
 - 3.11 https://app.circleci.com/pipelines/github/michaelsembwever/cassandra/150/workflows/33f936fe-8a18-48dd-b27d-f2b22e6c864b
 - 4.0 https://app.circleci.com/pipelines/github/michaelsembwever/cassandra/151/workflows/74683d61-3486-4c61-8d01-94d8da8fee16
 - 4.1 https://app.circleci.com/pipelines/github/michaelsembwever/cassandra/152/workflows/04be30b8-b211-43be-a098-1813cbb1aa2a



+1 for the follow up.

As agreed during review, two follow up tasks were opened - CASSANDRA-18501 and CASSANDRA-18502

Also, it seems we have some issue with the rolling upgrade tests in CircleCI now as reported in CASSANDRA-18499

