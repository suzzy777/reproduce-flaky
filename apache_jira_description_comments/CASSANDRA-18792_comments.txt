There are two problems (at least) here.  The first one is the 'Node is involved in cluster membership changes' error.  This is coming from node2 even though node1 has been moved because there is a race between nodetool returning from node1 and the streaming session being closed out on node2.  A [small sleep|https://github.com/driftx/cassandra-dtest/commit/dfd506ec81fb30a444da54e79e539159813815e1] is all we need to [avoid that|https://app.circleci.com/pipelines/github/driftx/cassandra/1266/workflows/584d0c94-1a42-4747-99bd-869e076184d5/jobs/51039] but leaves us with the second problem: occasional timeouts that are not environmental since they occur on a consistent basis both on circle and locally for me.

There's no real pattern to which node doesn't see node2 (the one that's always moved) come back up, and they appear to just miss the message:

bq. INFO  [GossipStage:1] 2023-09-12 20:41:08,196 Gossiper.java:1465 - Node /127.0.0.2:7000 has restarted, now UP

...

bq. ccmlib.node.TimeoutError: 12 Sep 2023 20:43:08 [node4] after 120.11/120 seconds Missing: ['127.0.0.2:7000.* is now UP'] not found in system.log:

I suspect this is the issue with this one too - CASSANDRA-18686

bq. they appear to just miss the message

From the 'Head' and 'Tail' in the error from watch_log_for, I can see that the UP message is indeed between those and present in the log, but somehow missed. Which doesn't really make any sense since we know that should work.

It turns out the message is actually missing, there are just two similar messages, one [here|https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/gms/Gossiper.java#L1465]: "restarted, now UP" which we have, but we need the one [here|https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/gms/Gossiper.java#L1411]: "is now UP" which occurs in realMarkAlive after the node has responded to an echo request.  In our failure case, the echo request is failing and never seems to be retried, which seems like another bug.

And that bug lies in CASSANDRA-18543, which I took a shot at and manually reverted, which now [makes the test pass|https://app.circleci.com/pipelines/github/driftx/cassandra/1269/workflows/05a0a95e-c71a-4698-ba61-ebe2fbdd9b81/jobs/51407].  I'll create a ticket for this.

[Here|https://app.circleci.com/pipelines/github/driftx/cassandra/1269/workflows/d3c9e9e5-cb6b-43fd-84cd-0487d421f7a3/jobs/51409] is another run that confirms it wasn't just luck.  Created CASSANDRA-18854 to handle this.

With CASSANDRA-18854 committed, [here|https://app.circleci.com/pipelines/github/driftx/cassandra/1299/workflows/317bdd56-281d-4230-8c7c-ac9a8330d4ba/jobs/54378] is a run against [this branch|https://github.com/driftx/cassandra-dtest/tree/CASSANDRA-18792].

Shouldn't we just close this one as a duplicate of CASSANDRA-18854?

No, CASSANDRA-18854 is only part of the problem here, we still need the dtest fix.

The sleep in the dtest needs some comment imo. Otherwise it's going to be too difficult for the reader to understand.

Agreed, I will add that on commit if the rest is good.

Th rest LGTM

Committed w/comment added, thanks!

