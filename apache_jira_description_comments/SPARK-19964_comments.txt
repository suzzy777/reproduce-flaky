It doesn't fail in master. This sounds like the kind of thing that fails when you have old builds lying around - could be local?

[~srowen] it looks like this is failing periodically in master: https://spark-tests.appspot.com/test-details?suite_name=org.apache.spark.deploy.SparkSubmitSuite&test_name=includes+jars+passed+in+through+--jars (I added flaky to the name which is I suspect the source of confusion)


Still flaky:
https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/88624/testReport/org.apache.spark.deploy/SparkSubmitSuite/includes_jars_passed_in_through___packages/

{noformat}
sbt.ForkMain$ForkError: org.scalatest.exceptions.TestFailedDueToTimeoutException: The code passed to failAfter did not complete within 60 seconds.
	at java.lang.Thread.getStackTrace(Thread.java:1552)
	at org.scalatest.concurrent.TimeLimits$class.failAfterImpl(TimeLimits.scala:234)
	at org.apache.spark.deploy.SparkSubmitSuite$.failAfterImpl(SparkSubmitSuite.scala:1066)
	at org.scalatest.concurrent.TimeLimits$class.failAfter(TimeLimits.scala:230)
	at org.apache.spark.deploy.SparkSubmitSuite$.failAfter(SparkSubmitSuite.scala:1066)
	at org.apache.spark.deploy.SparkSubmitSuite$.runSparkSubmit(SparkSubmitSuite.scala:1085)
	at org.apache.spark.deploy.SparkSubmitSuite$$anonfun$9$$anonfun$apply$mcV$sp$1.apply(SparkSubmitSuite.scala:525)
	at org.apache.spark.deploy.SparkSubmitSuite$$anonfun$9$$anonfun$apply$mcV$sp$1.apply(SparkSubmitSuite.scala:514)
	at org.apache.spark.deploy.IvyTestUtils$.withRepository(IvyTestUtils.scala:377)
	at org.apache.spark.deploy.SparkSubmitSuite$$anonfun$9.apply$mcV$sp(SparkSubmitSuite.scala:514)
	at org.apache.spark.deploy.SparkSubmitSuite$$anonfun$9.apply(SparkSubmitSuite.scala:510)
	at org.apache.spark.deploy.SparkSubmitSuite$$anonfun$9.apply(SparkSubmitSuite.scala:510)
{noformat}

I ran into this failure in our internal jenkins also... the logs look similar to the above failure. It seems the code is taking a long time inside ivy libraries:

{noformat}
18/03/27 02:20:43.516 Utils: SLF4J: Class path contains multiple SLF4J bindings.
...
18/03/27 02:21:22.384 Utils: 	found my.great.lib#mylib;0.1 in repo-1
{noformat}

Those are the first and last log lines for the test. In our internal jenkins spark-submit makes further progress, but still the timeout is caused by the call into ivy taking a long time:

{noformat}
18/03/27 11:21:20.307 Ivy Default Cache set to: /var/lib/jenkins/.ivy2/cache
...
18/03/27 11:21:20.582 :: resolving dependencies :: org.apache.spark#spark-submit-parent;1.0
18/03/27 11:21:20.582 	confs: [default]
18/03/27 11:21:41.618 	found my.great.lib#mylib;0.1 in repo-1
18/03/27 11:22:11.271 	found my.great.dep#mylib;0.1 in repo-1
...
18/03/27 11:22:18.878 INFO BlockManagerMasterEndpoint: Registering block manager 172.28.195.10:58362 with 366.3 MB RAM, BlockManagerId(0, 172.28.195.10, 58362, None)
{noformat}

Wonder if it has anything to to with ivy trying to access the network during these tests, or some local lock maybe (which would be affected by multiple jenkins jobs on the same machine).

http://dl.bintray.com doesn't seem to be loading right now, and that repo is hardcoded in {{SparkSubmit.scala}}. Might be good to make tests skip these remote repos if they don't need them.

User 'vanzin' has created a pull request for this issue:
https://github.com/apache/spark/pull/20916

Fixed in https://github.com/apache/spark/pull/20916

