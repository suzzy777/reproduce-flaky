cc [~philipthompson] 

I'll take a whack at reviewing this in the new year, but I'll need help on the gnarly python-specific things

There are a couple of tests left that need renaming to get picked up by pytest. Class names need to start with {{Test}} now if they have {{test_}} methods that should be run and are not purely used as superclass.

{noformat}
> find . -name \*.py |xargs egrep '^class [^(]+\(Tester\)' | grep -v 'class Test'
./thrift_hsha_test.py:class ThriftHSHATest(Tester):
./cql_test.py:class CQLTester(Tester):
./delete_insert_test.py:class DeleteInsertTest(Tester):
./sstable_generation_loading_test.py:class BaseSStableLoaderTest(Tester):
./replace_address_test.py:class BaseReplaceAddressTest(Tester):
./snapshot_test.py:class SnapshotTester(Tester):
./paging_test.py:class BasePagingTester(Tester):
./replication_test.py:class ReplicationTest(Tester):
./replication_test.py:class SnitchConfigurationUpdateTest(Tester):
./thrift_test.py:class ThriftTester(Tester):
./cqlsh_tests/cqlsh_copy_tests.py:class CqlshCopyTest(Tester):
./cqlsh_tests/cqlsh_tests.py:class CqlshSmokeTest(Tester):
./cqlsh_tests/cqlsh_tests.py:class CqlLoginTest(Tester):
./sstableutil_test.py:class SSTableUtilTest(Tester):
./upgrade_tests/compatibility_flag_test.py:class CompatibilityFlagTest(Tester):
./upgrade_tests/thrift_upgrade_test.py:class UpgradeSuperColumnsThrough(Tester):
./upgrade_tests/upgrade_through_versions_test.py:class UpgradeTester(Tester):
./upgrade_tests/upgrade_compact_storage.py:class UpgradeSuperColumnsThrough(Tester):
./json_test.py:class ToJsonSelectTests(Tester):
./json_test.py:class FromJsonUpdateTests(Tester):
./json_test.py:class FromJsonSelectTests(Tester):
./json_test.py:class FromJsonInsertTests(Tester):
./json_test.py:class FromJsonDeleteTests(Tester):
./json_test.py:class JsonFullRowInsertSelect(Tester):
./native_transport_ssl_test.py:class NativeTransportSSL(Tester):
./repair_tests/preview_repair_test.py:class PreviewRepairTest(Tester):
./repair_tests/repair_test.py:class BaseRepairTest(Tester):
{noformat}



Some minor readme feedback.

* Remove INSTALL.md and reference from README.md
* There is no virtualenv brew package, people should probably brew install brew-pip and then pip install virtualenv although I haven't tested this
* ~/.cassandra-dtest is still referenced in the readme and doesn't work anymore

I followed the instructions in the README, patched CCM in the virtual env, used (commit 05e434d1930298635f1de993483d1f682c3a9380 (HEAD, kjellman/dtests_on_pytest_v2), cassandra (commit 21be9d2f50cc6a6bdceff56389adc015f811d5d6 (HEAD, apache/trunk)) and got:
{noformat}
(venv-dtest) aweisberg-MacBook-Pro:cassandra-dtest aweisberg$ pytest --cassandra-dir=~/repos/cassandra
======================================================== test session starts =========================================================
platform darwin -- Python 3.6.4, pytest-3.3.1, py-1.5.2, pluggy-0.6.0
rootdir: /Users/aweisberg/repos/cassandra-dtest, inifile: pytest.ini
plugins: timeout-1.2.1, flaky-3.4.0
collected 1885 items / 1 errors

===Flaky Test Report===


===End Flaky Test Report===
=============================================================== ERRORS ===============================================================
_________________________________________________ ERROR collecting metadata_test.py __________________________________________________
metadata_test.py:10: in <module>
    class TestMetadata(Tester):
metadata_test.py:29: in TestMetadata
    @pytest.mark.skip(reason='hangs CI')
E   NameError: name 'pytest' is not defined
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 errors during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
======================================================= 1133 tests deselected ========================================================
============================================== 1133 deselected, 1 error in 4.32 seconds ==============================================
(venv-dtest) aweisberg-MacBook-Pro:cassandra-dtest aweisberg$ ./run_dtests.py --cassandra-dir=~/repos/cassandra
============================= test session starts =============================={noformat} 

For --cassandra-dir= you can't use ~/somepath because it won't expand ~. So sanitize the readme to not rely on that.

[~spodxx@gmail.com] good catch! i just pushed a commit to rename the additional snowflake test classes that i missed. i assume it's going to take me a few additional commits here to fix runtime exceptions on those tests from python 3 fallout on these test classes as they weren't being run in my testing thus far

[~aweisberg] just pushed up a fix for the missing pytest import on metadata_test.py

I think we should also preserve the CASSANDRA_DIR/CASSANDRA_VERSION configuration options. Being able to set an environment variable or keep an ini can be much more convenient than having to always include it as a cli option

also, here are fixes for 2 tests that were broken by the 2->3 / nose->pytest translation:

[fixing repair_tests.incremental_repair_test.TestIncRepair.test_subrange|https://github.com/bdeggleston/cassandra-dtest/commit/82b5179bc3bc35c13ef2caa1274def041421160e]
[fixing sstable_generation_loading_test.TestSSTableGenerationAndLoading.test_remove_index_file|https://github.com/bdeggleston/cassandra-dtest/commit/86bd7945e40c5bf0d2835b50fd408e847a2dd643]

i strongly disagree with this [~bdeggleston].... you shouldn't need to look thru the source or read random documentation to know how to run the dtests. these are required parameters and we should have good --help around them and validation when they are provided as arguments to see if they exist etc.

[~bdeggleston] thanks. committed the changes for the two tests you fixed above.

I'm not saying we should remove the command line parameters, just that we shouldn't remove the existing environment variables and ini stuff.

Also, regarding the {{~}} expansion, {{os.path.expanduser}} will do that. Probably better to do that internally than make users put in the full path?

I also liked the environment variables, but I think they aren't the best way forward. One of my biggest complaints is the extensive incantations you had to remember to get a usable debuggable run out of the dtests.

KEEP_TEST_DIR
CASSANDR_DIR
A bunch of stuff related to having stdout do something reasonable, logging to a file, making output visible immediately rather than at the end, including output for succeeding tests and not just failed tests.
Something related to logging so serious errors didn't just silently cause tests to fail with tool output not logged

I had all that stuff exported in my profile, but maybe a better way is to have a documented config file that is picked up so that rather than have to search for the common options you just edit the file and set/uncomment the ones you want. Environment variables aren't really that great because they aren't discoverable like a well documented config file.

If we really wanted to be minimal it could just be a shell script that invokes pytest and has all the optional stuff as environment variables that you can modify/uncomment to get the common behaviors people want. Then you don't have to do any config file plumbing and it's consistent with the pytest help output.

I committed quite a lot of extra fixes today to the branch. Some was to deal with broken tests that weren't being executed due to the regex not matching some of the test classes as [~spodxx@gmail.com] noticed this morning. I think that's fully resolved now but I'd appreciate it if you eyeball the branch as it exists now!

I also merged in a few tests fixed today by [~beobal] and [~bdeggleston]. With all of that work, we are *very* close to passing without any test failures but there are a few flaky tests that keep popping up and preventing victory...

+The latest two runs are below:+
* With vnodes
** https://circleci.com/gh/mkjellman/cassandra/339
** ran 771 tests with 3 failures (run time 18:51)
* Without vnodes 
** https://circleci.com/gh/mkjellman/cassandra/338
** ran 796 tests with 3 failures (run time 11:51)

Exciting news! Just got our first fully green/successful run!

https://circleci.com/gh/mkjellman/cassandra/365

Your build ran 796 tests in unknown with 0 failures
Slowest test: consistency_test.TestConsistency test_short_read (took 593.89 seconds).

Even more exciting news! We have a SECOND fully green/successful run!!!

https://circleci.com/gh/mkjellman/cassandra/383

Your build ran 796 tests in unknown with 0 failures
Slowest test: consistency_test.TestConsistency test_short_read (took 773.07 seconds).

Linking to the github diff seems broken right now. So I will have to specify files and line numbers.

* One thing I noticed is that it seems like it's a bit easier for the harness to orphan a running cluster? I know that with the nosetest setup I generally never had to worry about leaving a C* cluster behind (which is pretty shocking), but when I killed a running test today it left behind the cluster.
* cdc_test.py line 350 is part of a broken test you added a skip annotation to. It looks like you added some whitelisting for log output, but that didn't fix the test. Should we remove the whitelisting since it's not the right fix for the test?
* commitlog_test.py line 444, why do you have to use that idiom to update the list? List appending is still in python 3? Is this to avoid the not defined check?
* Can you elaborate on why you had to switch to opening files in binary mode? Was it a bug originally? Looks like those files are indeed binary. I am just wondering if it manifested differently in python 3.
* dtest.py:176, comment is out of date? Fault handler is always on now?
* dtest.py has a few commented out bits of code that eventually probably need to be deleted
* materialized view tests line 2390 you switch from threads to processes and added a join? What were you trying to address by switching from processes to threads, and adding the joins and timeouts? Was it hanging?
* I see cases in asserts where constant integers were changed from say 7L to just 7. Is that intentional? What is that about? (materialized view test, paging test)
* paxos_tests, you removed the utf-8 encoding statement at the top? Was that doing anything? This happens in several files.
* read_repair_test is now inlining a method manually? test_read_repair? Do we have to have that duplication? I know this Beobal's commit so I'll probably have to come back to it.
* incremental_repair_test:176, it's using the Latin-1 encoding?
* base_replace_address_test failed to properly handshake peer, is this just another case of this error is generated and it's fine? Seems like you add this to tests that use JMX. Maybe using JMX should automatically cause this to be added to ignored log lines?
* run_dtest.py still does the fork to a separate process. Does that accomplish anything? Can we remove it?
* snapshot_test assert_directory_not_empty, I looked at this twice, it's just a little too confusing and needs a comment as to what the parameters are and how it works.
* You regenerated the thrift bindings to get a python 3 supported version? You removed pycassa but it also looks like we were hardly using it? Just want to make sure I understand what happened.
* tools/assertions.py assert_lists_equal_ignoring_order, this seems to sort results coming from the DB. Shouldn't the DB already be providing a consistent sort order for results? I thought that was well defined. I am wondering if we are papering over result ordering issues in the DB.

I am going to look at read_repair_test now as it was a pretty significant change and I don't know exactly what went down there.

>Can you elaborate on why you had to switch to opening files in binary mode? Was it a bug originally? Looks like those files are indeed binary. I am just wondering if it manifested differently in python 3.

This is a python3 change. This gives us the same behavior we were relying on in python2.

>I see cases in asserts where constant integers were changed from say 7L to just 7. Is that intentional? What is that about? (materialized view test, paging test)

This was just something changed by the 2to3 tool.

> paxos_tests, you removed the utf-8 encoding statement at the top? Was that doing anything? This happens in several files.

this is unnecessary now in python3. everything is utf-8 by default.

> read_repair_test is now inlining a method manually? test_read_repair? Do we have to have that duplication? I know this Beobal's commit so I'll probably have to come back to it.

[~beobal], thoughts? the test isn't flaky anymore though...

> base_replace_address_test failed to properly handshake peer, is this just another case of this error is generated and it's fine? Seems like you add this to tests that use JMX. Maybe using JMX should automatically cause this to be added to ignored log lines?

did you run this locally to see this failure? i've seen this fail a few times in circle but not frequently...

> run_dtest.py still does the fork to a separate process. Does that accomplish anything? Can we remove it?

i think we can remove it... and maybe even just call pytest directly?

> snapshot_test assert_directory_not_empty, I looked at this twice, it's just a little too confusing and needs a comment as to what the parameters are and how it works.

i didn't code this.. just moved it... 

> You regenerated the thrift bindings to get a python 3 supported version? You removed pycassa but it also looks like we were hardly using it? Just want to make sure I understand what happened.

yes, pycassa isn't python 3 compatible and we needed new thrift bindings to get python 3 support for the remianing thrift tests we still have. [~jjirsa] did this work.

> tools/assertions.py assert_lists_equal_ignoring_order, this seems to sort results coming from the DB. Shouldn't the DB already be providing a consistent sort order for results? I thought that was well defined. I am wondering if we are papering over result ordering issues in the DB.

good question... i just maintained existing behavior in the asserts.... 

{noformat}
> base_replace_address_test failed to properly handshake peer, is this just another case of this error is generated and it's fine? Seems like you add this to tests that use JMX. Maybe using JMX should automatically cause this to be added to ignored log lines?
did you run this locally to see this failure? i've seen this fail a few times in circle but not frequently...
{noformat}
Sorry I butchered this question. I didn't notice a failure. So someone added log filtering to ignore that message. I think it's something that nodetool generates spuriously some of the time. I was suggesting detecting when nodetool has been invoked and automatically filtering the line.

bq. i think we can remove it... and maybe even just call pytest directly?
I am game for trying and seeing if anything goes wrong.

{noformat}
> snapshot_test assert_directory_not_empty, I looked at this twice, it's just a little too confusing and needs a comment as to what the parameters are and how it works.
i didn't code this.. just moved it...
{noformat}
Well... someone added it as part of the various change sets because it didn't exist before and wasn't invoked by the the test that is using it. There was some other snippet inllined to do the comparison previously. Blame fingers you for changing the invocations.

{noformat}
> tools/assertions.py assert_lists_equal_ignoring_order, this seems to sort results coming from the DB. Shouldn't the DB already be providing a consistent sort order for results? I thought that was well defined. I am wondering if we are papering over result ordering issues in the DB.
good question... i just maintained existing behavior in the asserts....
{noformat}
Ah you are right. I didn't realize that is what assertItemsEqual did. Well you didn't make it worse and at least now it's more explicit as to what the comparison is doing.

Finally just got a successful test run of the entire workflow!

[https://circleci.com/workflow-run/f3c2daf6-1537-4a5a-9c68-ff4f3f27d350]

Will press my luck now and see if I can get back to back green passes at the workflow level. :)

Reviewing the commits after the first review it seems like you have been adding a lot of sleeps to try and fix stuff and in at least the one [case I was looking at it doesn't fix the problem|https://github.com/apache/cassandra-dtest/commit/ab4b9b7f4b0f12fd667d16cc19d73efef99688a2].

The reason I push back on that is that future tests and modifications won't have the necessary sleeps. We want to push this into the infrastructure code as much as possible so we can "fix it once."

With several of them I need to review them on a case by case basis for appropriateness and does it fix the underlying problem. If a lot of these are schema change related I have to ask the question, why can't we change schema and know reliably when the schema is available to use? That seems like a pretty basic thing for the database to be able to do. If it doesn't work for us in tests I would say it's pretty broken for users. 

This also holds for nodetool. Nodetool shouldn't be generating errors some of the time spuriously.

[This shouldn't be necessary CCM has a log line it looks for to know when a node is up. If that's not working we need to fix it.|https://github.com/apache/cassandra-dtest/commit/bb1415597f80f2e4e25235e1ee8369b49561fc3f]

[This is another, wait for schema change stuff.|https://github.com/apache/cassandra-dtest/commit/c182a44b68a43dc0be50f1c3269ac220851010ac] If we really think this is necessary we should have them call a wrapper method. Really we shouldn't use sleeps we should do the schema change and then spin lightly waiting for the schema to be available everywhere it should be available by querying the nodes. Did this actually fix the test? 

[I really think we need to open up to a wider audience for discussing flaky annotations. We have already gone through this once and gone from using flaky to not using flaky.|https://github.com/apache/cassandra-dtest/commit/3ffa61717f760ef7bd6209ad1af9c7bba450492a] Flaky tests should be annoying and distracting.
Another usage of flakey https://github.com/apache/cassandra-dtest/commit/e2a3c5575155a45ae862400568be6463f47e1617
I am sort of warming up to using flaky because the alternative is that developers just don't use the tests and we are generally worse off.

[I couldn't figure out this fix for configuration test.|https://github.com/apache/cassandra-dtest/commit/aa225ab1c36959b3d19a607eddbae2b16f661194] Can you help out with an explanation for this? {{execute_concurrent_with_args}} doesn't document {{results_generator=True}}

I'm not sure if I should run the test fixes through CircleCI. Some of them have multiple rounds of changes and it's not clear which help and which are placebo or didn't end up contributing to reliability. Unless you know you only put in fixes that ended up clearing up a specific error?

So here are my ponies. I don't want to conflate the pytest changes with test fixes. The test fixes from Jan 4th and on I would really like to have broken out into individual tickets (per suite) and then we can run them to see which of these sleeps helps vs which doesn't. I just went and ran one test for instance and it's still flaky in multiple locations in the test including after a sleep was inserted.

I know it's annoying to break it out. The alternative is that we put in a bunch of changes some of which we don't know are effective and there some extra test code burden carrying around things that don't help. WDYT?

Happy to remove any commits that added sleeps to attempt to work around flaky tests due to schema changes -- some of them I did with [~jjirsa] and some myself. We too already discussed that maybe these are fundamental things that ccm needs to handle so it's fixed everywhere. I don't really know the answer there ot be honest.

My answer on how to coordinate test execution is still CASSANDRA-12944. Once we'd be able to raise e.g. a {{SecondaryIndexCreated(ks, table, col)}} event and propagate it to subscribed (dtest-)clients, we can get rid of sleep calls and brittle log file parsing. 

OK, how about we separate the flakey annotation work into a second ticket and the test fixes that consist of adding sleeps into a third ticket.

I wouldn't do the work to construct the branches for those other tickets we can discuss what you have here for now.

Then the only blockers for a +1 would be [these questions here|https://issues.apache.org/jira/browse/CASSANDRA-14134?focusedCommentId=16314133&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16314133] and it seems like you stopped using execute concurrent with results_generator=true, but left the comment in? I thought you added that in a few places, but now I don't see it and I can't find the commit where you removed it.

+1

Committed as:
Cassandra [e73bc32a940175a21700721bafaa593aa86a1a5f|https://github.com/apache/cassandra/commit/e73bc32a940175a21700721bafaa593aa86a1a5f]
dtests [49b2dda4e6643d2b18376d504b5fea4c0b3354a7|https://github.com/apache/cassandra-dtest/commit/49b2dda4e6643d2b18376d504b5fea4c0b3354a7]
cassandra-builds [6df93e990a93ea4e422b3b67b55cab49554909eb|https://github.com/apache/cassandra-builds/commit/6df93e990a93ea4e422b3b67b55cab49554909eb] and [63504a1ce2cec70e86bfd2f913325db8190f8f88|https://github.com/apache/cassandra-builds/commit/63504a1ce2cec70e86bfd2f913325db8190f8f88] and [d3cd2e8cec57633f8a064c3620f9f5af442640ca|https://github.com/apache/cassandra-builds/commit/d3cd2e8cec57633f8a064c3620f9f5af442640ca]

Thanks!

Hi [~mkjellman], [~aweisberg], should [.circleci/config.yml|https://github.com/apache/cassandra/blob/trunk/.circleci/config.yml] be part of the commit?

[~jay.zhuang] I was planning on doing that as a separate ticket/commit. got a bit sidelined with some other issues – hoping to get it done by EOD today. I'll ping the new JIRA here as well once it's created.

