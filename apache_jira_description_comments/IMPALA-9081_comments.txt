[~tarmstrong@cloudera.com] you've been working on mt_dop stuff lately and appear to have touched this test last. Any thoughts?

[~twmarshall] did you run into this locally or in a jenkins job? I did actually see a similar failure on my dev box at one point and put it down to a broken data load.

Its happened on several Jenkins jobs in the last day. I agree that it looks like an issue with data load, except that all of the other tests in those runs passed. I'll send you the links

Commit b496487cb9e8795050fd4f0215361da9849cdb67 in impala's branch refs/heads/master from Tim Armstrong
[ https://gitbox.apache.org/repos/asf?p=impala.git;h=b496487 ]

IMPALA-9081: disable flaky test temporarily

I still need to fix the root cause - I think there is an underlying bug
causing non-determinism in the stats.

Change-Id: Ie59973548a53ce85ca92d6a83c78290348cc69ab
Reviewed-on: http://gerrit.cloudera.org:8080/14542
Reviewed-by: Thomas Tauber-Marshall <tmarshall@cloudera.com>
Tested-by: Tim Armstrong <tarmstrong@cloudera.com>


{noformat}
F00:PLAN FRAGMENT [UNPARTITIONED] hosts=1 instances=1
|  Per-Host Resources: mem-estimate=1.01GB mem-reservation=12.09MB thread-reservation=1
WRITE TO HDFS [functional_parquet.alltypes, OVERWRITE=false, PARTITION-KEYS=(year,month)]
|  partitions=4
|  output exprs: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|  mem-estimate=1.00GB mem-reservation=0B thread-reservation=0
|
01:SORT
|  order by: year ASC NULLS LAST, month ASC NULLS LAST
|  mem-estimate=12.00MB mem-reservation=12.00MB spill-buffer=2.00MB thread-reservation=0
|  tuple-ids=2 row-size=80B cardinality=unavailable
|  in pipelines: 01(GETNEXT), 00(OPEN)
|
00:SCAN HDFS [functional_parquet.alltypessmall]
   HDFS partitions=4/4 files=4 size=14.51KB
   stored statistics:
     table: rows=unavailable size=unavailable
     partitions: 0/4 rows=unavailable
     columns missing stats: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col
   extrapolated-rows=disabled max-scan-range-rows=unavailable
   mem-estimate=16.00MB mem-reservation=88.00KB thread-reservation=0
   tuple-ids=0 row-size=80B cardinality=unavailable
   in pipelines: 00(GETNEXT)
{noformat}

{noformat}
F00:PLAN FRAGMENT [UNPARTITIONED] hosts=1 instances=1
|  Per-Host Resources: mem-estimate=1.01GB mem-reservation=12.09MB thread-reservation=1
WRITE TO HDFS [functional_parquet.alltypes, OVERWRITE=false, PARTITION-KEYS=(year,month)]
|  partitions=unavailable
|  output exprs: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|  mem-estimate=1.00GB mem-reservation=0B thread-reservation=0
|
01:SORT
|  order by: year ASC NULLS LAST, month ASC NULLS LAST
|  mem-estimate=12.00MB mem-reservation=12.00MB spill-buffer=2.00MB thread-reservation=0
|  tuple-ids=2 row-size=80B cardinality=unavailable
|  in pipelines: 01(GETNEXT), 00(OPEN)
|
00:SCAN HDFS [functional_parquet.alltypessmall]
   HDFS partitions=4/4 files=4 size=14.51KB
   stored statistics:
     table: rows=unavailable size=unavailable
     partitions: 0/4 rows=unavailable
     columns: unavailable
   extrapolated-rows=disabled max-scan-range-rows=unavailable
   mem-estimate=16.00MB mem-reservation=88.00KB thread-reservation=0
   tuple-ids=0 row-size=80B cardinality=unavailable
   in pipelines: 00(GETNEXT)
{noformat}
{noformat}
105c105
< |  partitions=4
---
> |  partitions=unavailable
120c120
<      columns missing stats: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col
---
>      columns: unavailable
139c139
{noformat}

Ok I know what's going on here.  In a couple of these tests we flip it from being a test to a non-test environment. This actually affects whether partition stats are updated via isStoredInImpaladCatalogCache(). So the loaded table differs depending on whether it was loaded when that flag was toggled. 
{noformat}
  @Test
  public void testMtDopValidationWithHDFSNumRowsEstDisabled() {
    // Tests that queries supported with mt_dop > 0 produce a parallel plan, or
    // throw a NotImplementedException otherwise (e.g. plan has a distributed join).
    TQueryOptions options = defaultQueryOptions();
    options.setMt_dop(3);
    options.setDisable_hdfs_num_rows_estimate(true);
    try {
      // Temporarily unset the test env such that unsupported queries with mt_dop > 0
      // throw an exception. Those are otherwise allowed for testing parallel plans.
      RuntimeEnv.INSTANCE.setTestEnv(false);
      runPlannerTestFile("mt-dop-validation", options);
    } finally {
      RuntimeEnv.INSTANCE.setTestEnv(true);
    }
  }
{noformat}

I think we should just leave this alone since these validation tests will eventually become redundant

Commit 4cce896b8fd8cd45f4b69e4ebcd540899b072f3b in impala's branch refs/heads/master from Tim Armstrong
[ https://gitbox.apache.org/repos/asf?p=impala.git;h=4cce896 ]

IMPALA-9081: fix mt_dop validation tests

This undoes the hack of pretending that it's not a test environment for
that single test. That had side effects, e.g. for the metadata loading
path.

Instead we have a special flag to enable the validation code in
frontend tests.

Note that the plans change to include join build sinks as an
expected result of undoing the hack.

Change-Id: I2e8823c562395e13f318d1ad6eed883d2d9d771f
Reviewed-on: http://gerrit.cloudera.org:8080/14707
Reviewed-by: Anurag Mantripragada <anurag@cloudera.com>
Reviewed-by: Thomas Tauber-Marshall <tmarshall@cloudera.com>
Tested-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>


