This issue is assigned but has not received an update in 30 days so it has been labeled "stale-assigned". If you are still working on the issue, please give an update and remove the label. If you are no longer working on the issue, please unassign so someone else may work on it. In 7 days the issue will be automatically unassigned.

This issue was marked "stale-assigned" and has not received a public comment in 7 days. It is now automatically unassigned. If you are still working on it, you can assign it to yourself again. Please also give an update about the status of the work.

One little thing: after calling {{p.run()}} you should start again with a newly created pipeline. Does it still repro?

Yup tried with pipeline.create() at start of each loop, changed the code above to have full working example.

This issue is P2 but has been unassigned without any comment for 60 days so it has been labeled "stale-P2". If this issue is still affecting you, we care! Please comment and remove the label. Otherwise, in 14 days the issue will be moved to P3.

Please see https://beam.apache.org/contribute/jira-priorities/ for a detailed explanation of what these priorities mean.


This issue was marked "stale-P2" and has not received a public comment in 14 days. It is now automatically moved to P3. If you are still affected by it, you can comment and move it back to P2.

The cause is that the GC timer occasionally fires before the looping timer is done. This means that the DirectRunner is violating Beam's contract on timer ordering. For a given key, all timers must fire in order (no guarantee across keys). The GC timer is set past the end of the window (in this example, the Global window), so it should not fire as long as an unfired user timer is active.

Several issues are causing this bug:
 * The DirectRunner implements timer ordering by short circuiting the bundle and "pushing back" the remaining  timers to the next bundle. This technique is hard to validate and appears racy. A more direct approach with a priority queue (such as used by FnApiDoFnRunner) is preferred.
 * DirectTimerInternals maintains timers in three separate data structures. Appears to be at least one consistency bug caused by looping timres (titmer removed from existingTimers even though it was reset)
 * Finally, the main cause of this bug: the direct runner uses various Concurrent* data structures. However these data structures provide only weak consistency when iterating. One example of this: the runner tries not to fire timers for a transform if any bundles for that transform are in flight. This is important for consistency, and can cause misordered timers if violated. This is accomplished by passing the set of transforms with in-flight bundles in here:

[https://github.com/apache/beam/blob/master/runners/direct-java/src/main/java/org/apache/beam/runners/direct/QuiescenceDriver.java#L186]

However inflightBundles is a ConcurrentHashMap, so the keySet() iterator may provide a stale view. A transform recently added to the map might not appear in keySet(), breaking consistency of QuiescenceDriver.

The simple fix is to replace these concurrent data strtuctures with standard data structures guarded by synchronized blocks. 

 

I fixed this issue, however the fix was rolled back. I will try and
resubmit the fix next week.




This issue is assigned but has not received an update in 30 days so it has been labeled "stale-assigned". If you are still working on the issue, please give an update and remove the label. If you are no longer working on the issue, please unassign so someone else may work on it. In 7 days the issue will be automatically unassigned.

This issue was marked "stale-assigned" and has not received a public comment in 7 days. It is now automatically unassigned. If you are still working on it, you can assign it to yourself again. Please also give an update about the status of the work.

This issue has been migrated to https://github.com/apache/beam/issues/20966

