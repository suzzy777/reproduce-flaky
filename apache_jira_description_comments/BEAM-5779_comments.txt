Another at https://builds.apache.org/job/beam_PostCommit_Python_Verify/6317/

The log from 6317 shows TestDataflowRunner attempting to cancel the job at about 17:27:40 (expected since streaming jobs never end).
However, the job is still starting up and fails at 17:28:07 with the message:

Workflow failed. Causes: Step "setup_resource_projects/apache-beam-testing/subscriptions/psit_subscription_input1a6def20-8a5b-4de7-a10b-609290f545b4__df_internale53817409a1b9ef015" failed., Step setup_resource_projects/apache-beam-testing/subscriptions/psit_subscription_input1a6def20-8a5b-4de7-a10b-609290f545b4__df_internale53817409a1b9ef015: Set up of resource projects/apache-beam-testing/subscriptions/psit_subscription_input1a6def20-8a5b-4de7-a10b-609290f545b4__df_internale53817409a1b9ef0 failed, Getting metadata for pubsub subscription projects/apache-beam-testing/subscriptions/psit_subscription_input1a6def20-8a5b-4de7-a10b-609290f545b4 failed with error: Resource not found (resource=psit_subscription_input1a6def20-8a5b-4de7-a10b-609290f545b4).

I believe increasing TEST_PIPELINE_DURATION_MS will fix the flakiness, which affects how long we wait for the pipeline to complete.
I think I set it aggressively low at 30s, while streaming_wordcount_it_test uses 3m.

https://builds.apache.org/job/beam_PostCommit_Python_Verify/6321/

Cool. Seems like setting it high is fine. The timeout is really just a backstop for killing a hung job. There is no value in it being anywhere near the actual target duration, if a successful run terminates right away.

Sadly it doesn't. The on_success_matcher is only run after the "timeout". Since it's a streaming job it always times out.

I think the error in 6321 is similar in nature: the job was cancelled (successfully this time) before it managed to process and write the expected output.

Still failing: https://builds.apache.org/job/beam_PostCommit_Python_Verify/6354/consoleFull

Went away on its own. Closing, please reopen if this happens again.

