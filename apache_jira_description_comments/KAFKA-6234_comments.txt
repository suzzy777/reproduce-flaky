Is the 1 second timeout in that relevant to what is being tested, or could we just try to increase this a little to fix the shaky test? Especially with stopping and restarting all brokers before that call, there may be some internal stuff going on that just needs longer than a second to complete. 
On the other hand, the waitUntilTrue call is obviously intended to solve this for a leader not available exception, but this is being interrupted by the Timeoutexception being thrown in KafkaFutureImpl.get, so this could get extended to catch this exception as well.
Since the delete request is inside the waitUntilTrue and we probably don't want to retry the entire delete just because we didn't get a low watermark returned I think increasing the timeout a bit as a first step is the way to go.

GitHub user soenkeliebau opened a pull request:

    https://github.com/apache/kafka/pull/4238

    KAFKA-6234: Increased timeout value for lowWatermark response to avoid test failing occasionally

    Increase timeout to fix flaky integration test testLogStartOffsetCheckpoint.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/soenkeliebau/kafka KAFKA-6234

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/4238.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #4238
    
----
commit 06eb877538ba01a2a285ef266592f72d124ebee9
Author: Soenke Liebau <soenke.liebau@opencore.com>
Date:   2017-11-20T06:26:03Z

    KAFKA-6234: Increased timeout value for lowWatermark response to avoid test failing occasionally.

----


I've run a few tests and looked at the value that the 1s timeout was exceeded by  and on my machine this was never more than 1/10th of a second, so this looks a lot like it's really just a too short timeout value. I've created a pull request to increase the timeout to 5s (added some extra to account for busy build servers and test no being run in isolation etc.)

I've created a patch that has been around for a while now. Tests seem stable for the last few runs.

Unless someone has reservations about the fix I think this can be merged - but we should watch out for the tests acting up again.

hachikuji closed pull request #4238: KAFKA-6234: Increased timeout value for lowWatermark response to avoid test failing occasionally
URL: https://github.com/apache/kafka/pull/4238
 
 
   

This is a PR merged from a forked repository.
As GitHub hides the original diff on merge, it is displayed below for
the sake of provenance:

As this is a foreign pull request (from a fork), the diff is supplied
below (as it won't show otherwise due to GitHub magic):

diff --git a/core/src/test/scala/integration/kafka/api/AdminClientIntegrationTest.scala b/core/src/test/scala/integration/kafka/api/AdminClientIntegrationTest.scala
index 0676a1a3263..2b3ca623c57 100644
--- a/core/src/test/scala/integration/kafka/api/AdminClientIntegrationTest.scala
+++ b/core/src/test/scala/integration/kafka/api/AdminClientIntegrationTest.scala
@@ -38,7 +38,7 @@ import org.apache.kafka.common.{KafkaFuture, TopicPartition, TopicPartitionRepli
 import org.apache.kafka.common.acl._
 import org.apache.kafka.common.config.ConfigResource
 import org.apache.kafka.common.errors._
-import org.junit.{After, Before, Ignore, Rule, Test}
+import org.junit.{After, Before, Rule, Test}
 import org.apache.kafka.common.requests.{DeleteRecordsRequest, MetadataResponse}
 import org.apache.kafka.common.resource.{Resource, ResourceType}
 import org.junit.rules.Timeout
@@ -733,7 +733,6 @@ class AdminClientIntegrationTest extends IntegrationTestHarness with Logging {
   }
 
   @Test
-  @Ignore // Disabled temporarily until flakiness is resolved
   def testLogStartOffsetCheckpoint(): Unit = {
     TestUtils.createTopic(zkUtils, topic, 2, serverCount, servers)
 
@@ -743,8 +742,8 @@ class AdminClientIntegrationTest extends IntegrationTestHarness with Logging {
 
     sendRecords(producers.head, 10, topicPartition)
     var result = client.deleteRecords(Map(topicPartition -> RecordsToDelete.beforeOffset(5L)).asJava)
-    var lowWatermark = result.lowWatermarks().get(topicPartition).get().lowWatermark()
-    assertEquals(5L, lowWatermark)
+    var lowWatermark: Option[Long] = Some(result.lowWatermarks.get(topicPartition).get.lowWatermark)
+    assertEquals(Some(5), lowWatermark)
 
     for (i <- 0 until serverCount) {
       killBroker(i)
@@ -759,16 +758,16 @@ class AdminClientIntegrationTest extends IntegrationTestHarness with Logging {
       // Need to retry if leader is not available for the partition
       result = client.deleteRecords(Map(topicPartition -> RecordsToDelete.beforeOffset(0L)).asJava)
 
+      lowWatermark = None
       val future = result.lowWatermarks().get(topicPartition)
       try {
-        lowWatermark = future.get(1000L, TimeUnit.MILLISECONDS).lowWatermark()
-        lowWatermark == 5L
+        lowWatermark = Some(future.get.lowWatermark)
+        lowWatermark.contains(5L)
       } catch {
-        case e: LeaderNotAvailableException => false
-      }
-
-    }, "Expected low watermark of the partition to be 5L")
-
+        case e: ExecutionException if e.getCause.isInstanceOf[LeaderNotAvailableException] ||
+          e.getCause.isInstanceOf[NotLeaderForPartitionException] => false
+        }
+    }, s"Expected low watermark of the partition to be 5 but got ${lowWatermark.getOrElse("no response within the timeout")}")
     client.close()
   }
 


 

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


