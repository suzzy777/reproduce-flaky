Looking at the stack trace in hung state:
{code}
"Time-limited test" #814 daemon prio=5 os_prio=31 tid=0x00007fa39d5d7000 nid=0x47a13 in Object.wait() [0x0000700022aa9000]
   java.lang.Thread.State: WAITING (on object monitor)
  at java.lang.Object.wait(Native Method)
  at java.lang.Object.wait(Object.java:502)
  at org.apache.curator.framework.state.ConnectionStateManager.blockUntilConnected(ConnectionStateManager.java:224)
  - locked <0x0000000791798dd8> (a org.apache.curator.framework.state.ConnectionStateManager)
  at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:266)
  at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:272)
  at org.apache.hadoop.hbase.client.ZKAsyncRegistry.<init>(ZKAsyncRegistry.java:84)
{code}
It seems that blockUntilConnected() never finished.


[~Apache9]:
Can you take a look ?

Let me take a look. If no cluster then no doubt we can not connect to zk... It does not make sense to create a zk registry.

OK, the test is used to test we will fail if no cluster.

Mark it as Ignored I'd say. Will be fixed automatically after we remove the blockUntilConnected.

Thanks.

Can variant of blockUntilConnected be used / added which takes into account zookeeper connection issue ?

curator provides: blockUntilConnected(int, TimeUnit)

Yeah there is method

{code}
public boolean blockUntilConnected(int maxWaitTime, TimeUnit units) throws InterruptedException;
{code}

I think 1 or 2 seconds is enough? You can provide a patch, and also add the Thread.interrupt you want.

Thanks.

You made all the previous changes.

It would be better you fix it.

Do not have much time. Thanks.

If you too do not have much time, I could find another person to fix this. What do you think? Thanks.

Sounds like you're a manager now.

This is high priority issue - without the fix, HBASE-19200 should be reverted.

I always say that, you can do what you think is right, if you want to revert then just revert, a test broken is enough to revert a commit. But I also have my own work plan, and also my judgement on which issue is more important. If you think this one is high priority then just do it.

Thanks.

I have fixed this issue, but I can not assign this issue to myself, if someone can assign it to me?

Assigned to you [~wuguoquan]. Please upload the patch. Thanks.

+1. Let's wait for the pre commit result.

ok, thanks

Where is the Thread.interrupt() call ?

How is 2 second interval determined ? Isn't this short for real scenario ?

{quote}
A temporary workaround is to call blockUntilConnected when constructing ZKAsyncRegistry but this is not a production level code. 
{quote}
I already said this is not a production level code, why do you keep asking 'what's the implication in production scenario', and 'Isn't this short for real scenario'? I can not get your point.

Thanks.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 11s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Findbugs executables are not available. {color} |
| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} master Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  5m 10s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 24s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 30s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  5m 29s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 21s{color} | {color:green} master passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 53s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 21s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 21s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 28s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  5m  2s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |
| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green} 55m 23s{color} | {color:green} Patch does not cause any errors with Hadoop 2.6.1 2.6.2 2.6.3 2.6.4 2.6.5 2.7.1 2.7.2 2.7.3 2.7.4 or 3.0.0-alpha4. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 23s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 37s{color} | {color:green} hbase-client in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m  8s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 75m 59s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hbase:eee3b01 |
| JIRA Issue | HBASE-19321 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12898802/HBASE-19321.master.001.patch |
| Optional Tests |  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  hbaseanti  checkstyle  compile  |
| uname | Linux aaf85642733d 3.13.0-129-generic #178-Ubuntu SMP Fri Aug 11 12:48:20 UTC 2017 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build@2/component/dev-support/hbase-personality.sh |
| git revision | master / 3b2b22b5fa |
| maven | version: Apache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T07:58:13Z) |
| Default Java | 1.8.0_151 |
|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/9961/testReport/ |
| modules | C: hbase-client U: hbase-client |
| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/9961/console |
| Powered by | Apache Yetus 0.6.0   http://yetus.apache.org |


This message was automatically generated.



Pushed to master and branch-2.

Thanks [~wuguoquan] for the contributing.

same to you 

SUCCESS: Integrated in Jenkins build HBase-2.0 #895 (See [https://builds.apache.org/job/HBase-2.0/895/])
HBASE-19321 ZKAsyncRegistry ctor would hang when zookeeper cluster is (zhangduo: rev 8c2a962d1c3b56dfad7ab927782605fdffc4bf30)
* (edit) hbase-client/src/main/java/org/apache/hadoop/hbase/client/ZKAsyncRegistry.java


FAILURE: Integrated in Jenkins build HBase-Trunk_matrix #4097 (See [https://builds.apache.org/job/HBase-Trunk_matrix/4097/])
HBASE-19321 ZKAsyncRegistry ctor would hang when zookeeper cluster is (zhangduo: rev 7acf3f9a9cfc6a93107428c3e75b94b8af7a174a)
* (edit) hbase-client/src/main/java/org/apache/hadoop/hbase/client/ZKAsyncRegistry.java


Guoquan:
TestAcidGuarantees started to timeout (again).
Check flaky test dashbaord:
https://builds.apache.org/job/HBASE-Flaky-Tests/23484/

Where is the dashboard? TestAcidGuarantees is not failed in your url?

And now TestAcidGuarantees has been promoted to LargeTests, so if it still timeout then there must be other problems. It has been marked as flakey tests long long ago.

Thanks.

Guoquan:
Did you run TestAcidGuarantees locally (since patch was attached) ?

bq. It has been marked as flakey tests long long ago

I disagree. It got stuck after HBASE-19200 went in.

Flaky test dashboard is here:
https://builds.apache.org/job/HBASE-Find-Flaky-Tests/lastSuccessfulBuild/artifact/dashboard.html

You can see clearly the last 5 blue bars which indicate timeout.

bq. I already said this is not a production level code

hbase-2 is getting into beta phase where dev / QA at various companies have started testing the daily build(s).

It would be weird when they find out that what worked yesterday no longer works for the new daily build.

In this case, TestAcidGuarantees can be thought of as mini environment which can tell us how robust the change is.
TestAcidGuarantees is a basic test. When developers make change to locking in HRegion, in-memory compaction, etc, they need to know that they are working with non-flaky base.

Then please help finding out the root cause instead of commanding others and repeating useless word again and again. You are not a manager in the community, no one need to accept your command. And even HBASE-19200 is not found by you. I will not reply your comments about this topic any more, it is just wasting of time. You can revert everything you dislike since you are a commiter.  I will revert back when I have time to digging in here.

I tried changing the duration passed to blockUntilConnected from 2 to 30.
There was no improvement in the runtime of TestAcidGuarantees.

Need to dig deeper when I have time.

{code}
2017-11-22 13:13:28,358 ERROR [MemStoreFlusher.1] regionserver.HRegion(1210): Asked to modify this region's (TestAcidGuarantees,,1511356384562.67f5ede11bc9d37151794455003c8ee9.) memstoreSize to a negative value which is incorrect. Current memstoreSize=251900, delta=-281670
java.lang.Exception
	at org.apache.hadoop.hbase.regionserver.HRegion.checkNegativeMemStoreDataSize(HRegion.java:1210)
	at org.apache.hadoop.hbase.regionserver.HRegion.decrMemStoreSize(HRegion.java:1203)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2639)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2355)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2327)
	at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2218)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:498)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:467)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$900(MemStoreFlusher.java:69)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:252)
	at java.lang.Thread.run(Thread.java:748)
{code}
It seems the eager policy cause the negative size of memstore, so it breaks the close of table (If the memstore size is negative, the rs will be aborted when closing the region.). We don't close the table before HBASE-19311 hence the issue doesn't hurt the {{TestAcidGuarantees}} previously. As [~Apache9] optimized the {{TestAcidGuarantees}} by creating the mini cluster once and creating/deleting the table for each test case, the issue hurts {{TestAcidGuarantees}} now. I revert the HBASE-19311 locally, and then run the {{TestAcidGuarantees}} with eager policy. The error about the negative size sill happens. We should file a issue to disable the eager policy for {{TestAcidGuarantees}} before we have time to dig in. [~tedyu] [~Apache9] WDYT?

bq. We should file a issue to disable the eager policy for TestAcidGuarantees

Since you are already working on HBASE-19266, this can be handled there - replacing EAGER with ADAPTIVE policy.

bq. Since you are already working on HBASE-19266, this can be handled there - replacing EAGER with ADAPTIVE policy.
We still create the {{TestAcidGuarantees}} for EAGER but it will be denoted with {{Ignore}}. Let us discuss them in HBASE-19266. What about closing this issue? [~ted_yu]

