cc [~jorisvandenbossche]

This was added in ARROW-15019 (cc [~vibhatha])

[~jorisvandenbossche] will take a look. 

I created a PR

[~westonpace] could this be happening due to the small data size? 
I increased it and lowered the `max_open_files` and tested it. 
Seems to be working, but can we fix this better. Am I missing something here? 

I also see this regularly on my local computer.

[~apitrou] could it be due to the less data size? 

Since the intial data size was too small? What I did was increase it a little bit and reduce the `max_open_files`. 

I have no idea. It may be timing-dependent?

Is parallel writing enabled by default? If so, disabling it would probably make the test more robust.

Yes, most probably. I changed `use_threads`=False and reduced the `max_open_files` = 1 it reduces the low number of file generation to an extent. 

 

Threading makes sense.  The WriteNode's InputReceived will be called 4 times (one per batch).  Each call will generate 5 calls to the dataset writer (one per partition in that batch).

We'd get more than 5 files if we get something like:

B1P1, B1P2, B1P3, B1P4, B1P5, B2P1, ..., B4P5

However, we'd only get 5 files if we get something like:

B1P1, B2P1, B3P1, B4P1, B1P2, ... B4P5

Since we scan the source in parallel both orders are possible.

> Is parallel writing enabled by default? If so, disabling it would probably make the test more robust.

There is no easy way in the dataset writer to disable parallel writing (the CPU path is completely serial but it submits I/O tasks for each batch so you would need to shrink the I/O thread pool to size 1).

>  I changed `use_threads`=False and reduced the `max_open_files` = 1 it reduces the low number of file generation to an extent. 

This will disable parallel scanning which should be enough to prevent the flakiness (unless I am misunderstanding how the error is generated).  I'll try and setup a reproduction.

I was able to reproduce fairly regularly and confirmed the issue was the order in which the batches were delivered to the dataset writer.  Unfortunately, we were also not completely respecting the {{use_threads}} option in {{write_dataset}}.  If {{use_threads=False}} then we would scan in serial but still send batches into the exec plan in parallel.  I added a new PR that sets {{use_threads=False}} (based on Vibhatha's PR) and also updates the Write method to be serial.

I don't know if this bug should block the RC but if we cut another RC it would probably be nice to include.

This is for the most part a flaky test, so while the fix is nice to have it shouldn't block the release IMHO.

Issue resolved by pull request 12263
[https://github.com/apache/arrow/pull/12263]

This issue has been migrated to [issue #30918|https://github.com/apache/arrow/issues/30918] on GitHub. Please see the [migration documentation|https://github.com/apache/arrow/issues/14542] for further details.

