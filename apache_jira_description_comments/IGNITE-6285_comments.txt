I have raised the priority of the issue to Blocker, as it is a critical usability problem.

In addition to (1) and (2) above, I believe that the right way to solve it would be to store the previous IP:port binding on disk, to make sure that we reuse the same binding upon restart.

[~dsetrakyan], [~yzhdanov], [~agoncharuk],

Binding to the same IP:port is a brittle scheme that might fail periodically in short term and will definitely fail in the long term resulting in partial partitions loss due to the redistribution. It's even worse for us if it happens in years of the cluster being used in production. Even a MAC address as  as constant ID approach is not a problem solver because the hardware can be replaced.

What if we try the following scheme. A special component will set an UUID as a consistent ID for a node on startup. All the generated UUID(s) will be persisted in a single file protected by file system lock. This guarantees IDs reuse after restarts and should solve the issue once and forever.

There are several scenarios when generating random IDs does not work predictably, specifically, when a user starts multiple node instances on the same physical machine. 

I suggest the following (assuming we maintain the backwards compatibility)
1) A starting node binds to a port and generates old-style consistent ID
2) The node scans the work directory and checks if there is a folder matching the consistent ID. If such a folder exists, we start up with this ID (compatibility mode)
3) If there are no matching folders, but the directory is not empty, scan it for old-style consistent IDs. If there are old-style db folders, print out a warning (or fail to start)
4) If there are existing new style folders, pick up the one with the smallest sequence number and try to lock the directory. Repeat until we succeed or until the list of new-style consistent IDs is empty
5) If there are no more available new-style folders, generate a new one with next sequence number and random UUID as consistent ID.
6) Use this consistent ID for the node startup
7) Add a system property to allow override the consistent ID

As Yakov suggested, we can update the lock file on every use and print out this timestamp during the node startup.

[~dmagda] [~yzhdanov] [~dsetrakyan] please let me know what you think.

[~agoncharuk] seems we need to lock parent directory to create the first subfolder to support simultaneous start. Is that true?

Yes, It's either a parent directory lock or try-catch-retry (I remember there were some issues with directory locking on Windows)

Is there any way we can keep folders with human-readable names, without UUID in the name? If yes, it would be preferable.


We can keep the first assigned consistent ID (the one obtained during the first startup) but in this case, it may be confusing because the actual IP address has changed, but we keep using the old one.

[~agoncharuk], my vote goes for your solution.

Do we agree that we're not going to handle the case of "multiple nodes from different clusters on a single box" automatically? To support this case I would request the user to change the storage directories using existing persistent store configuration parameters or introducing a new one.

GitHub user dspavlov opened a pull request:

    https://github.com/apache/ignite/pull/2752

    IGNITE-6285: Enhance persistent store paths logging on start

    Experimental commits to run TC tests, do not merge

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/gridgain/apache-ignite ignite-6285

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/ignite/pull/2752.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #2752
    
----
commit b150519f05c99e71be83af9d5107ae599c90f05f
Author: dpavlov <dpavlov@gridgain.com>
Date:   2017-09-26T13:31:54Z

    IGNITE-6285: Enhance persistent store paths logging on start

----


Github user dspavlov closed the pull request at:

    https://github.com/apache/ignite/pull/2752


PR https://github.com/apache/ignite/pull/2775

TC runs 
https://ci.ignite.apache.org/viewLog.html?buildId=863315&tab=buildResultsDiv&buildTypeId=Ignite20Tests_RunAll

latest 10 test failed, most are flaky

Hi [~yzhdanov], 

Could you please review my changes?

Hi [~agoncharuk], could you please review my PR? It was updated accoring to review.

PR https://github.com/apache/ignite/pull/2775

TC run (9 test fails, most are flaky):
https://ci.ignite.apache.org/viewLog.html?buildId=868325&tab=queuedBuildOverviewTab

Thanks, Dmitriy, merged your changes to master

[~dpavlov],

Thinking of a high level documentation, the user has to know:
* how to start nodes from different clusters on a single box. They need to specify unique paths for storage files.
* how to tackle the error described as Option 3 on wiki.
* how to bind storage files to specific node instance (consistent ID option).

Could you put all this together under this doc section?
https://apacheignite.readme.io/v2.2/docs/ignite-persistence-23#section-configuration

That page is hidden and will be released along with 2.3. Provided you with required permissions.

Don't close this ticket until the docs are ready.

