My failures from `mvn verify -Dparallel-tests -Ds3guard -Ddynamo` in hadoop-tools/hadoop-aws:

{noformat}
Failed tests:
 (1) ITestS3NContractRootDir>AbstractContractRootDirectoryTest.testListEmptyRootDirectory:188->Assert.assertEquals:555->Assert.assertEquals:118->Assert.failNotEquals:743->Assert.fail:88 listStatus on empty root-directory returned a non-empty list expected:<0> but was:<1>
  (2) ITestJets3tNativeS3FileSystemContract>NativeS3FileSystemContractBaseTest.testListStatusForRoot:71 Root directory is not empty;  expected:<0> but was:<1>
  (3) ITestJets3tNativeS3FileSystemContract>FileSystemContractBaseTest.testListStatus:321 expected:<1> but was:<12>

Tests in error:
  (4) ITestS3AContractRootDir>AbstractContractRootDirectoryTest.testRmEmptyRootDirNonRecursive:116 » PathIO
  (5) ITestS3AEncryptionSSEC.testCreateFileThenMoveWithDifferentSSECKey:136->lambda$testCreateFileThenMoveWithDifferentSSECKey$14:147
  (6) ITestJets3tNativeS3FileSystemContract>FileSystemContractBaseTest.testLSRootDir:847->FileSystemContractBaseTest.assertListFilesFinds:865 » FileNotFound
{noformat}

 #4  Happens because root was not empty.  Wondering if S3N folder objects caused the isEmptyDirectory() to be false?

[~mackrorysd] any thoughts on #5?

I need to re-test this stuff on trunk to isolate any differences vs. the feature branch. For now collecting details on HADOOP-13345 branch:

#1 I did not reproduce the second time.

#2 failed because root was non-empty: s3a://bucket/Users existed. 

#3 failed because it expected to only find a single path "testListStatus" in the listing, but it got much more:
s3n://fabbri-dev/user/fabbri/FileSystemContractBaseTest/testInputStreamClosedTwice
s3n://fabbri-dev/user/fabbri/FileSystemContractBaseTest/testListStatus
s3n://fabbri-dev/user/fabbri/FileSystemContractBaseTest/testMkdirsFailsForSubdirectoryOfExistingFile
s3n://fabbri-dev/user/fabbri/FileSystemContractBaseTest/testMoveFileUnderParent
s3n://fabbri-dev/user/fabbri/FileSystemContractBaseTest/testMultiByteFilesAreFiles
s3n://fabbri-dev/user/fabbri/FileSystemContractBaseTest/testOverWriteAndRead
s3n://fabbri-dev/user/fabbri/FileSystemContractBaseTest/testRenameDirectoryAsExistingFile
s3n://fabbri-dev/user/fabbri/FileSystemContractBaseTest/testRenameDirectoryAsExistingFileNew
s3n://fabbri-dev/user/fabbri/FileSystemContractBaseTest/testRenameDirectoryMoveToExistingDirectory
s3n://fabbri-dev/user/fabbri/FileSystemContractBaseTest/testRenameDirectoryMoveToExistingDirectoryNew
s3n://fabbri-dev/user/fabbri/FileSystemContractBaseTest/testRenameFileMoveToNonExistentDirectory
s3n://fabbri-dev/user/fabbri/FileSystemContractBaseTest/writeReadAndDelete

#4 failure, looks like someone deleted file (1) from underneath us, or (2) without using S3Guard (so a path was listed in MetadataStore still but we failed to stat it on S3).
Tests run: 9, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 224.52 sec <<< FAILURE! - in org.apache.hadoop.fs.contract.s3a.ITestS3AContractRootDir
testRecursiveRootListing(org.apache.hadoop.fs.contract.s3a.ITestS3AContractRootDir)  Time elapsed: 53.834 sec  <<< ERROR!
java.io.FileNotFoundException: No such file or directory: s3a://fabbri-dev/Users/fabbri/Code/hadoop/hadoop-tools/hadoop-aws/target/test-dir/3/kkrpL8TPXx/test
        at org.apache.hadoop.fs.s3a.S3AFileSystem.s3GetFileStatus(S3AFileSystem.java:1939)
        at org.apache.hadoop.fs.s3a.S3AFileSystem.innerGetFileStatus(S3AFileSystem.java:1834)
        at org.apache.hadoop.fs.s3a.S3AFileSystem.getFileStatus(S3AFileSystem.java:1777)
        at org.apache.hadoop.fs.s3a.S3AFileSystem.innerListStatus(S3AFileSystem.java:1557)
        at org.apache.hadoop.fs.s3a.S3AFileSystem.listStatus(S3AFileSystem.java:1533)
        at org.apache.hadoop.fs.contract.ContractTestUtils.treeWalk(ContractTestUtils.java:1168)
...

#6 failure looks like this:
testLSRootDir(org.apache.hadoop.fs.s3native.ITestJets3tNativeS3FileSystemContract)  Time elapsed: 24.063 sec  <<< ERROR!
java.io.FileNotFoundException: File s3n://fabbri-dev/Users/fabbri/Code/hadoop/hadoop-tools/hadoop-aws/target/test/data/2OvFym0hEP does not exist.
        at org.apache.hadoop.fs.s3native.NativeS3FileSystem.listStatus(NativeS3FileSystem.java:603)
        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1824)
        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1866)
        at org.apache.hadoop.fs.FileSystem$4.<init>(FileSystem.java:2028)
        at org.apache.hadoop.fs.FileSystem.listLocatedStatus(FileSystem.java:2027)
        at org.apache.hadoop.fs.FileSystem.listLocatedStatus(FileSystem.java:2010)
        at org.apache.hadoop.fs.FileSystem$5.handleFileStat(FileSystem.java:2168)
        at org.apache.hadoop.fs.FileSystem$5.hasNext(FileSystem.java:2145)
        at org.apache.hadoop.fs.FileSystemContractBaseTest.assertListFilesFinds(FileSystemContractBaseTest.java:869)
        at org.apache.hadoop.fs.FileSystemContractBaseTest.testLSRootDir(FileSystemContractBaseTest.java:851)



#5 failure was:
testCreateFileThenMoveWithDifferentSSECKey(org.apache.hadoop.fs.s3a.ITestS3AEncryptionSSEC)  Time elapsed: 8.719 sec  <<< ERROR!
java.lang.Exception: Exception should be thrown.
        at org.apache.hadoop.fs.s3a.ITestS3AEncryptionSSEC.lambda$testCreateFileThenMoveWithDifferentSSECKey$14(ITestS3AEncryptionSSEC.java:147)

Could skip all s3n tests if s3guard is turned on?

No, that's silly.

Aaron: use a different test filesystem for s3n

Yeah, I will add something in the testing.md docs to that effect, at least.

For the record, here are the failures on trunk (no s3guard) if I try to run s3a/s3n integration tests in parallel, using a single bucket

{noformat}
Failed tests:
 (2)  ITestJets3tNativeS3FileSystemContract>NativeS3FileSystemContractBaseTest.testListStatusForRoot:73 Root directory is not empty;  expected:<0> but was:<2>
 (3) ITestJets3tNativeS3FileSystemContract>FileSystemContractBaseTest.testListStatus:321 expected:<1> but was:<12>

Tests in error:
(4)  ITestS3AContractRootDir>AbstractContractRootDirectoryTest.testRmEmptyRootDirNonRecursive:116 » PathIO
 (6)  ITestJets3tNativeS3FileSystemContract>FileSystemContractBaseTest.testLSRootDir:833->FileSystemContractBaseTest.assertListFilesFinds:851 » FileNotFound
{noformat}

If I point s3a/s3n contract tests at different buckets, I still get the first three (but not #6).

{code}Sean Mackrory any thoughts on #5?{code}

The SSEC tests aren't supposed to be running in parallel. They're not, right? I'd suggest 2 likely explanations are that (1) it's failing because of something left behind when one of the S3N tests fails and left behind an object that is sometimes ignored by s3a but sometimes not (has happened to me a lot) or (2) that test is expected to throw an exception somewhere that always get short-circuited by S3Guard when it's enabled (see HADOOP-14448 - though I'm not sure what's changed since I fixed some others).

they all look like root dir deletion inconsistency...we do see that in places, don't we? Do they go away if you run them individually?

Options
# move to the sequential series
# ignore :)

Those are actually all already in the sequential series. I can't reproduce most of them, though - only 2 of the s3n failures. Many times I've seen the garbage left behind after an s3n failure be the reason why other tests subsequently fail. There should be a way to just not run s3n tests, though right? If I just don't configure any s3n properties the tests don't just skip, they fail...

S3n tests will all skip if you don't provide the binding endpoint, new feature with the move to JUnit4 everywhere

Attaching documentation-only patch (v1).

It looks like the main work here would be to make the S3N tests less flaky.  I view this as a low priority, however, so am just adding guidance to the S3A testing and S3Guard docs.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 10s{color} | {color:blue} Docker mode activated. {color} |
| {color:green} 1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green} 1{color} | {color:green} mvninstall {color} | {color:green} 18m 35s{color} | {color:green} HADOOP-13345 passed {color} |
| {color:green} 1{color} | {color:green} mvnsite {color} | {color:green}  0m 25s{color} | {color:green} HADOOP-13345 passed {color} |
| {color:green} 1{color} | {color:green} mvnsite {color} | {color:green}  0m 21s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 4 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green} 1{color} | {color:green} asflicense {color} | {color:green}  0m 18s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 20m  9s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14548 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12876017/HADOOP-14548-HADOOP-13345.001.patch |
| Optional Tests |  asflicense  mvnsite  |
| uname | Linux c2fd40511cca 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | HADOOP-13345 / 309b8c0 |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/12727/artifact/patchprocess/whitespace-eol.txt |
| modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12727/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



{quote}S3n tests will all skip if you don't provide the binding endpoint, new feature with the move to JUnit4 everywhere
{quote}

Huh - I could've sworn not having a valid URL there used to make those tests throw errors - but yeah, setting an empty value or not setting it at all seems to be skipping them gracefully. Maybe I'm just thinking of pre-JUnit4...

+1 to the patch. I can fix the whitespace when I commit shortly.

Committed and pushed. I applied the whitespace fix and did a local Yetus run to confirm.

