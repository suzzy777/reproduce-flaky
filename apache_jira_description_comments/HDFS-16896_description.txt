When hedged read is enabled by HDFS client, we see an increased failure rate on reads.

*stacktrace*

 
{code:java}
Caused by: org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1183972111-10.197.192.88-1590025572374:blk_17114848218_16043459722 file=/data/tracking/streaming/AdImpressionEvent/daily/2022/07/18/compaction_1/part-r-1914862.1658217125623.1362294472.orc
at org.apache.hadoop.hdfs.DFSInputStream.refetchLocations(DFSInputStream.java:1077)
at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:1060)
at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:1039)
at org.apache.hadoop.hdfs.DFSInputStream.hedgedFetchBlockByteRange(DFSInputStream.java:1365)
at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1572)
at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1535)
at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:112)
at org.apache.hadoop.fs.RetryingInputStream.lambda$readFully$3(RetryingInputStream.java:172)
at org.apache.hadoop.fs.RetryPolicy.lambda$run$0(RetryPolicy.java:137)
at org.apache.hadoop.fs.NoOpRetryPolicy.run(NoOpRetryPolicy.java:36)
at org.apache.hadoop.fs.RetryPolicy.run(RetryPolicy.java:136)
at org.apache.hadoop.fs.RetryingInputStream.readFully(RetryingInputStream.java:168)
at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:112)
at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:112)
at io.trino.plugin.hive.orc.HdfsOrcDataSource.readInternal(HdfsOrcDataSource.java:76)
... 46 more
{code}
 