If we get some algs to run, I have a bunch of bash scripting I've thrown together in the past that will run benchmarks, gather results, and plot a graph. They need updating and are somewhat rough, but at least it can serve as a guide for ideas. If we get something reasonable we should be able to start running a regular job somewhere.

[~michael.sun] expressed some interest in helping with these algorithms.

FWIW, I wrote a benchmark rig some time back. It's been running inside Lucidworks' nightly. See https://github.com/shalinmangar/solr-perf-tools

However, due to flaky hardware which changed (and got shared with other tests) without me knowing about it, the historical data from the nightly scripts are not useful anymore (too much unexplained variance) but I'm looking to host it on a bare metal box and have it run regularly.

Nice! Is that just indexing or are there query side tests too? Does that performance data get charted? I think doing this type of testing on a largish scale and charting it consistently is very important to get to. Even just one indexing and one querying test would be awesome. We can then add reviewing that information before a release a todo item (though hopefully we would notice things sooner).

Beyond that, I think SOLR-2646 makes covering a longer tail much more appealing. I'd like to have some blessed algorithms folder that gets run regularly and covers a wider range of use cases, patterns, and features. Not only is it very easy to script out behaviors, but it only takes a single cmd line for a developer to replicate the benchmark in some form.


It has only indexing tests right now -- 4 variants (500 MB JSON data, 1kb wiki docs, 4kb wiki docs, 1kb wiki docs on solrcloud with 2 shards, 1 replica each). The peformance data gets charted in the same fashion as McCandless' benchmarks.

I'm attaching the report that I have -- as I said before, there have been changes to the hardware as well as heavy tenants on the same hardware from time to time which has made these charts unreliable. But I think there may be some real regressions here which haven't been investigated.

I haven't got to the query part yet but it'd be great to have a whole suite running regularly.

That's great stuff. Do you publish those files to people.apache.org or somewhere?

No, this is Lucidworks internal only at the moment. But we do plan to publish it once we have stable hardware running it nightly.

