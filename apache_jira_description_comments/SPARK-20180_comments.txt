I assume user can achieve the same effect by setting maxPatternlength to a larger value. So the jira is really about changing the default behavior of PrefixSpan. 
Is there more background or context available, like why the current default length(10) is not good in practice? Thanks. We need to also consider the performance for larger dataset (in count and dimension).

Yes they can, it's really not a critical issue at all.
Current pattern length work also well for most in practice, except for very large datasets where sequence are very long. But then I suppose people
would know about the parameter, and set it to a large value.

However allowing unlimitted pattern length would cost nothing in terms of performance, it's just an additionnal condition in an if. And may be easier than always setting the highest value possible. At least, that option wouldn't hurt and there was a TODO for that in the code. I think it would be good, even if we don't change the default value of 10. Changing it make more sense to me, but I get that, to allow backward compatibility, we can't just change things as we want. So I will follow my senior's opinion on this.


Actually, I have quite a few improvement in store for Prefix-span since I worked on an algorithm for my master thesis. Notably a very performant implementation that specialize PrefixSpan for single-item pattern, while slightly improving the performance of multi-item pattern. But I was told I needed to get familiar with contributing to spark first ^^', thus why I'm proposing this small, non critical, improvement, and implementing it.

I'm ready to push this small change anytime, it's already implemented. But the contributor wiki ask to run dev/run-tests before pushing, and it's been running for a day and a half already ... Is that normal by the way ? Also, the test already found some error, but I'm 99.999% sure they're not mine. They're not even from the mllib module, which is the only thing I modified  ... Is that normal too ? I suppose so, but I wouldn't want to waste the reviewers time ^^'

It sounds like you're arguing for no max at all -- what do you mean? that doesn't sound right.

It's possible that you didn't quite run the tests correctly, or that a test is flaky. I wouldn't worry about that, it's not clear this is a change to make anyway.
Again, we use pull requests to propose changes.

I'm not arguing for no max at all. Just for a special value (0) which allow a user to find all pattern of any length.
Let's give a practical example, let's say i'm not the brightest user. I have a really big dataset I need to analyse, but because I'm not too bright, I don't run any analysis on that dataset, to know what the max possible length of a sequence would be. I look at the parameters and I tell myself that a maxlength of like 50 will be enough. I code quickly and launch it using spark's algo.

I wait a few day for the result, since it was a really big dataset, and I see that I have a few solution pattern of length 50. And there is the problem, now that I'm there, do I need to re-run everything because there was a larger pattern that I wanted to find, or was 50 really the limit ?

This may waste a lot of time for some people if that happens to them. So I want to create that special value (0) for maxpattern length. So that when the algorithm ends, you get all the patterns of any length, no doubt possible.

Now honestly, while I want to say that this change may be usefull, a carefull user can always set the maxpattern length at the max Integer value and, given the time the algorithm needs to run on a small dataset, he will never have any problem since it would take him months to get a pattern longer than that, even with the biggest dataset we can imagine and lot's of computing power. So this is not a mandatory feature, simply something I feel would be nice to have. Also, in case there really was someone crazy enough to run this algorithm with for goal to find pattern longer than the max for integer, that special value would allow him to find them for sure.

I also would like to advocate for setting that special value (0) as the default value, since the first time I ran a test was on a dataset that returned long pattern (kosarak or protein, I don't remember which of the two) and thanks to the default pattern length it finished super quickly and I tought I had a performance improvement, in comparison to another algorithm that allowed unllimited pattern length as default.

Took me two day to realise the default parameter was set to ten (guess I was the dumb user there. Not my proudest moment, I will admit). So I want to advocate for that 0 value as default, but I get for backward compatibility it may not be best to change the default behavior. So I want a senior's opinion, to know if changing that would be ok.


Again, we use pull requests to propose changes.
=> I know, (I read the contributor guide), but I'm waiting for the test to finish. I tested my code and had some error, which I'm pretty sure were unrelated to the few line of code I added. I'm relaunching it though, on the code without my changes, if the error are the same (And you feel like the changes I'm proposing are worth it) I will make the pull request. That way, I'm sure I don't waste anybody's time on reviewing code nobody (but the little inexperienced newbie I am) would feel usefull. 


So there we go, I hope that answer your questions.
If not drop me another message, I will answer as best as I can. :)


Can you not just set a very large max, like Int.MaxValue or similar?
It's not normal for tests to run more than a couple hours. You need to see why. Is your test of unlimited max pattern stuck?

Can you not just set a very large max, like Int.MaxValue or similar?
=> Yes, I said that in the fourth paragraph of my last coment. A carefull user could always set it to Int.MaxValue and never have problems in an empirical situation. Still, it doesn't change the fact that I advocate for that special value (0) as the default value. Since it would be nice that, at first run and no matter the dataset, all solution pattern are found. Even if they are longer than 10.

It's not normal for tests to run more than a couple hours. You need to see why. Is your test of unlimited max pattern stuck?
=> It's not my test per say, it's the dev/run-tests tests which are asked to run before creating a pull resquest. I tested with my few changes and it ran for a day and a half, I'm re-running it now on the current state of the lib, without my changes, it doesn't seem faster ... for now at least ...
So I'm pretty sure I didn't screw up on that, for now the errors seem the same too, but I didn't take a deep look at them.

Why not let the default be Int.MaxValue? if that's what this is about, update the title to reflect it.
This is a behavior change by default, so we should think carefully about it. What are the downsides -- why would someone have ever made it 10? presumably, performance.
I don't see you've benchmarked the impact of making this unlimited by default. You mention tests don't end and haven't established it's not due to your change. 
I don't think we can proceed with this in this state, right?

=> Why not let the default be Int.MaxValue?
I'm also ok with a default Int.MaxValue, if the special value zero is really something you are against.

if that's what this is about, update the title to reflect it.
=> I will gladly do that, if you think the current title is misleading.

This is a behavior change by default, so we should think carefully about it
=> Yes, I agree.

What are the downsides â€“ why would someone have ever made it 10? presumably, performance.
=> The changed code consist simply in an additionnal condition in an if. If you want to see a graph, I have one that test the differences in performances, but on my implementation optimised for single-item pattern. So it wouldn't be relevant, if you are worried of performance drop, I can do additional tests, on the two lines I changed. If you want me to use some particular dataset, I will also gladly oblige. Just say the word, and you will have them by tommorow.

So it would be less about what impact it has on the performance, since it would be negligeable (again, i'm ready to prove that if you want me to), but about whether that feature seems needed or not. Which I agree, is debatable.

Also, whichever senior implemented it that way, left this comment : 
// TODO: support unbounded pattern length when maxPatternLength = 0
Which you can find in the original code, and is the reason I created this Jira's thread first. Among the list of improvement I want to propose.
You can find that line in the PrefixSpan code if you don't believe me.If theses change are rejected, then when I have the occasion, I will remove that line. Since this thread would have established that it isn't needed.

You mention tests don't end and haven't established it's not due to your change. 
=> I'm establishing that right now ... as I said. Also, they are ending, but they are really really slow.

I don't think we can proceed with this in this state, right?
=> I will leave the decision to you




Surely, the impact is more than an 'if' statement. If you contemplate much larger spans that's going to take longer to compute and return right? I think we're not at all in agreement there, especially as you're seeing the test (?) run forever.

Yes I know there's a TODO (BTW you can see who wrote it with 'blame') but that doesn't mean I agree with it. It also doesn't say it should be a default.

Keep in mind how much time it takes to discuss these changes relative to the value. We need to converge rapidly to decisions. The question here is performance impact on non-trivial examples. So far I just don't see much compelling reason to change a default. The functionality you want is already available.

Fine, I thought a TODO left in the code would reflect the wish of the community, at least a little.
I will close this thread and open a new one on changing the default value to maxInteger, since I personnally think it would be more friendly to new users.

Link to new thread : https://issues.apache.org/jira/browse/SPARK-20203

Tomorrow, I will create a new thread with another improvement I want to add to spark. I need to run a performance test on just that change first,
to prove it will be usefull. I hope you will follow it too.

