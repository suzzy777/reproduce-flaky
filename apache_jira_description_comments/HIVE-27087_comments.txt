Submitted a test PR to see if it helps.

[~vihangk1] Thanks a lot for looking into this. Just FYI we had decided to upgrade netty to 4.1.69.Final to get rid of a lot of CVEs. We had spent a couple of weeks of efforts to make sure all test case pass with this upgrade. I would suggest not to downgrade this version. Also, this test was failing before the netty upgrade as well. I don't think we should downgrade netty. When you ran in your local was this the error you got? Because, when I run it my local, I get the following :
java.lang.AssertionError: Failed during createSources processLine with code=1
 at org.junit.Assert.fail(Assert.java:88)
 at org.apache.hadoop.hive.ql.QTestUtil.initFromScript(QTestUtil.java:1219)
 at org.apache.hadoop.hive.ql.QTestUtil.createSources(QTestUtil.java:1201)
 at org.apache.hadoop.hive.ql.QTestUtil.createSources(QTestUtil.java:1188)
 at org.apache.hadoop.hive.cli.control.CoreCliDriver$3.invokeInternal(CoreCliDriver.java:83)
 at org.apache.hadoop.hive.cli.control.CoreCliDriver$3.invokeInternal(CoreCliDriver.java:80)
 at org.apache.hadoop.hive.util.ElapsedTimeLoggingWrapper.invoke(ElapsedTimeLoggingWrapper.java:33)
 at org.apache.hadoop.hive.cli.control.CoreCliDriver.beforeClass(CoreCliDriver.java:86)
 at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:71)
 at org.junit.rules.RunRules.evaluate(RunRules.java:20)
 at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
 at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
 at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
 at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
 at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
 at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
 at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
 at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
 at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

I see. Do you have information on what are the CVEs between 4.1.69.Final and 4.1.51.Final? After downgrading the library I don't see the original exception which I have in the description but something else. I will investigate more.

The errors we see now are due to the OutOfMemoryErrors we see in the spark executor logs. I bumped up the memory to see if it helps.

I do not have an exact list of the CVEs. Netty was downgraded in branch-3.1 from where 3.1.3 release was done. We could have followed that way, but we decided to make netty closer to oss/master(4.1.77.Final) so this was kind of the first stepping stone to upgrade to 4.1.69.Final. As far I debugged there were quite a lot of changes in netty from 4.1.50- to 4.1.50+.Â  Therefore once we have netty to 4.1.69.Final it won't take much effort to bump it up to 4.1.77.Final to match with oss/master. I am also trying different approaches Vihang. But I do not think we should downgrade netty as was discussed extensively on this thread - https://github.com/apache/hive/pull/3859

I understand what you are saying [~amanraj2520]but if netty upgrade has broken a feature we should also consider that. I looked into the possibility of if upgrading spark will solve the problem or not. Unfortunately, it looks like even if we upgrade spark to 2.4 it would still depend on 4.1.47 as seen [here|https://github.com/apache/spark/blob/branch-2.4/pom.xml#L634] so that is not a solution either. Is there is a way to have a dependency only for spark-client to limit the exposure to it. I don't see Hive-on-Spark on master branch so the upgrade doesn't affect in master branch in this context and hence the goal of having it closer to master branch doesn't make much sense. branch-3 and master branches are significantly different.

[~chaosun] You probably are more familiar with HoS code than me. Do you have any thoughts or suggestions here?

I was able to find the memory leak finally. I think it is related to HIVE-21044 the CapturingLogAppender introduces an unbounded list. It somehow gets configured in the spark tests and eventually leads to OOMs. I have reverted HIVE-21044 and I can run the tests locally. Offcourse we will still need to revert the netty version to 4.1.51.Final to make things work.

