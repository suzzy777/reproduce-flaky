Logs for a 600-container min-held + ~50 containers in capacity.

The AM should not be releasing any containers it gets, but it does.

[~gopalv] Could you clarify on the bit about "the AM has received a soft pre-emption message". Any suggestions on potential approach for the AM inferring that the cluster no longer has additional available resources for the AM and should now start releasing held containers?




The performance bug occurs within the queue, that is a straight-forward failure to utilize available resources properly.

I can work-around this issue by upping the max-delay for releasing containers, but that's where the pre-emption scenario is relevant - that approach isn't good on a busy cluster with a lot of applications. I don't want to hurt the performance or concurrency considerations.

The AM-RM allocate responses contain the pre-emption messages, which should be a good enough indicator that a certain fraction of currently held resources will be removed soon.

The pre-emption period is the gap between that event and the event of termination, in which period the min-held rules will not be enforced - to protect the ones actually doing work, idle containers should be allowed to expire (still following the min-max delay curve).

I suspect the pre-emption contracts do not expose that sunset period for the ill-fated containers, which makes it slightly harder to do this directly off the message - perhaps there is one I can't find ?

That makes the system both performant on idle cluster, but handles the mid-query bottlenecking that is common on busy clusters - particularly if the container expiry is smaller than the sunset period for pre-empted containers.

Attaching a fix that ensures that when there are no further pending container requests then new containers are not released if they have been added to the min held list. This should be safe because there are no pending requests. [~gopalv] Can you please try this out and see if this fixes your case? If so, then a review would be great :) The code change is minimal and explained above. The test was a pain to write :P

I quickly cross-checked, this - it seems to be still letting go of containers despite min-held being > queue size.

The containers were observed as being released during the getSplits() operation.

{code}
2015-03-23 18:35:14,865 INFO [InputInitializer [Map 1] #0] io.HiveInputFormat: Generating splits
2015-03-23 18:35:14,870 INFO [InputInitializer [Map 1] #0] log.PerfLogger: <PERFLOG method=OrcGetSplits from=org.apache.hadoop.hive.ql.io.orc.ReaderImpl>
2015-03-23 18:35:14,889 INFO [DelayedContainerManager] rm.YarnTaskSchedulerService: Container's idle timeout expired. Releasing container, containerId=container_1424502260528_1391_01_000310, containerExpiryTime=1427160914665, idleTimeoutMin=5000
2015-03-23 18:35:14,889 INFO [DelayedContainerManager] rm.YarnTaskSchedulerService: Releasing unused container: container_1424502260528_1391_01_000310
2015-03-23 18:35:14,889 INFO [Dispatcher thread: Central] history.HistoryEventHandler: [HISTORY][DAG:dag_1424502260528_1391_11][Event:CONTAINER_STOPPED]: containerId=container_1424502260528_1391_01_000310, stoppedTime=1427160914889, exitStatus=0
2015-03-23 18:35:14,889 INFO [Dispatcher thread: Central] container.AMContainerImpl: AMContainer container_1424502260528_1391_01_000310 transitioned from IDLE to STOP_REQUESTED via event C_STOP_REQUEST
2015-03-23 18:35:14,890 INFO [ContainerLauncher #25] launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_STOP_REQUEST
{code}

[~bikassaha]: any suggestions on more logging in the code to narrow down this?

Sorry. To be clear. This is with the patch attached?

If its with the patch, then it would mean that the scheduler has non-empty task requests at that time. With the fix, can you please attach the AM logs with debug logging enabled for the YarnTaskSchedulerService only. Else it will have RPC junk in it. Thanks

Yes, the LOG does not say "delay expired or is new." - which seems in the codepath that this patch changed.

Which is why I asked about new logging.

The existing debug logs should be enough if enabled. What is intriguing is that at this point in time there are pending task requests that have not already been matched to the containers because I am guessing that the job already has all the containers it will ever get. If that was not the case then it would hit the changed code path (AM is idle or there are no pending requests).
What is the min expiry time compared to the delays between node-rack-star matching? Hoping that the containers have been tried to be matched upto star before the min expiry elapses. So all tasks should have been matched to some containers leading to empty task requests.

This may help in setting debug logs for only 1 class
{noformat}  /**
   * Root Logging level passed to the Tez app master.
   *
   * Simple configuration: Set the log level for all loggers.
   *   e.g. INFO
   *   This sets the log level to INFO for all loggers.
   *
   * Advanced configuration: Set the log level for all classes, along with a different level for some.
   *   e.g. DEBUG;org.apache.hadoop.ipc=INFO;org.apache.hadoop.security=INFO
   *   This sets the log level for all loggers to DEBUG, expect for the
   *   org.apache.hadoop.ipc and org.apache.hadoop.security, which are set to INFO
   *
   * Note: The global log level must always be the first parameter.
   *   DEBUG;org.apache.hadoop.ipc=INFO;org.apache.hadoop.security=INFO is valid
   *   org.apache.hadoop.ipc=INFO;org.apache.hadoop.security=INFO is not valid
   * */
  @ConfigurationScope(Scope.AM)
  public static final String TEZ_AM_LOG_LEVEL = TEZ_AM_PREFIX + "log.level";
  public static final String TEZ_AM_LOG_LEVEL_DEFAULT = "INFO";
{noformat}

{color:green}+1 overall{color}.  Here are the results of testing the latest attachment
  http://issues.apache.org/jira/secure/attachment/12706789/TEZ-2217.1.patch
  against master revision 6d0b10a.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-TEZ-Build/334//testReport/
Console output: https://builds.apache.org/job/PreCommit-TEZ-Build/334//console

This message is automatically generated.

Debug logs attached.

{code}
$ grep "Releasing unused" app-log.txt | wc -l
111
{code}

I always use {{--hiveconf tez.am.log.level="INFO;<class-name>=DEBUG"}}, that seems to have worked.

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment
  http://issues.apache.org/jira/secure/attachment/12706809/TEZ-2217-debug.txt.bz2
  against master revision 6d0b10a.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-TEZ-Build/337//console

This message is automatically generated.

New patch. The problem was that the expire time was not update until the min held container expire time actually elapsed. But if task requests would come in just before the update would happen, then in the next allocation cycle the min held containers would be released because they just crossed the expire time boundary. Looks like the timing of the next dag is currently hitting that race condition and probably was not hitting it earlier.
Can you please try this out?

{color:green}+1 overall{color}.  Here are the results of testing the latest attachment
  http://issues.apache.org/jira/secure/attachment/12707032/TEZ-2217.2.patch
  against master revision f53942c.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-TEZ-Build/341//testReport/
Console output: https://builds.apache.org/job/PreCommit-TEZ-Build/341//console

This message is automatically generated.

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment
  http://issues.apache.org/jira/secure/attachment/12707314/TEZ-2217.3.patch
  against master revision d1b4bd4.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in :
                   org.apache.tez.dag.app.rm.TestContainerReuse

Test results: https://builds.apache.org/job/PreCommit-TEZ-Build/348//testReport/
Console output: https://builds.apache.org/job/PreCommit-TEZ-Build/348//console

This message is automatically generated.

[~bikassaha]: The patch keeps containers alive, which works better with this patch.

There's a lot of log-spew with {{LOG.info("Holding onto idle container with no work. CId: "}} in the _post log files.

I might take a couple of days to reviewing this, so If [~rajesh.balamohan] can spare some time to review this, we can get this in quickly.

lgtm. + 1.  Minor comments.
- YarnTaskSchedulerService line 648. log statement is repeated.  May be it was intented to be debug log. 
- YarnTaskSchedulerService line 569. expireTime can be reused instead of recomputing expireTimeMin. 
- TestTaskScheduler Test doesn't cover the scenario when taskrequests are not empty. It should be fine, as the patch mainly updates the expiry time for the sessionMinHeldContainers so that they do not get released.

The issue was happening even with 20-40 second queries, but at a much lower pace. Verified that the patch holds min containers.

bq.YarnTaskSchedulerService line 648. log statement is repeated. May be it was intented to be debug log.
Removed

bq.YarnTaskSchedulerService line 569. expireTime can be reused instead of recomputing expireTimeMin.
Removed

I tried adding a test for that but unless we change the main code it would be hard to verify that the time was updated in exactly the newly added code path and not somewhere else. Hence I dropped that effort in favor of manual testing.

Thanks for the reviews!

Attaching commit patch.

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment
  http://issues.apache.org/jira/secure/attachment/12707535/TEZ-2217.4.patch
  against master revision 1ba1f92.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in :
                   org.apache.tez.dag.app.rm.TestContainerReuse

Test results: https://builds.apache.org/job/PreCommit-TEZ-Build/352//testReport/
Console output: https://builds.apache.org/job/PreCommit-TEZ-Build/352//console

This message is automatically generated.

master
commit d42a3c7a78b14ba496721e5db4a63229c3cf011c
Author: Bikas Saha <bikas@apache.org>
Date:   Thu Mar 26 10:05:29 2015 -0700

    TEZ-2217. The min-held-containers being released prematurely (bikas)

branch-0.6
commit 65f476ce083ed042532f10b0c38a3074f3be370a
Author: Bikas Saha <bikas@apache.org>
Date:   Thu Mar 26 10:05:29 2015 -0700

    TEZ-2217. The min-held-containers being released prematurely (bikas)
    (cherry picked from commit d42a3c7a78b14ba496721e5db4a63229c3cf011c)

branch-0.5
commit 0249a4318a022b77d26167bdb1783b763be254f3
Author: Bikas Saha <bikas@apache.org>
Date:   Thu Mar 26 10:05:29 2015 -0700

    TEZ-2217. The min-held-containers being released prematurely (bikas)
    (cherry picked from commit d42a3c7a78b14ba496721e5db4a63229c3cf011c)



The unit tests failed for the latest patch. This should not have been committed until the pre-commit build came back. 



I have already investigated the failures from last night and its an independent flakiness in TestContainerReuse that unrelated to the session min held containers.
I have opened TEZ-2238 for the test case failure and will post a patch for the test.

Closing issue as 0.5.4, 0.6.1 and 0.7.0 have been released. 

