[~dongjoon], I took tests for several times locally, the different tests are failed. 

Thank you for reporting, [~huangtianhua]. Yes. I suspect "with replication as stream" code path is related to this on ARM.

[~dongjoon] Seems it doesn't with 'with replication as stream', see https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-maven-arm/392/testReport/junit/org.apache.spark/DistributedSuite/caching_on_disk__replicated_2__encryption___on_/

Yes. That failure looks like that, but it's still irrelevant to DISK_3, isn't it? You can attach that to the PR description and make the scope broader.
{code}
caching on disk, replicated 2 (encryption = on)
{code}

> testOnly *DistributedSuite -- -z "caching in memory and disk, replicated (encryption = on) (with replication as stream)"
I test only for case "caching in memory and disk, replicated (encryption = on) (with replication as stream)", it's not fail always.
I am so sorry I can't fix this issue, and the arm jenkins failed for a few days, I am uploaded the success.log and failure.log to attach files, so if anybody can help to analysis, and I can provide the arm64 instance if need, thanks all!

You don't need to be sorry for not fixing the issue. Reporting a bug is an invaluable contribution. It's just difficult for most community members to reproduce/develop/test on ARM.

[~dongjoon], ok, thanks. And if anyone wants to reproduce the failure on ARM, I can provide an arm instance:)

[~huangtianhua]  [~dongjoon] I just see that the last two {{org.apache.spark.DistributedSuite}} tests pass, is this issue revolved?

[~podongfeng], it failed again. It seems that they are flaky tests.

 !Screen Shot 2020-09-28 at 8.49.04 AM.png! 

[~podongfeng] Seems the tests failed after https://issues.apache.org/jira/browse/SPARK-32517 merged, please help me to check this, thanks very much.

[~huangtianhua] As I posted at the initial analysis, it's irrelevant to the newly added code. Instead, it's relevant to the older code path which handles `with replication as stream`.

[~dongjoon] Sorry, but I have tested the case: remove the commit of SPRK-32517 , and then the tests success. 


[~dongjoon] And I found the failed tests are not 'with replication as stream'. like this https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-maven-arm/435/testReport/junit/org.apache.spark/DistributedSuite/caching_on_disk__replicated_2__encryption___on_/

[~huangtianhua] It looks like that this is an already existing issue before SPARK-32517, which is triggered by changing #executors. ({{val clusterUrl = "local-cluster[2,1,1024]"}} -> {{val clusterUrl = "local-cluster[3,1,1024]"}}).

 

in the attached failure.log, block {{rdd_0_0}} was added three time, but it should be added only twice:
{code:java}
...
20/08/31 20:39:21.361 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_0_0 in memory on 192.168.1.225:36305 (size: 416.0 B, free: 546.3 MiB)
...
20/08/31 20:41:21.844 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_0_0 in memory on 192.168.1.225:35957 (size: 416.0 B, free: 546.3 MiB)
...
20/08/31 20:41:27.771 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_0_0 in memory on 192.168.1.225:34623 (size: 416.0 B, free: 546.3 MiB)
...

 {code}
 

IIUC, the result of {{testCaching}} in {{DistributedSuite}} should be irrelevant to the number of executor? [~dongjoon]

 

 

[~podongfeng] Thanks, there are twice in success.log

I took test to remove the commit 32517 and just modify clusterUrl = "local-cluster[2,1,1024]" -> "local-cluster[3,1,1024]") then the tests failed.

So yes it's not related with commit 32517.

Thank you for confirming, [~huangtianhua]. :)

We have found the problem, it is take long time to replicate remote over the default timeout 120 seconds, so it try again to another executor, but in fact the replication is complete, so there are 3 replications total. Then we found the progress hang in CryptoRandomFactory.getCryptoRandom(properties), we found the jar commons-crypto v1.0.0 doesn't support aarch64, after we change to use v1.1.0 then the tests pass and the time is short. 
So I plan to propose a PR to change to use commons-crypto v1.1.0 which support aarch64: http://commons.apache.org/proper/commons-crypto/changes-report.html  https://issues.apache.org/jira/browse/CRYPTO-139

User 'huangtianhua' has created a pull request for this issue:
https://github.com/apache/spark/pull/30275

User 'huangtianhua' has created a pull request for this issue:
https://github.com/apache/spark/pull/30275

Issue resolved by pull request 30275
[https://github.com/apache/spark/pull/30275]

The ARM Jenkins CI still fail after this merged, it because we didn't install libssl-dev package. Now I think it's ok, let's wait today's Jenkins status.

[~huangtianhua] looks Spark ARM CI passed in these days, the issue have been fixed, right?

https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-maven-arm/

User 'huangtianhua' has created a pull request for this issue:
https://github.com/apache/spark/pull/31078

User 'huangtianhua' has created a pull request for this issue:
https://github.com/apache/spark/pull/31078

