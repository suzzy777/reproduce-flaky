[~vbalaji][~xleesf] [~yanghua] FYI 

if you notice the pdf, the flakiness is recent and I can't think of any of the recent commits that could signiificantly affect this this way 

Yeah, this looks like a recent issue. [~leesf] [~yanghua] [~nagarwal] : I am trying to get some tech debts related to timeline management finished up this week and would need one of your help to take a lead on this. Let me know if you have cycles. 

Thanks,

Balaji.V

Actually, based on my experience in the Flink community, Flink's Travis service also often fails for unusual reasons, but not as frequently as Hudi recently. I have an unfounded guess, is it due to the instability of the test environment itself (because many times local tests can pass)?

I will invertigate the frequently VM exit crash error when get a circle.

I think we could start by focussing on whether the integration test passes locally without hanging (as two people have reported so far) for N times. If this is true, this would be problematic on travis , causing vm timeouts. 

[~yanghua] some of this is definitely travis. esp the vm crashes . We have seen that in the past as well

[~vinoth] yes, agree.

For vm crashes, the following information is useful.
https://stackoverflow.com/questions/23260057/the-forked-vm-terminated-without-saying-properly-goodbye-vm-crash-or-system-exi.
I added <argLine>-Xmx1024m -XX:MaxPermSize=256m</argLine> to surefire plugin configuration(https://github.com/leesf/incubator-hudi/commit/d2b26650fc921666761d816b721cea22307bf884) and build it many times in travis (https://travis-ci.org/leesf/incubator-hudi/builds/603810854), the vm did not crash again. [~vinoth]

Worth giving a shot. Can you please send a PR. 

I am still tracking down the docker/spark-submit hang.. Have not gotten around to nailing it. 

Wil send a PR later today.

another build error (No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself.) https://travis-ci.org/leesf/incubator-hudi/jobs/604224429

Right now, this ticket lacks a clear owner :). Feel free to pick it up if interested. On no output, if its from the integ test, then the thread on the mailing list could be useful to understand

On no output, I changed the [travis.yaml|https://github.com/leesf/incubator-hudi/commit/dcc7e6a13b41dcf8e8df30eb8d5b64367b8feb06], borrow from [here|https://github.com/cyberFund/cybernode-archive/commit/0dbb14c5169144b7535cbf3dc474916b93a64a5e] and run more than 5 times in [travis|https://travis-ci.org/leesf/incubator-hudi/jobs/604252022], no output does not occurs again. I will continue restart the travis and observe the result before send a PR.

But does the test pass?  I am wondering if there is a root cause we are missing.. 
But agree with you fixes to first stabilize would be good. 

Yes, all tests pass. I run the [travis|https://travis-ci.org/leesf/incubator-hudi/jobs/604252022] for 13 times, no output does not occurs any more. I think the no output is more likely to be a problem with travis

Please open a PR. lets see how this goes.. 



May be we should open a new issue for the case of integ test hanging locally? are you able to reproduce this as well [~xleesf] ? 

Will provide a PR soon.
Of cause it is suitable to open a new issue to track integ test hanging. And I could not reproduce integ test hanging locally yet.:(

I am surprised that you are unable to reproduce.. me or balaji taking a stab at it. Seems bit tricky. But should have been a recent regression 

I am able to consistently reproduce the integration test hanging issue locally in my mac laptop. I tried with disabling embedded timeline server and the tests seems to pass. I ran this only one time though. Opening a PR [https://github.com/apache/incubator-hudi/pull/989] to run integration tests in travis. Embedded timeline had been enabled for some time now. So, it is still not clear if embedded timeline server is causing it. Even if this overcomes file hanging issue, we still need to get to the root of the issue.

> Embedded timeline had been enabled for some time now. So, it is still not clear if embedded timeline server is causing it.

Given its a feature we recommend to users, I would suggest not to disable this right away. 

@uditme This is where we are now. 

Next steps could be : 
 * Dump out the logs (currently logs are printed after command succeeds) as the command makes progress and see where the hang is at
 * Try force killing the jvm after that point and see if it exits atleast. (I tried added System.exit(0) to last line of DeltaStreamer::main and it did not do the trick. 

