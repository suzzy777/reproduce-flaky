So now each thread is handling one CF.  We need change the threading model and its work assignment.  The model should be based on store file count (across stores)  and each thread handling a group of store files.  You will provide a patch?

The storefiles can be handled in any order, as the splits are independent. A quickfix is to increase the pool size with a configurable upper limit. I made a patch and in the process of testing and doing some analysis. I will submit it soon.

Nice spotting [~haridsv] !

Pardon me, where is the patch ?

How about defaulting the pool size to the number of cores or the number of datanode directory entries?

Apologies Ted, I thought I already attached it.

Can't there be other regions splits that could go on in parallel? [~apurtell] have suggestions on using shared executor pools with larger scope, which would scale and perform better than sizing this thread pool proportional to some metric related to the current region.

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12741776/HBASE-13959.patch
  against master branch at commit 2df3236a4eee48bf723213a7c4ff3d29c832c8cf.
  ATTACHMENT ID: 12741776

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/14559//console

This message is automatically generated.

I am able to apply patch (created with `git format-patch`) with -p1, not sure what is wrong. I will attach again generated with `git diff`.

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12741781/HBASE-13959-2.patch
  against master branch at commit 2df3236a4eee48bf723213a7c4ff3d29c832c8cf.
  ATTACHMENT ID: 12741781

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/14561//console

This message is automatically generated.

Using Reply button can easily lead to multiple identical posts.

SplitTransaction has become an interface. Please make changes in SplitTransactionImpl.java
Your patch is based on 0.98
You can name it 13959-0.98-v1.txt, e.g.

Patch against master branch.

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12741801/HBASE-13959-3.patch
  against master branch at commit 2df3236a4eee48bf723213a7c4ff3d29c832c8cf.
  ATTACHMENT ID: 12741801

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 hadoop versions{color}. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.7.0)

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 protoc{color}.  The applied patch does not increase the total number of protoc compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

                {color:red}-1 checkstyle{color}.  The applied patch generated 1909 checkstyle errors (more than the master's current 1907 errors).

    {color:green}+1 findbugs{color}.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 lineLengths{color}.  The patch introduces the following lines longer than 100:
    +        LOG.debug("Splitting started for store file: " + sf.getPath() + " for region: " + this.parent);
+        LOG.debug("Splitting complete for store file: " + sf.getPath() + " for region: " + this.parent);

  {color:green}+1 site{color}.  The mvn post-site goal succeeds with this patch.

     {color:red}-1 core tests{color}.  The patch failed these unit tests:
     

Test results: https://builds.apache.org/job/PreCommit-HBASE-Build/14565//testReport/
Release Findbugs (version 2.0.3) 	warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/14565//artifact/patchprocess/newFindbugsWarnings.html
Checkstyle Errors: https://builds.apache.org/job/PreCommit-HBASE-Build/14565//artifact/patchprocess/checkstyle-aggregate.html

                Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/14565//console

This message is automatically generated.

Fix for checkstyle errors. The unit test org.apache.hadoop.hbase.master.TestDistributedLogSplitting passed on my local box, so hoping it is just flaky.

Is it possible to measure performance gain with your patch ?

Thanks

I just attached region-split-durations-compared.png.

I have done a basic comparison of split times with one thread vs 8 threads on a table. The table had no presplits and had a single column family. Starting from an empty table, I loaded 400M rows (about 570 bytes/row). The run with 1 thread encountered NSRE exceptions a few times that coincides with a long running split. The run with 8 threads had no NSRE's. Here are some numbers:

Thread pool size = 1
Number of splits: 27
Average split duration: 8.44s
Min split duration: 3
Max split duration: 16
p99 split duration: 16

Thread pool size = 8
Number of splits: 25
Average split duration: 3.4s
Min split duration: 2
Max split duration: 6
p99 split duration: 5.76


I will attach an histogram showing the durations side by side.

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12741822/HBASE-13959-4.patch
  against master branch at commit 2df3236a4eee48bf723213a7c4ff3d29c832c8cf.
  ATTACHMENT ID: 12741822

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 hadoop versions{color}. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.7.0)

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 protoc{color}.  The applied patch does not increase the total number of protoc compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 checkstyle{color}.  The applied patch does not increase the total number of checkstyle errors

    {color:green}+1 findbugs{color}.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 lineLengths{color}.  The patch does not introduce lines longer than 100

  {color:green}+1 site{color}.  The mvn post-site goal succeeds with this patch.

     {color:red}-1 core tests{color}.  The patch failed these unit tests:
                       org.apache.hadoop.hbase.util.TestHBaseFsck

     {color:red}-1 core zombie tests{color}.  There are 3 zombie test(s): 

Test results: https://builds.apache.org/job/PreCommit-HBASE-Build/14567//testReport/
Release Findbugs (version 2.0.3) 	warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/14567//artifact/patchprocess/newFindbugsWarnings.html
Checkstyle Errors: https://builds.apache.org/job/PreCommit-HBASE-Build/14567//artifact/patchprocess/checkstyle-aggregate.html

  Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/14567//console

This message is automatically generated.

Nice results in performance improvement.

Should the new constants be defined in SplitTransactionImpl.java ? They're only referenced by SplitTransactionImpl.java

Nice find and patch. The 8 seems to come out of nowhere.
Do you have numbers for different numbers of threads?
Maybe default it to 1/2 of blocking store file count...?

Specifically we can set the default maximum to the 1/2 #blockingStoreFiles (or maybe just #blockingStoreFiles)
That way we have a good default, and folks can override and (a) decrease if they set blockStoreFiles to a large value or (b) increase if they have many column families.


Something like this for example.
(This does leak HStore references into SplitTransactionImpl, though)

I'm just trying to a good default, rather than something else that everyone will have to configure.

Upping to critical, because the code completely misses to do what it wanted to do and as a result we split with one thread per column family, and that means that in many case we serialize creation of all reference files which can take 200-400ms, each.
So with 20 storefiles this can easily take 8-16s (needs to create 40 reference files).

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12741944/13959-suggest.txt
  against master branch at commit e6ed79219966ce0dac3bc748261fce9478aa7550.
  ATTACHMENT ID: 12741944

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 hadoop versions{color}. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.7.0)

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 protoc{color}.  The applied patch does not increase the total number of protoc compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 checkstyle{color}.  The applied patch does not increase the total number of checkstyle errors

    {color:green}+1 findbugs{color}.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 lineLengths{color}.  The patch does not introduce lines longer than 100

  {color:green}+1 site{color}.  The mvn post-site goal succeeds with this patch.

     {color:red}-1 core tests{color}.  The patch failed these unit tests:
                       org.apache.hadoop.hbase.TestRegionRebalancing

Test results: https://builds.apache.org/job/PreCommit-HBASE-Build/14578//testReport/
Release Findbugs (version 2.0.3) 	warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/14578//artifact/patchprocess/newFindbugsWarnings.html
Checkstyle Errors: https://builds.apache.org/job/PreCommit-HBASE-Build/14578//artifact/patchprocess/checkstyle-aggregate.html

  Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/14578//console

This message is automatically generated.

Lars, Is something missing in your comment? 

The current number of 8 threads is just something I thought would keep the max split duration acceptable. With 20 storefiles and about 700ms overhead from the reference file creation alone, 8 threads can keep the total split time to around 5 to 6 seconds. If we have a sense of the max number of storefiles, and have a specific target for the split time, then we can set the thread count to meet that goal. In our case, the client times out in 11 seconds, so keeping the max split time well under that is the goal. Instead of having a fixed thread count that is configurable, one alternative is to have configurable goal in seconds and then choose the number of threads based to meet it (using heuristics).

If minimizing the split time is to be our goal, we could have one thread for each reference file creation (i.e., 40 threads in case of 20 storefiles) and then the split time will always stay low at about 2 to 4 seconds. 

I also traced the reference file creation and found that the final FSDataOutputStream.close() takes almost all the time that goes into the reference file creation, which is between 300 to 400ms. In the same environment (using NNBenchWithoutMR), I sometime back found that small file creations take a minimum of 200ms and peak to about 378ms under load (200+ clients), so the timings I am seeing with the reference file creation seems about right.

Heh... See 13959-suggest.txt that I attached with same comment. :)
Basically your patch, but defaults the max to the max # of storefiles. So in typically setups one does not have to worry about this setting.

Yes, I think I understand your proposal better now. Since the max storefile count should be around the blocking store file count, it makes sense to use it as the max. However, I came across blogs in which folks used unusually large blocking store file count (e.g., 200) to optimize their write performance (at the cost of read performance, of course) which could translate to having too many threads and causing resource availability and performance issues, so perhaps we should also enforce an upper limit to the number of logical cores (as returned by Runtime.getRuntime().availableProcessors()) ?

As a follow up change, we could also create the two references on each storefile in parallel and shave off another 300 to 400ms in most scenarios. I can create a separate jira for this and work on it separately once this is merged.

Based on latest comments from Lars.

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12742484/HBASE-13959-5.patch
  against master branch at commit 7b92d8c06a9eced95c4390f0dae02ebb98aa3ef7.
  ATTACHMENT ID: 12742484

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 hadoop versions{color}. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.7.0)

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 protoc{color}.  The applied patch does not increase the total number of protoc compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 checkstyle{color}.  The applied patch does not increase the total number of checkstyle errors

    {color:green}+1 findbugs{color}.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 lineLengths{color}.  The patch does not introduce lines longer than 100

  {color:green}+1 site{color}.  The mvn post-site goal succeeds with this patch.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HBASE-Build/14599//testReport/
Release Findbugs (version 2.0.3) 	warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/14599//artifact/patchprocess/newFindbugsWarnings.html
Checkstyle Errors: https://builds.apache.org/job/PreCommit-HBASE-Build/14599//artifact/patchprocess/checkstyle-aggregate.html

  Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/14599//console

This message is automatically generated.

Updated fix versions.

+1 on v5.

Unless I hear otherwise I'll commit this today. Thanks for the detective work and the patch [~haridsv]!

bq. However, I came across blogs in which folks used unusually large blocking store file count (e.g., 200)

True. And that is why we need the new config option. Folks who increase # blocking store files that dramatically better know what they're doing. Either they'd presplit everything, or they'd want a large number of threads doing the splitting.
With this, we mostly keep the spirit of the original code: one thread per file. I think we can do that here, and then fix it in a better way.

This is just to come up with a good proxy that will work in most situations. Another good proxy would be the number of a handler threads configured for the NameNode (and then allow a split to use maybe a 1/4 of that by default).

As [~apurtell] and I pointed out elsewhere, on demand thread pools are smelly beasts and should be avoided. Once we fixed this issue, we should revisit that. The tricky part with a central pool - presumably - would be making sure that all tasks terminate; right now this is enforced by shutting down the pool.


+1

Sorry. Don't know why this got assigned to me. Assigned back to Hari.

Committed to 2.0.0, 1.3.0, 1.2.0, 1.1.2.
I'm making a 1.0 and 0.98 patch now.

0.98 patch.

And committed to 0.98 and 1.0.x as well.

FAILURE: Integrated in HBase-1.0 #980 (See [https://builds.apache.org/job/HBase-1.0/980/])
HBASE-13959 Region splitting uses a single thread in most common cases. (Hari Krishna Dara) (larsh: rev c343776a6a21b58c1971514cb996621825d63039)
* hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java
* hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java


FAILURE: Integrated in HBase-1.1 #566 (See [https://builds.apache.org/job/HBase-1.1/566/])
HBASE-13959 Region splitting uses a single thread in most common cases. (Hari Krishna Dara) (larsh: rev 0548da62d11934a204ac1697e6c655e417f371ed)
* hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransactionImpl.java
* hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java


SUCCESS: Integrated in HBase-1.3 #26 (See [https://builds.apache.org/job/HBase-1.3/26/])
HBASE-13959 Region splitting uses a single thread in most common cases. (Hari Krishna Dara) (larsh: rev 163ddbf03cb94e4823cbc694ccba92366ec35917)
* hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransactionImpl.java
* hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java


Thank you very much, [~lhofhansl] for creating the patch for 0.98 and 1.0 as well. Do we need to update any documentation or add a note somewhere?

Couple of more questions:
- Is there an existing jira to capture the requirements for central execution pool? If not, I can work on it. Good point about ensuring the termination, it could be tricky without having to shutdown the pool.
- Meanwhile, is it OK to work on a follow up patch to increase the concurrency further by creating both reference files in parallel? This work will not go waste when a central pool is introduced. 

FAILURE: Integrated in HBase-TRUNK #6615 (See [https://builds.apache.org/job/HBase-TRUNK/6615/])
HBASE-13959 Region splitting uses a single thread in most common cases. (Hari Krishna Dara) (larsh: rev f8bd578b80b4e656d799c82ca1b6191e35bb0ae4)
* hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransactionImpl.java
* hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java


This should battle tested. I do remember constant failures with # of split threads > 1 in my test runs a while ago (that was on a master branch ~ 9-10 months ago). 

Why does creation of reference files take so long? 

What kind of failures were they? Failure on hbase side or hdfs side?

I didn't trace the creation of the reference files very deep, but as I indicated in an earlier comment, the entire time is spent in the FSDataOutputStream.close(). The time also matches independent test done in the same environment using NNBenchWithoutMR. I glanced through the hdfs settings and didn't find anything that could help speed up the writes, but perhaps I missed something. One issue here is that reference files are very small and HDFS is optimized for large files, so it is hard to find any references for optimizing writes of small files.

SUCCESS: Integrated in HBase-1.2-IT #29 (See [https://builds.apache.org/job/HBase-1.2-IT/29/])
HBASE-13959 Region splitting uses a single thread in most common cases. (Hari Krishna Dara) (larsh: rev 38f43acc4ca1a1f57793ae906c911e40904b6249)
* hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransactionImpl.java
* hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java


FAILURE: Integrated in HBase-0.98 #1043 (See [https://builds.apache.org/job/HBase-0.98/1043/])
HBASE-13959 Region splitting uses a single thread in most common cases. (Hari Krishna Dara) (larsh: rev 1ee69096878927979a43ffb744870d44398f7c35)
* hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java
* hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java


SUCCESS: Integrated in HBase-1.3-IT #13 (See [https://builds.apache.org/job/HBase-1.3-IT/13/])
HBASE-13959 Region splitting uses a single thread in most common cases. (Hari Krishna Dara) (larsh: rev 163ddbf03cb94e4823cbc694ccba92366ec35917)
* hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java
* hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransactionImpl.java


SUCCESS: Integrated in HBase-1.2 #40 (See [https://builds.apache.org/job/HBase-1.2/40/])
HBASE-13959 Region splitting uses a single thread in most common cases. (Hari Krishna Dara) (larsh: rev 38f43acc4ca1a1f57793ae906c911e40904b6249)
* hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransactionImpl.java
* hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java


bq. Is there an existing jira to capture the requirements for central execution pool? If not, I can work on it.

Don't think so. Let's create a new one.

bq. Meanwhile, is it OK to work on a follow up patch to increase the concurrency further by creating both reference files in parallel? This work will not go waste when a central pool is introduced

Sure. Be very careful, though, for correctness it is essential that the daughter come online in the correct order (daughter B first). Or at least are made visible in META in that order.

bq. This should battle tested. I do remember constant failures with # of split threads > 1 in my test runs a while ago (that was on a master branch ~ 9-10 months ago).
That's the number of parallel splits executed. This is different. Clearly the intention of the code was to do this. As it is we make a new ThreadPool with exactly one thread in it in the vast majority of the cases.
I don't see how making multile references in parallel can cause harm unless we're overloading the system somewhere (maybe too many threads on the RS or not enough handler threads at the NN).

If I remember right you run with # blocking store files set to 200, right? You may have to dial down the max threads introduced here.

I have no problem running this in our production systems (of course we'll do our usual acceptance testing in any case).

bq. Why does creation of reference files take so long?
Each is creating a new file, which takes a while as the NN has to persist its state. (the Namenode can handle 10000 operation/sec, but each individual one takes a bit to finish). 1/5s-1/3s is about what I had measured in the past.


FAILURE: Integrated in HBase-0.98-on-Hadoop-1.1 #996 (See [https://builds.apache.org/job/HBase-0.98-on-Hadoop-1.1/996/])
HBASE-13959 Region splitting uses a single thread in most common cases. (Hari Krishna Dara) (larsh: rev 1ee69096878927979a43ffb744870d44398f7c35)
* hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java
* hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java


bq. Let's create a new one.

I will create a "Brainstorming" issue to start a discussion on this and capture requirements.

bq. Be very careful, though, for correctness it is essential that the daughter come online in the correct order (daughter B first). Or at least are made visible in META in that order.

This is actually a very local operation and so should be safe (bringing the daughters online comes outside this scope). I just created HBASE-13999 for this.


[~haridsv] mind adding a release note summarizing this change and pointing out your new config? Thanks.

Apologies for the late response, but I just added a release note. Please take a look and let me know if it needs to be more or less verbose than this and I can make adjustments.

Closing this issue after 1.0.2 release.

