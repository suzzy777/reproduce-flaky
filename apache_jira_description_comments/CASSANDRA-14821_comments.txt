What kind of bugs are you aiming to test for using this approach? Can you please add more complex, real-world test cases first, so it's possible to tell the advantages over existing testing approaches? Doesn't even have to compile, just to get an idea on where this is going...

[~spodxx@gmail.com]: if any change needed less justification, I can't think of it, but perhaps this hasn't been expressed clearly enough.  

You can think of dtests as deprecated as soon as this lands, with every new distributed test written here instead (and preferably all existing dtests being ported eventually).  

It will provide, in essence, an in-process ccm - but with the wiring to access each node's internal state directly at any point of the codebase.  dtests will be faster, less flaky, and more easily developed.  You'll be able to trivially debug them in your IDE, seeing all node states, and we can write complex fuzzers over entire cluster behaviours with total control over what happens.  We can reliably disable, corrupt or otherwise interfere with cross-node behaviours.

This is as good as testing gets, short of properly isolating and mocking out every subsystem.  It's only a shame we didn't do this a long time ago.

As it happens, I intend to write a test using this framework for CASSANDRA-14812.  But we should not block integration on that; this is too widely impactful.

Just as an example, even an extremely simple three-node in-jvm dtest has revealed a bug that'd be rather hard to spot otherwise: https://issues.apache.org/jira/browse/CASSANDRA-14807

I understand the intention and motivation behind this effort. No justification needed. Alex asked for early feedback and I responded that more complex, real-world test cases would help evaluating the usefulness and advantages of the provided code over existing testing approaches. His Jira comment and the corresponding PR now seem to be deleted/closed, so it looks like this is still largely work in progress at this point.

Thank you [~spodxx@gmail.com] for your feedback. I've added some more complex tests to make it more illustrative: one is illustrative for [CASSANDRA-13004] and one for failing read/repair (when node drops read-repair message). 

I wouldn't say that this is work in progress even by the time of first submission, but I agree that some additional description to get people more excited about it was due. I hoped it was covered in the initial issue description, but I'm also happy to elaborate. This testing framework will help us to introduce things that are otherwise difficult to reproduce. For example [CASSANDRA-13304] was quite hard to catch and only thanks to folks who have submitted a go program that would help to reproduce it we were able to catch it. Creating a dtest test for it would've been rather difficult. Similarly, read/repair dropping messages would've required to introduce Byteman scripts, which are much less reliable than direct code execution.

Hope the latest version and this comment will be more helpful in terms of our motivation.


As already mentioned, I really understand the motivation behind this and the intention to replace dtests with a JVM based solution in the long run. My approach to that was implementing CASSANDRA-12016 a little more than two years ago. The main assumption behind it was that tests would be less complex and could be run much more efficiently, by always focusing on a single node and mocking it's interactions with a simulated cluster, instead of actually running separate Cassandra instances in parallel and manipulating instances to exchange messages in a certain way for a particular test case. Some tests implemented based on that approach turned out to be promising. But there are certainly also limitations and I hope that looking at the solution provided as part of this ticket, would help me to learn more about use cases when tests could not be fully simulated (for functional or practical reasons) and really need to be run as multi instance integration tests. But that's just my personal curiosity. What we should do nonetheless, is to eventually update the documentation and describe which testing approach would fit best for which use case (dtest py/jvm, unit, message mocking, property based, ..). I'd be happy to do that, once this ticket is done.

[~spodxx@gmail.com] MessagingService mocks are great for the purposes you've listed in the original ticket (asserting that the outgoing messages are correct and a node proceeds correctly on response). In my view, intention here is rather orthogonal to MS mocks, since we're trying to capture end-to-end behaviour and interaction of multiple nodes (potentially with in different states / having different data).

We can start off a wider discussion separately on how we could use both approaches together or which tests we could write that would use MS mocks, as both approaches might be useful for verifying different behaviours. 

Great, let's wrap up testing approaches then in CASSANDRA-14830 and see if we can create a guideline to help people to understand which approach to use for which kind of test case. We should have a set of different solutions by now that allows writing tests at different abstraction levels, which is good IMO.

This patch is looking really good, and I'm looking forward to it landing.  I’ve gone ahead and made a few changes to it, that I’ve pushed [here|https://github.com/belliottsmith/cassandra/tree/14821]

The main change is around how we mock out the networking.  Before we were registering only very specific handlers, and only for the coordinator.  I’ve removed the special case handling and we’re now able to handle any message type, and we can deliver them between any nodes (not just from the nominated coordinator).

Relatedly, I’ve slightly improved the message filtering - there’s now a builder interface for dropping messages, that also returns a handle that permits toggling the specific filter.  The builder uses instance numbers rather than {{InetAddressAndPort}} to simplify for authors.  This also supports filtering messages between multiple sender and recipient nodes, for any selection of verbs.

The filtering is perhaps slightly less efficient, because it’s somewhat of a simple pattern match, so we must iterate all filters, but I think this is probably overall more ergonomic.

I’ve also changed the node numbering in TestCluster.get(), to index from 1.  This might seem counterintuitive, but it should make debugging easier, as now the instance number we use in the test cases will match the low digits of the broadcast address.

Otherwise, some refactoring:

ConfigUtil: merged into InstanceConfig
InstanceClassLoader: moved all class loading config here, introduced a factory to abstract their creation
Typo: org.apache.cassandra.disable_mbrean_registration
Coordinator: moved registerCallbacks -> Instance.registerMockMessaging
Shared Class Loader: Removed some (effectively) dead code with the intermediate class loader that wasn’t actually used (and probably isn’t necessary)
Shutdown: Used a varargs array of lambdas to simplify slightly
runOnAll: Still there, but wasn’t actually necessary for the use cases as the methods already invoked themselves on the target node, so the I’ve migrated the callsites to a simple submit of invoking the method.  I’ve also standardised most of the instance methods to transparently forwarding the invocation to the node.  We could consider removing runOnAll.


Many people have tried such class-loader approaches in the past and all attempts to do so have failed (making things worse, cluttered the code base, or simply failed to work) sooner or later - especially in an environment where static-initializers are used all over the place.

Deprecating dtests is just wrong as long as there is no replacement that can test things in the same way as dtests do. How do you test startup scripts? How do you invoke all the tools? What happens if you kill an instance? How to you intend to test upgrades? Or is there some other tool that can do test things like that, that's not mentioned here?

Testing distributed processes in a single JVM is definitely not the same as testing it in multiple JVMs.

The patch itself touches a lot of quite important areas in the code base and adds a bunch of test-only code to the production code base. What's the performance impact of a change like this? How does this change work in Java 11 or even with upcoming features? What's the plan to maintain that?

Please feel free to prove me wrong by implementing this in a fork and running it in parallel over multiple months and the tests implemented with this approach can do the same things as dtests do and also show the same test results as dtests do.

I agree, that testing the code base is hard and dtests are not the most convenient thing, but I'm really afraid that this one introduces more difficulties and other issues than it solves.

{quote}The patch itself touches a lot of quite important areas in the code base and adds a bunch of test-only code to the production code base
{quote}
Could you elaborate?  I see four category of changes to the main codebase, all of which improvements, many of which _nonessential_, so if it's contentious we can remove them:
 # MBean registration abstraction, so we can mock it out - this is anyway much cleaner than prior copy/paste jobs
 # Internode message parsing - I cleaned up (in my view) some of the netty parsing, but we could roll this back. I had already considered deferring it to the overall internode messaging review/audit work I'll be undertaking soon. Otherwise, this code does not touch the production code paths, it just offers a synchronous equivalent for parsing.
 # Executor shutdown - this by definition only happens at shutdown, so is essentially a no-op for production running. The reason being that we (lazily) depend on daemon thread status to cleanup after ourselves. This is anyway good hygiene, and neutral to the codebase.
 # InfiniteLoopExecutor - this is simply a cleanup abstraction of something we do in several places, that I suggested we do alongside this, because it made sense. It's non-essential, but I don't see the problem with it? It's very simple, and improves codebase clarity.

Could you point me to your issues with these, or other issues I missed? I'm pretty sure we can assuage your concerns.
{quote}Many people have tried such class-loader approaches in the past and all attempts to do so have failed
{quote}
Can you refer me to an example?  This attempt seems pretty damn clean to me, and demonstrably works. I've done this kind of thing in the past, and been successful.
{quote}How to you intend to test upgrades? 
{quote}
It's not implemented yet, but I've already back ported this to 3.0 successfully in order to debug CASSANDRA-14812 (making it *significantly* easier to do so. It's surely telling that I would prefer to backport this than debug via CCM?). It's a relatively straightforward thing to support multiple versions once the core functionality is available in each version we want to test.
{quote}How do you test startup scripts? How do you invoke all the tools? What happens if you kill an instance? How to you intend to test upgrades?
{quote}
Almost none of these things are tested (at least in any meaningful sense) in today's dtests, I think?

Sure, perhaps deprecating _all_ dtests is maybe over stating it, we'll have to wait and see. But the use cases you listed - in the kind of isolated tests dtests perform - are just as easily tested by unit tests I think? We're talking exclusively about abnormal JVM exit and startup scripts in *extremely curated circumstances*. These are local node behaviours, and just as easily tested without the distributed aspect, surely? dtests aren't, after all, complex randomised tests exploring obscure cluster states.

But if we decide we need a few dtests, sure, I'm not suggesting they'd be literally forbidden. I just don't see a strong enough case for them after this becomes full-featured and commonplace. I would prefer we ported all dtests to this framework.

Lets talk about the advantages of this approach:
 # Dramatically shorter test times
 # Reduced flakiness of tests, as tests can be deterministic instead of based on sleeps that are hoped to be sufficient
 # Ability to directly debug failures in your IDE
 # *Vastly* greater control over node behaviours when writing tests
 # Writing tests in the language we write the database in, reducing friction costs for most developers on the project
 # Tests can live in-tree, alongside our other tests

So far I've not seen a real downside that you've listed? Why wouldn't we deprecate python tests for a majority of use cases?

bq. but I'm really afraid that this one introduces more difficulties and other issues than it solves.

It'd be great to elaborate on it as I see no difficulties, but I'm open to your suggestions if you describe which exactly parts introduce any difficulties. I realise however that benefits will be only adding up with time as there are more tests and more discovered issues and I'm happy to make benefits even larger than they already are.

Additionally, the benefits are already starting to show: we have already found and fixed two issues and were able to write tests for third one which proved it works well, with this approach and now can test things that previously were impossible to test (listed in detail in other comments).

I'd also be curious to see previously where this approach was successfully implemented. The only that I'm aware of is Embedded Cassandra, but this does not come even close as it neither allowed successfully stopping the process nor did it allow to launch multiple instances.

I think the future of dtests is completely *out of scope* of this ticket and it should only be discussed in a wider forum and requires a deep analysis. The only goal here is to allow testing things which are hard to reproduce with dtests and unit tests (among others, ones that have fine-grained control over instance state and behaviour). Focus is to allow test _some_ things differently, quicker, more deterministically and with native debugger.

{quote}I think the future of dtests is completely *out of scope* of this ticket
{quote}
You're absolutely right.  It wasn't my plan to litigate this here, it was an error to refer to this implication when trying to explain the value of the patch.  Integrating this patch was never expected to immediately deprecate dtests - such a decision would have to happen with wider input, and could not happen until this work has proven itself over many months, perhaps years.

But I stand by the implication / prediction.

I've made several additional improvements and removed the only two cases where we were using CQLStatement methods (however minor they were), so we're using only public APIs now.

 [~ifesdjeen], I went over the PR and it looks pretty cool. I did not have major concerns. I think this would be a valuable addition to the way we test Cassandra. There were some minor nits that you can address on commit. Please see below -
 # {{SecondaryIndexManager#shutdownExecutors}}, {{NettyFactory#close}}, {{PendingRangeCalculatorService#shutdownExecutor}}, {{Ref#shutdownReferenceReaper}}, {{BufferPool#shutdownLocalCleaner}}, {{MemTablePool#shutdown}} - should the number of seconds be configurable? At least make it a constant?
 # {{MessagingService#L472}} - braces are unnecessary for a single line if condition.
 # {{MessageInHandler}} - unused import statements in the file.
 # {{ByteBufferUtil#L495}} - "Can not" -> "Cannot"
 # {{Instance.java}} - Is there a reason that variable `root` is package-private? I think it can be private.
 # {{InstanceClassLoader}} - `commonClasses` can be made final
 # {{InstanceClassLoader}} - `id` variable is assigned but unused. Do we need it?
 # {{MessageFilters#allVerbs}} - method is unused. Do we need it?
 # {{RowUtil}} - has unused imports.
 # {{TestCluster#withThreadLeakCheck}} - method is unused. Do we need it?
 # {{TestCluster#close}} - L219 did you intend to comment out this?

Addressed comments from Dinesh, except: 

bq. SecondaryIndexManager#shutdownExecutors, NettyFactory#close, PendingRangeCalculatorService#shutdownExecutor, Ref#shutdownReferenceReaper, BufferPool#shutdownLocalCleaner, MemTablePool#shutdown - should the number of seconds be configurable? At least make it a constant?

Since it's test-only, I'd say it's good enough as it is, we do not have any use for those other than tests 

bq. InstanceClassLoader - `id` variable is assigned but unused. Do we need it?

We do, sometimes it's useful to understand which instance you're on, in debug. There's a comment indicating that.

bq. MessageFilters#allVerbs - method is unused. Do we need it?

We do: it's a DSL, if you'd like to make node fully unavailable.

bq. TestCluster#withThreadLeakCheck - method is unused. Do we need it? && TestCluster#close - L219 did you intend to comment out this?

We do need both of these, until SEPExecutor patch is committed, it makes no sense to enable thread leak checks. I'd also say that thread leak check should be optimal generally, but rewriting it every time is unnecessary.

[~benedict] I've also changed configuration to avoid using YAML round-trips and just make a config right away, without loader. Could you take a short look?

I've also added some tests inspired by [~benedict] patch on re-creating static columns, to check what happens during disagreement.

Do you have a branch with your prior round of improvement changes split out, just to corroborate them (this branch has them squashed)?

Couple of minor suggestions on the branch as stands:

* Maybe worth extracting an {{assertThrows}} method accepting a lambda (with optional predicate) for the tests?
* Maybe worth moving this into its own top level test/integration folder, or test/distributed?  Not sure; at present these are easily called unit tests, but we anticipate non-unit tests, which might be strange to depend on the unit test tree.  It also might anyway be nice to separate out our distributed tests?


I have pushed a couple of minor suggestions to my 14821 branch, mostly to make schema agreement deterministic.  I'm happy to commit as-is, though I do think there would be value in moving this to its own tree.

Moved code to its own tree, now it's under {{test/distributed}}; added them to circleci. 

(y) ship it

[~ifesdjeen] please let myself or [~vinaykumarcse] know of any high value areas you think we could add some coverage using these in JVM dtests, we'd like to give them a try (and think they will be much easier to use than traditional dtests!). 

[~jolynch] I will, thank you for interest! I'll reach out next week if that's ok.

[~benedict] [~djoshi3] thank you very much for review & feedback!

Committed to trunk with [f22fec927de7ac291266660c2f34de5b8cc1c695|https://github.com/apache/cassandra/commit/f22fec927de7ac291266660c2f34de5b8cc1c695].

This is great. 

Sure [~ifesdjeen], that works. you can reach out to us on dev-irc. 

