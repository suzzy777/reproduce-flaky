Hi [~wzhou] Assigning this to you since you may be more familiar with these tests than myself. Please feel free to reassign to someone else who might be a better person to fix this.

Confirmed with bug reporter. This issue happened in ASAN build.

This is same as IMPALA-8064: (test_min_max_filters is flaky) due to runtime filters not arriving in time. 

There is only one query in min_max_filters.test  with expected probe rows as 619.  That is  following query:

select STRAIGHT_JOIN count (* ) from decimal_rtf_tbl a join [BROADCAST] decimal_rtf_tiny_tbl b
 where a.d28_28 = b.d28_28 and b.d28_28 != 0;

All_runtime_filters.test also has this query with expected probe rows as 37. 

When applied min_max filter on target,  the aggregated probe rows equals 619. When applied bloom filter or both bloom and min-max filters on target,   the aggregated  probe rows equals 37. When don't apply runtime filter on target (for example, set runtime_filter_mode as off), the aggregated probe rows equals 718.

Since the actual probe rows equals 718 in both cases, it seems that the runtime filters were not applied on the target during the test when the issues happened. Also the issue happened randomly, it maybe caused by some timing issue. Most likely the Kudu scanner on the executer did not receive the runtime filters on time when executing the query, hence filter were not apply to the Kudu scan.

This issue is likely to happen in ASAN build for the test cases on Kudu table since the Kudu scan performance is blow HDFS. The single node benchmark for TPCH shows that standard deviation is pretty high for Kudu scan, sometimes it could reach more than 50%.  That could slow the process significantly to build runtime filter on Kudu table.    

Maybe we should increase RUNTIME_FILTER_WAIT_TIME_MS value for the query with runtime filters building from Kudu table.

  

[~wzhou] yeah I think bumping RUNTIME_FILTER_WAIT_TIME_MS would make sense to make the tests more deterministic.

This issue randomly happened in impala-cdpd-master-core-asan builds.

Checked the query profiles in log files, the issue happened for following query for TestMinMaxFilters.test_min_max_filters and TestAllRuntimeFilters.test_all_runtime_filters:

select STRAIGHT_JOIN count(*) from decimal_rtf_tbl a join [BROADCAST] decimal_rtf_tiny_tbl b
 where a.d28_28 = b.d28_28 and b.d28_28 != 0

When the issue happened, backend took 4 to 6 minutes to finish the query plan. The filters did not arrive scan node in time. Arrival delay is about 4 m ~ 5 m.  The codegen for one fragment tooks about 3 m. Kudu scan did not take too much time (about ~25 s).

Here the messages in query profile for one of the failures, others have same pattern.

impala-ec2-centos74-r5-4xlarge-ondemand-0573.vpc.cloudera.com:22002: Filter 1 arrival: 5m42s

Fragment F00: CodeGen:(Total: 3m58s, non-child: 0.000ns, % non-child: 0.00%)

     - CodegenInvoluntaryContextSwitches: 106 (106)
     - CodegenTotalWallClockTime: 3m58s
     - CodegenSysTime: 8.058ms
     - CodegenUserTime: 3m58s
     - CodegenVoluntaryContextSwitches: 0 (0)
     - CompileTime: 1s125ms
     - IrGenerationTime: 121.999ms
     - LoadTime: 0.000ns
     - ModuleBitcodeSize: 2.55 MB (2676464)
     - NumFunctions: 136 (136)
     - NumInstructions: 5.37K (5368)
     - OptimizationTime: 3m57s
     - PeakMemoryUsage: 2.62 MB (2748416)
     -  PrepareTime: 258.999ms

Fragment F01: CodeGen:(Total: 3m39s, non-child: 0.000ns, % non-child: 0.00%)

KUDU_SCAN_NODE (id=0):(Total: 20.999ms, non-child: 20.999ms, % non-child: 100.00%)
 Table Name: functional_kudu.decimal_rtf_tbl
 Runtime filters: Not all filters arrived (arrived: [], missing [1]), waited for 0. Arrival delay: 6m14s.

 

These runtime filter testing are executed in the end part of whole testing.  According to [https://gerrit.cloudera.org/#/c/16155/, |https://gerrit.cloudera.org/#/c/16155/]as the stacks accumulate in ASAN build, allocations and frees get slower and slower. This causes test execution time to degrade over time especially for codegen, hence increase the delay for runtime filters to arrive the scan node.

IMPALA- 9887 (Add support for sharding end-to-end tests)  and IMPALA-5444 (Asynchronous code generation) should be helpful to solve the issue. IMPALA-5444  was merged into upstream recently, but query option ASYNC_CODEGEN was off by default. We should turn on ASYNC_CODEGEN for runtime filter testing against Kudu table when test runs slowly, like ASAN build.

  

 

Commit d12ceec23bbb11da171cb54a3370d22a904f1d2a in impala's branch refs/heads/master from wzhou-code
[ https://gitbox.apache.org/repos/asf?p=impala.git;h=d12ceec ]

IMPALA-9889: Fixed flaky test_runtime_filters on Kudu table

Test cases in test_runtime_filters failed occasionally in ASAN
builds due to runtime filters not arriving scan nodes in time.
Query profiles showed that codegen took 2 to 4 minutes for one
fragment when this issue happened. This caused hash join nodes
waiting long time to generate and publish runtime filters, hence
arrival delay on scan nodes. To avoid the delay, turn on
ASYNC_CODEGEN for test_runtime_filters when test runs for slow
build like ASAN, TSAN, UBSAN, etc.

Testing:
 - Passed core test for regular debug build and ASAN build.

Change-Id: I94a08e272f0870c04c96563fa614e3416fb5379b
Reviewed-on: http://gerrit.cloudera.org:8080/16191
Reviewed-by: Thomas Tauber-Marshall <tmarshall@cloudera.com>
Tested-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>


