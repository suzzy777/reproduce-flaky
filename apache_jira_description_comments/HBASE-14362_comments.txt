The issue reproduced just now!  

https://builds.apache.org/job/PreCommit-HBASE-Build/15596//testReport/org.apache.hadoop.hbase.master.procedure/TestWALProcedureStoreOnHDFS/testWalRollOnLowReplication/

After analysis the log, i found something 
Testcase failed is due to the exception 
{code}
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /test-logs/state-00000000000000000018.log could only be replicated to 2 nodes instead of minReplication (=3).  There are 3 datanode(s) running and 3 node(s) are excluded in this operation.
{code}

There are lots of this kind exceptions in log, and it appears from the beginning of the log.

But most of this exception is catched in {{WALProcedureStore}}, except the last one which was thrown by method {{syncSlots}} when logRolled times larger than {{maxSyncFailureRoll}} 

{code}
  private long syncSlots() throws Throwable {
    int retry = 0;
    int logRolled = 0;
    long totalSynced = 0;
    do {
      try {
        totalSynced = syncSlots(stream, slots, 0, slotIndex);
        break;
      } catch (Throwable e) {
        if (++retry >= maxRetriesBeforeRoll) {
          if (logRolled >= maxSyncFailureRoll) {
            LOG.error("Sync slots after log roll failed, abort.", e);
            sendAbortProcessSignal();
            throw e;   // here, the exception is throw out,  and cause the syncLoop exit!!
          }

          if (!rollWriterOrDie()) {
            throw e;
          }

          logRolled++;
          retry = 0;
        }
      }
    } while (isRunning());
    return totalSynced;
  }
{code}

So if i set {{hbase.procedure.store.wal.wait.before.roll}} and {{hbase.procedure.store.wal.sync.failure.roll.max}} to be a smaller number,  the testcase will always run failed.


So to fix this issue,  we could increase the number when test-env is slow. Or we catch the exception.

.


{quote}
But most of this exception is catched in WALProcedureStore,
{quote}

this description has some misunderstanding.

It should be 

"But most of this exception is catched in {{WALProcedureStore.syncLoop}},"

if you look at the TestWALProcedureStoreOnHDFS code it already say that is flaky in case of slow machines.
you can bump the value as much as you want, but if the machine is even slower it will fail again. 
the other downside is that it will slow down runs on faster machines
{code}
    // increase the value for slow test-env
    conf.setInt("hbase.procedure.store.wal.wait.before.roll", 1000);
    conf.setInt("hbase.procedure.store.wal.max.roll.retries", 5);
    conf.setInt("hbase.procedure.store.wal.sync.failure.roll.max", 5);
{code}

If i set param 
{code}
    conf.setInt("hbase.procedure.store.wal.max.roll.retries", 1);
    conf.setInt("hbase.procedure.store.wal.sync.failure.roll.max", 1);
{code}

This issue will be reproduced locally.  

I think the reason is, as original logic  
{code}
 store.insert(new TestProcedure(i, -1), null);
 waitForNumReplicas(3);
{code}

after we restart dn,  we insert immediately,  when dn is not started fully, the testcase will failed.

So we use {{waitForNumReplicas(3)}} before insert,  in {{waitForNumReplicas(3)}} it will wait dn start fully. 

after do that,  the testcase will not failed again locally.



using waitForNumReplicas() invalidate the test. 
The point of the test is verify what happens when there are not enough replicas.

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12764151/HBASE-14362.patch
  against master branch at commit f6be2f9bf357d25e2b04afd20170ad20662b834f.
  ATTACHMENT ID: 12764151

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified tests.

    {color:green}+1 hadoop versions{color}. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.7.0 2.7.1)

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 protoc{color}.  The applied patch does not increase the total number of protoc compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 checkstyle{color}.  The applied patch does not increase the total number of checkstyle errors

    {color:green}+1 findbugs{color}.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 lineLengths{color}.  The patch does not introduce lines longer than 100

  {color:green}+1 site{color}.  The mvn post-site goal succeeds with this patch.

     {color:red}-1 core tests{color}.  The patch failed these unit tests:
     

     {color:red}-1 core zombie tests{color}.  There are 1 zombie test(s): 	at org.apache.hadoop.hbase.regionserver.TestHRegion.testFlushCacheWhileScanning(TestHRegion.java:3756)

Test results: https://builds.apache.org/job/PreCommit-HBASE-Build/15792//testReport/
Release Findbugs (version 2.0.3) 	warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/15792//artifact/patchprocess/newFindbugsWarnings.html
Checkstyle Errors: https://builds.apache.org/job/PreCommit-HBASE-Build/15792//artifact/patchprocess/checkstyle-aggregate.html

  Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/15792//console

This message is automatically generated.

{quote}
using waitForNumReplicas() invalidate the test. 
The point of the test is verify what happens when there are not enough replicas.
{quote}

yeah....  I made a stupid mistake...

There is another way to fix this,  we can catch the exception thrown out by {{syncSlots(stream, slots, 0, slotIndex)}}

I update the patch,  Any concerns?  [~mbertozzi]

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12764208/HBASE-14362.patch
  against master branch at commit 2ea70c7e6c70c4bd689b79718999a948001f3b21.
  ATTACHMENT ID: 12764208

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 hadoop versions{color}. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.6.1 2.7.0 2.7.1)

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 protoc{color}.  The applied patch does not increase the total number of protoc compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 checkstyle{color}.  The applied patch does not increase the total number of checkstyle errors

    {color:green}+1 findbugs{color}.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 lineLengths{color}.  The patch does not introduce lines longer than 100

  {color:green}+1 site{color}.  The mvn post-site goal succeeds with this patch.

     {color:red}-1 core tests{color}.  The patch failed these unit tests:
                       org.apache.hadoop.hbase.mapreduce.TestImportExport
                  org.apache.hadoop.hbase.master.procedure.TestWALProcedureStoreOnHDFS
                  org.apache.hadoop.hbase.util.TestProcessBasedCluster
                  org.apache.hadoop.hbase.master.procedure.TestMasterFailoverWithProcedures

     {color:red}-1 core zombie tests{color}.  There are 4 zombie test(s): 	at org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScanBase.testScan(TestTableInputFormatScanBase.java:236)
	at org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan1.testScanEmptyToBBB(TestTableInputFormatScan1.java:84)
	at org.apache.hadoop.hbase.mapreduce.TestCellCounter.testCellCounter(TestCellCounter.java:99)
	at org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat2.testExcludeMinorCompaction(TestHFileOutputFormat2.java:1103)
	at org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.testWritingPEData(TestHFileOutputFormat.java:334)

Test results: https://builds.apache.org/job/PreCommit-HBASE-Build/15800//testReport/
Release Findbugs (version 2.0.3) 	warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/15800//artifact/patchprocess/newFindbugsWarnings.html
Checkstyle Errors: https://builds.apache.org/job/PreCommit-HBASE-Build/15800//artifact/patchprocess/checkstyle-aggregate.html

  Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/15800//console

This message is automatically generated.

in that way we just loose data. 
The exception in syncSlots(Stream, slots, offset, count) is already catched in syncSlots().
if we are not able to write/sync, we are trying to close the current wal and reopen a new one.
we try N times, if we can't we give up because maybe that machine is no longer able to talk with HDFS or something like that. and we let the backup master try.
for the test we just need to increase the number of retries, to be able to the slow test machines

{quote}
in that way we just loose data
{quote}

yeah, but we can use one class extends {{WALProcedureStore}} and override {{syncSlots(Stream, slots, offset, count)}} in this class.

How about this?

the code and the test are correct as they are. the test is flaky by nature, as the comment point out, since is bounded to the time it takes to restart the DN. the only thing we can do if we want to verify the retry code is just bump the retries value.

{quote}
the only thing we can do if we want to verify the retry code is just bump the retries value.
{quote}

So your suggestion is to make the issue to be invalid or bump the retries value?

yeah, bump the retry value. we want to verify this situation and we know that the test will pass at some point, we just don't know how long the DN takes to get back online

{quote}
yeah, bump the retry value. we want to verify this situation and we know that the test will pass at some point, we just don't know how long the DN takes to get back online
{quote}

Double the retry value as [~mbertozzi] suggestion....

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12764262/HBASE-14362_v1.patch
  against master branch at commit 37877e3f56b038c0821138862813e567390a9ff4.
  ATTACHMENT ID: 12764262

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified tests.

    {color:green}+1 hadoop versions{color}. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.6.1 2.7.0 2.7.1)

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 protoc{color}.  The applied patch does not increase the total number of protoc compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 checkstyle{color}.  The applied patch does not increase the total number of checkstyle errors

    {color:green}+1 findbugs{color}.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 lineLengths{color}.  The patch does not introduce lines longer than 100

  {color:green}+1 site{color}.  The mvn post-site goal succeeds with this patch.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

     {color:red}-1 core zombie tests{color}.  There are 1 zombie test(s): 	at org.apache.camel.component.jetty.jettyproducer.HttpJettyProducerRecipientListCustomThreadPoolTest.testRecipientList(HttpJettyProducerRecipientListCustomThreadPoolTest.java:40)

Test results: https://builds.apache.org/job/PreCommit-HBASE-Build/15808//testReport/
Release Findbugs (version 2.0.3) 	warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/15808//artifact/patchprocess/newFindbugsWarnings.html
Checkstyle Errors: https://builds.apache.org/job/PreCommit-HBASE-Build/15808//artifact/patchprocess/checkstyle-aggregate.html

  Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/15808//console

This message is automatically generated.

Lets try it ([~mbertozzi] is good w/ it... too... )

Pushed to branch-1.1+. Thanks for patch [~chenheng]  Hopefully we are no longer super duper flakey... probably just a bit flakey.

FAILURE: Integrated in HBase-1.1 #684 (See [https://builds.apache.org/job/HBase-1.1/684/])
HBASE-14362 org.apache.hadoop.hbase.master.procedure.TestWALProcedureStoreOnHDFS is super duper flaky (Heng Chen) (stack: rev 591e52b9657e2039085187fe0c8eb613d475be8b)
* hbase-server/src/test/java/org/apache/hadoop/hbase/master/procedure/TestWALProcedureStoreOnHDFS.java


SUCCESS: Integrated in HBase-1.2-IT #175 (See [https://builds.apache.org/job/HBase-1.2-IT/175/])
HBASE-14362 org.apache.hadoop.hbase.master.procedure.TestWALProcedureStoreOnHDFS is super duper flaky (Heng Chen) (stack: rev a2db17b796e56f1e208c7a4c1ab83a4dcccbe05e)
* hbase-server/src/test/java/org/apache/hadoop/hbase/master/procedure/TestWALProcedureStoreOnHDFS.java


SUCCESS: Integrated in HBase-1.3-IT #191 (See [https://builds.apache.org/job/HBase-1.3-IT/191/])
HBASE-14362 org.apache.hadoop.hbase.master.procedure.TestWALProcedureStoreOnHDFS is super duper flaky (Heng Chen) (stack: rev 255fd07d357d37c469b20db4d8b7ab52400b0ba8)
* hbase-server/src/test/java/org/apache/hadoop/hbase/master/procedure/TestWALProcedureStoreOnHDFS.java


FAILURE: Integrated in HBase-1.2 #209 (See [https://builds.apache.org/job/HBase-1.2/209/])
HBASE-14362 org.apache.hadoop.hbase.master.procedure.TestWALProcedureStoreOnHDFS is super duper flaky (Heng Chen) (stack: rev a2db17b796e56f1e208c7a4c1ab83a4dcccbe05e)
* hbase-server/src/test/java/org/apache/hadoop/hbase/master/procedure/TestWALProcedureStoreOnHDFS.java


FAILURE: Integrated in HBase-1.3 #215 (See [https://builds.apache.org/job/HBase-1.3/215/])
HBASE-14362 org.apache.hadoop.hbase.master.procedure.TestWALProcedureStoreOnHDFS is super duper flaky (Heng Chen) (stack: rev 255fd07d357d37c469b20db4d8b7ab52400b0ba8)
* hbase-server/src/test/java/org/apache/hadoop/hbase/master/procedure/TestWALProcedureStoreOnHDFS.java


FAILURE: Integrated in HBase-TRUNK #6855 (See [https://builds.apache.org/job/HBase-TRUNK/6855/])
HBASE-14362 org.apache.hadoop.hbase.master.procedure.TestWALProcedureStoreOnHDFS is super duper flaky (Heng Chen) (stack: rev 4cb3e029b0fe8dabd972fb39aa24f1ff0ad69b4c)
* hbase-server/src/test/java/org/apache/hadoop/hbase/master/procedure/TestWALProcedureStoreOnHDFS.java


Updating fix version based on release audit vs what's committed.

Bulk closing 1.1.3 issues.

FAILURE: Integrated in HBase-1.1-JDK7 #1668 (See [https://builds.apache.org/job/HBase-1.1-JDK7/1668/])
HBASE-15169 Backport HBASE-14362 'TestWALProcedureStoreOnHDFS is super (chenheng: rev 10d607717257af8e83368e34bc32f98f98389dc8)
* hbase-server/src/test/java/org/apache/hadoop/hbase/master/procedure/TestWALProcedureStoreOnHDFS.java


FAILURE: Integrated in HBase-1.1-JDK8 #1755 (See [https://builds.apache.org/job/HBase-1.1-JDK8/1755/])
HBASE-15169 Backport HBASE-14362 'TestWALProcedureStoreOnHDFS is super (chenheng: rev 10d607717257af8e83368e34bc32f98f98389dc8)
* hbase-server/src/test/java/org/apache/hadoop/hbase/master/procedure/TestWALProcedureStoreOnHDFS.java


