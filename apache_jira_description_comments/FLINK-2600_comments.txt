This might not be reproducible, the Elasicsearch sink has been in there for a few weeks now and we never saw this. Nevertheless, I will look into how we can harden this.

Hi, 
https://travis-ci.org/apache/flink/builds/79250039
Is it the same issue?
Log following:
`Running org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkITCase
Tests run: 3, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 7.352 sec <<< FAILURE! - in org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkITCase
testNodeClient(org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkITCase)  Time elapsed: 1.372 sec  <<< ERROR!
org.apache.flink.runtime.client.JobExecutionException: Job execution failed.
	at org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1.applyOrElse(JobManager.scala:414)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.flink.runtime.testingUtils.TestingJobManager$$anonfun$handleTestingMessage$1.applyOrElse(TestingJobManager.scala:285)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.flink.runtime.LeaderSessionMessageFilter$$anonfun$receive$1.applyOrElse(LeaderSessionMessageFilter.scala:36)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.flink.runtime.LogMessages$$anon$1.apply(LogMessages.scala:33)
	at org.apache.flink.runtime.LogMessages$$anon$1.apply(LogMessages.scala:28)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at org.apache.flink.runtime.LogMessages$$anon$1.applyOrElse(LogMessages.scala:28)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
	at org.apache.flink.runtime.jobmanager.JobManager.aroundReceive(JobManager.scala:104)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
	at akka.actor.ActorCell.invoke(ActorCell.scala:487)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:254)
	at akka.dispatch.Mailbox.run(Mailbox.scala:221)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:231)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.RuntimeException: An error occured in ElasticsearchSink.
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSink.close(ElasticsearchSink.java:307)
	at org.apache.flink.api.common.functions.util.FunctionUtils.closeFunction(FunctionUtils.java:40)
	at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.close(AbstractUdfStreamOperator.java:75)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.closeAllOperators(StreamTask.java:243)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:185)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:581)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: IndexMissingException[[my-index] missing]
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSink$1.afterBulk(ElasticsearchSink.java:240)
	at org.elasticsearch.action.bulk.BulkProcessor.execute(BulkProcessor.java:316)
	at org.elasticsearch.action.bulk.BulkProcessor.executeIfNeeded(BulkProcessor.java:299)
	at org.elasticsearch.action.bulk.BulkProcessor.internalAdd(BulkProcessor.java:281)
	at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:264)
	at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:260)
	at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:246)
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSink.invoke(ElasticsearchSink.java:286)
	at org.apache.flink.streaming.api.operators.StreamSink.processElement(StreamSink.java:37)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:163)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:56)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:172)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:581)
	at java.lang.Thread.run(Thread.java:745)


Results :

Tests in error: 
  ElasticsearchSinkITCase.testNodeClient Â» JobExecution Job execution failed.

Tests run: 3, Failures: 0, Errors: 1, Skipped: 0`

Yes, that's the same issue.

Would be nice to harden such tests that can spuriously fail in the external dependencies.

How about having a loop of re-tries (up to 5 times) until it works? For errors that are out of our hands, this may help reducing the number of failed builds we see...

If retry I think it is better that record the fail in somewhere even the test is passed finally.
After all, if there is a problem it needs to be solved.

There are surefire/failsafe configs that allow rerunning tests: 
https://maven.apache.org/surefire/maven-surefire-plugin/examples/rerun-failing-tests.html
https://maven.apache.org/surefire/maven-failsafe-plugin/examples/rerun-failing-tests.html

Should we maybe set those? These would help with all flaky tests.

These would retry all tests. That masks valid failures in unstable features.

I would not use these unless you can activate them for very specific tests...

We can set the surefire/failsafe settings on a per maven module basis. I would enable this for the "flink-yarn-tests", the fs tests and elasticsearch.

GitHub user aljoscha opened a pull request:

    https://github.com/apache/flink/pull/1108

    [FLINK-2600] Enable test rerun for Elasticsearch Tests

    This also bumps surefire/failsafe version to 2.8.1

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/aljoscha/flink el-test-rerun

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/flink/pull/1108.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1108
    
----
commit 3065a9d34c62baee2311580aae7f9081cfcf058c
Author: Aljoscha Krettek <aljoscha.krettek@gmail.com>
Date:   2015-09-08T18:43:05Z

    [FLINK-2600] Enable test rerun for Elasticsearch Tests
    
    This also bumps surefire/failsafe version to 2.8.1

----


Github user StephanEwen commented on the pull request:

    https://github.com/apache/flink/pull/1108#issuecomment-138672001
  
    Since this is a test case where the failure is not due to a Flink issue, this looks like a good way to stabilize the tests.
    
    +1 to merge


Github user rmetzger commented on the pull request:

    https://github.com/apache/flink/pull/1108#issuecomment-138820891
  
    +1


Github user aljoscha commented on the pull request:

    https://github.com/apache/flink/pull/1108#issuecomment-138823043
  
    Manually merged


(Hopefully) fixed in https://github.com/apache/flink/commit/a9c29a760d68202622328bcd723ef9b0b071684e

Github user aljoscha closed the pull request at:

    https://github.com/apache/flink/pull/1108


Observed a failure just now: Here's the build log: https://s3.amazonaws.com/archive.travis-ci.org/jobs/79486037/log.txt if that's helpful but it's the same exception log. 
[Before you ask, it was rebased on today's fix. :') ]

Edit: The exception log is different. Sorry. Deadlocked.

I don't think that's anything that we could resolve.

But this is a test stability issue though. Maybe we should keep this open and see if it occurs again? 

Sure :D

We could also close it and reopen when it re-occurs.

That way we avoid all these zombie-issues that we have plentiful already. Fixed or no-problem issues that were never closed...

Occurred again

https://s3.amazonaws.com/archive.travis-ci.org/jobs/80770633/log.txt

But that's differente, isn't it? The other time the test failed with an exception in Elasticsearch, here it's a deadlock.

Failed again: https://s3.amazonaws.com/archive.travis-ci.org/jobs/81824062/log.txt

{code}
org.apache.flink.runtime.client.JobExecutionException: Job execution failed.
	at org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$7.apply$mcV$sp(JobManager.scala:528)
	at org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$7.apply(JobManager.scala:473)
	at org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$7.apply(JobManager.scala:473)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:401)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.RuntimeException: An error occured in ElasticsearchSink.
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSink.close(ElasticsearchSink.java:307)
	at org.apache.flink.api.common.functions.util.FunctionUtils.closeFunction(FunctionUtils.java:40)
	at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.close(AbstractUdfStreamOperator.java:84)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.closeAllOperators(StreamTask.java:236)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:181)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:579)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: UnavailableShardsException[[my-index][0] Primary shard is not active or isn't assigned to a known node. Timeout: [1m], request: org.elasticsearch.action.bulk.BulkShardRequest@518c3966]
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSink$1.afterBulk(ElasticsearchSink.java:240)
	at org.elasticsearch.action.bulk.BulkProcessor.execute(BulkProcessor.java:316)
	at org.elasticsearch.action.bulk.BulkProcessor.executeIfNeeded(BulkProcessor.java:299)
	at org.elasticsearch.action.bulk.BulkProcessor.internalAdd(BulkProcessor.java:281)
	at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:264)
	at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:260)
	at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:246)
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSink.invoke(ElasticsearchSink.java:286)
	at org.apache.flink.streaming.api.operators.StreamSink.processElement(StreamSink.java:37)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:162)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:56)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:168)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:579)
	at java.lang.Thread.run(Thread.java:745)
{code}

Ah man, this Elasticsearch embedded Node seems very fragile... :-(

How about we start a new maven project for "manual tests" that contain programs for release testing, that we do not execute as part of regular builds?

We put tests there that cannot be stabilized (external dependencies) or would simply take too long (such as some massive sorting tests)...

This sounds good. But then we should move the discussion to the mailing list or open a new jira that is not specific to Elasticsearch.

https://s3.amazonaws.com/archive.travis-ci.org/jobs/92033118/log.txt

Another incident: https://s3.amazonaws.com/archive.travis-ci.org/jobs/94123465/log.txt

I think we should start making this a manual test, or add code that polls whether the index has been created...

One more: https://s3.amazonaws.com/archive.travis-ci.org/jobs/106246892/log.txt

This seems to not have occurred in a while. Any updates here?

I just got this here via Maven with what I think are unrelated changes:

{code}
org.apache.flink.runtime.client.JobExecutionException: Job execution failed.
	at org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$8.apply$mcV$sp(JobManager.scala:810)
	at org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$8.apply(JobManager.scala:756)
	at org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$8.apply(JobManager.scala:756)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:401)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.RuntimeException: Client is not connected to any Elasticsearch nodes!
	at org.apache.flink.streaming.connectors.elasticsearch2.ElasticsearchSink.open(ElasticsearchSink.java:172)
	at org.apache.flink.api.common.functions.util.FunctionUtils.openFunction(FunctionUtils.java:38)
	at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.open(AbstractUdfStreamOperator.java:91)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.openAllOperators(StreamTask.java:389)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:256)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:638)
	at java.lang.Thread.run(Thread.java:745)
{code}


Hasn't occurred in about a year.

