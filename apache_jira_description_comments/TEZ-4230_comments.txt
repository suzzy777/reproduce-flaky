For reference:
logs for a good run:  [^org.apache.hadoop.hive.ql.txn.compactor.TestCrudCompactorOnTez-output.txt] 
logs for a hanging run 1:  [^TestCrudCompactorOnTez.log] 
logs for a hanging run 2:  [^TestCrudCompactorOnTez2.log] 

-what is strange for the first sight, I cannot see MergeManager related log messages when it's expected, so this could be a shuffle issue-
this is more like a LocalContainerLauncher issue, see next comment

good run:
{code}
2020-09-03T15:13:19,604  INFO [I/O Setup 0 Start: {Map 1}] orderedgrouped.Shuffle: Map_1: Shuffle assigned with 1 inputs, codec: None, ifileReadAhead: true
2020-09-03T15:13:19,605  INFO [I/O Setup 0 Start: {Map 1}] orderedgrouped.MergeManager: Map 1: MergerManager: memoryLimit=1278984847, maxSingleShuffleLimit=319746208, mergeThreshold=844130048, ioSortFactor=10, postMergeMem=0, memToMemMergeOutputsThreshold=10
2020-09-03T15:13:19,605  INFO [I/O Setup 0 Start: {Map 1}] orderedgrouped.ShuffleScheduler: ShuffleScheduler running for sourceVertex: Map 1 with configuration: maxFetchFailuresBeforeReporting=5, reportReadErrorImmediately=true, maxFailedUniqueFetches=1, abortFailureLimit=15, maxTaskOutputAtOnce=20, numFetchers=1, hostFailureFraction=0.2, minFailurePerHost=4, maxAllowedFailedFetchFraction=0.5, maxStallTimeFraction=0.5, minReqProgressFraction=0.5, checkFailedFetchSinceLastCompletion=true
2020-09-03T15:13:19,606  INFO [I/O Setup 0 Start: {Map 1}] runtime.LogicalIOProcessorRuntimeTask: Started Input with src edge: Map 1
2020-09-03T15:13:19,606  INFO [TezChild] runtime.LogicalIOProcessorRuntimeTask: AutoStartComplete
2020-09-03T15:13:19,606  INFO [ShuffleAndMergeRunner {Map_1}] orderedgrouped.MergeManager: Setting merger's parent thread to ShuffleAndMergeRunner {Map_1}
2020-09-03T15:13:19,606  INFO [TezChild] task.TaskRunner2Callable: Running task, taskAttemptId=attempt_1599171197926_0001_1_01_000000_0
2020-09-03T15:13:19,607  INFO [TezTaskEventRouter{attempt_1599171197926_0001_1_01_000000_0}] orderedgrouped.ShuffleInputEventHandlerOrderedGrouped: Map 1: numDmeEventsSeen=1, numDmeEventsSeenWithNoData=0, numObsoletionEventsSeen=0
2020-09-03T15:13:19,607  INFO [TezChild] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2020-09-03T15:13:19,607  INFO [TezChild] exec.Utilities: Deserialized plan (via RPC) - name: Reducer 2 size: 1.87KB
2020-09-03T15:13:19,607  INFO [TezChild] tez.ObjectCache: Caching key: lbodor_20200903151317_7f539b53-07fb-4bb1-97db-c37d72aba99d_Reducer 2__REDUCE_PLAN__
2020-09-03T15:13:19,607  INFO [TezChild] tez.RecordProcessor: conf class path = []
2020-09-03T15:13:19,608  INFO [TezChild] tez.RecordProcessor: thread class path = []
2020-09-03T15:13:19,608  INFO [Fetcher_O {Map_1} #0] orderedgrouped.MergeManager: close onDiskFile. State: NumOnDiskFiles=1. Current: path=/Users/lbodor/apache/hive/itests/hive-unit/target/tmp/scratchdir/lbodor/_tez_session_dir/e01fa9d5-36d9-4449-bfa4-d12b5fa290f8/.tez/application_1599171197926_0001_wd/localmode-local-dir/output/attempt_1599171197926_0001_1_00_000000_0_10098/file.out, len=26
2020-09-03T15:13:19,608  INFO [Fetcher_O {Map_1} #0] ShuffleScheduler.fetch: Completed fetch for attempt: {0, 0, attempt_1599171197926_0001_1_00_000000_0_10098} to DISK_DIRECT, csize=26, dsize=22, EndTime=1599171199608, TimeTaken=1, Rate=0.02 MB/s
2020-09-03T15:13:19,608  INFO [Fetcher_O {Map_1} #0] orderedgrouped.ShuffleScheduler: All inputs fetched for input vertex : Map 1
{code}

hanging run:
{code}
2020-09-04T02:12:16,392  INFO [I/O Setup 0 Start: {Map 1}] orderedgrouped.Shuffle: Map_1: Shuffle assigned with 1 inputs, codec: None, ifileReadAhead: true
2020-09-04T02:12:16,392  INFO [I/O Setup 0 Start: {Map 1}] orderedgrouped.MergeManager: Map 1: MergerManager: memoryLimit=1278984847, maxSingleShuffleLimit=319746208, mergeThreshold=844130048, ioSortFactor=10, postMergeMem=0, memToMemMergeOutputsThreshold=10
2020-09-04T02:12:16,394  INFO [I/O Setup 0 Start: {Map 1}] orderedgrouped.ShuffleScheduler: ShuffleScheduler running for sourceVertex: Map 1 with configuration: maxFetchFailuresBeforeReporting=5, reportReadErrorImmediately=true, maxFailedUniqueFetches=1, abortFailureLimit=15, maxTaskOutputAtOnce=20, numFetchers=1, hostFailureFraction=0.2, minFailurePerHost=4, maxAllowedFailedFetchFraction=0.5, maxStallTimeFraction=0.5, minReqProgressFraction=0.5, checkFailedFetchSinceLastCompletion=true
2020-09-04T02:12:16,398  INFO [I/O Setup 0 Start: {Map 1}] runtime.LogicalIOProcessorRuntimeTask: Started Input with src edge: Map 1
2020-09-04T02:12:16,398  INFO [TezChild] runtime.LogicalIOProcessorRuntimeTask: AutoStartComplete
2020-09-04T02:12:16,398  INFO [TezChild] task.TaskRunner2Callable: Running task, taskAttemptId=attempt_1599210735282_0001_1_01_000000_0
2020-09-04T02:12:16,416  INFO [TezChild] tez.ReduceRecordProcessor: Waiting for ShuffleInputs to become ready
{code}

so in the hanging run we reach the point of ShuffleScheduler instantiation, but than hanging here according to jstack
{code}
"ShuffleAndMergeRunner {Map_1}" #919 daemon prio=5 os_prio=0 tid=0x00007ff864012800 nid=0x1959e9 in Object.wait() [0x00007ff835ee1000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	at org.apache.tez.runtime.library.common.shuffle.orderedgrouped.ShuffleScheduler.waitAndNotifyProgress(ShuffleScheduler.java:1459)
	- locked <0x00000000fa885a20> (a org.apache.tez.runtime.library.common.shuffle.orderedgrouped.ShuffleScheduler)
	at org.apache.tez.runtime.library.common.shuffle.orderedgrouped.ShuffleScheduler.access$700(ShuffleScheduler.java:85)
	at org.apache.tez.runtime.library.common.shuffle.orderedgrouped.ShuffleScheduler$ShuffleSchedulerCallable.callInternal(ShuffleScheduler.java:1374)
	- locked <0x00000000fa885a20> (a org.apache.tez.runtime.library.common.shuffle.orderedgrouped.ShuffleScheduler)
	at org.apache.tez.runtime.library.common.shuffle.orderedgrouped.ShuffleScheduler$ShuffleSchedulerCallable.callInternal(ShuffleScheduler.java:1364)
	at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
	at org.apache.tez.runtime.library.common.shuffle.orderedgrouped.ShuffleScheduler.start(ShuffleScheduler.java:444)
	at org.apache.tez.runtime.library.common.shuffle.orderedgrouped.Shuffle$RunShuffleCallable.callInternal(Shuffle.java:293)
	at org.apache.tez.runtime.library.common.shuffle.orderedgrouped.Shuffle$RunShuffleCallable.callInternal(Shuffle.java:287)
	at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
	at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:108)
	at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:41)
	at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:77)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
{code}


seems like all hanging test runs contain an unexpected thread interrupt exception, which could be the root cause of the issue:
{code}
2020-09-04T02:12:16,148  WARN [LocalTaskExecutionThread #0] common.AsyncDispatcher: AsyncDispatcher thread interrupted
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1223) ~[?:1.8.0_262]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:340) ~[?:1.8.0_262]
	at java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:339) ~[?:1.8.0_262]
	at org.apache.tez.common.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:347) [tez-common-0.9.2.jar:0.9.2]
	at org.apache.tez.dag.app.TaskCommunicatorManager.sendEvent(TaskCommunicatorManager.java:656) [tez-dag-0.9.2.jar:0.9.2]
	at org.apache.tez.dag.app.TaskCommunicatorManager.heartbeat(TaskCommunicatorManager.java:357) [tez-dag-0.9.2.jar:0.9.2]
	at org.apache.tez.dag.app.TaskCommunicatorContextImpl.heartbeat(TaskCommunicatorContextImpl.java:99) [tez-dag-0.9.2.jar:0.9.2]
	at org.apache.tez.dag.app.TezTaskCommunicatorImpl$TezTaskUmbilicalProtocolImpl.heartbeat(TezTaskCommunicatorImpl.java:383) [tez-dag-0.9.2.jar:0.9.2]
	at org.apache.tez.runtime.task.TaskReporter$HeartbeatCallable.heartbeat(TaskReporter.java:272) [tez-runtime-internals-0.9.2.jar:0.9.2]
	at org.apache.tez.runtime.task.TaskReporter$HeartbeatCallable.taskSucceeded(TaskReporter.java:345) [tez-runtime-internals-0.9.2.jar:0.9.2]
	at org.apache.tez.runtime.task.TaskReporter$HeartbeatCallable.access$200(TaskReporter.java:134) [tez-runtime-internals-0.9.2.jar:0.9.2]
	at org.apache.tez.runtime.task.TaskReporter.taskSucceeded(TaskReporter.java:446) [tez-runtime-internals-0.9.2.jar:0.9.2]
	at org.apache.tez.runtime.task.TezTaskRunner2.run(TezTaskRunner2.java:211) [tez-runtime-internals-0.9.2.jar:0.9.2]
	at org.apache.tez.runtime.task.TezChild.run(TezChild.java:270) [tez-runtime-internals-0.9.2.jar:0.9.2]
	at org.apache.tez.dag.app.launcher.LocalContainerLauncher$1.call(LocalContainerLauncher.java:394) [tez-dag-0.9.2.jar:0.9.2]
	at org.apache.tez.dag.app.launcher.LocalContainerLauncher$1.call(LocalContainerLauncher.java:385) [tez-dag-0.9.2.jar:0.9.2]
	at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:108) [guava-19.0.jar:?]
	at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:41) [guava-19.0.jar:?]
	at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:77) [guava-19.0.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_262]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_262]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_262]
{code}

it looks like TezChild sends a final event, indicating that (Map?) task succeeded, but AM thread (which looks like the same, I guess it's because of local execution) is interrupted while handling that event, and somehow this leads to hanging later

I think this is caused by TEZ-3897, which seems to involve a race condition by [future.cancel(true)|https://github.com/apache/tez/commit/c34e46c73218bf21a0219f3004e20cbedaad92f4#diff-a1849ff607725cf1b84d74e78823ca3cR305]

in the hive tests mentioned above, we can see hanging with tez 0.9.2 and 0.10.0 (staging artifact), and the issue now seems clear to me based on [^TestCrudCompactorOnTez.log]

somehow the task's heartbeat thread is interrupted while the AsyncDispatcher is handling the event, and the last log message before the "AsyncDispatcher thread interrupted" is "Stopping containerId", so I suspect that LocalContainerLauncher cancels the task runnable, and won't wait for the heartbeat to be processed fully...cc: [~jeagles], [~jlowe] wondering if this makes sense to you...before TEZ-3897 LocalContainerLauncher totally ignored task callback on container stop, after TEZ-3897 "future.cancel(true)" seems to be quite strict under some circumstances...I'm about to test the flaky hive test somehow with [future.cancel(false)|https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Future.html?is-external=true#cancel-boolean-]

UPDATE: testing with future.cancel(false) is in progress (built a 0.9.2.1 artifact and [deployed|https://repository.apache.org/content/repositories/orgapachetez-1069/])
 [http://ci.hive.apache.org/job/hive-flaky-check/103/console]
http://ci.hive.apache.org/job/hive-flaky-check/104/console
 [http://ci.hive.apache.org/job/hive-flaky-check/105/console]
 [http://ci.hive.apache.org/job/hive-flaky-check/106/console]
 [http://ci.hive.apache.org/job/hive-flaky-check/107/console]

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  9m 52s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} dupname {color} | {color:green}  0m  0s{color} | {color:green} No case conflicting files found. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} master Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 11m  8s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 28s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 26s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 40s{color} | {color:green} master passed {color} |
| {color:blue}0{color} | {color:blue} spotbugs {color} | {color:blue}  1m 50s{color} | {color:blue} Used deprecated FindBugs config; considering switching to SpotBugs. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 49s{color} | {color:green} master passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 20s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 15s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 20s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 10s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  4m 12s{color} | {color:green} tez-dag in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 18s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 32m 55s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/PreCommit-TEZ-Build/10/artifact/out/Dockerfile |
| JIRA Issue | TEZ-4230 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/13011093/TEZ-4230.01.patch |
| Optional Tests | dupname asflicense javac javadoc unit spotbugs findbugs checkstyle compile |
| uname | Linux 1b514f7efd4f 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | personality/tez.sh |
| git revision | master / 79048f9e4 |
| Default Java | Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |
|  Test Results | https://ci-hadoop.apache.org/job/PreCommit-TEZ-Build/10/testReport/ |
| Max. process+thread count | 224 (vs. ulimit of 5500) |
| modules | C: tez-dag U: tez-dag |
| Console output | https://ci-hadoop.apache.org/job/PreCommit-TEZ-Build/10/console |
| versions | git=2.17.1 maven=3.6.0 findbugs=3.0.1 |
| Powered by | Apache Yetus 0.12.0 https://yetus.apache.org |


This message was automatically generated.



[~jeagles], [~jlowe]: could you please review this small patch? this is probably the last 0.10.0 blocker

long story short, I identified this with a flaky hive test, analyzed the logs, and with the fix, the test passed 500 times without an issue (details in previous comment)

+1. Thanks for the analysis and patch.

thanks for the review [~jeagles]! this is pushed to branch-0.9 / master / branch-0.10.0

