http://sandbox.jenkins.cloudera.com/view/Impala/view/Evergreen-cdh5-trunk/job/impala-cdh5-trunk-core-asan/363/ is the first occurance from what I can tell. The failure was unnoticed due to other failures.

359-362 did NOT have the failure.

I can investigate this. It started failing consistently?

Yes. There was a gap where the test couldn't run due to infrastructural failures, but otherwise I've seen it consistently.

That's in Jenkins, mind you. I have not tried to make it fail locally.

For what it's worth, this failure didn't occur in the last 2 ASAN builds, 369, 370.

i wasn't able to repro it locally after trying for a bit yesterday. It looks like classic racy memory consumption probably triggered by different timing in ASAN - this has been a problem with these tests because we don't guarantee much about queries completing in a particular mem limit (that is an end goal of some of our memory management work).

This contributed to a lot of build failures so I think we should try to prevent it in future. We could set query/mem limit combination to xfail on mem limit exceeded for the time being: we can reenable it later after the memory management work. That way we get coverage for correctness and crashes under different mem limits. Would that work for you?

Sure.


IMPALA-3328: xfail TPC-H q9 if memory limit exceeded

The test is flaky due to nondeterministic memory consumption under ASAN.
Xfail until we have more concrete guarantees on mem usage.

Change-Id: Ieefcb8f8ecc179f483f6d06af80c814fe0ef728e
Reviewed-on: http://gerrit.cloudera.org:8080/2770
Reviewed-by: Tim Armstrong <tarmstrong@cloudera.com>
Tested-by: Internal Jenkins
---
M tests/query_test/test_mem_usage_scaling.py
1 file changed, 2 insertions(+), 1 deletion(-)

Approvals:
  Internal Jenkins: Verified
  Tim Armstrong: Looks good to me, approved

