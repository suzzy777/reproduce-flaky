Seems like the topic is deleted before shutting down the job?

 

I am also wondering where this test is cancelling the streaming job. As it is still running,

Race in resource creation- I need to add sleeps here.

The test is still failing with [https://github.com/apache/beam/pull/15537] merged.

I think the test is probably not gonna work for dataflow reading elements directly from PCollection locally [https://github.com/dpcollins-google/beam/blob/23ab96cffc5a72f1716d2e4ab13dc0c0d0a9ec27/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/pubsublite/ReadWriteIT.java#L214,|https://github.com/dpcollins-google/beam/blob/23ab96cffc5a72f1716d2e4ab13dc0c0d0a9ec27/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/pubsublite/ReadWriteIT.java#L214]

You'd probably want to read from the output topic directly for getting the elements or use the PTransform to check elements then publish a success signal to pubsub sink for validation, for reference: [https://github.com/dpcollins-google/beam/blob/23ab96cffc5a72f1716d2e4ab13dc0c0d0a9ec27/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/pubsub/PubsubReadIT.java#L55]

 

I'm gonna sickbay the test and feel free to unsickbay it when it is fixed. You can test locally with ' ./gradlew :runners:google-cloud-dataflow-java:googleCloudPlatformLegacyWorkerIntegrationTest --tests org.apache.beam.sdk.io.gcp.pubsublite.ReadWriteIT'

ReadWriteIT.testReadWrite is still failing on Dataflow v2 [https://ci-beam.apache.org/job/beam_PostCommit_Java_DataflowV2/758/testReport/org.apache.beam.sdk.io.gcp.pubsublite/ReadWriteIT/testReadWrite/]

java.lang.AssertionError: Did not receive signal on projects/apache-beam-testing/subscriptions/result-subscription--5335365384640437489 in 300s

Looks like v1 is passing now, so we can close this.

I opened a new issue for v2: BEAM-13025

