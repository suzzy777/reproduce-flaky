I think one step we could take to make tests that utilize tracing less flaky is to add a system flag to make trace writes synchronous and at {{CL.ALL}} instead of async and {{CL.ANY}}.

Hmm, I tried this out and blocking on tracing in the write path seems to result in some sort of deadlock.  Since this test has only flapped once in a hundred runs, I'm not sure how much effort we want to invest in this right now.

The dtest has been marked flaky.  Since this test fails very rarely, and it's somewhat of a pain to fix, I'm going to label this ticket "flaky" and unassign myself for now.

Seems to be a regression in trunk of CASSANDRA-11465, the tracing doesn't use same consistency level as the request.
  trunk: https://builds.apache.org/view/A-D/view/Cassandra/job/Cassandra-trunk-dtest/856/testReport/junit/cql_tracing_test/TestCqlTracing/
  3.11: https://builds.apache.org/view/A-D/view/Cassandra/job/Cassandra-3.11-dtest/466/testReport/cql_tracing_test/TestCqlTracing/

My understanding is that tracing data was intended to be eventually consistent, and making it strictly consistency (via {{`-Dcassandra.wait_for_tracing_events_timeout_secs=xx`}}) was only for the purpose of testing. 

If that's true, a simple fix is just to reduce ccm nodes for that test, ie https://github.com/thelastpickle/cassandra-dtest/commit/f22f89fdb3080ac48f4310ee1a5aeb219ac2f093#diff-b866cba7cf982d53e6406cca014e659eR23

[~pauloricardomg], [~jkni], [~mambocab], thoughts? Is it worth bisecting where the regression came from? Or removing the {{wait_for_tracing_events_timeout_secs}} flag?

I've been able to reproduce the flakiness of the dtest along all of trunk since the {{cassandra-3.11}} was branched. This corresponds to the date of when this ticket was reported. Oddly though, we don't see the flakiness in ASF Jenkins anywhere except for against trunk. This could be because Cassandra 4.0 uses more resources per node than previous versions (getting a three node ccm working reliably in tests in circleci/travis/jenkens is considerably harder than it was in Cassandra 3.11 and before).

The bisecting i did used the following {{bisect.sh}} script and recipe.
The {{bisect.sh}} script:
{noformat}
#!/bin/bash
set -e
cd /home/mick/src/apache/cassandra
ant realclean
ant artifacts
cd /home/mick/src/apache/cassandra-dtest/
source ~/dtest/bin/activate
# iterate 20 times, making sure this flakey test works on this sha
for i in {0..19} ; do
  echo " ITERATION $i "
  python -m pytest --cassandra-dir=/home/mick/src/apache/cassandra cql_tracing_test.py
done
cd /home/mick/src/apache/cassandra
git stash
{noformat}
The execution:
{code}
git bisect start
git bisect bad
git bisect good `git log cassandra-3.11..trunk --oneline | tail -1 | cut -d' ' -f1`
git bisect run ./bisect.sh
{code}

#justfyi #collborating CASSANDRA-16073 is my take at trying to fix tracing test failures. Apologies I missed this ticket. I didn't go down the route of investigating mismatched CLs but found a few timeouts I could repro locally and a PR that fixes them. If we came to agreement that is good we could close this one

Closing as part of a batch operation on 2021-09-13 on all test tickets >= 52 weeks old. Please re-open if this is still a valid ticket.

