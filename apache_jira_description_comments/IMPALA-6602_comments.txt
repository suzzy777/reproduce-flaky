This could be a duplicate of IMPALA-6338.

Note that this test was modified recently, and also a new form of expiration was added. See commit ff3ddb51. cc:[~tarmstrong@cloudera.com]

Yeah this test is inherently timing-dependent. It may be that the tolerance is too low in some place here to be non-flaky.

My understanding of the code is that it should timeout after 6 seconds: https://gerrit.cloudera.org/#/c/9227/11/tests/custom_cluster/test_query_expiration.py@67

The assertion {{4==5}} has {{4}} as the client query state, which is {{FINISHED}} but expects {{5 = EXCEPTION}}.

Does this imply that the server did not bound the timeout correctly?

In looking at the logs a bit more, and comparing to the logs from a passing run, my most likely explanation is that there's a race between the metrics reaching the expected state (L100) and the client's query state being updated. Is there a polling interval in the client that updates this state?

...

I0302 23:05:36.582569 15766 impala-server.cc:1944] Expiring query due to client inactivity: c9406e1afa61ebc0:3d9e81d500000000, last activity was at: 2018-03-02 23:05:29.716
I0302 23:05:36.583142 15766 impala-server.cc:1944] Expiring query due to client inactivity: 604b87ba72de744f:83a9499d00000000, last activity was at: 2018-03-02 23:05:29.888
I0302 23:05:36.583230 15762 impala-server.cc:1098] Cancel(): query_id=c9406e1afa61ebc0:3d9e81d500000000
I0302 23:05:36.639046 15763 impala-server.cc:1098] Cancel(): query_id=604b87ba72de744f:83a9499d00000000
I0302 23:05:36.914713 15762 coordinator.cc:896] Cancel() query_id=c9406e1afa61ebc0:3d9e81d500000000
{color:#FF0000}I0302 23:05:37.034353 16473 impala-server.cc:1788] Connection from client 127.0.0.1:45589 closed, closing 1 associated session(s){color}
I0302 23:05:37.064713 15763 coordinator.cc:896] Cancel() query_id=604b87ba72de744f:83a9499d00000000

...

That "close" is from the failing assert on the second timeout query test case. I'm unclear when the client state should be expected to be updated.

Possible options here:
 * disable the test, its new
 * roll back the change
 * change how we wait on the expected client state-- should it be time-based, should we try looping several times, other options?
 * if the client state is supposed to be changed in sync with num-queries-expired, then debug that.

I guess it makes sense that the race is possible. The code is here:
{code}
void ImpalaServer::ExpireQuery(ClientRequestState* crs, const Status& status) {
  DCHECK(!status.ok());
  cancellation_thread_pool_->Offer(CancellationWork(crs->query_id(), status, false));
  ImpaladMetrics::NUM_QUERIES_EXPIRED->Increment(1L);
  crs->set_expired();
}
{code}

The cancellation happens asynchronously whereas the increment is synchronous. The window is probably pretty small given that we only poll the metric periodically and the cancellation should generally happen pretty quickly. Maybe the best option is "change how we wait on the expected client state-- should it be time-based, should we try looping several times, other options?"

Maybe we should move the metric increment to CancelFromThreadPool() after the cancel is actually called?

There are multiple reasons (I saw 3) for canceling from this thread pool, expiration (this case) is one of them. We could add a flag for the CancellationWork for this case, but it seems a little arbitrary.

What's our general direction in terms of syncing metrics and other internal state? While easier to test, I'm unclear if we always want to enforce it.

I think the flag already exists - the last parameter to CancellationWork(), but you're right it's not fine grained enough to distinguish between the MembershipCallback case and this one. So yeah, maybe not a great option.

Generally I agree we don't want to try to enforce it since metrics are inherently racy.  The only reason to do it in this case would be for testing, but I'm also fine with modifying the test instead to not make this assumption about the state being in sync with the metric.

Commit 1f573e08b8ab8ab84ad06555e6647e66970a0ab5 in impala's branch refs/heads/2.x from [~vercego]
[ https://git-wip-us.apache.org/repos/asf?p=impala.git;h=1f573e0 ]

IMPALA-6602: fixes flaky expiration test

The test_query_expiration test assumes that a metric and
the query state are maintained atomically. Since they're
not, occasionaly flakes (false negatives) occur.

The fix in this patch is to loop until the expected state
is seen. If the expected state is not seen with a given number
of iterations, the test fails. These tests depend on timing so
if this validation takes too long, the test will also fail.
Such looping is used in the two places where its assumed that the
client state and metrics are maintained atomically.

Change-Id: I7aabed87d84d5cfd8078cc6c39df48e22ff30afc
Reviewed-on: http://gerrit.cloudera.org:8080/9538
Reviewed-by: Tim Armstrong <tarmstrong@cloudera.com>
Tested-by: Impala Public Jenkins


Commit b50aaff399d8da368c992217d35d42083444357a in impala's branch refs/heads/master from [~vercego]
[ https://git-wip-us.apache.org/repos/asf?p=impala.git;h=b50aaff ]

IMPALA-6602: fixes flaky expiration test

The test_query_expiration test assumes that a metric and
the query state are maintained atomically. Since they're
not, occasionaly flakes (false negatives) occur.

The fix in this patch is to loop until the expected state
is seen. If the expected state is not seen with a given number
of iterations, the test fails. These tests depend on timing so
if this validation takes too long, the test will also fail.
Such looping is used in the two places where its assumed that the
client state and metrics are maintained atomically.

Change-Id: I7aabed87d84d5cfd8078cc6c39df48e22ff30afc
Reviewed-on: http://gerrit.cloudera.org:8080/9538
Reviewed-by: Tim Armstrong <tarmstrong@cloudera.com>
Tested-by: Impala Public Jenkins


[~vukercegovac] - Should the Fix Version be 2.12?

yes, updated.

