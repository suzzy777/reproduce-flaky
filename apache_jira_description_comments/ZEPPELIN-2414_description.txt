When using scoped mode of SparkInterpreter, after several repetitions of these three steps (create-notebook -> run a paragraph -> remove-notebook), the occupation rate of RemoteInterpreterServer process heap will grow to 100% rapidly.

For example, in my local environment, RemoteInpreterServer's max heap size is 2 GB. After I repeatedly run a simple paragrah
{quote}%spark 
sc{quote}
15 times (each time in a new notebook and delete the notebook after running), RemoteInpreterServer's heap has no more free space and the 15th execution of the paragrah was never finished.

heap occupation:
{quote}
  S0     S1     E      O      P     YGC     YGCT    FGC    FGCT     GCT   
  0.00   0.00 100.00  99.98  49.38     19    2.304  1093  798.293  800.597
{quote}
