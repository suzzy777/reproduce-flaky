review here: https://reviews.apache.org/r/8629/

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12561212/HBASE-7365-v0.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified tests.

    {color:green}+1 hadoop2.0{color}.  The patch compiles against the hadoop 2.0 profile.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any additional warning messages.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 26 new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

     {color:red}-1 core tests{color}.  The patch failed these unit tests:
     

     {color:red}-1 core zombie tests{color}.  There are zombie tests. See build logs for details.

Test results: https://builds.apache.org/job/PreCommit-HBASE-Build/3567//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3567//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3567//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3567//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3567//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3567//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3567//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3567//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html
Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/3567//console

This message is automatically generated.

Makes sense doing stuff in .tmp (which mirrors table .tmp and region .tmp).

In below... the archive tool will be able to make sense of the deleted table?


+    if (fs.exists(tmpdir)) {
+      // Archive table in temp, maybe are failed deletion left over,
+      // if not the cleaner will take care of them.
+      for (Path tabledir: FSUtils.getTableDirs(fs, tmpdir)) {
+        for (Path regiondir: FSUtils.getRegionDirs(fs, tabledir)) {
+          HFileArchiver.archiveRegion(fs, this.rootdir, tabledir, regiondir);
+        }
+      }
+      fs.delete(tmpdir, true);


Do you want to check the returned value on the above delete?


Why not call checkTempDir rather than do this?

+    // Ensure temp exists
+    if (!fs.exists(tempdir) && !fs.mkdirs(tempdir)) {
+      throw new IOException("HBase temp directory '" + tempdir + "' creation failure.");


I love it when TODOs get cleaned up...

-    // TODO: Currently we make the table descriptor and as side-effect the
-    // tableDir is created.  Should we change below method to be createTable
-    // where we create table in tmp dir with its table descriptor file and then
-    // do rename to move it into place?


Should we remove the old handleCreateTable now we have your fancy new one?  Or is it still used?


Patch looks good otherwise Matteo.

{quote}
In below... the archive tool will be able to make sense of the deleted table?
{quote}
Not sure what you mean here, if is something like "can you move that in the archiver?"
or is more like "does it works?"

Basically the archiver just takes the specified region folder in the tabledir and
move it in the rootdir/.archive (not sure why the fancy 2 path arg for tabledir and regiondir)
In reality the move is done file by file... but this is another story...

{quote}
Why not call checkTempDir rather than do this?
{quote}
checkTempDir() does another job, that is more like initTempDir() that means create or cleaning it if exists.
In this case we don't want to clean it. What do you think? keep the code as is? rename the checkTempDir() in initTempDir() and create the checkTempDir() that only creates the directory?

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12563152/HBASE-7365-v1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified tests.

    {color:green}+1 hadoop2.0{color}.  The patch compiles against the hadoop 2.0 profile.

    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated 2 warning messages.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 lineLengths{color}.  The patch introduces lines longer than 100

     {color:red}-1 core tests{color}.  The patch failed these unit tests:
                       org.apache.hadoop.hbase.regionserver.TestMultiColumnScanner
                  org.apache.hadoop.hbase.security.access.TestTablePermissions
                  org.apache.hadoop.hbase.replication.TestMultiSlaveReplication
                  org.apache.hadoop.hbase.regionserver.TestStoreFileBlockCacheSummary
                  org.apache.hadoop.hbase.TestMultiVersions
                  org.apache.hadoop.hbase.security.token.TestZKSecretWatcher
                  org.apache.hadoop.hbase.regionserver.wal.TestLogRollAbort
                  org.apache.hadoop.hbase.regionserver.handler.TestOpenRegionHandler
                  org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster
                  org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoad
                  org.apache.hadoop.hbase.regionserver.handler.TestCloseRegionHandler
                  org.apache.hadoop.hbase.replication.regionserver.TestReplicationSink
                  org.apache.hadoop.hbase.regionserver.TestPriorityRpc
                  org.apache.hadoop.hbase.regionserver.TestStore
                  org.apache.hadoop.hbase.replication.TestReplicationWithCompression
                  org.apache.hadoop.hbase.TestFullLogReconstruction
                  org.apache.hadoop.hbase.security.token.TestTokenAuthentication
                  org.apache.hadoop.hbase.regionserver.wal.TestHLog
                  org.apache.hadoop.hbase.regionserver.TestHRegionOnCluster
                  org.apache.hadoop.hbase.replication.TestReplication
                  org.apache.hadoop.hbase.client.TestClientScannerRPCTimeout
                  org.apache.hadoop.hbase.trace.TestHTraceHooks
                  org.apache.hadoop.hbase.regionserver.TestHRegionBusyWait
                  org.apache.hadoop.hbase.regionserver.TestClusterId
                  org.apache.hadoop.hbase.regionserver.wal.TestLogRolling
                  org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster
                  org.apache.hadoop.hbase.regionserver.TestHRegion
                  org.apache.hadoop.hbase.TestHBaseTestingUtility
                  org.apache.hadoop.hbase.regionserver.TestParallelPut

     {color:red}-1 core zombie tests{color}.  There are 16 zombie test(s): 	at org.apache.hadoop.hbase.master.TestOpenedRegionHandler.testOpenedRegionHandlerOnMasterRestart(TestOpenedRegionHandler.java:104)
	at org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.testFromClientSideWhileSplitting(TestEndToEndSplitTransaction.java:180)
	at org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.testEmptyOpenLogFiles(TestHLogSplit.java:435)

Test results: https://builds.apache.org/job/PreCommit-HBASE-Build/3836//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3836//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3836//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3836//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3836//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3836//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3836//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3836//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html
Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/3836//console

This message is automatically generated.

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12564298/HBASE-7365-v2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified tests.

    {color:green}+1 hadoop2.0{color}.  The patch compiles against the hadoop 2.0 profile.

    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated 2 warning messages.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 lineLengths{color}.  The patch introduces lines longer than 100

     {color:red}-1 core tests{color}.  The patch failed these unit tests:
                       org.apache.hadoop.hbase.replication.TestReplicationWithCompression

Test results: https://builds.apache.org/job/PreCommit-HBASE-Build/3969//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3969//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3969//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3969//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3969//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3969//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3969//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3969//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html
Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/3969//console

This message is automatically generated.

bq. ...more like "does it works?"

It was more the above.  Archiver will be able to deal w/ tables and regions over in tmp dir?  Sounds like it can so I have answer for my question.

bq.  What do you think? keep the code as is? rename the checkTempDir() in initTempDir() and create the checkTempDir() that only creates the directory?

What you suggest sounds like some nice clean up.  If it is too much to do, don't bother (You have enough on your plate at moment).


v3 fixes javadoc and lineLength issue

+1 for trunk.  No harm letting hadoopqa have a go at v3 before commit.

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12564368/HBASE-7365-v3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified tests.

    {color:green}+1 hadoop2.0{color}.  The patch compiles against the hadoop 2.0 profile.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 lineLengths{color}.  The patch does not introduce lines longer than 100

     {color:red}-1 core tests{color}.  The patch failed these unit tests:
                       org.apache.hadoop.hbase.TestLocalHBaseCluster

     {color:red}-1 core zombie tests{color}.  There are 2 zombie test(s): 	at org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup.testBalancerWithRackLocality(TestBalancerWithNodeGroup.java:220)

Test results: https://builds.apache.org/job/PreCommit-HBASE-Build/3978//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3978//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3978//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3978//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3978//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3978//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3978//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/3978//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html
Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/3978//console

This message is automatically generated.

admin.deleteTable() relies on the fact that the descriptor removal is the last operation, so moving to the .tmp directory archiving can't be done at the end.

Any idea why this worked in the snapshot branch and why it is now flakey in 2/1/13's trunk?  (I'm investigating now)

Patch v4 is rebased on trunk.

I'm -1 on this patch at the moment (at least for the Delete handler), 
as per my previous comment, until we have a proper way to handle async operations we cannot change the handler code. The client heavily relies on implementation assumptions.

{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12567956/7365-v4.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified tests.

    {color:green}+1 hadoop2.0{color}.  The patch compiles against the hadoop 2.0 profile.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 lineLengths{color}.  The patch does not introduce lines longer than 100

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HBASE-Build/4327//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/4327//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/4327//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/4327//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/4327//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/4327//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/4327//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html
Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/4327//console

This message is automatically generated.

Looked at the code,  Master-side DeleteTableHandler does the following steps:

# wait for related RITs to resolve
# delete entries from META
# mv table to /hbase/.tmp
# archive regions in /hbase/.tmp
# delete .tmp delete table dir
# update master table desc cache
# rm AM's zk entry (is this always present?).

HBaseAdmin waits for: 
# table meta entries to be deleted
# HMaster.getTableDescriptors file to be deleted

Matteo says the problem seems to be that the HMaster.getTableDescriptors looks at the hdfs and file is "deleted" when move hdfs table data to .tmp.  (Thi sseems to say the table returns as deleted before the .tmp stuff and ZK stuff is cleaned up.

Look like we could:

# use the same steps but check the .tmp dir for the tableinfo descriptor?  We could add a getDeletingTableDescriptors method (that checks the .tmp delete dir) so the HBaseAdmin can poll and waits until it is gone, or trigger on when the .tmp delete table dir is gone.
# use the AM's setDeletedTable/getDeletedTable znode as the last set? (need to look into this more)
# Move table to temp before deleting from meta?

Not sure about the 3rd point? how should that work? the problem is that once you've moved to .tmp for the client you're done, but you're still archiving files. And there's a test that relies on the deleteTable() to be sync and check for the files to be archived.

I prefer the 2nd one because I don't like adding to another place the fancy double check original + temp only because we have a bad fs layout. Also the client already communicate with zookeeper for other operations (e.g. -ROOT-).

Option #2 should work, until HBASE-7767 gets rid of ZKTable :-)

Ok, a simple workaround is updating the descriptor cache before moving to temp, so the next calls from the client are from the cache and not from disk...

but since we're rewriting the RPC, we should include a proper handling for the async operations. [~saint.ack@gmail.com] any ideas?

There still is a race where the descriptor cache may get reloaded if between the cache remove and he table rename.  probably need to remove again right afterwards.  I'll tweak and test for the short term.  I think changing the rpcs to have consistent semantics for async calls is a problem bigger than this guy's scope currently.

So I tried [~mbertozzi]'s approach (cache removal earlier) it it incurs a problem with coprocs -- delete completes before the (expected postdeletetablehandler fires), and the archiver test (files not moved yet)

org.apache.hadoop.hbase.coprocessor.TestMasterObserver.testTableOperations 
org.apache.hadoop.hbase.backup.TestHFileArchiving.testArchiveOnTableDelete 

I think it really boils down to picking which event is the "completion" event.  I'd expect all coprocs to be complete before we return so I think we need to move this event to after the post deletetablehandler coproc call.  I like having the cache invalidation be the event, but it breaks some other snapshot restore/clone tests. 

In the current implementation the clone call waits until after the newly created table isTableEnabled.  However there is another state (apparently orthogonal) that a newly created table is assumed to be -- isTableAvailable (all regions assigned).  The logic for checking after table creation and after clone creation are slightly different -- creation  does the equivalent of isTableAvailable but clone does not check this availability condition.  

This causes flaky failures in tests that quickly try to use/delete a newly cloned table.

TestRestoreSnapshotFromClient#testCloneSnapshot
TestRestoreFlushSnapshotFromCleitn#testCloneSnapshot

I believe there also are race conditions because of the postTableCreateHandler corpco and postTableDeleteHandler coproc hooks.

I'm going to file the fix to this problem as a new issue.  Since this patch has laned in the snapshot branch and not landed on trunk yet, I'm going to suggest we close this issue as a subissue of the snapshot branch.

Moved to be a subissue of hbase-6055 since it is committed there and resolving.

Marking closed.

