GitHub user hsun-cnnxty opened a pull request:

    https://github.com/apache/storm/pull/728

    [STORM-1038] Upgraded netty to 4.x

    Upgraded the netty transportation layer to 4.x to take advantage of its memory management efficiency.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hsun-cnnxty/storm netty-4

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/storm/pull/728.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #728
    
----
commit ec785930ec2c5b5730a4ec1446642fbe684e6711
Author: Hang Sun <hsun@shopzilla.com>
Date:   2015-09-09T05:46:17Z

    Migrated netty to 4.x

----


Github user HeartSaVioR commented on the pull request:

    https://github.com/apache/storm/pull/728#issuecomment-139122346
  
    @hsun-cnnxty 
    Great work. Since it can affect performance I recommend you to include benchmark test result.
    You can refer #521 (comment) to how to do it.


Github user HeartSaVioR commented on the pull request:

    https://github.com/apache/storm/pull/728#issuecomment-139122864
  
    @hsun-cnnxty 
    Btw, Netty 4.0.31 was released 8 days ago, so we may also want to check this out to test it works.
    And we'd like to see memory usages with Netty 3.x / 4.x to confirm 4.x is superior to 3.x.


Github user hsun-cnnxty commented on the pull request:

    https://github.com/apache/storm/pull/728#issuecomment-139123790
  
    Good suggestion. I will get to work on them as soon as I get some time.  I am also curious to verify the memory efficiency claimed by 4.x


Github user hsun-cnnxty commented on the pull request:

    https://github.com/apache/storm/pull/728#issuecomment-141744079
  
    Upgraded to latest 4.0.31.Final and changed the buffer allocation to lett netty choose the best default based on the platform.


Github user revans2 commented on the pull request:

    https://github.com/apache/storm/pull/728#issuecomment-145253788
  
    @hsun-cnnxty, The changes look good to me.  Please upmerge to the latest code.  Then I would like to run some performance tests on it to see how it compares to the current code.  Please also look at shading.  In storm-core we are shading netty now, and I would like to be sure that it is still shaded correctly.
    
    If you have any questions on how to do this please let me know and I will be happy to help out.


Github user hsun-cnnxty commented on the pull request:

    https://github.com/apache/storm/pull/728#issuecomment-145318156
  
    @revans2, just merged with the latest master.  I don't have a decent storm cluster for performance test.  With a small local cluster on single machine.   I had tried https://github.com/yahoo/storm-perf-test and did not see any difference in memory consumption after the upgrade (It was configured in a way to make sure there is inter-worker communication using Netty).  Hope your test can reveal more information.
    
    -thanks  
    



Github user rfarivar commented on a diff in the pull request:

    https://github.com/apache/storm/pull/728#discussion_r47586615
  
    --- Diff: storm-core/src/jvm/backtype/storm/messaging/netty/Client.java ---
    @@ -23,24 +23,17 @@
     import backtype.storm.metric.api.IStatefulObject;
     import backtype.storm.utils.StormBoundedExponentialBackoffRetry;
     import backtype.storm.utils.Utils;
    -import org.jboss.netty.bootstrap.ClientBootstrap;
    -import org.jboss.netty.channel.Channel;
    -import org.jboss.netty.channel.ChannelFactory;
    -import org.jboss.netty.channel.ChannelFuture;
    -import org.jboss.netty.channel.ChannelFutureListener;
    -import org.jboss.netty.util.HashedWheelTimer;
    -import org.jboss.netty.util.Timeout;
    -import org.jboss.netty.util.TimerTask;
    +import io.netty.bootstrap.Bootstrap;
    +import io.netty.channel.*;
    --- End diff --
    
    Could you please expand the imports?
    
    Also below. 


Github user rfarivar commented on a diff in the pull request:

    https://github.com/apache/storm/pull/728#discussion_r47586629
  
    --- Diff: storm-core/src/jvm/backtype/storm/messaging/netty/Client.java ---
    @@ -23,24 +23,17 @@
     import backtype.storm.metric.api.IStatefulObject;
     import backtype.storm.utils.StormBoundedExponentialBackoffRetry;
     import backtype.storm.utils.Utils;
    -import org.jboss.netty.bootstrap.ClientBootstrap;
    -import org.jboss.netty.channel.Channel;
    -import org.jboss.netty.channel.ChannelFactory;
    -import org.jboss.netty.channel.ChannelFuture;
    -import org.jboss.netty.channel.ChannelFutureListener;
    -import org.jboss.netty.util.HashedWheelTimer;
    -import org.jboss.netty.util.Timeout;
    -import org.jboss.netty.util.TimerTask;
    +import io.netty.bootstrap.Bootstrap;
    +import io.netty.channel.*;
    +import io.netty.channel.socket.nio.NioSocketChannel;
    +import io.netty.util.*;
    +import io.netty.util.TimerTask;
     import org.slf4j.Logger;
     import org.slf4j.LoggerFactory;
     
     import java.net.InetSocketAddress;
     import java.net.SocketAddress;
    -import java.util.ArrayList;
    -import java.util.HashMap;
    -import java.util.Iterator;
    -import java.util.List;
    -import java.util.Map;
    +import java.util.*;
    --- End diff --
    
    Expand import


Github user rfarivar commented on a diff in the pull request:

    https://github.com/apache/storm/pull/728#discussion_r47586860
  
    --- Diff: storm-core/src/jvm/backtype/storm/messaging/netty/Client.java ---
    @@ -182,7 +177,7 @@ private boolean connectionEstablished(Channel channel) {
             // See:
             // - http://netty.io/3.9/api/org/jboss/netty/channel/ChannelEvent.html
             // - http://stackoverflow.com/questions/13356622/what-are-the-netty-channel-state-transitions
    -        return channel != null && channel.isConnected();
    +        return channel != null && channel.isOpen();
    --- End diff --
    
    Why the change from connected to open? the channel could be open, but not yet in the connected state, and this could cause a bug.
    
    Unless Netty 4 has changed the model....


Github user hsun-cnnxty commented on a diff in the pull request:

    https://github.com/apache/storm/pull/728#discussion_r47597958
  
    --- Diff: storm-core/src/jvm/backtype/storm/messaging/netty/Client.java ---
    @@ -182,7 +177,7 @@ private boolean connectionEstablished(Channel channel) {
             // See:
             // - http://netty.io/3.9/api/org/jboss/netty/channel/ChannelEvent.html
             // - http://stackoverflow.com/questions/13356622/what-are-the-netty-channel-state-transitions
    -        return channel != null && channel.isConnected();
    +        return channel != null && channel.isOpen();
    --- End diff --
    
    Thanks for the code review. It could be a bug. Netty 4.x has simplified the state model. See 
    
    http://netty.io/wiki/new-and-noteworthy-in-4.0.html#wiki-h4-19  
    
    So channelOpen, channelBound, and channelConnected have been merged to channelActive and Channel.isBound() and isConnected() have been merged to isActive().  The isConnected() method is removed.  I think I should use isActive() instead of isOpen().  The code comments need update too.  I will fix it and other format issues this weekend if I get time.
    



Github user revans2 commented on a diff in the pull request:

    https://github.com/apache/storm/pull/728#discussion_r49227072
  
    --- Diff: storm-core/src/jvm/backtype/storm/messaging/netty/ISaslClient.java ---
    @@ -17,11 +17,9 @@
      */
     package backtype.storm.messaging.netty;
     
    -import org.jboss.netty.channel.Channel;
    -import backtype.storm.Config;
    -
     public interface ISaslClient {
    -    void channelConnected(Channel channel);
    +
    +    // void channelConnected(Channel channel);
    --- End diff --
    
    If this is not needed we should remove it, not comment it out.


Github user revans2 commented on a diff in the pull request:

    https://github.com/apache/storm/pull/728#discussion_r49227209
  
    --- Diff: storm-core/src/jvm/backtype/storm/messaging/netty/KerberosSaslClientHandler.java ---
    @@ -46,56 +44,48 @@ public KerberosSaslClientHandler(ISaslClient client, Map storm_conf, String jaas
         }
     
         @Override
    -    public void channelConnected(ChannelHandlerContext ctx,
    -                                 ChannelStateEvent event) {
    +    public void channelActive(ChannelHandlerContext ctx) throws Exception {
             // register the newly established channel
    -        Channel channel = ctx.getChannel();
    -        client.channelConnected(channel);
    +        Channel channel = ctx.channel();
    +        client.channelReady();
     
             LOG.info("Connection established from {} to {}",
    -                 channel.getLocalAddress(), channel.getRemoteAddress());
    +                 channel.localAddress(), channel.localAddress());
    --- End diff --
    
    I don't think channel.getRemoteAddress and channel.localAddress return the same thing.


Github user revans2 commented on a diff in the pull request:

    https://github.com/apache/storm/pull/728#discussion_r49227426
  
    --- Diff: storm-core/src/jvm/backtype/storm/messaging/netty/NettyUncaughtExceptionHandler.java ---
    @@ -21,6 +21,24 @@
     import org.slf4j.Logger;
     import org.slf4j.LoggerFactory;
     
    +/*
    +public class StormClientErrorHandler extends ChannelInboundHandlerAdapter {
    +    private static final Logger LOG = LoggerFactory.getLogger(StormClientErrorHandler.class);
    +    private String name;
    +
    +    StormClientErrorHandler(String name) {
    +        this.name = name;
    +    }
    +
    +    @Override
    +    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
    +        if (!(cause instanceof ConnectException)) {
    +            LOG.info("Connection failed " + name, cause);
    +        }
    +    }
    +}
    +*/
    +
    --- End diff --
    
    We should delete this commented out code.


Github user revans2 commented on the pull request:

    https://github.com/apache/storm/pull/728#issuecomment-170100773
  
    Everything looks really good now.  just a few minor nits.  I still have not found time to run some performance tests, but I will try to do that today.


Github user revans2 commented on the pull request:

    https://github.com/apache/storm/pull/728#issuecomment-170145276
  
    I just ran some performance tests using https://github.com/apache/storm/blob/master/examples/storm-starter/src/jvm/storm/starter/ThroughputVsLatency.java
    
    I ran with 4 workers on a MacBookPro and the numbers don't look good for netty4.
    
    With the older code I was able to do 20,000 sentences/second at 
    99%-ile:      43 ms 
    99.9%-ile:      99 ms
    min:       8.8 ms
    max:     177 ms
    mean:   16 ms
    
    CPU Utilization over 30 second interval:
    user:    159,718 ms
    sys:     49,670 ms
    
    But with the netty4 patch it could only handle 17,000/sec and the latency was much worse
    99%-lie:     148 ms
    99.9%-lie:     230 ms
    min:       9.2 ms
    max:     332 ms
    mean:   32 ms
    
    CPU:
    user:    162,984 ms
    sys:     55,867 ms
    
    To have the netty4 patch have similar latency we needed to only run at 14,000 sentences per second.
    
    99%-lie:      38 ms
    99.9%-lie:      55 ms
    min:       8.8 ms
    max:      76 ms
    mean:   16 ms
    
    CPU:
    user:    152,865 ms
    sys:     52,535 ms
    
    Unless we can get the numbers to be close to or better than the netty3 implementation I cannot let this in.


Github user hsun-cnnxty commented on the pull request:

    https://github.com/apache/storm/pull/728#issuecomment-170147036
  
    Cool, at least we get some numbers to compare. I will see if there is default setting need to be changed for netty 4.


Github user revans2 commented on the pull request:

    https://github.com/apache/storm/pull/728#issuecomment-170149708
  
    @hsun-cnnxty I hope it is something like that.  You should be able to run the tests yourself too.  They are not that complex.  I build
    
    ```
    mvn clean install -DskipTests
    cd storm-dist/binary
    mvn clean package
    tar -xzvf ./target/apache-storm-0.11.0-SNAPSHOT.tar.gz
    cd apache-storm-0.11.0-SNAPSHOT
    ```
    
    I then run a small single node cluster
    ```
    ./bin/storm dev-zookeeper &
    ./bin/storm nimbus &
    ./bin/storm supervisor &
    ./bin/storm ui &
    ./bin/storm logviewer &
    ```
    
    Once it is all up and ready you can run the test.
    ```
    ./bin/storm jar ./examples/storm-starter/storm-starter-topologies-0.11.0-SNAPSHOT.jar storm.starter.ThroughputVsLatency $THROUGHPUT 4 5 wc-test | tee results.txt
    ```
    
    It will output metrics about the running test every 30 seconds for 5 mins.  Some of the numbers are in nanoseconds and others are in milliseconds so pay attention to them.  I like to vary the throughput and look to see when it cannot keep up any more to get an idea of the maximum throughput the setup can handle, and what the latency is for a given throughput so we can see how they compare to each other.


Github user harshach commented on a diff in the pull request:

    https://github.com/apache/storm/pull/728#discussion_r49248827
  
    --- Diff: storm-core/src/jvm/backtype/storm/messaging/netty/Client.java ---
    @@ -17,41 +17,31 @@
      */
     package backtype.storm.messaging.netty;
     
    -import java.net.InetSocketAddress;
    -import java.net.SocketAddress;
    -import java.util.Iterator;
    -import java.util.Collection;
    -import java.util.Map;
    -import java.util.HashMap;
    -import java.util.concurrent.atomic.AtomicBoolean;
    -import java.util.concurrent.atomic.AtomicInteger;
    -import java.util.concurrent.atomic.AtomicReference;
    -import java.lang.InterruptedException;
    -
     import backtype.storm.Config;
     import backtype.storm.grouping.Load;
     import backtype.storm.messaging.ConnectionWithStatus;
    -import backtype.storm.messaging.TaskMessage;
     import backtype.storm.messaging.IConnectionCallback;
    +import backtype.storm.messaging.TaskMessage;
     import backtype.storm.metric.api.IStatefulObject;
     import backtype.storm.utils.StormBoundedExponentialBackoffRetry;
     import backtype.storm.utils.Utils;
    -import org.jboss.netty.bootstrap.ClientBootstrap;
    -import org.jboss.netty.channel.Channel;
    -import org.jboss.netty.channel.ChannelFactory;
    -import org.jboss.netty.channel.ChannelFuture;
    -import org.jboss.netty.channel.ChannelFutureListener;
    -import org.jboss.netty.util.HashedWheelTimer;
    -import org.jboss.netty.util.Timeout;
    -import org.jboss.netty.util.TimerTask;
    +import io.netty.bootstrap.Bootstrap;
    +import io.netty.channel.*;
    +import io.netty.channel.socket.nio.NioSocketChannel;
    +import io.netty.util.HashedWheelTimer;
    +import io.netty.util.Timeout;
    +import io.netty.util.TimerTask;
     import org.slf4j.Logger;
     import org.slf4j.LoggerFactory;
     
    -
    -import java.util.ArrayList;
    -import java.util.List;
    +import java.net.InetSocketAddress;
    +import java.net.SocketAddress;
    +import java.util.*;
    --- End diff --
    
    please remove wildcard and import the packages you needed


Github user darionyaphet commented on the pull request:

    https://github.com/apache/storm/pull/728#issuecomment-170354259
  
    mark 


Github user hsun-cnnxty commented on the pull request:

    https://github.com/apache/storm/pull/728#issuecomment-173483216
  
    With some refactoring, now it can sustain throughput of 20,000 /sec  which it was not able to before.  But latency at 20,000 /sec is still much higher than 3.x (5+ times).  I will continue to investigate.


Github user hsun-cnnxty commented on the pull request:

    https://github.com/apache/storm/pull/728#issuecomment-188640434
  
    @revans2 
    
    Just merged code from master and seems there is performance degradation with recent changes.  I noticed that it not only affects this branch, but also the master branch.  Here are the comparison on my laptop for running the perf test with only 5,000/sec throughput with code from master.
    
    Before (git hash: 3db968092077363bd766db516b9e1135273672bf)
    [netty3-r5000.txt](https://github.com/apache/storm/files/146057/netty3-r5000.txt)
    
    Now (git hash: bd396b3a4ec0c242f18725ddf43e35f26da51269)
    [netty3-new-r5000.txt](https://github.com/apache/storm/files/146058/netty3-new-r5000.txt)
    
    Note: when running the latest code, my CPU is almost 100% busy which may explain why it was so much worse.  When running the "old" code, my CPU still had 10% idle time.
    
    
    -thanks
    
    
    
    
      


Github user revans2 commented on the pull request:

    https://github.com/apache/storm/pull/728#issuecomment-188822872
  
    Yes I am aware of it.  We are in the process of merging with the JStorm project, and part of this merger involves moving most of the clojure code to java.  In all likelihood the degradation is due to reflection happening on the critical path because many new places in the code are calling into java that were not doing so before.  I plan on doing some profiling soon and submit some fixes, but it is very much a moving target so I have not been very motivated to do so.  The code for the netty messaging layer should stay mostly the same between 1.0 and 2.0 for this, so if you want to do your work based off of the 1.0 branch and show performance comparisons there being the same I would totally accept that as proof that the code is good.
     - Bobby 
    
        On Thursday, February 25, 2016 12:53 AM, Sun <notifications@github.com> wrote:
     
    
     @revans2 Just merged code from master and seems there is performance degradation with recent changes. I noticed that it not only affects this branch, but also the master branch. Here are the comparison on my laptop for running the perf test with only 5,000/sec throughput with code from master.Before (git hash: 3db9680)
    netty3-r5000.txtNow (git hash: bd396b3)
    netty3-new-r5000.txtNote: when running the latest code, my CPU is almost 100% busy which may explain why it was so much worse. When running the "old" code, my CPU still had 10% idle time.-thanks—
    Reply to this email directly or view it on GitHub.  
    
      


Github user harshach commented on the issue:

    https://github.com/apache/storm/pull/728
  
    @hsun-cnnxty we would like to get this into 1.x-branch as well as master. Did you get a chance to look at @revans2 comment above . It will be great if you can address the comment and up merge your patch.


Github user hsun-cnnxty commented on the issue:

    https://github.com/apache/storm/pull/728
  
    I am currently on vacation and will be back in two weeks.  Will work on it as soon as I am back home.
    
    -thanks


Github user HeartSaVioR commented on the issue:

    https://github.com/apache/storm/pull/728
  
    After rebasing, could you do the performance test against 1.x branch? The status of master branch is a  WIP so we would be more convenient with 1.x branch.


Github user hsun-cnnxty commented on the issue:

    https://github.com/apache/storm/pull/728
  
    Sure.


GitHub user hsun-cnnxty opened a pull request:

    https://github.com/apache/storm/pull/1591

    STORM-1038: Upgrade netty to 4.x in 1.x-branch

    This is to add the feature to 1.x-branch.  The original PR for master branch is #728.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hsun-cnnxty/storm 1.x-branch-netty4

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/storm/pull/1591.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1591
    
----
commit 57fbccc7e0d710ccaf04a5a828f0ff4cf29ec855
Author: Hang Sun <hsun@connexity.com>
Date:   2016-07-25T22:30:54Z

    STORM-1038: Upgraded netty to 4.x

----


Github user hsun-cnnxty commented on the issue:

    https://github.com/apache/storm/pull/728
  
    As this PR is for master,  new PR #1591 is created for 1.x-branch.  Performance tests to be done soon.


Github user hsun-cnnxty commented on the issue:

    https://github.com/apache/storm/pull/1591
  
    Performance test results are attached here.  
    [perf_compare_netty_3vs4_1.x-branch.zip](https://github.com/apache/storm/files/392165/perf_compare_netty_3vs4_1.x-branch.zip)
    
    Baseline: current head of 1.x-branch (e55684b164fe99823a4ae3562b62867a26aaba97)
    Netty4:   57fbccc7e0d710ccaf04a5a828f0ff4cf29ec855
    
    In addition to default configuration, 
    io.netty.noPreferDirect=false
    io.netty.allocator.type=pooled
    
    following configurations are also tested for netty 4.x
    
    -unpool
    io.netty.allocator.type=unpooled. Ask Netty to not use pooled allocation for buffer
    
    -nodirect
    io.netty.noPreferDirect=true.  Ask Netty to not use off-heap buffer allocation
    
    -unpool-nodirect
    io.netty.noPreferDirect=true
    io.netty.allocator.type=unpooled
    
    Due to the capacity of my laptop, I tested following loads: 2k, 5k, 10k.  At 10k, the CPU usage reaches above 85% and failures started to appear at startup. 
    
    The performance data seems to suggest
    - no big difference is observed comparing before/after netty upgrades
    I suspect only a small percentage of traffic will cross worker instances (jvm) so Netty does not play a big role in performance measured
    
    - netty 4.x consumes a little more CPU and memory
    The small memory increment may be simply b/c netty 4.x pulled in more classes.
    
    - netty 4.x has lower CPU consumption on GC
    This is especially visible with the default configuration where off-heap buffer allocation is used.
    
     
    
    
    
    
    
    



Github user hsun-cnnxty commented on the issue:

    https://github.com/apache/storm/pull/728
  
    @HeartSaVioR @harshach 
    
    I posted performance test results on  #1591.


Github user hsun-cnnxty commented on the issue:

    https://github.com/apache/storm/pull/1591
  
    Seems the Travis CI build will fail at random places which are not related to this PR.
    
    For example the last build failed due to
    
    `[ERROR] Failed to execute goal org.apache.maven.plugins:maven-remote-resources-plugin:1.2.1:process (default) on project flux-examples: Error resolving project artifact: Could not transfer artifact io.confluent:kafka-schema-registry-client:pom:1.0 from/to sonatype-apache (https://repository.apache.org/releases/): Connect to repository.apache.org:443 [repository.apache.org/207.244.88.143] failed: Connection timed out for project io.confluent:kafka-schema-registry-client:jar:1.0 -> [Help 1]
    `
    
    Any way to manually trigger a new CI build w/o code change?
    
    -thanks


Github user HeartSaVioR commented on the issue:

    https://github.com/apache/storm/pull/1591
  
    You can close and reopen this PR to retrigger. Btw, apache repository seems to be unstable recent days. I saw other build failures due to repository connectivity issue.


Github user satishd commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1591#discussion_r73129527
  
    --- Diff: storm-core/src/jvm/org/apache/storm/messaging/netty/KerberosSaslClientHandler.java ---
    @@ -46,56 +44,48 @@ public KerberosSaslClientHandler(ISaslClient client, Map storm_conf, String jaas
         }
     
         @Override
    -    public void channelConnected(ChannelHandlerContext ctx,
    -                                 ChannelStateEvent event) {
    +    public void channelActive(ChannelHandlerContext ctx) throws Exception {
             // register the newly established channel
    -        Channel channel = ctx.getChannel();
    -        client.channelConnected(channel);
    +        Channel channel = ctx.channel();
    +        client.channelReady();
     
             LOG.info("Connection established from {} to {}",
    -                 channel.getLocalAddress(), channel.getRemoteAddress());
    +                 channel.localAddress(), channel.remoteAddress());
     
             try {
    -            KerberosSaslNettyClient saslNettyClient = KerberosSaslNettyClientState.getKerberosSaslNettyClient
    -                .get(channel);
    +            KerberosSaslNettyClient saslNettyClient = channel.attr(KerberosSaslNettyClientState.KERBEROS_SASL_NETTY_CLIENT).get();
     
                 if (saslNettyClient == null) {
                     LOG.debug("Creating saslNettyClient now for channel: {}",
                               channel);
                     saslNettyClient = new KerberosSaslNettyClient(storm_conf, jaas_section);
    -                KerberosSaslNettyClientState.getKerberosSaslNettyClient.set(channel,
    -                                                                            saslNettyClient);
    +                channel.attr(KerberosSaslNettyClientState.KERBEROS_SASL_NETTY_CLIENT).set(saslNettyClient);
                 }
                 LOG.debug("Going to initiate Kerberos negotiations.");
                 byte[] initialChallenge = saslNettyClient.saslResponse(new SaslMessageToken(new byte[0]));
                 LOG.debug("Sending initial challenge: {}", initialChallenge);
    -            channel.write(new SaslMessageToken(initialChallenge));
    +            channel.writeAndFlush(new SaslMessageToken(initialChallenge));
    --- End diff --
    
    Why is it changed to use `writeAndFlush`? 


Github user satishd commented on the issue:

    https://github.com/apache/storm/pull/1591
  
    @hsun-cnnxty `Channel#write` is modified to `Channel#writeAndFlush` at multiple places. Does not that flush to the underlying stream without buffering and flush it when buffers are full?


Github user hsun-cnnxty commented on the issue:

    https://github.com/apache/storm/pull/1591
  
    @satishd nett 4.x has removed auto-flush in write() and it requires user to explicitly call flush() or writeAndFlush(), so we need to flush for the last message in the logic flow. Fortunately,  the storm netty client does batching of messages itself and it does not flush for every message.


Github user hsun-cnnxty closed the pull request at:

    https://github.com/apache/storm/pull/1591


GitHub user hsun-cnnxty reopened a pull request:

    https://github.com/apache/storm/pull/1591

    STORM-1038: Upgrade netty to 4.x in 1.x-branch

    This is to add the feature to 1.x-branch.  The original PR for master branch is #728.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hsun-cnnxty/storm 1.x-branch-netty4

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/storm/pull/1591.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1591
    
----
commit 57fbccc7e0d710ccaf04a5a828f0ff4cf29ec855
Author: Hang Sun <hsun@connexity.com>
Date:   2016-07-25T22:30:54Z

    STORM-1038: Upgraded netty to 4.x

commit 144b6eddf314ce9a0b5beb8c99500c56ff0b8ec0
Author: Hang Sun <hsun@connexity.com>
Date:   2016-07-30T23:42:52Z

    STORM-1038: removed unused imports

----


Github user hsun-cnnxty closed the pull request at:

    https://github.com/apache/storm/pull/1591


GitHub user hsun-cnnxty reopened a pull request:

    https://github.com/apache/storm/pull/1591

    STORM-1038: Upgrade netty to 4.x in 1.x-branch

    This is to add the feature to 1.x-branch.  The original PR for master branch is #728.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hsun-cnnxty/storm 1.x-branch-netty4

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/storm/pull/1591.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1591
    
----
commit 57fbccc7e0d710ccaf04a5a828f0ff4cf29ec855
Author: Hang Sun <hsun@connexity.com>
Date:   2016-07-25T22:30:54Z

    STORM-1038: Upgraded netty to 4.x

commit 144b6eddf314ce9a0b5beb8c99500c56ff0b8ec0
Author: Hang Sun <hsun@connexity.com>
Date:   2016-07-30T23:42:52Z

    STORM-1038: removed unused imports

----


[~sunh11373] Hi, it's been a while since the last work on these branches. If you're not planning on finishing these PRs up, I'd like to give it a try. Let me know if you still intend to work on this, if not I might try to finish up your work.

Hi [~Srdo],

Feel free to finish it.  Unfortunately my project has moved on with a different technology choice, so I don't get to spend more time on this change.  With busy work at hand, I don't think I will be able to follow up with what has been changed here.

Thanks

 

 

 

 

 

[~sunh11373] Okay. Thanks for the contribution regardless, it's a great help.

