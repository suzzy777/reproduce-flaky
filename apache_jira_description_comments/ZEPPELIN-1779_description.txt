Here's my travis job based on master. PySparkInterpreterMatplotlibTest would fail as following. I also hit the same issue in my other PR
https://travis-ci.org/zjffdu/zeppelin/jobs/182518614
https://travis-ci.org/apache/zeppelin/jobs/182509095
{noformat}
16/12/09 08:14:29 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
16/12/09 08:14:29 INFO SessionState: Created local directory: /tmp/68ddb8b5-ab8d-4a69-a24b-7d216cd62357_resources
16/12/09 08:14:29 INFO SessionState: Created HDFS directory: /tmp/hive/travis/68ddb8b5-ab8d-4a69-a24b-7d216cd62357
16/12/09 08:14:29 INFO SessionState: Created local directory: /tmp/travis/68ddb8b5-ab8d-4a69-a24b-7d216cd62357
16/12/09 08:14:29 INFO SessionState: Created HDFS directory: /tmp/hive/travis/68ddb8b5-ab8d-4a69-a24b-7d216cd62357/_tmp_space.db
_binder: java.util.HashMap[String,Object] = {}
z: org.apache.zeppelin.spark.ZeppelinContext = org.apache.zeppelin.spark.ZeppelinContext@70dc202a
sc: org.apache.spark.SparkContext = org.apache.spark.SparkContext@e3a39bc
sqlc: org.apache.spark.sql.SQLContext = org.apache.spark.sql.hive.HiveContext@33d93a5a
sqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.hive.HiveContext@33d93a5a
import org.apache.spark.SparkContext._
import sqlContext.implicits._
import sqlContext.sql
import org.apache.spark.sql.functions._
16/12/09 08:14:33 INFO PySparkInterpreter: File /tmp/zeppelin_pyspark-3928618807844395916.py created
16/12/09 08:14:33 INFO SparkInterpreter: Sending metainfos to Zeppelin server: {url=http://172.17.0.4:4040}
No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself.
Check the details on how to adjust your build configuration on: https://docs.travis-ci.com/user/common-build-problems/#Build-times-out-because-no-output-was-received
The build has been terminated

{noformat}

\cc [~agoodman]