gjacoby126 opened a new pull request, #1469:
URL: https://github.com/apache/phoenix/pull/1469

   … compilation phase leads to poor performance




gjacoby126 commented on PR #1469:
URL: https://github.com/apache/phoenix/pull/1469#issuecomment-1191873154

   This is a rebase of #1467 since merging #1465 caused GitHub to incorrectly think there was a merge conflict there. (This is still @jpisaac 's code, I'm just doing it since he's out of office.) @dbwong and @tkhurana , you know the query parsing code better than me, so could you please take a look?




gjacoby126 commented on PR #1469:
URL: https://github.com/apache/phoenix/pull/1469#issuecomment-1192986121

   This PR has caused InListIT to crash twice, and InListIT is a test that it modifies. More investigation is needed before it can be merged. @jpisaac , @dbwong , @tkhurana , fyi. 




gjacoby126 commented on PR #1469:
URL: https://github.com/apache/phoenix/pull/1469#issuecomment-1203265073

   @jpisaac - the new test in InListIT was causing OOMs during the iteration where it ran with 50,000 ORs (both in CI and locally). I tweaked it so it runs with at most 5000 ORs, and now it passes for me locally. If 50,000 ORs needs to be supported, either the test heap size needs to be bigger, or we need further optimization.




gjacoby126 commented on PR #1469:
URL: https://github.com/apache/phoenix/pull/1469#issuecomment-1239785748

   I'll let @jpisaac re-base his original PR now that he's back and close this one.




gjacoby126 closed pull request #1469: PHOENIX-6752 Duplicate expression nodes in extract nodes during WHERE…
URL: https://github.com/apache/phoenix/pull/1469




[~jisaac],would you mind explaining more about what is the most time-consuming code for the problem you described ? I don't quite understand what problem this JIRA is trying to solve.

[~comnetwork] I have updated the problem description.

I have also added the [PR|[https://github.com/apache/phoenix/pull/1508]] Hopefully, the code comments should help clarify.

[code|https://github.com/apache/phoenix/pull/1508/files#diff-9494157265dca11f05041f6a7238b64857cc22e08c3c23e92412e1a0da1d12feR937]

 

 

gjacoby126 commented on PR #1468:
URL: https://github.com/apache/phoenix/pull/1468#issuecomment-1262709278

   Closing because it's been superseded by #1508 




gjacoby126 closed pull request #1468: PHOENIX-6752 Duplicate expression nodes in extract nodes during WHERE compilation phase leads to poor performance
URL: https://github.com/apache/phoenix/pull/1468




gjacoby126 commented on PR #1467:
URL: https://github.com/apache/phoenix/pull/1467#issuecomment-1262709700

   Closing because it's been superseded by #1508 




gjacoby126 closed pull request #1467: PHOENIX-6752 Duplicate expression nodes in extract nodes during WHERE compilation phase leads to poor performance
URL: https://github.com/apache/phoenix/pull/1467




comnetwork commented on code in PR #1508:
URL: https://github.com/apache/phoenix/pull/1508#discussion_r984304639


##########
phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java:
##########
@@ -926,7 +934,11 @@ private KeySlots andKeySlots(AndExpression andExpression, List<KeySlots> childSl
                             if (slot.getOrderPreserving() != null) {
                                 orderPreserving = slot.getOrderPreserving().combine(orderPreserving);
                             }
-                            if (slot.getKeyPart().getExtractNodes() != null) {
+                            // Extract once per iteration, when there are large number
+                            // of OR clauses (for e.g N > 100k).
+                            // The extractNodes.addAll method can get called N times.
+                            if (!visitedKeyParts.contains(slot.getKeyPart()) && slot.getKeyPart().getExtractNodes() != null) {
+                                visitedKeyParts.add(slot.getKeyPart());
                                 extractNodes.addAll(slot.getKeyPart().getExtractNodes());

Review Comment:
   The problem of this jira to solve is here? `KeyExpressionVisitor.andKeySlots` adds many repeated `keyPart.extractNodes` to extractNodes and extractNodes is exploded ? 
   Make the extractNodes from List to Set could prevent the extractNodes exploded, but for the case there are large number of OR clauses，how this PR could prevent the cpu time consumed by `SlotsIterator` to enumerate all `KeyRange` combination？ 



##########
phoenix-core/src/it/java/org/apache/phoenix/end2end/InListIT.java:
##########
@@ -1856,6 +1936,40 @@ public void testBaseTableAndIndexTableHaveRightScan() throws Exception {
         }
     }
 
+    @Test
+    public void testWithLargeORs() throws Exception {

Review Comment:
   For this test, we test the `WhereOptimizer.pushKeyExpressionsToScan` and assert the `extractedNodes` is worked as we expected,  I think we would better simplify this test and put it in `WhereOptimizerTest`, not in `InListIT`.If we could put a test in UTs, we would not put it in ITs.





comnetwork commented on code in PR #1508:
URL: https://github.com/apache/phoenix/pull/1508#discussion_r984243344


##########
phoenix-core/src/it/java/org/apache/phoenix/end2end/InListIT.java:
##########
@@ -1856,6 +1936,40 @@ public void testBaseTableAndIndexTableHaveRightScan() throws Exception {
         }
     }
 
+    @Test
+    public void testWithLargeORs() throws Exception {

Review Comment:
   For this test, we test the `WhereOptimizer.pushKeyExpressionsToScan` and assert the `extractedNodes` is worked as we expected,  I think we would better simplify this test and put it in `WhereOptimizerTest`, not in `InListIT`.If we could put a test in UTs, we would not put it in ITs. Usually we put end-to-end query result test in ITs and internal state test in UTs.





comnetwork commented on code in PR #1508:
URL: https://github.com/apache/phoenix/pull/1508#discussion_r985057617


##########
phoenix-core/src/it/java/org/apache/phoenix/end2end/QueryIT.java:
##########
@@ -169,4 +174,41 @@ public void testDistinctLimitScan() throws Exception {
         }
     }
 
+    @Test
+    public void testSelectWithLargeORs() throws Exception {
+        String viewName = generateUniqueName();
+        Properties tenantProps = PropertiesUtil.deepCopy(TEST_PROPERTIES);
+        tenantProps.setProperty(PhoenixRuntime.TENANT_ID_ATTRIB, tenantId);
+        Random rnd = new Random();
+        int numORs = 50000;
+        int numCols = 100;
+
+        try (Connection tenantConnection = DriverManager.getConnection(getUrl(), tenantProps)) {
+            String createViewSQL = String.format("CREATE VIEW IF NOT EXISTS %s(ID1 TIMESTAMP NOT NULL, ID2 VARCHAR(30) NOT NULL, ID3 INTEGER NOT NULL, COL_V0 VARCHAR ", viewName);
+            for (int i = 1; i < numCols;i++) {
+                createViewSQL += String.format(", COL_V%06d VARCHAR ", i);
+            }
+            createViewSQL += " CONSTRAINT pk PRIMARY KEY (ID1 DESC, ID2 DESC, ID3 DESC )) AS SELECT * FROM " + tableName + " WHERE entity_id = 'ECZ' ";
+            tenantConnection.createStatement().execute(createViewSQL);
+
+            StringBuilder whereClause = new StringBuilder("ID1 = ? AND ID2 > ? AND (ID3 = ? ");
+            for (int i = 0; i < numORs;i++) {
+                whereClause.append(" OR ID3 = ?");
+            }
+            whereClause.append(") LIMIT 200");
+            String query = String.format("select * from %s where ", viewName) + whereClause;
+
+            PhoenixPreparedStatement stmtForTimingCheck = tenantConnection.prepareStatement(query.toString()).unwrap(PhoenixPreparedStatement.class);
+            stmtForTimingCheck.setTimestamp(1, new Timestamp(System.currentTimeMillis() + rnd.nextInt(50000)));
+            stmtForTimingCheck.setString(2, RandomStringUtils.randomAlphanumeric(30));
+
+            for (int i = 0; i<numORs+1; i++) {
+                stmtForTimingCheck.setInt(i + 3, rnd.nextInt() );
+            }
+
+            long startResultSetTime = System.currentTimeMillis();
+            ResultSet rs = stmtForTimingCheck.executeQuery(query.toString());
+            assertTrue("Query execution time exceeded limit exceeded 10s", (System.currentTimeMillis() - startResultSetTime) < 10000);

Review Comment:
   I suggest we would better not assert the query time in test,  which may be cause the test flaky. In my opinion, for test, we could assert the internal state which your PR modified to cause the query not timeout , and is same as above, I think it is would be a UT, not a IT test.





[~jisaac], thank you very much.
The problem of this jira to solve is  {{KeyExpressionVisitor.andKeySlots}} adds many repeated {{keyPart.extractNodes}} to {{extractNodes}} and {{extractNodes}} is exploded ?
Yes, make the {{extractNodes}} from {{List}} to {{Set}} could prevent the {{extractNodes}} exploded, but for the case you described there are large number of OR clauses, how the PR could prevent the cpu time consumed by {{SlotsIterator}} to enumerate all {{KeyRange}} combinations？

comnetwork commented on code in PR #1508:
URL: https://github.com/apache/phoenix/pull/1508#discussion_r990620327


##########
phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java:
##########
@@ -926,7 +934,11 @@ private KeySlots andKeySlots(AndExpression andExpression, List<KeySlots> childSl
                             if (slot.getOrderPreserving() != null) {
                                 orderPreserving = slot.getOrderPreserving().combine(orderPreserving);
                             }
-                            if (slot.getKeyPart().getExtractNodes() != null) {
+                            // Extract once per iteration, when there are large number
+                            // of OR clauses (for e.g N > 100k).
+                            // The extractNodes.addAll method can get called N times.
+                            if (!visitedKeyParts.contains(slot.getKeyPart()) && slot.getKeyPart().getExtractNodes() != null) {
+                                visitedKeyParts.add(slot.getKeyPart());
                                 extractNodes.addAll(slot.getKeyPart().getExtractNodes());

Review Comment:
   @gjacoby126 , ok,  thank you for reply.





gjacoby126 commented on PR #1508:
URL: https://github.com/apache/phoenix/pull/1508#issuecomment-1295111820

   @jpisaac - Checking back in on this patch 

[~jisaac] Do we need this for 5.1.3 release ?

stoty commented on code in PR #1508:
URL: https://github.com/apache/phoenix/pull/1508#discussion_r1019855744


##########
phoenix-core/src/it/java/org/apache/phoenix/end2end/QueryIT.java:
##########
@@ -169,4 +174,41 @@ public void testDistinctLimitScan() throws Exception {
         }
     }
 
+    @Test
+    public void testSelectWithLargeORs() throws Exception {
+        String viewName = generateUniqueName();
+        Properties tenantProps = PropertiesUtil.deepCopy(TEST_PROPERTIES);
+        tenantProps.setProperty(PhoenixRuntime.TENANT_ID_ATTRIB, tenantId);
+        Random rnd = new Random();
+        int numORs = 50000;
+        int numCols = 100;
+
+        try (Connection tenantConnection = DriverManager.getConnection(getUrl(), tenantProps)) {
+            String createViewSQL = String.format("CREATE VIEW IF NOT EXISTS %s(ID1 TIMESTAMP NOT NULL, ID2 VARCHAR(30) NOT NULL, ID3 INTEGER NOT NULL, COL_V0 VARCHAR ", viewName);
+            for (int i = 1; i < numCols;i++) {
+                createViewSQL += String.format(", COL_V%06d VARCHAR ", i);
+            }
+            createViewSQL += " CONSTRAINT pk PRIMARY KEY (ID1 DESC, ID2 DESC, ID3 DESC )) AS SELECT * FROM " + tableName + " WHERE entity_id = 'ECZ' ";
+            tenantConnection.createStatement().execute(createViewSQL);
+
+            StringBuilder whereClause = new StringBuilder("ID1 = ? AND ID2 > ? AND (ID3 = ? ");
+            for (int i = 0; i < numORs;i++) {
+                whereClause.append(" OR ID3 = ?");
+            }
+            whereClause.append(") LIMIT 200");
+            String query = String.format("select * from %s where ", viewName) + whereClause;
+
+            PhoenixPreparedStatement stmtForTimingCheck = tenantConnection.prepareStatement(query.toString()).unwrap(PhoenixPreparedStatement.class);
+            stmtForTimingCheck.setTimestamp(1, new Timestamp(System.currentTimeMillis() + rnd.nextInt(50000)));
+            stmtForTimingCheck.setString(2, RandomStringUtils.randomAlphanumeric(30));
+
+            for (int i = 0; i<numORs+1; i++) {
+                stmtForTimingCheck.setInt(i + 3, rnd.nextInt() );
+            }
+
+            long startResultSetTime = System.currentTimeMillis();
+            ResultSet rs = stmtForTimingCheck.executeQuery(query.toString());
+            assertTrue("Query execution time exceeded limit exceeded 10s", (System.currentTimeMillis() - startResultSetTime) < 10000);

Review Comment:
   I agree with not checking for timeouts. anything can happen on the test infra, from GC pauses to swapping.





jpisaac commented on PR #1508:
URL: https://github.com/apache/phoenix/pull/1508#issuecomment-1312289719

   @gjacoby126 @stoty @tkhurana Can u take a look again? I have addressed all of the review comments. Let me know if there is more. 




tkhurana commented on PR #1529:
URL: https://github.com/apache/phoenix/pull/1529#issuecomment-1312314804

   @stoty Any idea why the tests didn't run ?




stoty commented on PR #1529:
URL: https://github.com/apache/phoenix/pull/1529#issuecomment-1312374677

   The test have ran, but something (either the tests or the postback) got delayed @tkhurana.
   This happens sometimes.
   I've restarted the tests, as there was a JVM crash during it.
   
   https://ci-hadoop.apache.org/job/Phoenix/job/Phoenix-PreCommit-GitHub-PR/view/change-requests/job/PR-1529/




stoty commented on code in PR #1508:
URL: https://github.com/apache/phoenix/pull/1508#discussion_r1020679650


##########
pom.xml:
##########
@@ -85,7 +85,7 @@
     <!

stoty commented on code in PR #1529:
URL: https://github.com/apache/phoenix/pull/1529#discussion_r1020680442


##########
phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java:
##########
@@ -926,7 +932,11 @@ private KeySlots andKeySlots(AndExpression andExpression, List<KeySlots> childSl
                             if (slot.getOrderPreserving() != null) {
                                 orderPreserving = slot.getOrderPreserving().combine(orderPreserving);
                             }
-                            if (slot.getKeyPart().getExtractNodes() != null) {
+                            // Extract once per iteration, when there are large number
+                            // of OR clauses (for e.g N > 100k).
+                            // The extractNodes.addAll method can get called N times.
+                            if (!visitedKeyParts.contains(slot.getKeyPart()) && slot.getKeyPart().getExtractNodes() != null) {

Review Comment:
   Does this contains() check improve perf ?
   I'd expect checking then adding an existing element to a hash to take similar (or more) time to simply adding it, and letting the hash take care of  duplicates.





stoty commented on PR #1508:
URL: https://github.com/apache/phoenix/pull/1508#issuecomment-1313189918

   I was able to repro the LogicalTableNameIT failures locally.
   




jpisaac commented on PR #1529:
URL: https://github.com/apache/phoenix/pull/1529#issuecomment-1314469848

   Rebased and resolved conflicts with 5.1 branch FYI @stoty @tkhurana @gjacoby126 




gjacoby126 commented on code in PR #1508:
URL: https://github.com/apache/phoenix/pull/1508#discussion_r1025823378


##########
phoenix-core/src/test/java/org/apache/phoenix/query/BaseTest.java:
##########
@@ -146,13 +149,15 @@
 import org.apache.phoenix.jdbc.PhoenixConnection;
 import org.apache.phoenix.jdbc.PhoenixDatabaseMetaData;
 import org.apache.phoenix.jdbc.PhoenixEmbeddedDriver;
+import org.apache.phoenix.jdbc.PhoenixPreparedStatement;

Review Comment:
   nit: added imports with no added code anymore, which probably means these are unused imports. 





mnpoonia commented on PR #1529:
URL: https://github.com/apache/phoenix/pull/1529#issuecomment-1323912370

   @jpisaac This PR seems to be duplicate of https://github.com/apache/phoenix/pull/1508/files




jpisaac commented on PR #1529:
URL: https://github.com/apache/phoenix/pull/1529#issuecomment-1329577240

   > @jpisaac This PR seems to be duplicate of #1508
   
   @mnpoonia This is the same PR for the 5.1 branch.
   
   @stoty @gjacoby126 can u approve this too, if there are no concerns?




jpisaac commented on PR #1508:
URL: https://github.com/apache/phoenix/pull/1508#issuecomment-1329794896

   @gjacoby126 Rebased to latest and removed unused imports




jpisaac commented on PR #1529:
URL: https://github.com/apache/phoenix/pull/1529#issuecomment-1329822097

   Rebased to the latest and removed unused imports from BaseTest.java




jpisaac commented on PR #1529:
URL: https://github.com/apache/phoenix/pull/1529#issuecomment-1339945164

   @stoty @gjacoby126 can u approve, if there are no concerns?




jpisaac commented on PR #1508:
URL: https://github.com/apache/phoenix/pull/1508#issuecomment-1339946102

   @gjacoby126 can u approve, if there are no concerns?




stoty commented on PR #1529:
URL: https://github.com/apache/phoenix/pull/1529#issuecomment-1340512768

   We usually don't review backport PRs separately, unless there is a big difference in the implementation.
   When the master patch is approved, this one is also good.




jpisaac merged PR #1508:
URL: https://github.com/apache/phoenix/pull/1508




jpisaac merged PR #1529:
URL: https://github.com/apache/phoenix/pull/1529




