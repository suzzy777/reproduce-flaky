001.patch
The threadpool is a mashup of the code that was in S3AFileSystem and the S4 code in the link in the description above.

This required bumping the AWS SDK dependency from version 1.7.4 to 1.7.8, where the constructor for TransferManager can be passed any ExecutorService instead of only a ThreadPool. However, I decided to upgrade the version to a very recent version (1.9.27), as from 1.9 onwards, the different components of the sdk can be imported individually. We now only include S3, resulting in much smaller binaries. 

BEWARE: To prove that the inclduded test fails when the rest of the patch is not applied one has to uncomment a line as Constants.MAX_THREADS is removed from the codebase by the patch. 

As a side effect, the version upgrade also fixes following bug in TransferManager: multiPartThreshold is now a long instead of an int.

 

Thomas, could you split the POM patch from the rest of the change. That way it is more visible in CHANGES.TXT and something we can link to from HADOOP-9991, the general JIRA to track updates. 

The aws-sdk version bump was seperated out to HADOOP-12269 and merged into trunk. This patch only contains the BlockingThreadpool code. 

To witness the exception without the fix: 
* only apply the new testclass: {{TestS3ABlockingThreadpool.java}}
* manually add a line setting CORE_THREADS to 2: (needed because this constant is removed in the patch)
{code}
@Before
  public void setUp() throws Exception {
    conf = new Configuration();
    ...
    conf.setInt(Constants.MAX_TOTAL_TASKS, 1);
+   conf.setInt(Constants.CORE_THREADS, 2);
  }
{code}
* run test: The upload will generate 4 parts which exceeds threads + tasks -> Exception

\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  20m 17s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 38s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 43s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 23s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | site |   2m 59s | Site still builds. |
| {color:red}-1{color} | checkstyle |   1m 26s | The applied patch generated  6 new checkstyle issues (total was 64, now 61). |
| {color:green}+1{color} | whitespace |   0m  1s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 20s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   2m 36s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:red}-1{color} | common tests |  22m 31s | Tests failed in hadoop-common. |
| {color:green}+1{color} | tools/hadoop tests |   0m 14s | Tests passed in hadoop-aws. |
| | |  69m 45s | |
\\
\\
|| Reason || Tests ||
| Failed unit tests | hadoop.ha.TestZKFailoverController |
|   | hadoop.net.TestNetUtils |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12749878/HADOOP-11684-002.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle site |
| git revision | trunk / fa1d84a |
| checkstyle |  https://builds.apache.org/job/PreCommit-HADOOP-Build/7439/artifact/patchprocess/diffcheckstylehadoop-aws.txt |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7439/artifact/patchprocess/testrun_hadoop-common.txt |
| hadoop-aws test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7439/artifact/patchprocess/testrun_hadoop-aws.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7439/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf906.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7439/console |


This message was automatically generated.

[~Thomas Demoor] reading your patch.. Curious, did you consider just using [http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ThreadPoolExecutor.CallerRunsPolicy.html|CallerRunsPolicy]?  

Thanks for the review Aaron.

I did. I think that with CallerRunsPolicy, if multiple write commands would be issued from separate threads, each of these threads would be allowed to continue, still running the JVM into an OOM. I agree this is quite far fetched, but, as there is a whole ecosystem depending on the Hadoop filesystems, I went for the robuster (but indeed more complex and thus error-prone) implementation. If people who know the ecosystem better than me can assert that this case does not occur "in the wild" I'm fine with simply using CallerRunsPolicy.

I guess the argument for CallerRunsPolicy is:

1. One line(ish) change.  Low risk for regressions.
2. Eventual, possible OOM better than immediate exception fail.

I'm still pretty new to codebase. Anyone have example where many threads would be entering S3AFilesystem to do writes?

I still intend to spend more time reviewing the patch to convince myself it is correct.. just didn't get to it this week.  A unit test for the new blocking executor would be sweet as well.

As said previously, I agree with your points above. I propose to use CallerRunsPolicy (I'll add a patch) and we can always move to the current patch later if the threaded writers would come up.



003.patch throttles using {{CallerRunsPolicy}}. Changed some of the default config settings to reasonable values.

As before, if one only applies the new test case, it will fail with a {{RejectedExecutionException}}, highlighting the need for the patch.

\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  23m 40s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   8m 52s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |  11m 39s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 25s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | site |   3m 24s | Site still builds. |
| {color:red}-1{color} | checkstyle |   1m 38s | The applied patch generated  1 new checkstyle issues (total was 61, now 61). |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 42s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 37s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   3m  5s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | common tests |  24m 38s | Tests passed in hadoop-common. |
| {color:green}+1{color} | tools/hadoop tests |   0m 14s | Tests passed in hadoop-aws. |
| | |  80m  0s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12762134/HADOOP-11684-003.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle site |
| git revision | trunk / ead1b9e |
| checkstyle |  https://builds.apache.org/job/PreCommit-HADOOP-Build/7699/artifact/patchprocess/diffcheckstylehadoop-aws.txt |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7699/artifact/patchprocess/testrun_hadoop-common.txt |
| hadoop-aws test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7699/artifact/patchprocess/testrun_hadoop-aws.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7699/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf907.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7699/console |


This message was automatically generated.

Looks pretty good.  A couple of questions:

1. Can you comment on how you arrived at the new default values for `fs.s3a.threads.max`, `fs.s3a.threads.core`, and `fs.s3a.max.total.tasks`? (i.e. we no longer need artificially large thread pools to hack around the fact that the old implementation would throw an exception when `threads * fs.s3a.max.total.tasks` requests in flight was exceeded).
2. Since the behavior of these parameters has changed, should we add an entry to release notes notifying folks of the new behavior?

Would you like some help testing?

bq. Anyone have example where many threads would be entering S3AFilesystem to do writes

any multi-threaded process with lots of workers committing the output of their work to s3. Examples: MR, Tez, Spark work

HADOOP-11446 caught this with HBase FS snapshots.

bq.  Since the behavior of these parameters has changed, should we add an entry to release notes notifying folks of the new behavior?

s3a has still been in stabilisation phase, so I'm not so sure as to how much we need to detail. the main thing is "do the changes consistute some form of regression?". If they improve things, then they aren't. After all, currently when the thread pool fills up, you are in trouble â€”so you do need to overallocate

Thanks [~stevel@apache.org].  My remaining curiosity is whether the new default parameter values will result in a decrease in throughput for some people.  

One has to take into account that s3a runs within the  "Hadoop container" (Mapper / Reducer / ...). The new defaults allow for 3 (active uploads = threads.max) + 1 (queued upload = max.total.tasks) + 1 (active upload = in calling thread due to CallerRuns) = 5 concurrent uploads *per Hadoop container* on the node. This should easily fill up the network pipe of the node, whereas, on my setup, the current (much higher) defaults cause starvation.

Thus, with CallerRuns (003.patch), if extra upload attempts are made by *other threads* they will cause concurrent upload 6,7,8,..., likely running the JVM out of memory. [~stevel@apache.org], do you agree we need the approach from 002.patch, which is robust against this behaviour?

We've been running MR-style workflows on our test-cluster with 002.patch for a while now (~ 2 months) and haven't run into any issues. Of course, additional testing (more workflows) would be welcome.



Ok.  With that explanation I'm fine with the new defaults.  Worst case a config change can be made to re-tune.

I'm a little confused about the JVM out of memory (OOM) issue: Either way, you have many threads in play.  Whether they block, or start uploading themselves. Is there something about uploading that dramatically increases the memory usage per thread?

Certainly, the blocking executor is more robust at limiting the number of concurrent uploads.  I like it, it just takes more effort for me to understand it is bug-free.

S3a has 2 modes for uploading: 
* fs.s3a.fast.upload=false (default): S3AOutputStream.java
** files are buffered to local disk first, on fs.close() the upload to S3 is initiated
** similar behaviour to s3n, other 3d party filesystems
** downsides: throughput of local disk, remaining space on local disk, delayed start of upload 
* fs.s3a.fast.upload=true: S3AFastOutputStream.java
** Hadoop writes are buffered in memory, if written data > threshold: multipart is initiated, uploading multiple parts in parallel in different *threads* (as soon as the data is in memory)
** EMR probably does something similar
** in this mode, fs.s3a.multipart.size should be set to something like 64 or 128MB, similar to hdfs block size.
** downsides: buffers data in memory inside JVM (~ fs.s3a.multipart.size * (fs.s3a.threads.max + fs.s3a.max.total.tasks) +1 ), HADOOP-12387 will improve memory management

In fast mode, more threads / queued parts improve parallelism but require additional memory buffer space. Setting max.total.tasks=1000 certainly runs the JVM OOM here, as do applications that write files from separate threads (with CallerRuns, not with Blocking Threadpool). In default mode, the threadpool is used by the AWS SDK TransferManager.

Indeed, the blocking threadpool is non-trivial (semaphores,...) and thus higher-risk. Is there similar code in HDFS we could inspect / reuse?


I've been switching to concurrent queues for sync, as sync setup is a simple take() call.

+1 on the 002 patch.

I'm attaching a 004 patch that is identical, except it adds an extra unit test on {{BlockingThreadPoolExecutorService}}.  It is optional, but demonstrates some testing I've done.  These blobstore tests don't run by default, but my test does depend on timing, so it could theoretically fail on a heavily loaded system. (I detect whether or not the threadpool blocks via elapsed system time across {{submit()}} calls, and these aren't realtime systems.}

Reviewers: The idea behind the 002 approach pretty simple.  The meat of the change is just a semaphore around {{ExecutorService}} functions {{submit()}} etc..  e.g.

{code}
+  @Override
+  public ListenableFuture<?> submit(Runnable task) {
+    try {
+      queueingPermits.acquire();
+    } catch (InterruptedException e) {
+      Thread.currentThread().interrupt();
+      return Futures.immediateFailedCheckedFuture(e);
+    }
+    return super.submit(new RunnableWithPermitRelease(task));
+  }
{code}

\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  21m 43s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 2 new or modified test files. |
| {color:green}+1{color} | javac |   8m  5s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |  10m 26s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 25s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | site |   3m  6s | Site still builds. |
| {color:red}-1{color} | checkstyle |   1m 31s | The applied patch generated  6 new checkstyle issues (total was 64, now 61). |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 31s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 34s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   2m 34s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:red}-1{color} | common tests |   7m 34s | Tests failed in hadoop-common. |
| {color:green}+1{color} | tools/hadoop tests |   0m 13s | Tests passed in hadoop-aws. |
| | |  57m 46s | |
\\
\\
|| Reason || Tests ||
| Failed unit tests | hadoop.metrics2.impl.TestGangliaMetrics |
|   | hadoop.ipc.TestIPC |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12766270/HADOOP-11684-004.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle site |
| git revision | trunk / 69b025d |
| checkstyle |  https://builds.apache.org/job/PreCommit-HADOOP-Build/7797/artifact/patchprocess/diffcheckstylehadoop-aws.txt |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7797/artifact/patchprocess/testrun_hadoop-common.txt |
| hadoop-aws test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7797/artifact/patchprocess/testrun_hadoop-aws.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7797/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf903.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7797/console |


This message was automatically generated.

Thanks a lot for working on this, [~Thomas Demoor] and [~fabbri]. It looks good overall.

I have a few nitpicks, would +1 after addressing them:

* {{BlockingThreadPoolExecutorServiceTest}} should be renamed to {{TestBlockingThreadPoolExecutorService}}.
* Could you consider not throwing {{RuntimeException}} in the BlockingThreadPoolExecutorServiceTest? I.e. , we might want to change 
{code}
if (sw.now(TimeUnit.MILLISECONDS) > BLOCKING_THRESHOLD_MSEC) {
  throw new RuntimeException("Non-blocking call took too long.");
}
{code} to
{code}
assertTrue("Non-blocking call took too long.", sw.now(...) > BLOCK...)
{code}
* Should we expect the "	import static org.junit.Assert.*;" ?
* Lets change {{int shutdown_tries = SHUTDOWN_WAIT_TRIES;}} to {{int shutdownTries = ...}} for code style consistency. 
* Use {{sleeper}} to test blocking the threadpool might be little bit flaky from time to time. Could you consider to use a conditional variable or latch to block the active tasks?

Thanks a lot!

Thanks for review [~eddyxu].  I will fix the style issues you mention.

On the final point: Using synchronization instead of sleeps to block tasks from finishing.. I like the idea.   I can implement it, but detecting whether or not the final submit() blocks will still be subject to sleep race condition.

That is, I can guarantee first n threads will not finish before I've determined that the n+1'th thread has blocked (i.e. latch instead of sleep), but determining how long to wait until that n+1'th threadPool.submit() has "blocked" is still a race.  I can't distinguish between our thread being runnable but not scheduled and actually blocking from Java, AFAIK.

Three options:
1. I fix this test (which doesn't run by default) to be less-but-still-racy.
2. I fix all style etc. issues, but leave sleep-based implementation.
3. I remove the unit test.  It has served to show the amount of testing done on the patch, and may be a little too fancy anyways.

Hi, [~fabbri].  I am OK with either 1 or 2.  Please feel free to choose one as you see fit.

Sorry for late reply. 

005 patch addresses [~eddyxu]'s comments on the test I added:
- No wildcard static import.
- Use assert instead of runtime exception.
- camelCasify

Left sleep-based implementation because detecting "blocking" is racy no matter what.

Ran all the s3a unit tests again. 

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 6s {color} | {color:blue} docker + precommit patch detected. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 2m 56s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 17s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 10s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 56s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 15s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 31s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 8s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 5s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 17s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 49s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 17s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 4m 16s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 8s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 4m 8s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 57s {color} | {color:red} Patch generated 6 new checkstyle issues in root (total was 64, now 61). {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 8s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 26s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green} 0m 0s {color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 23s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javadoc {color} | {color:red} 0m 12s {color} | {color:red} hadoop-aws in the patch failed with JDK v1.8.0_60. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 17s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 6m 8s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_60. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 11s {color} | {color:green} hadoop-aws in the patch passed with JDK v1.8.0_60. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 6m 24s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_79. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 12s {color} | {color:green} hadoop-aws in the patch passed with JDK v1.7.0_79. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 21s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 50m 41s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_60 Failed junit tests | hadoop.metrics2.sink.TestFileSink |
| JDK v1.7.0_79 Failed junit tests | hadoop.metrics2.sink.TestFileSink |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=1.7.1 Server=1.7.1 Image:test-patch-base-hadoop-date2015-11-04 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12770521/HADOOP-11684-005.patch |
| JIRA Issue | HADOOP-11684 |
| Optional Tests |  asflicense  javac  javadoc  mvninstall  unit  xml  findbugs  checkstyle  compile  site  mvnsite  |
| uname | Linux 761cfe595d7f 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HADOOP-Build/patchprocess/apache-yetus-d0f6847/precommit/personality/hadoop.sh |
| git revision | trunk / 194251c |
| Default Java | 1.7.0_79 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_60 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_79 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/8026/artifact/patchprocess/diff-checkstyle-root.txt |
| javadoc | https://builds.apache.org/job/PreCommit-HADOOP-Build/8026/artifact/patchprocess/patch-javadoc-hadoop-tools_hadoop-aws-jdk1.8.0_60.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8026/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_60.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8026/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_79.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8026/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_60.txt https://builds.apache.org/job/PreCommit-HADOOP-Build/8026/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_79.txt |
| JDK v1.7.0_79  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8026/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-tools/hadoop-aws U: . |
| Max memory used | 225MB |
| Powered by | Apache Yetus   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8026/console |


This message was automatically generated.



Hi, [~fabbri]. 

It LGTM. Could you update {{TestBlockingThreadPoolExecutorService}}, which is 4 space indent?

will +1 after it.

This 006 patch fixes indentation on the test I added.  My editor was not picking up my hadoop settings.  Thanks!

BTW we should attribute patch to [~Thomas Demoor].. All I did is add another test.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 11s {color} | {color:blue} docker + precommit patch detected. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 3m 59s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 58s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 40s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 1m 0s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 14s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 31s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 12s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 6s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 16s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 46s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 15s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 4m 15s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 6s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 4m 6s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 55s {color} | {color:red} Patch generated 6 new checkstyle issues in root (total was 64, now 61). {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 9s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 26s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green} 0m 1s {color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 23s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javadoc {color} | {color:red} 0m 12s {color} | {color:red} hadoop-aws in the patch failed with JDK v1.8.0_60. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 16s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 3s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_60. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 12s {color} | {color:green} hadoop-aws in the patch passed with JDK v1.8.0_60. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 37s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_79. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 13s {color} | {color:green} hadoop-aws in the patch passed with JDK v1.7.0_79. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 23s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 55m 16s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_60 Failed junit tests | hadoop.security.token.delegation.TestZKDelegationTokenSecretManager |
| JDK v1.7.0_79 Failed junit tests | hadoop.metrics2.impl.TestGangliaMetrics |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=1.7.1 Server=1.7.1 Image:test-patch-base-hadoop-date2015-11-04 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12770664/HADOOP-11684-006.patch |
| JIRA Issue | HADOOP-11684 |
| Optional Tests |  asflicense  javac  javadoc  mvninstall  unit  xml  findbugs  checkstyle  compile  site  mvnsite  |
| uname | Linux ded19bdbaa89 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HADOOP-Build/patchprocess/apache-yetus-e8bd3ad/precommit/personality/hadoop.sh |
| git revision | trunk / 5667129 |
| Default Java | 1.7.0_79 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_60 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_79 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/8031/artifact/patchprocess/diff-checkstyle-root.txt |
| javadoc | https://builds.apache.org/job/PreCommit-HADOOP-Build/8031/artifact/patchprocess/patch-javadoc-hadoop-tools_hadoop-aws-jdk1.8.0_60.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8031/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_60.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8031/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_79.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8031/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_60.txt https://builds.apache.org/job/PreCommit-HADOOP-Build/8031/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_79.txt |
| JDK v1.7.0_79  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8031/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-tools/hadoop-aws U: . |
| Max memory used | 227MB |
| Powered by | Apache Yetus   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8031/console |


This message was automatically generated.



Re-attaching 006 patch.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 13s {color} | {color:blue} docker + precommit patch detected. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 3m 42s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 30s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 11s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 1m 10s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 34s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 37s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 43s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 32s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 37s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 2m 6s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 27s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 5m 27s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 9s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 5m 9s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 1m 12s {color} | {color:red} Patch generated 6 new checkstyle issues in root (total was 64, now 61). {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 24s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 32s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green} 0m 1s {color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 2s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javadoc {color} | {color:red} 0m 19s {color} | {color:red} hadoop-aws in the patch failed with JDK v1.8.0_60. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 41s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 9m 1s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_60. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 17s {color} | {color:green} hadoop-aws in the patch passed with JDK v1.8.0_60. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 8m 29s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_79. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 15s {color} | {color:green} hadoop-aws in the patch passed with JDK v1.7.0_79. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 27s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 65m 59s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_60 Failed junit tests | hadoop.ipc.TestIPC |
|   | hadoop.ha.TestZKFailoverController |
|   | hadoop.metrics2.impl.TestMetricsSystemImpl |
| JDK v1.7.0_79 Failed junit tests | hadoop.metrics2.impl.TestMetricsSystemImpl |
|   | hadoop.security.ssl.TestReloadingX509TrustManager |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=1.7.1 Server=1.7.1 Image:test-patch-base-hadoop-date2015-11-05 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12770865/HADOOP-11684-006.patch |
| JIRA Issue | HADOOP-11684 |
| Optional Tests |  asflicense  javac  javadoc  mvninstall  unit  xml  findbugs  checkstyle  compile  site  mvnsite  |
| uname | Linux 33cae2212252 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HADOOP-Build/patchprocess/apache-yetus-ee5baeb/precommit/personality/hadoop.sh |
| git revision | trunk / 21c0e3e |
| Default Java | 1.7.0_79 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_60 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_79 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/8035/artifact/patchprocess/diff-checkstyle-root.txt |
| javadoc | https://builds.apache.org/job/PreCommit-HADOOP-Build/8035/artifact/patchprocess/patch-javadoc-hadoop-tools_hadoop-aws-jdk1.8.0_60.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8035/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_60.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8035/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_79.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8035/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_60.txt https://builds.apache.org/job/PreCommit-HADOOP-Build/8035/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_79.txt |
| JDK v1.7.0_79  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8035/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-tools/hadoop-aws U: . |
| Max memory used | 228MB |
| Powered by | Apache Yetus   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8035/console |


This message was automatically generated.



+1. Thanks for working on this, [~Thomas Demoor] and [~fabbri].

Committed.

FAILURE: Integrated in Hadoop-trunk-Commit #8765 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/8765/])
HADOOP-11684. S3a to use thread pool that blocks clients. (Thomas Demoor (lei: rev bff7c90a5686de106ca7a866982412c5dfa01632)
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/TestS3ABlockingThreadPool.java
* hadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/index.md
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/TestBlockingThreadPoolExecutorService.java
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Constants.java
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/BlockingThreadPoolExecutorService.java
* hadoop-common-project/hadoop-common/src/main/resources/core-default.xml


SUCCESS: Integrated in Hadoop-Yarn-trunk #1368 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/1368/])
HADOOP-11684. S3a to use thread pool that blocks clients. (Thomas Demoor (lei: rev bff7c90a5686de106ca7a866982412c5dfa01632)
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Constants.java
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java
* hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/TestBlockingThreadPoolExecutorService.java
* hadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/index.md
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/BlockingThreadPoolExecutorService.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/TestS3ABlockingThreadPool.java
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java


FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #635 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/635/])
HADOOP-11684. S3a to use thread pool that blocks clients. (Thomas Demoor (lei: rev bff7c90a5686de106ca7a866982412c5dfa01632)
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Constants.java
* hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/TestBlockingThreadPoolExecutorService.java
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/BlockingThreadPoolExecutorService.java
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java
* hadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/index.md
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/TestS3ABlockingThreadPool.java


SUCCESS: Integrated in Hadoop-Yarn-trunk-Java8 #645 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/645/])
HADOOP-11684. S3a to use thread pool that blocks clients. (Thomas Demoor (lei: rev bff7c90a5686de106ca7a866982412c5dfa01632)
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/BlockingThreadPoolExecutorService.java
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java
* hadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/index.md
* hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/TestBlockingThreadPoolExecutorService.java
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Constants.java
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/TestS3ABlockingThreadPool.java
* hadoop-common-project/hadoop-common/CHANGES.txt


FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #576 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/576/])
HADOOP-11684. S3a to use thread pool that blocks clients. (Thomas Demoor (lei: rev bff7c90a5686de106ca7a866982412c5dfa01632)
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Constants.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/BlockingThreadPoolExecutorService.java
* hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
* hadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/index.md
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/TestBlockingThreadPoolExecutorService.java
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/TestS3ABlockingThreadPool.java


FAILURE: Integrated in Hadoop-Mapreduce-trunk #2575 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2575/])
HADOOP-11684. S3a to use thread pool that blocks clients. (Thomas Demoor (lei: rev bff7c90a5686de106ca7a866982412c5dfa01632)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/TestBlockingThreadPoolExecutorService.java
* hadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/index.md
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/TestS3ABlockingThreadPool.java
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/BlockingThreadPoolExecutorService.java
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Constants.java
* hadoop-common-project/hadoop-common/src/main/resources/core-default.xml


bq. -1	javadoc	0m 19s	hadoop-aws in the patch failed with JDK v1.8.0_60.
Please don't ignore the failure. The patch breaks "mvn package -Pdist -DskipTests" with JDK8. I'll create a follow-on jira to fix it.

FAILURE: Integrated in Hadoop-Hdfs-trunk #2515 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2515/])
HADOOP-11684. S3a to use thread pool that blocks clients. (Thomas Demoor (lei: rev bff7c90a5686de106ca7a866982412c5dfa01632)
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/TestBlockingThreadPoolExecutorService.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/BlockingThreadPoolExecutorService.java
* hadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/index.md
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Constants.java
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/TestS3ABlockingThreadPool.java


Filed HADOOP-12553.

Can I note that this was checked in with javadoc failing: -1	javadoc	0m 19s	hadoop-aws in the patch failed with JDK v1.8.0_60.



Err, shouldn't the removal of a tune-able throw a deprecation warning or be an incompatible change not eligible for branch-2?

[~stevel@apache.org]  What is up with these failures:

JDK v1.8.0_60 Failed junit tests	hadoop.ipc.TestIPC
 	hadoop.ha.TestZKFailoverController
 	hadoop.metrics2.impl.TestMetricsSystemImpl
JDK v1.7.0_79 Failed junit tests	hadoop.metrics2.impl.TestMetricsSystemImpl
 	hadoop.security.ssl.TestReloadingX509TrustManager

If commit checks are not reliably green, how do you guys tell what is a "valid" failure and what is noise?

Are there Jiras open to fix these issues?

Thanks for finding the issues. [~aw], [~ajisakaa] and [~stevel@apache.org]

I reverted the change in branch-2.

Aaron - We are having jenkins problems, with (a) stability and (b) people caring about they've just broken the build. 

How to tell
# if you look at >1 jenkins patch runs you learn to recognise which tests are unreliable right now
#  https://builds.apache.org/view/H-L/view/Hadoop/ gives you the overall view
# given the location of a patch, anything which only touches a single module is likely to have no impact on modules other than it and its direct/indirect dependencies.

Here it was clear that the test runs had to be unrelated (we all hate ZKFailover controller), but javadoc was something else

Hi [~eddyxu], would you move the section in CHANGES.txt from 2.8.0 to 3.0.0?

[~ajisakaa] Thanks a lot for this note. I put the changes into 3.0.0 section in CHANGES.txt.  

Really sorry for all these troubles. 

FAILURE: Integrated in Hadoop-trunk-Commit #8776 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/8776/])
Fix CHANGES.txt for HADOOP-11684. (lei: rev 655d43442f5cc0ba54597d283cdfa576a76ae3ed)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt


FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #654 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/654/])
Fix CHANGES.txt for HADOOP-11684. (lei: rev 655d43442f5cc0ba54597d283cdfa576a76ae3ed)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt


FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #643 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/643/])
Fix CHANGES.txt for HADOOP-11684. (lei: rev 655d43442f5cc0ba54597d283cdfa576a76ae3ed)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt


SUCCESS: Integrated in Hadoop-Yarn-trunk #1377 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/1377/])
Fix CHANGES.txt for HADOOP-11684. (lei: rev 655d43442f5cc0ba54597d283cdfa576a76ae3ed)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt


FAILURE: Integrated in Hadoop-Mapreduce-trunk #2584 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2584/])
Fix CHANGES.txt for HADOOP-11684. (lei: rev 655d43442f5cc0ba54597d283cdfa576a76ae3ed)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt


FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #585 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/585/])
Fix CHANGES.txt for HADOOP-11684. (lei: rev 655d43442f5cc0ba54597d283cdfa576a76ae3ed)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt


FAILURE: Integrated in Hadoop-Hdfs-trunk #2524 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2524/])
Fix CHANGES.txt for HADOOP-11684. (lei: rev 655d43442f5cc0ba54597d283cdfa576a76ae3ed)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt


Playing with this and large files, i'm starting to think we should actually have defaults of lower fs.s3a.threads.max and a longer queue. Why? it's too easy with 10 threads to OOM a big distcp from outside an AWS DC.

[~stevel@apache.org] I assume you are testing with fast upload on?  Should we file a new jira for this?

I'm doing a whole new upload stream in HADOOP-13560; leaving the fast upload stream alone *for now*; even tuning those settings isn't enough to eliminate risk of heap overflows. Its just that the current settings are fairly vulnerable if you set a large partition size, as the amount of ram consumed is O((threads + tasks) * partitionSize)

[~stevel@apache.org] you should not make the queue (tasks) long. Indeed the consumed memory is (threads + tasks + 1) * partitionSize) (the 1 is due to the buffer itself )

The point of this ticket was to introduce the BlockingThreadPoolExecutorService that, in contrast to the default Executorservice, does not error out when the queue is full but blocks ALL clients from making progress (= using additional memory), not even in the calling thread (thus different from CallerRunsPolicy). 

Threads = number of parallel busy (part)uploads 
Tasks = waiting uploads (already in memory)

The intended usage is setting the number of threads and tasks to small values (threads=3, (waiting)tasks= 1). Additional work coming in from the application will be blocked due to the special executorservice.




I concur with the small numbers. The defaults of 10, 10 are too big

