Looks like Hadoop QA is down again.
{code}
+          if (!isAppendSupported(conf)) {
+            LOG.warn("Running on HDFS without append. Can't recover the lease with append.");
+            break;
+          }
{code}
Should we return in the above case ? Otherwise we incur the 1 second sleep.

In the above case, when ex != null I think throwing ex out of recoverFileLease() may be more informative to the caller.

bq. Should we return in the above case ? Otherwise we incur the 1 second sleep.
It's safer and more logic to continue waiting, no? Btw, is there a document explaining the cases where append would work while recoverLease would not?

Looking at the code again, we should as well ensure that we try a minimum number of time: currently, if we have any issue (a garbage collection at the wrong time for example), we will stop trying, and do for the append way. WDYT?

bq. It's safer and more logic to continue waiting
Looking at the code again, I agree. It is just that with the proposed change, isAppendSupported() may be called more than once.
{code}
        SequenceFile.Writer.class.getMethod("syncFs", new Class<?> []{});
{code}
Above call may be executed more than once.

bq. is there a document explaining the cases where append would work while recoverLease would not?
I plan to look at revision history to find out.

"hbase.lease.recovery.timeout" has default value of 5 minutes. GC shouldn't be that long, right ?

bq. "hbase.lease.recovery.timeout" has default value of 5 minutes. GC shouldn't be that long, right ?
You're right, I missed one of the '0' actually. Sorry.


bq. Looking at the code again, I agree. It is just that with the proposed change, isAppendSupported() may be called more than once.
Ok, I will read it at the beginning then.


bq. I plan to look at revision history to find out.
Ok, if you find something tell me, because if we can get rid of it, it will save us from a complicated setting and a warning when we start hbase :-).




After some digging, I found https://issues.apache.org/jira/secure/attachment/12472743/3285-v3.txt
where recoverLease was introduced.

Looks like using append to trigger the close of HLog during Hlog split was first implementation as safeguard.

Would it make sense to rely solely on lease recovery in 0.95 and beyond ?

From this paper, it seems recoverLease was introduced by Facebook: http://borthakur.com/ftp/RealtimeHadoopSigmod2011.pdf
In the 0.89 branch, we do have the append as a failback mechanism: http://svn.apache.org/viewvc/hbase/branches/0.89-fb/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java?revision=1377223&view=markup. [~amitanand], [~nspiegelberg] do you know what are the implications of removing append here?


[~nkeywal]  Amit or Pritam will know about failure scenarios much better, but we originally put in the append() fallback because we had mixed HDFS version scenarios not because of disjoint functionality. 

Thanks a lot for the information, it clarifies something that was quite confusing for me. It means that we can remove this in 0.96, except if someones comes in saying that we can have users with an hold hdfs version. In all case, I can update the doc to lower the configuration requirement to set 'support append' to true. I will publish an update patch this Friday.

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12575747/HBASE-8204.v1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/5035//console

This message is automatically generated.

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12576140/8204.v2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified tests.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/5049//console

This message is automatically generated.

{code}
+        //  file is closed, false when it starts the lease recovery, true when the lease recovery
{code}
I understand the above comment. But for people unfamiliar with how lease recovery works, it may be clearer to separate the two cases w.r.t. whether the file is closed.
Simplest is to use semicolon following 'file is closed'.
{code}
-        } else if (e instanceof LeaseExpiredException &&
-            e.getMessage().contains("File does not exist")) {
-          // This exception comes out instead of FNFE, fix it
{code}
The above is not needed anymore ?

Please consider changing the subject of this JIRA because we're taking out fs.append() call.

{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12576144/8204.v3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified tests.

    {color:green}+1 hadoop2.0{color}.  The patch compiles against the hadoop 2.0 profile.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 lineLengths{color}.  The patch does not introduce lines longer than 100

  {color:green}+1 site{color}.  The mvn site goal succeeds with this patch.

     {color:red}-1 core tests{color}.  The patch failed these unit tests:
                       org.apache.hadoop.hbase.coprocessor.TestMasterObserver
                  org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithRemove
                  org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort
                  org.apache.hadoop.hbase.master.TestMasterTransitions
                  org.apache.hadoop.hbase.master.TestTableLockManager
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat

Test results: https://builds.apache.org/job/PreCommit-HBASE-Build/5050//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/5050//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/5050//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/5050//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/5050//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/5050//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/5050//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/5050//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/5050//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html
Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/5050//console

This message is automatically generated.

[~nkeywal] One motivation for you to remove the {code} FSDataOutputStream out = fs.append(p);{code} from function recoverFileLease. Today I found the test case TestDistributedLogSplitting#testWorkerAbort is flaky due to we don't handle java.nio.channels.ClosedByInterruptException when "recoverLease" get interrupted. Even after it's interrupted but it still calls fs.append which result in an extra minute wait so fails the test case with timeout error. Below are related traces:
{code}
2013-04-01 14:45:04,735 DEBUG [SplitLogWorker-10.11.2.103,58161,1364852631051] util.FSHDFSUtils(95): Failed fs.recoverLease invocation, java.io.IOException: Call to localhost/127.0.0.1:58147 failed on local exception: java.nio.channels.ClosedByInterruptException, trying fs.append instead
2013-04-01 14:45:04,735 DEBUG [SplitLogWorker-10.11.2.103,58161,1364852631051] util.FSHDFSUtils(100): trying fs.append for hdfs://localhost:58147/user/jzhong/hbase/.logs/10.11.2.103,58161,1364852631051/10.11.2.103%2C58161%2C1364852631051.1364852632043 with java.io.IOException: Call to localhost/127.0.0.1:58147 failed on local exception: java.nio.channels.ClosedByInterruptException
...
2013-04-01 14:46:04,737 WARN  [SplitLogWorker-10.11.2.103,58161,1364852631051] regionserver.SplitLogWorker$1(124): log splitting of hdfs://localhost:58147/user/jzhong/hbase/.logs/10.11.2.103,58161,1364852631051/10.11.2.103%2C58161%2C1364852631051.1364852632043 failed, returning error
java.io.IOException: Failed to open hdfs://localhost:58147/user/jzhong/hbase/.logs/10.11.2.103,58161,1364852631051/10.11.2.103%2C58161%2C1364852631051.1364852632043 for append
        at org.apache.hadoop.hbase.util.FSHDFSUtils.recoverFileLease(FSHDFSUtils.java:126)
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.getReader(HLogSplitter.java:743)
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.splitLogFile(HLogSplitter.java:436)
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.splitLogFile(HLogSplitter.java:397)
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker$1.exec(SplitLogWorker.java:111)
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.grabTask(SplitLogWorker.java:274)
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.taskLoop(SplitLogWorker.java:195)
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.run(SplitLogWorker.java:162)
        at java.lang.Thread.run(Thread.java:680)
Caused by: java.io.IOException: Call to localhost/127.0.0.1:58147 failed on local exception: java.nio.channels.ClosedByInterruptException
        at org.apache.hadoop.ipc.Client.wrapException(Client.java:1144)
        at org.apache.hadoop.ipc.Client.call(Client.java:1112)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
â€¦.
{code}  

[~jeffreyz]
Nice catch (and another example of 'why it is bad to catch the raw Exception class'). I definitively wish to have this into 0.95/0.96. I will submit a new version that takes Ted's comment into account today.

V4. Ted's comments taken into account. All tests that failed on the Jenkins build worked locally.

{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12576538/8204.v4.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified tests.

    {color:green}+1 hadoop2.0{color}.  The patch compiles against the hadoop 2.0 profile.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 lineLengths{color}.  The patch does not introduce lines longer than 100

  {color:green}+1 site{color}.  The mvn site goal succeeds with this patch.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HBASE-Build/5092//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/5092//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/5092//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/5092//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/5092//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/5092//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/5092//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/5092//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/5092//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html
Console output: https://builds.apache.org/job/PreCommit-HBASE-Build/5092//console

This message is automatically generated.

Tests ok (it's great that the precommit env can now be green sometimes), so waiting for +1 to commit.

+1 from me.

SUCCESS: Integrated in HBase-0.94-security #240 (See [https://builds.apache.org/job/HBase-0.94-security/240/])
HBASE-8670 [0.94] Backport HBASE-8449,HBASE-8204 and HBASE-8699 to 0.94 (Refactor recoverLease retries and pauses) (enis: rev 1509532)
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/util/FSHDFSUtils.java
* /hbase/branches/0.94/src/main/resources/hbase-default.xml
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestHLog.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/util/TestFSHDFSUtils.java


SUCCESS: Integrated in HBase-0.94 #1088 (See [https://builds.apache.org/job/HBase-0.94/1088/])
HBASE-8670 [0.94] Backport HBASE-8449,HBASE-8204 and HBASE-8699 to 0.94 (Refactor recoverLease retries and pauses) (enis: rev 1509532)
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/util/FSHDFSUtils.java
* /hbase/branches/0.94/src/main/resources/hbase-default.xml
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestHLog.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/util/TestFSHDFSUtils.java


