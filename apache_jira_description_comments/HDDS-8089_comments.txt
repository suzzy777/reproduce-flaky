I mistakenly filed a dup of this in HDDS-8379. In the zip file attached there it looks like RocksDB seg faulted during the test.

bq. In the zip file attached there it looks like RocksDB seg faulted during the test.

There were two failed attempts:

1. [{{TestOzoneManagerHAWithData}} crashed|https://github.com/apache/ozone/actions/runs/4523186498/jobs/7966155110#step:5:3754] (fixed by HDDS-8282)
2. [TestOmSnapshot.checkKey failed|https://github.com/apache/ozone/actions/runs/4523186498/jobs/7980400152#step:5:3643] (this issue)

[CI|https://github.com/mladjan-gadzic/ozone/actions/workflows/HDDS-8089.yml] is configured to continuously run as per [doc|https://cwiki.apache.org/confluence/display/OZONE/Github+Actions+tips+and+tricks]. 

I noticed next:
* unusual number of iteration failures due to timeout
* {{testBucketDeleteIfSnapshotExists}} test seems to be flaky as well, check [CI run|https://github.com/mladjan-gadzic/ozone/actions/runs/5267378106/jobs/9522554071#step:4:7286]

Timeout was increased from 180sec to 300sec but it still happens. I added logs for {{checkKey}} test and I am closely monitoring it. 

[~adoroszlai] you might have an experience with tests that have intermittent failure. Is there any chance that CI setup as above can impact results of the tests? So far that was not the case for other tests that have intermittent failure which I worked on.

[~mladjangadzic],

bq. any chance that CI setup as above can impact results of the tests?

Seems unlikely, your setup looks good.

You might want to rebase on current master to skip native build, saving 15 minutes.

[~adoroszlai],
{quote}You might want to rebase on current master to skip native build, saving 15 minutes.{quote}

Thanks! I will try that.

According to latest [CI|https://github.com/mladjan-gadzic/ozone/actions/runs/5339000207/jobs/9677134108#step:4:5183] run, it looks likeÂ there is one more flaky test {{TestOmSnapshot.testBucketDeleteIfSnapshotExists}}. I checked and there is no Jira for this? Would you like me to create one?

