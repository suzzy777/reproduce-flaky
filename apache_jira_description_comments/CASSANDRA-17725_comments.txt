interdcstreamthroughput flags added in this  [commit|https://github.com/ekaterinadimitrova2/cassandra/commit/d5e7134c99e5e938b74c2ad74fbf2c916f0785ce] and streamthroughput flag added in this [commit|https://github.com/ekaterinadimitrova2/cassandra/commit/9c6e1452a939ad5420daa5eefce33ac5b6e050ec] 

The only thing I am wondering here is how to handle that nodetool and the StorageService JMX methods are rounding to int and 0 very small values in megabits to MiB/s (the getters in MiB, when we provide too small megabits) I added in nodetool a check that will say instead of unlimited - 1 MiB/s. I plan to document that when you use one or the other unit you should use the respective setter/getter as otherwise you might see that side effect. Seeing 0 in MiB - someone might decide that they are unthrottling when in reality they have super low value in megabits internally. What do others think about this?

I had a few findings which I addressed in separate commits:
 * [several changes in output|https://github.com/ekaterinadimitrova2/cassandra/commit/92e0c3948fc65b29fbe289814f84aaf603188152] - I tried instead to clarify the unit in the description
 * [cassandra.yaml|https://github.com/ekaterinadimitrova2/cassandra/commit/153ccb6dfff630b2229bbcc5c92d201e5e5d2616] - there were a few parameters which were commented for testing and that was not reverted. It doesn't break anything as then we are using the same default value which is in DatabaseDescriptor but it is not needed change and makes it confusing for the users
 * I believe this [withBufferSizeInMB|https://github.com/ekaterinadimitrova2/cassandra/commit/d16170fd6a15f2ec20acd057e8f44ec5ded39094] method had to be deprecated and not just removed

And a few topics I am adding for discussion:

- [https://github.com/apache/cassandra/commit/5bb4bab12f8edfef95ed13cbabf8c0f377986065#diff-f7dd0237c343649f70b7ec9fefd7f6941a40b5164fd6063dce00fc09d2c234a7L163-R163] - method which is not exposed by the mbean but it is public; is this a breaking change?
 * [https://github.com/apache/cassandra/commit/c51a7c66fc21ca2da08b89ae5f9b4817ee4d8c23#diff-2314788f556b14ab8cd9c4cf4eba04f4b292f0b9c93d74919eed33a0af42ababL279-L280] —> breaking change?? - I doubt it but double-checking. I can revert it just to be on the safe side

And a bug I found that I want to ask [~jolynch] for advise as he was involved into adding that property:

[https://github.com/apache/cassandra/commit/9f56bf4ca7fdb61ad09e5f2ad09b87cd01e0716b#diff-77707d0908c31940828b6425dcb09a7409827db99b48c371f71c63294dfe1562L444-R444] —> please check, I believe this change is a bug. The Converter used for that property with the pre-4.0 format does not allow negatives and we will always have 0 in AutoSavingCache where we check for negatives and not 0. The test where this was set to -1 is testKeyCacheLoadZeroCacheLoadTime and it works without an issue with 0. . For [~jolynch] - long story short we prohibited the usage of negatives as it was considered a bug in 4.1. But it seems different here with this property. If negatives and 0 will do the same (I am not sure, didn’t dive too much into that patch), maybe we can use the  _NEGATIVE_SECONDS_DURATION_ converter from the Converters class we added for validation_preview_purge_head_start which will convert a negative number to 0 in 4.1 and tell people from now on will use 0 to disable but at the same time if they upgrade with negative and the old value format and property name, they will be able to set negative number which will be migrated internally to 0. I am really not completely sure, what do others think?

CI running here for the 4.1 branch: [j8|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1767/workflows/5f62f5d2-0930-4084-9031-61e1087b22fb], [j11|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1767/workflows/781c87d6-9ea1-45ad-838e-53e0d9ee50ee]

[~maedhroz] , [~dcapwell] , [~mck] , can I ask you for review, please?

{quote}And a bug I found that I want to ask [~jolynch] for advise as he was involved into adding that property:

[https://github.com/apache/cassandra/commit/9f56bf4ca7fdb61ad09e5f2ad09b87cd01e0716b#diff-77707d0908c31940828b6425dcb09a7409827db99b48c371f71c63294dfe1562L444-R444] —> please check, I believe this change is a bug. The Converter used for that property with the pre-4.0 format does not allow negatives and we will always have 0 in AutoSavingCache where we check for negatives and not 0. The test where this was set to -1 is testKeyCacheLoadZeroCacheLoadTime and it works without an issue with 0. . For [~jolynch] - long story short we prohibited the usage of negatives as it was considered a bug in 4.1. But it seems different here with this property. If negatives and 0 will do the same (I am not sure, didn’t dive too much into that patch), maybe we can use the  _NEGATIVE_SECONDS_DURATION_ converter from the Converters class we added for validation_preview_purge_head_start which will convert a negative number to 0 in 4.1 and tell people from now on will use 0 to disable but at the same time if they upgrade with negative and the old value format and property name, they will be able to set negative number which will be migrated internally to 0. I am really not completely sure, what do others think?
{quote}
Or maybe [~hari_nv] or [~marcuse] can help me with this question as you were also working on CASSANDRA-14898 where the property was added?

bq. maybe we can use the  NEGATIVE_SECONDS_DURATION converter from the Converters class we added for validation_preview_purge_head_start which will convert a negative number to 0 in 4.1 and tell people from now on will use 0 to disable but at the same time if they upgrade with negative and the old value format and property name, they will be able to set negative number which will be migrated internally to 0. I am really not completely sure, what do others think?

The sequence in the code is...

{noformat}
long start = nanoTime();
...
long loadByNanos = start + TimeUnit.SECONDS.toNanos(DatabaseDescriptor.getCacheLoadTimeout());
while (nanoTime() < loadByNanos && in.available() > 0)
{
// do saved cache loading stuff
{noformat}

So unless the high-resolution clock goes backwards, -1 and 0 should have the same effect. (i.e. {{start == loadByNanos}} and getting {{nanoTime()}} again should be >= {{start}}) The condition of the {{while}} loop, if interpreted strictly as "don't try any more saved cache loading if we've hit the load-by time", is fine, and I think the only concern we have is making sure an inherited -1 from an old config doesn't make things explode. (There was never any explicit checking for -1 in the original patch that I can see.)

If the original logic had been...

{noformat}
while (nanoTime() <= loadByNanos && in.available() > 0)
{noformat}

...perhaps you could have imagined a case for zero where the clock didn't advance, and you would have been able to load the first table in the while body, but that seems pretty esoteric.

{quote}The only thing I am wondering here is how to handle that nodetool and the StorageService JMX methods are rounding to int and 0 very small values in megabits to MiB/s (the getters in MiB, when we provide too small megabits) I added in nodetool a check that will say instead of unlimited - 1 MiB/s. I plan to document that when you use one or the other unit you should use the respective setter/getter as otherwise you might see that side effect. Seeing 0 in MiB - someone might decide that they are unthrottling when in reality they have super low value in megabits internally. What do others think about this?
{quote}
Why don't we just simplify things and leave MiB/s values as doubles everywhere? If we do that for JMX and {{{}nodetool{}}}, can't we just sidestep the rounding ambiguity almost entirely? (I mean, we still need to decide on how many decimals we'll report, but we can probably do 2 or 3 and call it a day.) I don't see any reason to force a rounded/integer output when it would only materialize in conjunction with our new flag.

Other minor notes from my pass at review:
 - In the {{MEGABITS_TO_MEBIBYTES_PER_SECOND_DATA_RATE}} JavaDoc, "megatibs" -> "megabits"?
 - There's enough in common that it might be nice to combine {{SetGetInterDCStreamThroughputMiBTest}} and {{SetGetInterDCStreamThroughputTest}} into a single {{{}InterDCStreamThroughputConfigTest{}}}. (Same goes for the non-inter-DC versions.)
 - In {{{}StorageService{}}}, we have {{{}int oldValue = (int) DatabaseDescriptor.getStreamThroughputOutboundMebibytesPerSec();{}}}. Why not just get the existing value as a double and log it that way? (Happens in {{setStreamThroughputMebibytesPerSec}} and {{{}setInterDCStreamThroughputMebibytesPerSec{}}}.)
 - Given we're going to a new major version, did we really have to change {{MiB}} back to {{MB}} in [this commit|https://github.com/ekaterinadimitrova2/cassandra/commit/92e0c3948fc65b29fbe289814f84aaf603188152]? Even if someone was parsing tool output, they still would only break if they explicitly validated "MB" rather than just making sure to take the numeric value, right?
 - Two things on {{"i", "stream_throughput_mib"}}. First, is the normal pattern to use hyphens instead of underscores for the long form? Second, given this is a modifier on the default argument, why not just use something like {{"m", "mib"}}?

{quote}...perhaps you could have imagined a case for zero where the clock didn't advance, and you would have been able to load the first table in the while body, but that seems pretty esoteric.
{quote}
That's what I was thinking but figured that the world of Cassandra is always surprising me so better to check also with reviewer/authors. I will take care of the converter
{quote}bq. Why don't we just simplify things and leave MiB/s values as doubles everywhere?
{quote}
While it is tempting, I think it might be confusing for the end users. They can't be setting double numbers but they are getting some and only for the mebibytes version. Also, we cannot switch to doubles for the megabits which are 4.0-addition properties and they will still suffer of that problem. This is also an issue with the bulk loader that [~frankgh] fights. In theory I would expect/recommend people to set and get with the same unit, but the practice is different - someone will come and just use the first getter they see to check values...

I started wondering whether we should not make those flags bytes and not mebibytes and internally those properties also can be operated in bytes. It will also automatically solve the Settings Virtual table (the precision there) as a side effect. But he issue is that people will have to input quite big numbers and they can make mistakes, MiB/s was not chosen randomly I think. 
{quote} - Given we're going to a new major version, did we really have to change {{MiB}} back to {{MB}} in [this commit|https://github.com/ekaterinadimitrova2/cassandra/commit/92e0c3948fc65b29fbe289814f84aaf603188152]? Even if someone was parsing tool output, they still would only break if they explicitly validated "MB" rather than just making sure to take the numeric value, right?{quote}
I would personally keep the MiB but after all latest discussions I would prefer to revert it and just use it in the description, if you don't mind :) 
{quote} - Two things on {{{}"i", "stream_throughput_mib"{}}}. First, is the normal pattern to use hyphens instead of underscores for the long form? Second, given this is a modifier on the default argument, why not just use something like {{{}"m", "mib"{}}}?{quote}
Good catch, definitely hyphens. I like the idea of switching to "mib" and "m", I will change this.
{quote} - In the {{MEGABITS_TO_MEBIBYTES_PER_SECOND_DATA_RATE}} JavaDoc, "megatibs" -> "megabits"?
 - There's enough in common that it might be nice to combine {{SetGetInterDCStreamThroughputMiBTest}} and {{SetGetInterDCStreamThroughputTest}} into a single {{{}InterDCStreamThroughputConfigTest{}}}. (Same goes for the non-inter-DC versions.){quote}
Will include in the PR tomorrow, thanks

bq. While it is tempting, I think it might be confusing for the end users. They can't be setting double numbers but they are getting some and only for the mebibytes version. Also, we cannot switch to doubles for the megabits which are 4.0-addition properties and they will still suffer of that problem.

I would really like to avoid rounding. The comment [here|https://github.com/ekaterinadimitrova2/cassandra/commit/d5e7134c99e5e938b74c2ad74fbf2c916f0785ce#diff-f365bd58caccc9a8022b55c1d7706d7543057a56333df0a9ab5b952c29d96695R38] doesn't feel very friendly. Even if we can't use non-integers in any of our setters, not using exact values for the getter seems suboptimal. (What if someone doesn't pay attention to the option comment? I'd rather have an error message saying you need to use integers in the setter than rely on that.)

Other than that, +1 from me.

EDIT: Let's also make sure we don't explode on an inherited {{-1}} for {{cache_load_timeout_seconds}}. The {{NEGATIVE_SECONDS_DURATION}} solution works for me, along the lines of our discussion above.

I just rebased and pushed a [commit|https://github.com/ekaterinadimitrova2/cassandra/commit/09d0a4104d803771bef4f5d0637e64aeee771ce8] to address the review comments, except for the doubles.

A proposal I have is:
 * the old deprecated methods (from 4.0; getStreamThroughputMbPerSec and getInterDCStreamThroughputMbPerSec) still should return int but we can throw error message that they need either to use some of the other methods or to set a whole number in megabits when the actual number internally is not an integer.
 * make all new methods (both megabits and mibs) to return double plus printing double in the setters as you pointed.

Does this sound reasonable and do you think I should confirm it on the mailing list?

Also, further to the review comments I added the check for upper bound when assigning the two old properties in the setters and added a unit test for that. I also added a unit test for cache_load_timeout_seconds = -1. 

bq. Does this sound reasonable and do you think I should confirm it on the mailing list?

I'd rather have an explicit error message than hidden rounding. If that's the approach you like best that avoids the latter, I'm fine w/ it. (For the new methods, I don't even care if we print whole number if there are no significant digits after the decimal anyway.) Probably doesn't rise to the level of needing ML involvement, but it never hurts.

bq. I also added a unit test for cache_load_timeout_seconds = -1. 

Sweet.

[Mail|https://lists.apache.org/thread/vgnjnkhbml7zocxpohth8x443rzgvbz5] fired to the mailing list. 

As agreed on the Mailing list I went for error out in the old megabits int JMX methods.

Further to that, I realized that we better move the 4 properties to LongBytesBound internally so that we do not struggle internally with megabits to mebibytes and the opposite as the Rate Limiter is also getting bytes anyway. Also, this will help with another ticket (CASSANDRA-17677) where if we keep the mebibytes/s internally we should do a bunch of not needed calculations. CC [~frankgh] 

Now the issue that [CI reminded me of|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra?branch=test-bytes-4.1] is that JMX getters should not throw exceptions. (Please check the in-jvm failure - org.apache.cassandra.distributed.test.jmx.JMXGetterCheckTest.test, the other 2 were test issues that I already fixed) We can error out in nodetool I guess but tools as JConsole will just output Unavailable the attribute which is bad. :( 

So I guess what we can do is to add double version of those methods and deprecate the old ones? Nodetool I guess we can make to error out but the JMX methods - we will have to leave to round and put in bold everywhere a point about the rounding - the docs, the NEWS.txt, CHANGES.txt and we can even make a point on social media...

What do you think about that?

This is the new branch where the latest suggestion resides: [4.1|https://github.com/apache/cassandra/compare/trunk...ekaterinadimitrova2:cassandra:test-bytes-4.1] , the last two commits

Also, in the Settings Virtual Table the old property will be rounded, note to self - I have to make the new MiB properties to return there double... 

One more point - the posted branch is not ready for full-fledged review, it is draft for confirming the final version we want as it is easier to show some code than just descriptions. 

bq. So I guess what we can do is to add double version of those methods and deprecate the old ones?

As long as nothing new does any rounding, fine with me. We could also just not have the old {{nodetool}} commands worry about {{MiB}}, given there are going to be new methods anyway, where we won't have to round.

{quote}We could also just not have the old {{nodetool}} commands worry about {{{}MiB{}}}, given there are going to be new methods anyway, where we won't have to round.
{quote}
We can't really as then the setters will be adding the 2 new entire_sstable* parameters in mebibytes/s and the old two in megabits/s which I bet will be a total mess unfortunately.

I did the changes, added a bunch of unit tests. Also took care about compaction_throughput as it was suffering from the same issues even if it was already in mebibytes/s. (nodetool takes it in MiB/s)

Further to the setters/getters CompactionStats was also affected from the rounding. The good news are that it was already producing output in bytes so I just had to change the methods to point to the right byte methods to ensure no intermediate non-precise calculation happens in between. 

This is the new 4.1  [PR|https://github.com/apache/cassandra/pull/1754]. I still haven't squashed with the old commits you already saw, hopefully to make it easier to review this last part. The patch is rather noisy and it adds a lot of unit tests as the devil is in the details with this one.

[CI is fully green.|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra?branch=17725-4.1] 

I just submitted a commit to address any feedback from the previous PR [here|https://github.com/ekaterinadimitrova2/cassandra/commit/0a5da08fc4d269e2b7e0f5b23d44fd759821ecec]

CI run  [#1828|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra?branch=17725-4.1], there is only one [failed test|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1828/workflows/eadcc3a3-ec7d-40f3-99ec-fcf9b6db8d11/jobs/14115/tests#failed-test-0] which seems unrelated but  we might want to open a followup ticket?

Also, for the record, we agreed to remove IntMeibytesBound nested class now when it is not needed anymore and we don't want to encourage people to start using it. (while we are still in alpha release)

+1 LGTM

bq. there is only one failed test which seems unrelated but  we might want to open a followup ticket?

WFM...the CAS tests seem generally flaky right now

Thanks [~maedhroz] , I will wait to see if [~frankgh] is happy with the latest changes and then squash, add the NEWS.txt entries and propagate also to trunk. Pending also full CI

Looks good to me! Thanks for addressin the feedback

Thank you both [~frankgh] and [~maedhroz] .

I squashed the commits, updated NEWS.txt and CHANGES.txt and also propagated the patch to trunk.
||Patch||CI||
|[4.1|https://github.com/apache/cassandra/commit/314ac8d890c90930e14d5e45744e3da229015443]| [Circle CI|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra?branch=17725-4.1-final]|
|[trunk|https://github.com/apache/cassandra/commit/9355fd9603ee7c1e0730091559722be0ae2101b2]|[Circle CI|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra?branch=17725-trunk-final]|

Pending commit on CI, also I will reformat a bit the commit msg on commit.

CI results:

4.1 - [test_parent_repair_session_cleanup|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1830/workflows/0ca3086d-6651-4f06-acab-2cd2ea208d93/jobs/14139/tests#failed-test-0]  failed for port being potentially busy to be used by Jolokia, I think this is environmental seen with different tests before

trunk -  [transient_replication_test.TestTransientReplicationRepairStreamEntireSSTable|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1829/workflows/b123b955-9fbb-413e-a2a5-8f654dabee1f/jobs/14193/tests#failed-test-0] failed for port being potentially busy to be used by Jolokia, same as the previous one

Also, I reran those two tests locally and they pass successfully.

Starting commit soon.  

Committed:

fe28f482db..dd08314ed6  cassandra-4.1 -> cassandra-4.1

0daf21244f..62ac5da78a  trunk -> trunk

