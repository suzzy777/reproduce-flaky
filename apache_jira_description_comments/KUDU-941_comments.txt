when deleting large tables on bolt80, we end up hitting this issue about half the time. Should try to fix this for beta.

this is also apparently causing some flakiness of some of the delete_table-test test cases.. hitting the following sequence:
- we delete the table
- master deletes one replica
- the leader hasn't been deleted yet, and tells the replica to bootstrap
- the bootstrap fails for some reason (either another bug, or maybe because the leader got deleted?), but only after writing its "BOOTSTRAPPING" state metadata to disk
- the replica ends up orphaning that metadata file on disk, and the test times out waiting for the metadata to get deleted.

Perhaps the trick here is we should tablet-report the peer as soon as we start bootstrapping it. That's good for status reporting to the master, and also means that if the table has been deleted, the master will wake up and tell the TS to delete it again?

[~mpercy] is working on this this week.

This patch was pushed back in August as 85ffb65960e351c59e569dc668dd35b51dff5324

