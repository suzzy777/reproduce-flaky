renamed to SimpleReadWriteTest so :

{code}
junit.framework.AssertionFailedError
	at org.apache.cassandra.distributed.test.SimpleReadWriteTest.readWithSchemaDisagreement(SimpleReadWriteTest.java:274)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
{code}

as seen in https://circleci.com/gh/clohfink/cassandra/674

This was renamed in 0f22dab1a015cb84d9857f940de5a256bfbee083

This is relatively easy to reproduce. We can get three types of responses here.  The one the test wants:

{code}
org.apache.cassandra.exceptions.ReadFailureException: Operation failed - received 1 responses and 1 failures: INCOMPATIBLE_SCHEMA from 127.0.0.3:7012, INCOMPATIBLE_SCHEMA from 127.0.0.2:7012
{code}

but sometimes with two failures:
{code}
org.apache.cassandra.exceptions.ReadFailureException: Operation failed - received 1 responses and 2 failures: INCOMPATIBLE_SCHEMA from 127.0.0.3:7012, INCOMPATIBLE_SCHEMA from 127.0.0.2:7012
{code}

And sometimes either one of the nodes by itself:
{code}
org.apache.cassandra.exceptions.ReadFailureException: Operation failed - received 1 responses and 1 failures: INCOMPATIBLE_SCHEMA from 127.0.0.3:7012
{code}
 
At the least it seems we have a legit problem with terminology or counting here.

Anyone working on this one?

I don't know of anyone working on it.

Any guidance or suggestions [~ifesdjeen] since this is your test?

I have been looking into this issue and trying to reproduce it locally. Did not have much luck, re-executed the test about 2500 times (let it run overnight) and only managed to reproduce something ~inconsistent in one case.

The test setup is: execute a schema alteration request on 1 node, don't let the node propagate the schema changes to other nodes, then execute a select at Consistency = ALL on that same node and expect a failure, because the 2 other nodes did not get the schema alteration request.

So the message we expect from the Select request would be the following:
{code:java}
Operation failed - received 1 responses and 2 failures: INCOMPATIBLE_SCHEMA from 127.0.0.3:7012, INCOMPATIBLE_SCHEMA from 127.0.0.2:7012{code}
Node1's response is successful (because it has the schema changes), but all the others fail because they have a stale schema.

The closest I got to reproducing something inconsistent to this was:
{code:java}
Operation failed - received 0 responses and 2 failures: INCOMPATIBLE_SCHEMA from 127.0.0.3:7012, INCOMPATIBLE_SCHEMA from 127.0.0.2:7012{code}
But also let's consider the ones Brandon had observed.

I have looked into some of the places where {{ReadFailureException}} are generated, and landed in the [{{ReadCallback}}|https://github.com/apache/cassandra/blob/aed15bfb01e753f9bac8b149b382c7a7c8d33183/src/java/org/apache/cassandra/service/reads/ReadCallback.java#L162] class.

The logic of the code is:
- call {{awaitResults()}}
- in {{awaitResults()}}:
-- block on {{await()}}
-- when {{await()}} exits, check what responses we got and whether errors came back

Also looked into {{onFailure()}} method, the logic is the following:
{code:java}
int n = waitingFor(from)
      ? failuresUpdater.incrementAndGet(this)
      : failures;

failureReasonByEndpoint.put(from, failureReason);

if (blockFor + n > replicaPlan().contacts().size()) {
    condition.signalAll(); // this signals as soon as 1 failure happens
}
{code}
{{waitingFor(from)}} is supposed to filter out errors coming from non local nodes it seems. In this test it always returns true, for simplicity we'll consider it is.
 Same for {{blockFor}}, and {{replicaPlan().contacts().size()}} these are both {{3}} for the test, I supposed these may differ in some use case.

As we can see above once 1 failure happens, the {{condition}} will be signaled to unblock waiting callers. When {{awaitResults()}} unblocks, it checks the value of {{failures}} to see how many errors happened and report it as a {{ReadFailureException}}.

The code is designed so that the {{condition}} is freed when either all responses are successful, or one failure happened.

Now my understanding of this is that, on certain circumstances, we end up returning an error message as soon as 1 error happens, and not wait for all responses to come back, and the values of {{failures}} and {{received}} are not guaranteed to be at a certain value, except we know in case of a failure that {{failures}} will be > 0.

I am unclear on what the expected behavior should be here. 
From my POV, I would think the most reasonable logic would be that {{await()}} only exits once all responses have come back, failed or successful, or it times out. Therefore I would replace the {{"SimpleCondition condition"}} with a {{CountDownLatch}} initialized to the value of the number of expected responses, and {{countDown()}} on {{onReceived()}} and {{onFailure()}} and have {{await()}} use that countDownLatch.

If the behavior of failing as soon as 1 failure happens is preferred, then the logic can stay that way, but the test needs to be modified to account for the possibility that only 1 error and No successful response may be returned in the {{ReadFailureException}}.

[~brandon.williams] [~e.dimitrova] got any insights?

Also, I suggested we wait for all responses because this is what the test expects, the test waits for the {{ReadFailureException}} to contain *both* failures without accounting for possible race conditions of the {{ReadCallback}} returning before all responses have come back.

EDIT: I confused the number of received and the number of failures, I think what is below is incorrect.

-Also noticed that in the current context, the number of {{failure}} and the list of failures can be inconsistent with each other, because we create the exception with-
{code:java}
new ReadFailureException(replicaPlan().consistencyLevel(), received, blockFor, resolver.isDataPresent(), failureReasonByEndpoint){code}
-Concurrently, {{received}} can have been incremented but not the map of {{failureReasonByEndpoint}} and we could end up with:-
{code:java}
Operation failed - received 1 responses and 2 failures: INCOMPATIBLE_SCHEMA from 127.0.0.3:7012{code}
-"2" failures but only 1 error message. (number of {{received}} is irrelevant)-

-Conversely, since the reference to the map is passed to {{ReadFailureException}} but {{received}} is passed by value, we can end up in the following scenario:-
 - -1 error triggers awaitResults() to unblock-
 - -call to {{new ReadFailureException(received, failureReasonByEndpoint)}}-
 - -value of 1 for {{received}} copied when calling {{ReadFailureException}} constructor but only reference to {{failureReasonByEndpoint}} given-
 - -concurrently second failure calls to {{onFailure()}} which updates {{failures}} and the map-
 - -{{ReadFailureException}} has the {{1}} value for {{failures}} but the map has been updated to have 2 failures and constructs the error message-

-We end up with the error message:-
{code:java}
Operation failed - received 1 responses and 1 failures: INCOMPATIBLE_SCHEMA from 127.0.0.3:7012, INCOMPATIBLE_SCHEMA from 127.0.0.2:7012{code}
-"1" failure but 2 error messages. (number of {{received}} is irrelevant)-

-One way to solve these issues would be to pass a copy of the {{failureReasonByEndpoint}} to the constructor of {{ReadFailureException}}.-

-If {{await()}} waited until all messages came back or timeout the 2 issues wouldn't be problematic I think.-

Actually I just realized that the value passed in the {{ReadFailureException}} constructor is {{received}}, I confused and thought it was the number of failures. Need to re-think about that comment above

{{RequestFailureException}} uses the map's size to find out the number of entries in it:

{code}
protected RequestFailureException(ExceptionCode code, ConsistencyLevel consistency, int received, int blockFor, Map<InetAddressAndPort, RequestFailureReason> failureReasonByEndpoint)
    {
        super(code, String.format("Operation failed - received %d responses and %d failures: %s",
                                  received,
                                  failureReasonByEndpoint.size(),
                                  buildFailureString(failureReasonByEndpoint)));
{code}

It does a copy of the map later in the constructor but I suppose there is still a chance the content of the map may be different between the call to {{size()}} and the entries when iterated in {{buildFailureString()}}.

Hi Kevin,

Thanks for the extensive explanation! I am gonna review everything on Monday. 

Have a nice weekend!

Sounds good, thanks, hope you had a good weekend :)

As a summary, 

In any case, I believe passing an immutable copy of the {{failureReasonByEndpoint}} map to the constructor of Read/WriteFailureException would reduce the chances for the {{number of failures}} and the failure messages to be inconsistent.

In addition to that, there's the remaining question of the behavior of ReadCallback when failures happen (do we fail fast? or do we wait for all responses to come back/timeout?). Depending on the outcome of that, the test that is flaky at the moment would need to be adjusted to expect 1 *or* 2 failures in the response.

Hi Kevin,

"In any case, I believe passing an immutable copy of the {{failureReasonByEndpoint}} map to the constructor of Read/WriteFailureException would reduce the chances for the {{number of failures}} and the failure messages to be inconsistent." 

Agree with you. I would personally expect 1 response from node1 where the schema was altered and two failures with the two messages. 

"In addition to that, there's the remaining question of the behavior of ReadCallback when failures happen (do we fail fast? or do we wait for all responses to come back/timeout?). Depending on the outcome of that, the test that is flaky at the moment would need to be adjusted to expect 1 *or* 2 failures in the response."

Or we can say "as soon as it fails more than 0 times" and be safe?

This is my personal interpretation.

I believe  [~ifesdjeen] would be the best person to confirm any details but for test fix this would be enough I think to make it deterministic. I don't see a bug but confusing responses to the user (same as you, as we discussed on Slack)

Thanks for the reply, Ekaterina, and for confirming the behavior described.

Got some more time to think about this, and it seems the best way to approach it, since what I suggest would be a larger behavioral change, would be to create a separate ticket for it. 

I think in this ticket I would rather: Fix the discrepancies between the failures number and the failure messages with the immutable map copy + fix the test that expects 2 failures to only expect 1 to match current behavior. 

Then, in the other ticket we can properly advocate/discuss pros and cons of returning cohesive error messages VS fail-fast & incohesive error message.

Does that make sense?

Yes, I would also separate them. This is test fix. The other one would be to improve the failure reporting for the end users and try to mitigate any potential confusion. 

Also, RequestFailureException is not used only here in the codebase...

bq. Also, RequestFailureException is not used only here in the codebase...

Right, I was planning on making the immutable copy changes for calls to WriteFailureException too

Changes available at https://github.com/newkek/cassandra/tree/15543-trunk/

[~ifesdjeen] since you were the author of the test originally, would you have some to review the fixes above? Thank you

Hi [~benedict], I've seen you have done quite a bit of work in {{ReadCallback}}, I was wondering if you had some cycles to take a look at the patch above (and optionally the discussion going on in this ticket)? Thanks

Probably not anytime soon I'm afraid, [~newkek]

I should be able to have the review done by tomorrow evening.

Great, thanks Benedict and Benjamin.

I have launched builds of this branch, you can see the results [on CircleCI|https://app.circleci.com/pipelines/github/newkek/cassandra?branch=15543-trunk]

After review from [~blerer] I have made some changes and the latest CI run is [here|https://app.circleci.com/pipelines/github/newkek/cassandra?branch=15543-trunk] as #11. All the unit and JVM dtests ran successfully.

Just pushed a small commit that removes some unused imports I forgot to clean up: [https://github.com/newkek/cassandra/commit/55e94d94168ec62b01bdb764e1ea74d3d217ec41] 

 

Feel free to squash

Patch committed into trunk at b6176906e71620b37920eaf84fa51516b046bdce

Thanks [~blerer]!

