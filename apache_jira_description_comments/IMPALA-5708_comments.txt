Saw another failure on a subsequent jenkins job. This time a different test failed:

{code}
08:37:05 =================================== FAILURES ===================================
08:37:05 _________ TestFragmentLifecycle.test_finst_cancel_when_query_complete __________
08:37:05 [gw0] linux2 -- Python 2.6.6 /data/jenkins/workspace/impala-umbrella-build-and-test/repos/Impala/bin/../infra/python/env/bin/python
08:37:05 query_test/test_lifecycle.py:87: in test_finst_cancel_when_query_complete
08:37:05     self.client.execute("with l as (select 1 from functional.alltypes), r as"
08:37:05 common/impala_connection.py:160: in execute
08:37:05     return self.__beeswax_client.execute(sql_stmt, user=user)
08:37:05 beeswax/impala_beeswax.py:194: in execute
08:37:05     result.exec_summary = self.get_exec_summary(handle)
08:37:05 beeswax/impala_beeswax.py:213: in get_exec_summary
08:37:05     self.__build_summary_table(summary, 0, False, 0, False, output)
08:37:05 beeswax/impala_beeswax.py:252: in __build_summary_table
08:37:05     for stats in node.exec_stats:
08:37:05 E   TypeError: 'NoneType' object is not iterable
08:37:05 ---------------------------- Captured stderr setup -----------------------------
08:37:05 -- connecting to: localhost:21000
08:37:05 ----------------------------- Captured stderr call -----------------------------
08:37:05 -- executing against localhost:21000
08:37:05 with l as (select 1 from functional.alltypes), r as (select count(*) from tpch_parquet.lineitem a cross join tpch_parquet.lineitem b)select * from l union all (select * from r) LIMIT 1024;
08:37:05 
08:37:05 ======= 1 failed, 1452 passed, 42 skipped, 36 xfailed in 3954.77 seconds =======
08:37:05 ============================= test session starts ==============================
{code}

Observation: In both cases the query had a union

Happened again, though this time I don't think a union was in the query:
{code}
17:33:25 =================================== FAILURES ===================================
17:33:25  TestQueries.test_with_clause[exec_option: {'batch_size': 0, 'num_nodes': 0, 'disable_codegen_rows_threshold': 0, 'disable_codegen': True, 'abort_on_error': 1, 'exec_single_node_rows_threshold': 0} | table_format: rc/gzip/block] 
17:33:25 [gw0] linux2 -- Python 2.6.6 /data/jenkins/workspace/impala-umbrella-build-and-test/repos/Impala/bin/../infra/python/env/bin/python
17:33:25 query_test/test_queries.py:124: in test_with_clause
17:33:25     self.run_test_case('QueryTest/with-clause', vector)
17:33:25 common/impala_test_suite.py:390: in run_test_case
17:33:25     result = self.__execute_query(target_impalad_client, query, user=user)
17:33:25 common/impala_test_suite.py:598: in __execute_query
17:33:25     return impalad_client.execute(query, user=user)
17:33:25 common/impala_connection.py:160: in execute
17:33:25     return self.__beeswax_client.execute(sql_stmt, user=user)
17:33:25 beeswax/impala_beeswax.py:194: in execute
17:33:25     result.exec_summary = self.get_exec_summary(handle)
17:33:25 beeswax/impala_beeswax.py:213: in get_exec_summary
17:33:25     self.__build_summary_table(summary, 0, False, 0, False, output)
17:33:25 beeswax/impala_beeswax.py:252: in __build_summary_table
17:33:25     for stats in node.exec_stats:
17:33:25 E   TypeError: 'NoneType' object is not iterable
17:33:25 ----------------------------- Captured stderr call -----------------------------
17:33:25 -- executing against localhost:21000
17:33:25 use functional_rc_gzip;
17:33:25 
17:33:25 SET batch_size=0;
17:33:25 SET num_nodes=0;
17:33:25 SET disable_codegen_rows_threshold=0;
17:33:25 SET disable_codegen=True;
17:33:25 SET abort_on_error=1;
17:33:25 SET exec_single_node_rows_threshold=0;
17:33:25 -- executing against localhost:21000
17:33:25 with t as (select int_col x, bigint_col y from functional.alltypestiny)
17:33:25 select count(x), count(y) from t;
17:33:25 
17:33:25 -- executing against localhost:21000
17:33:25 with t as (select abc x, xyz y from functional.complex_view)
17:33:25 select x, y from t order by y limit 10;
17:33:25 
17:33:25 -- executing against localhost:21000
17:33:25 with t(c1, c2) as (select int_col, bigint_col y from functional.alltypestiny)
17:33:25 select * from t limit 1;
17:33:25 
17:33:25 -- executing against localhost:21000
17:33:25 with t(c1) as (select int_col, bigint_col from functional.alltypestiny)
17:33:25 select * from t limit 1;
17:33:25 
17:33:25 -- executing against localhost:21000
17:33:25 with t(c1, c2) as (select int_col from functional.alltypestiny)
17:33:25 select * from t limit 1;
17:33:25 
17:33:25 -- executing against localhost:21000
17:33:25 with t1 as (select int_col x, bigint_col y from functional.alltypestiny),
17:33:25 t2 as (select 1 x, 10 y), t3 as (values(2 x, 20 y), (3, 30))
17:33:25 select x, y from t2;
17:33:25 
17:33:25 -- executing against localhost:21000
17:33:25 with t1 as (select int_col x, bigint_col y from functional.alltypestiny),
17:33:25 t2 as (select 1 x, 10 y), t3 as (values(2 x, 20 y), (3, 30))
17:33:25 select * from t1 union all select * from t2 union all (select * from t3) order by x limit 20;
17:33:25 
17:33:25 -- executing against localhost:21000
17:33:25 with t1(c1, c2) as (select int_col x, bigint_col y from functional.alltypestiny),
17:33:25 t2(c3, c4) as (select 1 x, 10 y)
17:33:25 select * from t1 limit 1 union all select * from t2 limit 1;
17:33:25 
17:33:25 -- executing against localhost:21000
17:33:25 with t1 as (select int_col x, bigint_col y from functional.alltypes limit 2),
17:33:25 t2 as (select int_col x, bigint_col y from functional.alltypestiny limit 2),
17:33:25 t3 as (select int_col x, bigint_col y from functional.alltypessmall limit 2)
17:33:25 select * from t1, t2, t3 where t1.x = t2.x and t2.x = t3.x;
17:33:25 
17:33:25 -- executing against localhost:21000
17:33:25 with t as (select int_col x, bigint_col y from functional.alltypestiny order by id limit 2)
17:33:25 select * from t t1 left outer join t t2 on t1.y = t2.x full outer join t t3 on t2.y = t3.x
17:33:25 order by t1.x limit 10;
17:33:25 
17:33:25 -- executing against localhost:21000
17:33:25 with t1 as (values('a', 'b'))
17:33:25 (with t2 as (values('c', 'd')) select * from t2) union all
17:33:25 (with t3 as (values('e', 'f')) select * from t3);
17:33:25 
17:33:25 -- executing against localhost:21000
17:33:25 with t1 as (select tinyint_col, count(*) from alltypesagg group by 1
17:33:25 order by 1 desc nulls last limit 10) select * from t1;
17:33:25 
17:33:25 -- executing against localhost:21000
17:33:25 select 1 from (
17:33:25   with w as (
17:33:25     select 1 from alltypestiny
17:33:25     where exists (select 1 from alltypestiny))
17:33:25   select 1 from w) tt;
17:33:25 
17:33:25 ===== 1 failed, 11027 passed, 187 skipped, 304 xfailed in 30372.06 seconds =====
{code}

Hit two more instances of it recently:

{noformat}
query_test/test_queries.py:124: in test_with_clause
    self.run_test_case('QueryTest/with-clause', vector)
common/impala_test_suite.py:390: in run_test_case
    result = self.__execute_query(target_impalad_client, query, user=user)
common/impala_test_suite.py:598: in __execute_query
    return impalad_client.execute(query, user=user)
common/impala_connection.py:160: in execute
    return self.__beeswax_client.execute(sql_stmt, user=user)
beeswax/impala_beeswax.py:194: in execute
    result.exec_summary = self.get_exec_summary(handle)
beeswax/impala_beeswax.py:213: in get_exec_summary
    self.__build_summary_table(summary, 0, False, 0, False, output)
beeswax/impala_beeswax.py:252: in __build_summary_table
    for stats in node.exec_stats:
E   TypeError: 'NoneType' object is not iterable
Standard Error

MainThread: Skipping type verification of Avro-format table.
-- executing against localhost:21000
with t1 as (select tinyint_col, count(*) from alltypesagg group by 1
order by 1 desc nulls last limit 10) select * from t1;

MainThread: Skipping type verification of Avro-format table.
-- executing against localhost:21000
select 1 from (
  with w as (
    select 1 from alltypestiny
    where exists (select 1 from alltypestiny))
  select 1 from w) tt;
{noformat}

{noformat}
query_test/test_queries.py:90: in test_union
    result = self.execute_query(query_string, vector.get_value('exec_option'))
common/impala_test_suite.py:506: in wrapper
    return function(*args, **kwargs)
common/impala_test_suite.py:531: in execute_query
    return self.__execute_query(self.client, query, query_options)
common/impala_test_suite.py:598: in __execute_query
    return impalad_client.execute(query, user=user)
common/impala_connection.py:160: in execute
    return self.__beeswax_client.execute(sql_stmt, user=user)
beeswax/impala_beeswax.py:194: in execute
    result.exec_summary = self.get_exec_summary(handle)
beeswax/impala_beeswax.py:213: in get_exec_summary
    self.__build_summary_table(summary, 0, False, 0, False, output)
beeswax/impala_beeswax.py:252: in __build_summary_table
    for stats in node.exec_stats:
E   TypeError: 'NoneType' object is not iterable

-- executing against localhost:21000
select 1, 1
union all
select avg(id), id
from alltypestiny
group by id;

SET batch_size=10;
SET num_nodes=0;
SET disable_codegen_rows_threshold=0;
SET disable_codegen=True;
SET abort_on_error=1;
SET exec_single_node_rows_threshold=0;
-- executing against localhost:21000
select count(c) from ( select bigint_col + 1 as c from functional.alltypes limit 15 union all select bigint_col as c from functional.alltypes limit 15 union all select bigint_col + 1 as c from functional.alltypes limit 15 union all (select bigint_col as c from functional.alltypes limit 15)) t;
{noformat}

So the problem here is that we update the exec summary when backend status reports come in. Every fragment is guaranteed to send at least one status report, in Finalize, so we're guaranteed to get reports with info for all of the exec summary nodes, but we only update the exec summary if the status in the report is 'ok'.

In the cases where this is failing, some of the fragments were cancelled very quickly, so the only report they send has a status of 'cancelled' and the exec summary isn't updated for them, resulting in some nodes never having exec_stats set for them in the exec summary, which then causes an error in the testing code when it tries to read the exec_stats.

The impact is low (just info missing from the exec summary), but its happening more frequently than it would seem from the sporadic test failures (its being hidden by some test framework code that unintentionally catches the exception and discards it in most cases).

I think the right solution is to update the exec summary even if the status is not ok (probably just on the first error report, maybe only if the error status is 'cancelled'?), but I'm not sure of the entire impact of such a change (eg if fragment reports with error statuses in general include exec_stats info that is accurate).

[~henryr] any thoughts?

It makes sense that this could happen with successful limit queries, so those tests shouldn't fail.

It looks like this code in Coordinator::ExecSummary::Init() where we pre-allocate the list of exec stats is at fault:
{code}
        node_summary.exec_stats.resize(num_instances);
{code}

But node_summary.__isset.exec_stats isn't set to true. I think it makes sense for us to mark it as set, either explicitly or via the __set_exec_stats(vector) fn. I think it makes sense because the attributes on the TExecStats will still be unset for now, and that makes sense before the updates come in.

It looks like we're setting it in {{InstanceStats::Update}} (coordinator-backend-state.cc):
{code}
    node_exec_summary.__isset.exec_stats = true;
{code}

Which makes sense why it works when the Updates come in. On second thought, it might just be better to update our test code (and any other code that reads exec_stats) to understand that exec_stats may not be set.

[~mjacobs] right so those suggestions would work to stop the test from failing, but it would still mean that we wouldn't be returning exec stats in situations where we had them available, which seems non-ideal.

I think it depends on the case. If a query has a limit, then the coordinator will cancel the remote fragments once it has reached the limit, and it doesn't wait for their completion because it doesn't need to. The same thing happens when an error is observed- the rest of the fragments are cancelled and the query completes without waiting for them. Ideally we would update the reports if we could, but we'd have to start waiting on the coordinator for the final reports, which sounds like a scary change to me (what if Close() ends up taking a long time?), but in both of these cases I think it's acceptable to keep the current behavior, and instead say the contract for a profile is that it may not be complete in these cases.

The last case though, when a query without a limit completes successfully, should have a full profile/summary. If we're finding that the summary isn't fully written, that seems like there's some other bug as well.

I think it'll be reasonable for us to just update the summary handling code for now (although it's not ideal), especially if we add an assertion that the summary is complete if it's not a limit query and the query was successful.

commit 6757b6235c68f3886e28ecda8fc6598305717d2e
Author: Thomas Tauber-Marshall <tmarshall@cloudera.com>
Date:   Wed Aug 9 09:17:37 2017 -0700

    IMPALA-5708: Test failure with invalid exec summary
    
    For some queries, the exec summary will not be completely filled
    in even if the query is FINISHED. In particular, the exec_stats field
    may not be set. This was causing an error in our test code that
    converts the exec summary to a more usable format.
    
    The situation is essentially deterministic for some queries, but
    it was being hidden by testing code that caught the error and
    discarded it in most situations, leading to flaky tests.
    
    This patch removes the 'try' that was hiding the error and makes
    the code check for the presence of exec_stats and handle it rather
    than generating an error.
    
    I filed IMPALA-5783 for followup work to be more rigorous about
    when the exec summary should and shouldn't be fully present.
    
    Testing:
    - Ran the affected tests in a loop and they are no longer flaky.
    
    Change-Id: Id52ac62da2b01f9e163e97cbe4590f8db6b663d2
    Reviewed-on: http://gerrit.cloudera.org:8080/7627
    Tested-by: Impala Public Jenkins
    Reviewed-by: Thomas Tauber-Marshall <tmarshall@cloudera.com>

