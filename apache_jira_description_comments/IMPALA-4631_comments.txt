I saw this again on a build.

I saw this on a build, too. Please contact me and I can share build artifacts in private.

Saw this yet again on a build.

Happened again in an ASAN build.

Saw this yet again an an exhaustive. Increasing priority as various flaky tests are adding up.

Saw it again 6 hours ago.

Should we consider xfailing this? Or increase the right hand side of the comparison by 1 to account for the error?

Dunno if it's easy to xfail as it doesn't seem to be a particular test which failed

There aren't many places where {{clock_gettime}} or {{1e9}} show up in a git grep. Any reason we can't just fix them and re-open this issue if we see it again?

[~jbapple], I had fixed all the places I could find that used floating point on the relevant paths some time back.  Was there a specific {{1e9}} use that you think might still cause this problem? 

Nope, just forgot that the Description is now obsolete.

And it would have helped if I had pasted this in earlier, oops:
{code}
commit 54194af6ef08048a1ae367f29350228dafd8f2aa
Author: Dan Hecht <dhecht@cloudera.com>
Date:   Thu Dec 8 15:29:47 2016 -0800

    IMPALA-4631: don't use floating point operations for time unit conversions

    This was leading to the PlanFragmentExecutor::Close() DCHECK because
    with floating point we can have c * a + c * b > c * (a + b).  Also note
    this is much more likely to happen when using the MONOTONIC_COARSE since
    that will result in the nested scoped timers ending up starting/stopping
    at exactly the same time.  Additionally, the new code is faster.

    Change-Id: I7237f579b201f5bd3930f66e9c2c8d700c37ffeb
    Reviewed-on: http://gerrit.cloudera.org:8080/5434
    Reviewed-by: Dan Hecht <dhecht@cloudera.com>
    Tested-by: Jim Apple <jbapple-impala@apache.org>
{code}

This comment should avoid the dcheck, but leaving this open since we don't yet understand the root cause.

{code}
commit de12d86f208ceaf75b5d45aca229002002e8f860
Author: Dan Hecht <dhecht@cloudera.com>
Date:   Mon Mar 13 18:24:25 2017 -0700

    IMPALA-4631: avoid DCHECK in PlanFragementExecutor::Close().

    Occasionally, we see other_time == total_time+1 for some reason
    we don't yet understand. We've only seen this on EC2 and with
    CLOCK_MONOTONIC_COARSE, so it could be that clock occasionally
    goes backwards. The intent of the DCHECK is to verify that
    we didn't miss accounting entire intervals of time, so let's
    loosen it slightly to avoid this "false" positive.

    Change-Id: Ia9883fdb1be6a4301864da85da56ec96f4dafbe7
    Reviewed-on: http://gerrit.cloudera.org:8080/6375
    Reviewed-by: Dan Hecht <dhecht@cloudera.com>
    Reviewed-by: Michael Ho <kwho@cloudera.com>
    Tested-by: Impala Public Jenkins
{code}

Shouldn't show up in tests anymore with the new dcheck.

We've now seen this fail once with an off-by-2, in off-by-2.INFO.gz.

The check was:
{noformat}
F0217 21:35:52.840801  4863 fragment-instance-state.cc:319] Check failed: other_time <= total_time + 1 (6000312 vs. 6000310)
{noformat}
And relevant host info:
{code:java}
I0217 15:18:29.693150 31590 atomicops-internals-x86.cc:98] vendor GenuineIntel  family 6  model 13  sse2 1  cmpxchg16b 1
I0217 15:18:29.709362 31590 init.cc:231] impalad version 2.11.0-SNAPSHOT DEBUG (build d36ff19e8e783ed70e70fd1bf9fdd468654d7edb)
Built on Sat Feb 17 13:21:02 PST 2018
I0217 15:18:29.711091 31590 init.cc:240] OS version: Linux version 2.6.32-358.14.1.el6.centos.plus.x86_64 (mockbuild@c6b9.bsys.dev.centos.org) (gcc v

ersion 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ) #1 SMP Tue Jul 16 21:33:24 UTC 2013

Clock: clocksource: 'xen', clockid_t: CLOCK_MONOTONIC_COARSE

I0217 15:18:29.711099 31590 init.cc:241] Process ID: 31590

I0217 15:18:32.440771 31590 llvm-codegen.cc:152] CPU class for runtime code generation: sandybridge

I0217 15:18:32.440954 31590 llvm-codegen.cc:154] Detected CPU flags: +sse2,+cx16,-tbm,-avx512ifma,-avx512dq,-fma4,-prfchw,-bmi2,-xsavec,-fsgsbase,+po

pcnt,-aes,-pcommit,-xsaves,-avx512er,-clwb,-avx512f,-pku,-smap,+mmx,-xop,-rdseed,-hle,-sse4a,-avx512bw,-clflushopt,-xsave,-avx512vl,-invpcid,-avx512c

d,-avx,-rtm,-fma,-bmi,-mwaitx,-rdrnd,+sse4.1,+sse4.2,-avx2,+sse,-lzcnt,-pclmul,-prefetchwt1,-f16c,+ssse3,-sgx,+cmov,-avx512vbmi,-movbe,-xsaveopt,-sha

,-adx,-avx512pf,+sse3
{code}
This was on ec2 m2-4xlarge centos 6.5 x64.

And clocksource was:
{code:java}
Clock: clocksource: 'xen', clockid_t: CLOCK_MONOTONIC_COARSE{code}

Is it possible the m2 family is running on a Xen where a VM migration can break the monotonicity guarantee of CLOCK_MONOTONIC_COARSE?

We also can hit the same issue in a different place: see IMPALA-6450 

We also saw a case where it was off by 3. Can we loosen the DCHECK to avoid having to triage test failures?


Maybe we should just remove these DCHECKs and assume we need to cope with the monotonic clock going backwards.

Hit this again:
{noformat}
F0409 01:18:21.443645 30316 runtime-profile-counters.h:308] Check failed: offset_ >= -1 (-2 vs. -1)
*** Check failure stack trace: ***
    @          0x3f5c6ad  google::LogMessage::Fail()
    @          0x3f5df52  google::LogMessage::SendToLog()
    @          0x3f5c087  google::LogMessage::Flush()
    @          0x3f5f64e  google::LogMessageFatal::~LogMessageFatal()
    @          0x198ecb0  impala::RuntimeProfile::EventSequence::Start()
    @          0x1989002  impala::FragmentInstanceState::Prepare()
    @          0x1988595  impala::FragmentInstanceState::Exec()
    @          0x19974d3  impala::QueryState::ExecFInstance()
    @          0x1995d4c  _ZZN6impala10QueryState15StartFInstancesEvENKUlvE_clEv
    @          0x19980ed  _ZN5boost6detail8function26void_function_obj_invoker0IZN6impala10QueryState15StartFInstancesEvEUlvE_vE6invokeERNS1_15function_bufferE
    @          0x18d16c6  boost::function0<>::operator()()
    @          0x1bea43d  impala::Thread::SuperviseThread()
    @          0x1bf2913  boost::_bi::list5<>::operator()<>()
    @          0x1bf2837  boost::_bi::bind_t<>::operator()()
    @          0x1bf27fa  boost::detail::thread_data<>::run()                                                                                                                                                         @          0x2e8965a  thread_proxy
    @       0x3172607851  (unknown)                                                                                                                                                                                   @       0x31722e894d  (unknown)
tingMethodAccessorImpl.java:43)                                                   
{noformat}

Commit 54f70b6d6960ad53355b43f704a82f1f3a457d4d in impala's branch refs/heads/master from [~tarmstrong@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=impala.git;h=54f70b6 ]

IMPALA-4631: loosen monotonic clock DCHECK

We saw another build failure due to hitting one of these DCHECKs.
Let's further loosen the check to avoid the failures on misbehaving
systems.

Change-Id: I72d314518087aede16e8d702c2f904b679a55f6d
Reviewed-on: http://gerrit.cloudera.org:8080/10026
Tested-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>
Reviewed-by: Tim Armstrong <tarmstrong@cloudera.com>


Commit 22750d4561193cf28d8de28ce7c20fceca61f205 in impala's branch refs/heads/2.x from [~tarmstrong@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=impala.git;h=22750d4 ]

IMPALA-4631: loosen monotonic clock DCHECK

We saw another build failure due to hitting one of these DCHECKs.
Let's further loosen the check to avoid the failures on misbehaving
systems.

Change-Id: I72d314518087aede16e8d702c2f904b679a55f6d
Reviewed-on: http://gerrit.cloudera.org:8080/10026
Tested-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>
Reviewed-by: Tim Armstrong <tarmstrong@cloudera.com>


This is still showing up in my flaky test JIRA search but hasn't happened for a couple of months. Safe to close it?

Yeah, I don't think there's value in keeping this open.

The problem still occurs after loosening the DCHECK:

{noformat}
F0420 03:50:03.056339  2817 fragment-instance-state.cc:330] Check failed: other_time <= total_time + 3 (646003282 vs. 646003278)
{noformat}

Makes me wonder if there is a genuine bug here. Could we be missing a barrier somewhere ?

This happened twice in June for us. I don't have bandwidth to investigate though so will unassign.

{noformat}

F0619 02:51:02.015914  9248 runtime-profile-counters.h:321] 634465dfcb8fe9db:26a226c400000000] Check failed: offset_ >= -3 (-5 vs. -3) 
{noformat}
{noformat}
F0526 02:51:41.276341 14161 fragment-instance-state.cc:330] Check failed: other_time <= total_time + 3 (59001395 vs. 59001392) 
{noformat}


I saw this again. This happened on a CentOS 6.4 vm on a m2-4xlarge ec2 instance.
{noformat}
F0217 02:10:47.921636 14885 runtime-profile-counters.h:572] 9945dfcfab2eb54c:1609788600000001] Check failed: offset_ >= -3 (-15 vs. -3) 
{noformat}

I took another look at the code.

We set QueryState::fragment_instance_start_time_ here https://github.com/apache/impala/blob/091faebe61645c9f86f59bc67668688f15a2fc7c/be/src/runtime/query-state.cc#L574, before we allocate any FragmentInstanceStates for the query or start any threads.
{code}
  fragment_events_start_time_ = MonotonicStopWatch::Now();
{code}

 fragment_events_start_time_ is passed into EventSequence::Start() here in FragmentInstanceState::Prepare() https://github.com/apache/impala/blob/091faebe61645c9f86f59bc67668688f15a2fc7c/be/src/runtime/fragment-instance-state.cc#L157
{code}
  event_sequence_->Start(query_state_->fragment_events_start_time());
{code}

In event_sequence_->Start(), MonotonicStopWatch::Now() is returning a lower value https://github.com/apache/impala/blob/091faebe61645c9f86f59bc67668688f15a2fc7c/be/src/util/runtime-profile-counters.h#L567
{code}
  void Start(int64_t start_time_ns) {
    offset_ = MonotonicStopWatch::Now() - start_time_ns;
    // TODO: IMPALA-4631: Occasionally we see MonotonicStopWatch::Now() return
    // (start_time_ns - e), where e is 1, 2 or 3 even though 'start_time_ns' was
    // obtained using MonotonicStopWatch::Now().
    DCHECK_GE(offset_, -3);
    sw_.Start();
  }
{code}

I don't think a missing barrier can be an issue, since the thread creation should be a memory barrier. The only explanation I can see is that MonotonicStopWatch::Now() is going backwards. That just calls clock_gettime(CLOCK_MONOTONIC_COARSE) on these systems.

This was only ever seen infrequently on a old hypervisor/kernel combination. I think we probably just need to avoid this by upgrading those...

{noformat}
OS version: Linux version 2.6.32-358.14.1.el6.centos.plus.x86_64 (mockbuild@c6b9.bsys.dev.centos.org) (gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ) #1 SMP Tue Jul 16 21:33:24 UTC 2013
Clock: clocksource: 'xen', clockid_t: CLOCK_MONOTONIC_COARSE
{noformat}

And AWS sometimes moves VMs between physical hosts, yes? I wonder if there's a race somewhere in there. Hopefully this will not be an issue for tests on Nitro.

We run a lot more tests on newer VMs/images and have never seen this failure, so I'd tend to think it's gotten better.

I would guess it might be some kind of inconsistency of clocks between CPUs, since there are two different threads involved.

