The test failed with following error:
{code:java}
Error Message
Impalad startup failed but not for the expected reason. See logs in the '/tmp/testJwtAuthWithUntrustedJwksHttpsUrl2894276427247184414' folder for details.
Expected: a collection containing a string containing "Impalad services did not start correctly, exiting.  Error: Error downloading JWKS from 'https://localhost:25010/www/temp_jwks.json': Network error: curl error: SSL peer certificate or SSH remote key was not OK: SSL certificate problem: unable to get local issuer certificate"
     but: was "Log file created at: 2023/02/24 05:19:30", was "Running on machine: impala-ec2-centos79-m6i-4xlarge-ondemand-1ddc.vpc.cloudera.com", was "Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg", was "E0224 05:19:30.876717 21307 logging.cc:248] stderr will be logged to this file.", was "23/02/24 05:19:31 WARN fs.FileSystem: Cannot load filesystem: java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.hive.ql.io.NullScanFileSystem not found", was "23/02/24 05:19:31 WARN fs.FileSystem: Cannot load filesystem: java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem not found", was "23/02/24 05:19:31 INFO util.JvmPauseMonitor: Starting JVM pause monitor", was "23/02/24 05:19:32 WARN executor.HiveLegacyJavaFunction: Ignoring incompatible method: public org.apache.hadoop.io.BytesWritable org.apache.hadoop.hive.ql.udf.esri.ST_Union.evaluate(org.apache.hadoop.io.BytesWritable[]) during load of Hive UDF: st_union from class org.apache.impala.builtins.ST_Union_Wrapper", was "23/02/24 05:19:32 WARN executor.HiveLegacyJavaFunction: Ignoring incompatible method: public org.apache.hadoop.io.BytesWritable org.apache.hadoop.hive.ql.udf.esri.ST_Polygon.evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable[]) throws org.apache.hadoop.hive.ql.exec.UDFArgumentLengthException during load of Hive UDF: st_polygon from class org.apache.impala.builtins.ST_Polygon_Wrapper", was "23/02/24 05:19:32 WARN executor.HiveLegacyJavaFunction: Ignoring incompatible method: public org.apache.hadoop.io.BytesWritable org.apache.hadoop.hive.ql.udf.esri.ST_LineString.evaluate(java.util.ArrayList) throws org.apache.hadoop.hive.ql.exec.UDFArgumentException during load of Hive UDF: st_linestring from class org.apache.impala.builtins.ST_LineString_Wrapper", was "23/02/24 05:19:32 WARN executor.HiveLegacyJavaFunction: Ignoring incompatible method: public org.apache.hadoop.io.BytesWritable org.apache.hadoop.hive.ql.udf.esri.ST_LineString.evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable[]) throws org.apache.hadoop.hive.ql.exec.UDFArgumentException during load of Hive UDF: st_linestring from class org.apache.impala.builtins.ST_LineString_Wrapper", was "23/02/24 05:19:32 WARN executor.HiveLegacyJavaFunction: Ignoring incompatible method: public org.apache.hadoop.io.BytesWritable org.apache.hadoop.hive.ql.udf.esri.ST_LineString.evaluate(java.util.ArrayList,java.util.ArrayList) throws org.apache.hadoop.hive.ql.exec.UDFArgumentException during load of Hive UDF: st_linestring from class org.apache.impala.builtins.ST_LineString_Wrapper", was "23/02/24 05:19:32 WARN executor.HiveLegacyJavaFunction: Ignoring incompatible method: public org.apache.hadoop.io.BytesWritable org.apache.hadoop.hive.ql.udf.esri.ST_MultiPoint.evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable[]) throws org.apache.hadoop.hive.ql.exec.UDFArgumentLengthException during load of Hive UDF: st_multipoint from class org.apache.impala.builtins.ST_MultiPoint_Wrapper", was "23/02/24 05:19:32 WARN executor.HiveLegacyJavaFunction: Ignoring incompatible method: public org.apache.hadoop.io.BytesWritable org.apache.hadoop.hive.ql.udf.esri.ST_ConvexHull.evaluate(org.apache.hadoop.io.BytesWritable[]) during load of Hive UDF: st_convexhull from class org.apache.impala.builtins.ST_ConvexHull_Wrapper"

Stacktrace
java.lang.AssertionError: 
Impalad startup failed but not for the expected reason. See logs in the '/tmp/testJwtAuthWithUntrustedJwksHttpsUrl2894276427247184414' folder for details.
Expected: a collection containing a string containing "Impalad services did not start correctly, exiting.  Error: Error downloading JWKS from 'https://localhost:25010/www/temp_jwks.json': Network error: curl error: SSL peer certificate or SSH remote key was not OK: SSL certificate problem: unable to get local issuer certificate"
     but: was "Log file created at: 2023/02/24 05:19:30", was "Running on machine: impala-ec2-centos79-m6i-4xlarge-ondemand-1ddc.vpc.cloudera.com", was "Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg", was "E0224 05:19:30.876717 21307 logging.cc:248] stderr will be logged to this file.", was "23/02/24 05:19:31 WARN fs.FileSystem: Cannot load filesystem: java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.hive.ql.io.NullScanFileSystem not found", was "23/02/24 05:19:31 WARN fs.FileSystem: Cannot load filesystem: java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem not found", was "23/02/24 05:19:31 INFO util.JvmPauseMonitor: Starting JVM pause monitor", was "23/02/24 05:19:32 WARN executor.HiveLegacyJavaFunction: Ignoring incompatible method: public org.apache.hadoop.io.BytesWritable org.apache.hadoop.hive.ql.udf.esri.ST_Union.evaluate(org.apache.hadoop.io.BytesWritable[]) during load of Hive UDF: st_union from class org.apache.impala.builtins.ST_Union_Wrapper", was "23/02/24 05:19:32 WARN executor.HiveLegacyJavaFunction: Ignoring incompatible method: public org.apache.hadoop.io.BytesWritable org.apache.hadoop.hive.ql.udf.esri.ST_Polygon.evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable[]) throws org.apache.hadoop.hive.ql.exec.UDFArgumentLengthException during load of Hive UDF: st_polygon from class org.apache.impala.builtins.ST_Polygon_Wrapper", was "23/02/24 05:19:32 WARN executor.HiveLegacyJavaFunction: Ignoring incompatible method: public org.apache.hadoop.io.BytesWritable org.apache.hadoop.hive.ql.udf.esri.ST_LineString.evaluate(java.util.ArrayList) throws org.apache.hadoop.hive.ql.exec.UDFArgumentException during load of Hive UDF: st_linestring from class org.apache.impala.builtins.ST_LineString_Wrapper", was "23/02/24 05:19:32 WARN executor.HiveLegacyJavaFunction: Ignoring incompatible method: public org.apache.hadoop.io.BytesWritable org.apache.hadoop.hive.ql.udf.esri.ST_LineString.evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable[]) throws org.apache.hadoop.hive.ql.exec.UDFArgumentException during load of Hive UDF: st_linestring from class org.apache.impala.builtins.ST_LineString_Wrapper", was "23/02/24 05:19:32 WARN executor.HiveLegacyJavaFunction: Ignoring incompatible method: public org.apache.hadoop.io.BytesWritable org.apache.hadoop.hive.ql.udf.esri.ST_LineString.evaluate(java.util.ArrayList,java.util.ArrayList) throws org.apache.hadoop.hive.ql.exec.UDFArgumentException during load of Hive UDF: st_linestring from class org.apache.impala.builtins.ST_LineString_Wrapper", was "23/02/24 05:19:32 WARN executor.HiveLegacyJavaFunction: Ignoring incompatible method: public org.apache.hadoop.io.BytesWritable org.apache.hadoop.hive.ql.udf.esri.ST_MultiPoint.evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable[]) throws org.apache.hadoop.hive.ql.exec.UDFArgumentLengthException during load of Hive UDF: st_multipoint from class org.apache.impala.builtins.ST_MultiPoint_Wrapper", was "23/02/24 05:19:32 WARN executor.HiveLegacyJavaFunction: Ignoring incompatible method: public org.apache.hadoop.io.BytesWritable org.apache.hadoop.hive.ql.udf.esri.ST_ConvexHull.evaluate(org.apache.hadoop.io.BytesWritable[]) during load of Hive UDF: st_convexhull from class org.apache.impala.builtins.ST_ConvexHull_Wrapper"
	at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)
	at org.junit.Assert.assertThat(Assert.java:956)
	at org.apache.impala.customcluster.JwtHttpTest.testJwtAuthWithUntrustedJwksHttpsUrl(JwtHttpTest.java:421)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:272)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:236)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:386)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:323)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:143) {code}