Added a check to skip creating \{{FileEncryptionInfo}} if the path is /.reserved/raw.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 40s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m  9s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 50s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 52s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 41s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 48s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 52s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 40s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m  5s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 49s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}117m 37s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 25s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}163m  5s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |
|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |
|   | hadoop.hdfs.web.TestWebHdfsTimeouts |
|   | hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations |
|   | hadoop.hdfs.server.datanode.TestNNHandlesCombinedBlockReport |
|   | hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy |
|   | hadoop.hdfs.server.datanode.TestDataNodeUUID |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:d4cc50f |
| JIRA Issue | HDFS-13281 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12914714/HDFS-13281.001.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux b11d41c61cff 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 5e013d5 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/23501/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/23501/testReport/ |
| Max. process+thread count | 3190 (vs. ulimit of 10000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/23501/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



All the above test failures are unrelated to my patch.
[~daryn], [~weichiu]: can you please help review this tiny patch ? 

[~xiaochen]: can you please help me review this patch ?

Thanks for working on this [~shahrs87].

Could you provide some background? Is this required for the webhdfs work? Please link it if so.

 

I'm a bit nervous on supportability, because it would be hard to tell whether a file without FileEncryptionInfo in an EZ is due to a bug or due to it's written this way. Currently it's always a bug. Re-encryption can still work but each file without feInfo leads to a warn message, we should check if there are any similar assumptions / checks else where in HDFS.

This will be used in HDFS-12597 but it is not directly related.
By definition, if I am using {{/.reserved/raw}} path for reading then namenode will not return {{FileEncryptionInfo}} object in {{LocatedBlocks}} and HdfsClient will serve the raw bytes(i.e client will not decrypt).
That same rule should apply for write path also.
In write path, namenode is not returning {{FileEncryptionInfo}} in {{HdfsFileStatus}} but internally it is creating {{FileEncryptionInfo}} and adding to file.

If I use distcp to copy files using {{/.reserved/raw}} paths and assuming both the path are in EZ, then also namenode will generate a new edek (different from the source's edek) while creating the file.
As the last step in distcp, it copies all the raw xattrs from source to destination and that way it overwrites the old (wrong) edek.

bq. I'm a bit nervous on supportability,
{{/.reserved/raw}} is a special path prefix and you should be very careful to use it and not use irresponsibly.

Still don't understand the use cases, please help me understand.

I played with distcp a little bit, IIUC this is an optimization for that scenario so that the extra EDEK doesn't get generated unnecessarily. How does HDFS-12597 use it? From [this comment|https://issues.apache.org/jira/browse/HDFS-12574?focusedCommentId=16329149&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16329149] client will still create the file in NN, only the streaming part will write encrypted data to DN, right?

bq. /.reserved/raw is a special path prefix and you should be very careful to use it and not use irresponsibly.
Exactly. Instead of educating every user when they raise an issue, can we proactively prevent this? How are we planning to set the EDEKs after a /.reserved/raw file is created? 1 atomic RPC to startFile with a user-provided edek feels safer, but messier to do.... 

bq. How does HDFS-12597 use it?
The use case is:
1. EZ-aware webhdfs client (i.e add header:X-Hadoop-Accept-EZ) will send {{createFile}} request to namenode.(the path won't be /.reserved/raw) {color:red}(edited by rushabh on 03/29){color} 
2. If the client supports webhdfs and if the file in EZ, then namenode will return {{FeInfo}} in response via header and append "/.reserved/raw" to redirect path.
3. The client will encrypt data with {{FeInfo}} and stream the encrypted bytes to -namenode- datanode. {color:red}(edited by rushabh on 03/29){color}.
4. Since the path is prepended with {{/.reserved/raw}}, datanode will not encrypt again.
5. At the end, client will issue {{setXAttr}} on path to namenode.
6. According to HDFS-13035, we will allow owner of the file to do {{setXAttr}} _only if it is not set_. If namenode will {{setXAttr}} even on {{/.reserved/raw}} then webhdfs client will fail to {{setXAttr}}.
Hope it makes sense.

Makes sense, so this patch only applies if step #1 does a {{startFile}} with /.reserved/raw, in which case there will be no step #3, and will be assumed that encrypted bytes are streamed to DN. And step#5 also only applies to files created with /.reserved/raw.

Could you rebase the patch? Doesn't apply to trunk.

Code comments:
 * The test doesn't verify that there was no intermediate EDEK consumed and set on the file. Probably need to set a customer provider with some counters to make sure the startfile didn't go through it
 * Because reading /.reserved/raw is supposed to be returning the raw bytes, shouldn't {{encryptedReservedStream}} be different than {{unEncryptedBytes}}? 
 * Can you add a distcp test as you mentioned before? Best if it's between 2 zones with different keys, so the test can verify the decryption with the correct key.

Please link this to the webhdfs umbrella jira.

Thanks [~xiaochen] for the comment.
bq. so this patch only applies if step #1 does a startFile with /.reserved/raw
Yes.
bq. in which case there will be no step #3
Didn't get you. can you please elaborate.
bq. And step#5 also only applies to files created with /.reserved/raw.
Yes. but only if namenode returned {{FeInfo}} to client in response to {{createFile}} call.
WebhdfsFileSystem won't be able to know that path is {{/.reserved/raw}}.
WebhdfsFileSystem will issue {{createFile}} call (without /.reserved/raw) path.
Namenode will check whether path is in EZ and whether client indicated EZ support via header.
If both the conditions are met, then namenode will return {{FeInfo}} and it will prepend the redirect path with {{/.reserved/raw}}.
Client never reads the redirect path so client will issue {{setXAttr}} just based on whether namenode returned {{FEInfo}}.

bq. Could you rebase the patch? Doesn't apply to trunk.
Done.
bq. The test doesn't verify that there was no intermediate EDEK consumed and set on the file.
Currently on create call, namenode will generate edek and sets the xattr {{raw.hdfs.crypto.file.encryption.info}} if the path is in an EZ irrespective whether path is {{/.reserved/raw}}.
In test case, I am creating a file with {{/.reserved/raw}} mimicking the way datanode will issue {{createFile}} to namenode.
In test, I am checking whether {{raw.hdfs.crypto.file.encryption.info}} attr is set or not.
If it is set that means namenode generated edek and if not, then it means namenode didn't generate edek.

bq. Can you add a distcp test as you mentioned before? 
As I mentioned before, distcp is just an example. The problem lies in namenode generating edek even though the path is {{/.reserved/raw}}. So I think the test case is sufficient to prove that namenode didn't generate edek if path is {{/.reserved/raw}}.


{quote}
Because reading /.reserved/raw is supposed to be returning the raw bytes, shouldn't encryptedReservedStream be different than unEncryptedBytes? 
{quote}
Forgot to address this in last comment.
Since the client is writing directly to {{/.reserved/raw}} path, it is client's responsibility to encrypt the data and call {{setXAttr}} to set {{FEInfo}}.
In test case, I didn't set that raw attribute so the raw bytes and decrypted bytes are the same.


| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 25m 35s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m  6s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 55s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 46s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 52s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 52s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 26s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}100m 43s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 25s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}162m 14s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes |
|   | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8620d2b |
| JIRA Issue | HDFS-13281 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12916831/HDFS-13281.002.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 12fea90a9a16 3.13.0-143-generic #192-Ubuntu SMP Tue Feb 27 10:45:36 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 431076f |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/23718/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/23718/testReport/ |
| Max. process+thread count | 3424 (vs. ulimit of 10000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/23718/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



{quote}
{quote}in which case there will be no step #3
{quote}
Didn't get you. can you please elaborate.

{quote}

I was saying: This patch works for an hdfs client, writing to /.reserved/raw. In this case, the client writes raw data, so no encrypt in step #3, just raw bytes written:

Let's step back from webhdfs, because here we're changing the NN code. Say you're using hdfs client, and you write to /.reserved/raw. Before this patch you'll always get a feinfo and encrypt (which probably isn't correct. But from NN's view there's no 'write-to-raw', it just resolves to a regular path). After this patch, you get no feinfo, and just write raw (presumably encrypted) bytes to DN. You'll have to setxattr on that file to NN, otherwise we'll end up with a file in HDFS that's raw and doesn't have feinfo, which is essentially corrupt data, right?

Along this line, for webhdfs/hdfs client, after the file is created and been written (1 block closed, or file closed), and until setxattr, the file will be readable but undecryptable.

I think at the minimum we should setxattr immediately after the file is created. One atomic way is perhaps pass in xattr at file creation time. What do you think [~shahrs87] [~daryn]?

{quote}I think at the minimum we should setxattr immediately after the file is created. 
{quote}
Exactly. I will add that functionality in HDFS-12597. The steps would be something like this. 
Webhdfs client will issue setXAttr after it issues {{create}} call to _datanode_ and before it starts streaming encrypted data to datanode.
 As you said that this just NN side change so I didn't incorporate that.

bq. One atomic way is perhaps pass in xattr at file creation time.
We did think that option also. Adding a new parameter {{FeInfo}} to create call.
If {{FeInfo}} is present, then namenode will use that FeInfo otherwise it will generate new FeInfo but there was compatibility issue if namenode and datanode is old but client is new and then it would double encrypt. So we threw away that idea.


Fair enough for webhdfs. Please add necessary links. I'd think this as a subtask of HDFS-12355 and required by HDFS-12597.

Could you write a design doc elaborating all these, and add to the umbrella jira? Not a blocker for this one but I'd feel more comfortable having a doc to look at first, instead of asking questions on each jira. I'm also not sure a first time reviewer would be able to catch up from any individual jira.

{quote}Could you write a design doc elaborating all these, and add to the umbrella jira?
{quote}
Sure when I start working on HDFS-12597 (in about a week), writing a design doc would be the first thing I will do.
I am sorry that even you asking me multiple times on HDFS-12574, I didn't get enough cycles to write a design doc.
I will find cycles for that and will have write up on that jira also.

bq.  Please add necessary links. I'd think this as a subtask of HDFS-12355 and required by HDFS-12597.
Added necessary links.

As always test failures are not related to this patch.

[~xiaochen]: Is there anything you expect me to change in the latest trunk patch ?
The trunk patch doesn't apply cleanly to branch-2 due to some import changes.
Attached a branch-2 (which pplies to branch-2.8 also)


| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} docker {color} | {color:red} 21m 25s{color} | {color:red} Docker failed to build yetus/hadoop:dbd69cb. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HDFS-13281 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12917027/HDFS-13281.002.branch-2.patch |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/23735/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} docker {color} | {color:red}  2m 40s{color} | {color:red} Docker failed to build yetus/hadoop:dbd69cb. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HDFS-13281 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12917047/HDFS-13281.002.branch-2.patch |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/23737/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



Thanks Rushabh.

bq. Is there anything you expect me to change in the latest trunk patch ?
2 things:
- Current test is logically correct. But for readability I'd prefer we do the test like this:
# write the file
# read from reserved raw to get the raw bytes, verify it's different than input
# write the raw bytes to a new file via /.reserved/raw, read that via /.reserved/raw, verify it's the same as step 2.
- close the streams.
I'm +1 pending the above 2.

You can also skip the branch-2 patch, since that's only import conflicts in the test. This rule is there to ensure quality. You can expect minor conflicts been handled correctly, and committers would compile locally before pushing.

bq. I didn't get enough cycles to write a design doc.
Appreciate the explanation and the promise. I think having it ready would save time for everyone in the long run. Surely it will help all the reviewers, and it may also save you some time if you ever page out. :)

Hi [~shahrs87] and [~xiaochen], do we have plan to get this patch in shortly? If not, I will move it to 2.8.5 to unblock 2.8.4 release.

{quote}do we have plan to get this patch in shortly?
{quote}
I should have a patch by Monday or Tuesday. But I have changed the target version to 2.8.5 since it is not blocker.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 37s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 25m 55s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 58s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 20s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 53s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 46s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  2s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 17s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 44s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}110m 43s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}173m 21s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency |
|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |
|   | hadoop.hdfs.server.namenode.TestReencryptionWithKMS |
|   | hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics |
|   | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.TestDFSClientRetries |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HDFS-13281 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12923357/HDFS-13281.003.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 8171f1cabf49 3.13.0-143-generic #192-Ubuntu SMP Tue Feb 27 10:45:36 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 2d00a0c |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_162 |
| findbugs | v3.1.0-RC1 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/24192/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/24192/testReport/ |
| Max. process+thread count | 2939 (vs. ulimit of 10000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/24192/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



Test failures on the recent run.
{noformat}
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 97.262 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting
[INFO] Running org.apache.hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 88.916 s - in org.apache.hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS
[ERROR] Tests run: 33, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 174.586 s <<< FAILURE! - in org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS
[ERROR] testReencryptionKMSDown(org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS)  Time elapsed: 1.921 s  <<< FAILURE!
java.lang.AssertionError: expected:<5> but was:<0>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hdfs.server.namenode.TestReencryption.testReencryptionKMSDown(TestReencryption.java:1777)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA

[ERROR] Tests run: 22, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 214.029 s <<< FAILURE! - in org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA
[ERROR] testUpdatePipeline(org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA)  Time elapsed: 16.525 s  <<< FAILURE!
java.lang.AssertionError: After waiting the operation updatePipeline still has not taken effect on NN yet
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testClientRetryWithFailover(TestRetryCacheWithHA.java:1324)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testUpdatePipeline(TestRetryCacheWithHA.java:1222)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.437 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.273 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean
[INFO] Running org.apache.hadoop.hdfs.TestDFSClientRetries
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 148.538 s - in org.apache.hadoop.hdfs.TestDFSClientRetries
[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Failures: 
[ERROR]   TestReencryptionWithKMS>TestReencryption.testReencryptionKMSDown:1777 expected:<5> but was:<0>
[ERROR]   TestRetryCacheWithHA.testUpdatePipeline:1222->testClientRetryWithFailover:1324 After waiting the operation updatePipeline still has not taken effect on NN yet
[INFO] 
[ERROR] Tests run: 98, Failures: 2, Errors: 0, Skipped: 0
{noformat}
For {{TestRetryCacheWithHA.testUpdatePipeline}}, reopened HDFS-7524
For {{TestReencryptionWithKMS}}, some other test is failing in local run. In jenkins build, {{TestReencryptionWithKMS#testReencryptNestedZones}} failed and in local run, {{TestReencryption#testReencryptionKMSDown}} failed. 
Also on re-running, all tests passes.
{noformat}
INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS
[INFO] Tests run: 33, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 171.625 s - in org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS
{noformat}
Seems like some flaky tests in {{TestReencryptionWithKMS}}.
[~xiaochen]: do you mind giving final pass.
Changed the tests according to your suggestions from last comment.

Thanks [~shahrs87] for continuing on this.

{code}
os = fs.create(reservedRawP2Path);
// Write un-encrypted bytes to reserved raw stream.
os.write(unEncryptedBytes.getBytes());
{code}
I feel unit tests should serve as examples. So here should we write 'encryptedBytes' to a reserved raw, and verify when reading it from {{p2}}, we can get "hello world"? (It's technically correct that you can write uncrypted to a raw, but I don't see the point of doing so practically.)

+1 once this is done.

Thanks [~xiaochen] for reviewing the latest patch.
bq. So here should we write 'encryptedBytes' to a reserved raw, and verify when reading it from p2,
The whole point of this jira is namenode shouldn't create an edek when client writes to {{/.reserved/raw}} path. Its the client's responsibility to setXAttr. Also note that {{setXAttr}} in test is out of scope of this jira.
So if we somehow write some encrypted bytes, then how would we decrypt in absence of an edek ?


{code}
   try {
     fs.getXAttr(reservedRawP2Path, HdfsServerConstants
         .CRYPTO_XATTR_FILE_ENCRYPTION_INFO);
     fail("getXAttr should have thrown an exception");
   } catch (IOException ioe) {
     assertExceptionContains("At least one of the attributes provided was " +
         "not found.", ioe);
   }
{code}
IMHO the above chunk of code is only required to test this jira which tests that there is no {{CRYPTO_XATTR_FILE_ENCRYPTION_INFO}} xattr on that path.

Aha, my memory faded with this....

I was thinking about [this comment|https://issues.apache.org/jira/browse/HDFS-13281?focusedCommentId=16419803&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16419803] earlier. As far as this unit test is concerned, we should still write encrypted bytes, right? Then you verify that the read bytes are encrypted.
My point is: even with the ability to write to raw, under no scenario should a user write cleartext data to /.reserved/raw since that defeats the purpose of encryption.

bq. As far as this unit test is concerned, we should still write encrypted bytes, right? Then you verify that the read bytes are encrypted.
The whole point of this jira is namenode _will not_ create an edek if we write to {{/.reserved/raw}} path.
If there is no edek, then how will client decrypt ?

{quote}
My point is: even with the ability to write to raw, under no scenario should a user write cleartext data to /.reserved/raw since that defeats the purpose of encryption.
{quote}
I understand your point but it is difficult to incorporate in this unit test.

I understand the no edek part. The argument is the test should verify the encrypted bytes written are still encrypted bytes.
bq. If there is no edek, then how will client decrypt ?
client does not. The test verifies that the read bytes are the same, like you're doing now. Only the bytes being verifies should be encrypted bytes, because as explained there should be no circumstance you'd want to write clear text to it. 

{quote}The argument is the test should verify the encrypted bytes written are still encrypted bytes.
{quote}
Whether it's "encrypted" is irrelevant though.  There's already tests for read/write to raw so I'd say testing file contents is beyond the scope of this jira.
{quote}The whole point of this jira is namenode _will not_ create an edek if we write to {{/.reserved/raw}} path.
{quote}
Correct.  How about we end the debate by just creating the file and verifying no edek is present?

bq. How about we end the debate by just creating the file and verifying no edek is present?
Sounds like an acceptable middle ground. Attaching patch#4 to address this comment.

WFM, +1 on patch 4.

bq. WFM, +1 on patch 4.
Thank you [~xiaochen], [~daryn].
Will commit once jenkins comes back and if it is clean.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 32s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 28m 40s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 20s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 20s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 57s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  7s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 48s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 20s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}113m 28s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 28s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}183m 39s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.TestDFSInotifyEventInputStreamKerberized |
|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |
|   | hadoop.hdfs.client.impl.TestBlockReaderLocal |
|   | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |
|   | hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks |
|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HDFS-13281 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12923938/HDFS-13281.004.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 225d61bc1179 3.13.0-143-generic #192-Ubuntu SMP Tue Feb 27 10:45:36 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 0ce6290 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_162 |
| findbugs | v3.1.0-RC1 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/24243/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/24243/testReport/ |
| Max. process+thread count | 3056 (vs. ulimit of 10000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/24243/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.



Ran all of failed tests but only couple of them failed on my local machine.
{noformat}
[INFO] Results:
[INFO] 
[ERROR] Failures: 
[ERROR]   TestRetryCacheWithHA.testUpdatePipeline:1222->testClientRetryWithFailover:1324 After waiting the operation updatePipeline still has not taken effect on NN yet
[ERROR] Errors: 
[ERROR]   TestDataNodeVolumeFailure.testUnderReplicationAfterVolFailure:424 » Timeout Ti...
[INFO] 
[ERROR] Tests run: 84, Failures: 1, Errors: 1, Skipped: 37
{noformat}
Both of the tests are frequently failing tests.
Will commit #4 of the patch tomorrow if no objections.

SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #14349 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/14349/])
HDFS-13281 Namenode#createFile should be /.reserved/raw/ aware.. (shahrs87: rev e2289c8d1496a5eff88e6bcb8776a11d45371ffc)
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java


Committed patch#4 to trunk and all the way back to 2.8.
Thanks [~xiaochen] and [~daryn] for reviews.

