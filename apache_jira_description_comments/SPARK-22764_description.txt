Saw this in a PR builder:

{noformat}
[info] - Cancelling stages/jobs with custom reasons. *** FAILED *** (135 milliseconds)
[info]   Expected exception org.apache.spark.SparkException to be thrown, but no exception was thrown (SparkContextSuite.scala:531)
[info]   org.scalatest.exceptions.TestFailedException:
[info]   at org.scalatest.Assertions$class.newAssertionFailedException(Assertions.scala:528)
[info]   at org.scalatest.FunSuite.newAssertionFailedException(FunSuite.scala:1560)
[info]   at org.scalatest.Assertions$class.intercept(Assertions.scala:822)
[info]   at org.scalatest.FunSuite.intercept(FunSuite.scala:1560)

{noformat}

From the logs, the job is finishing before the test code cancels it:

{noformat}
17/12/12 11:00:41.680 Executor task launch worker for task 1 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 703 bytes result sent to driver
17/12/12 11:00:41.681 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 13 ms on localhost (executor driver) (1/1)
17/12/12 11:00:41.681 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/12 11:00:41.681 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (apply at Assertions.scala:805) finished in 0.066 s
17/12/12 11:00:41.681 pool-1-thread-1-ScalaTest-running-SparkContextSuite INFO DAGScheduler: Job 1 finished: apply at Assertions.scala:805, took 0.066946 s
17/12/12 11:00:41.682 spark-listener-group-shared INFO DAGScheduler: Asked to cancel job 1
{noformat}
