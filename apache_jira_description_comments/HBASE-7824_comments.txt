Hey Lars,

Do you want me to put the fix into 0.94.6? After the fix, master starts up will only blocked on meta region servers(including root & meta) recovery. Assuming, a 100 nodes cluster, the meta region servers is only about 2% of all region servers. Therefore, master virtually doesn't wait log splitting work for starting up.

Thanks,
-Jeffrey
 

Unblock master starts up when there are non-meta region servers' split work. After the fix, master will only block by meta region server log spliting work. More details as following:
    
    1) Adding support to fast master up
    2) Adding a test case for new code
    3) Fix test function makehlog to creat rows with keys within assigned region's key space

Hi Jeffrey,

Is this for 0.94.x? Or for trunk? If it's for trunk, I think the patch not done on the right directory level. Seems to be missing hbaser-server/ 


This patch is for 0.94.6.


Thanks. I will apply it and test it since it will be very usefull for my needs.

Few small comments.
In HMaster, you are testing if failedServers is null to handle other dead servers in SSH. So it can be null there, should it be tested also for META and ROOT? (failedServers.contains())
In MasterFileSystem, there is some extra spaces in getFailedServersFromLogFolders() (After retrySplitting declaration).
In ServerManager, does processDeadServer need to be synchronized? Many other methods calling deadservers and services are not synchronized. So I'm just asking. FindBug seems to be fine with that.



Looks good overall.
{code}
+    // Make sure root assigned before proceeding.
+    if (!assignRoot(status)) return;
{code}
I think exception should be thrown in the above case.
{code}
+    if (failedServers != null) {
+      for (ServerName curServer : failedServers) {
{code}
The null check didn't appear ahead of the above if block. I guess the check is not needed.
{code}
+   * Check <code>.META.</code> is assigned. If not, assign it.
+   * @throws InterruptedException
+   * @throws IOException
+   * @throws KeeperException
+   * @return Count of regions we assigned.
+   */
+  boolean assignMeta(MonitoredTask status, ServerName previousRootServer)
{code}
Please add javadoc for parameters. @return doesn't match actual return.
{code}
+  public synchronized void processDeadServer(final ServerName serverName) {
{code}
This method can be package private.



@Jean-Marc,

Thanks for reviewing. 

1)
"In HMaster, you are testing if failedServers is null to handle other dead servers in SSH. So it can be null there, should it be tested also for META and ROOT? (failedServers.contains())"

failedServers can't be null. I can remove the null check to be consistant.
2)
"In ServerManager, does processDeadServer need to be synchronized? Many other methods calling deadservers and services are not synchronized."

A good point. it's not needed for the fix at least.
 

@Ted,

Thanks for the reviewing. assignRoot will throw exact same exceptions as before so we should be fine there. I'll make the other changes per your comments.
 

Incorporate review comments. 

Thanks,
-Jeffrey

All tests passed. with the previous version. They are running now, I will post the results tomorrow.

{code}
  Set<ServerName> getFailedServersFromLogFolders() {
    boolean retrySplitting = !conf.getBoolean("hbase.hlog.split.skip.errors",
      HLog.SPLIT_SKIP_ERRORS_DEFAULT);
....
    Set<ServerName> serverNames = new HashSet<ServerName>();
    Path logsDirPath = new Path(this.rootdir, HConstants.HREGION_LOGDIR_NAME);
{code}
Still have some extra spaces here (replaced by dots to highlight them).

+1 for me.

Patch looks great.

Why we doing the below?  Doesn't recoverablezookeeper do this for us?

-      LOG.error("ZooKeeper exception trying to set cluster as down in ZK", e);
+      if (e instanceof KeeperException.SessionExpiredException) {
+        LOG.warn("ZK session expired. Retry a new connection...");
+        try {
+          this.zooKeeper.reconnectAfterExpiration();
+          this.clusterStatusTracker.setClusterDown();

+1 on commit.

Need to "Submit Patch" to have Hadoop QA looking at it...

The patch is for 0.94 branch.

hadoop-qa is for trunk only...

I skimmed the patch. Looks good as far as I can tell. Definitely a worthy addition ton0.94.

Has anyone been able to run all the tests successfuly? I tried 3 times today and always TestReplicationQueueFailoverCompressed was part of the failed tests.

However, I'm not sure it's realy related to this fix. I will try again tomorrow.

Tests in error: 
  queueFailover(org.apache.hadoop.hbase.replication.TestReplicationQueueFailoverCompressed): test timed out after 300000 milliseconds

Tests in error: 
  queueFailover(org.apache.hadoop.hbase.replication.TestReplicationQueueFailoverCompressed): test timed out after 300000 milliseconds
  queueFailover(org.apache.hadoop.hbase.replication.TestReplicationQueueFailover): test timed out after 300000 milliseconds

Tests in error: 
  queueFailover(org.apache.hadoop.hbase.replication.TestReplicationQueueFailoverCompressed): test timed out after 300000 milliseconds


@Jean-Marc:
Thanks for your verification.

I don't think the above test failures were caused by the patch.

@Stack

Thanks for reviewing. Though recoverablezookeeper does retry after errors, SessionExpiredException is special and normal retry won'recover the error no matter how many retries. It has to reconnect to ZK and retry.

@Jean-Marc,

I was able to run "mvn test -PlocalTests -Dtest=TestReplicationQueueFailoverCompressed" successfully on my dev box.

Working for me too with mvn test -PlocalTests -Dtest=TestReplicationQueueFailoverCompressed

Running org.apache.hadoop.hbase.replication.TestReplicationQueueFailoverCompressed
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 126.846 sec

[~lhofhansl]:
Do you want to take another look ?

Thanks

[~jeffreyz] This is for 0.94.  We don't need a trunk patch (or it is dealt w/ already in another issue?)


@Stack, the similar work is captured in HBASE-7835 for trunk. 


[~jeffreyz] Ok. +1 on commit to 0.94.

Integrated to 0.94 branch.

Thanks for the patch, Jeffrey.

Thanks for the reviews, Stack, Lars and Jean-Marc.

Integrated in HBase-0.94 #859 (See [https://builds.apache.org/job/HBase-0.94/859/])
    HBASE-7824 Improve master start up time when there is log splitting work (Jeffrey Zhong) (Revision 1449920)

     Result = SUCCESS
tedyu : 
Files : 
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/catalog/CatalogTracker.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperNodeTracker.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java


Integrated in HBase-0.94-security #112 (See [https://builds.apache.org/job/HBase-0.94-security/112/])
    HBASE-7824 Improve master start up time when there is log splitting work (Jeffrey Zhong) (Revision 1449920)

     Result = SUCCESS
tedyu : 
Files : 
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/catalog/CatalogTracker.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperNodeTracker.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java


We're seeing relatively frequent failures of TestMasterFailover.testMasterFailoverWithMockedRITOnDeadRS now. Over in HBASE-7985 Ram determined that this always happens when the RS we abort does not carry META. It might be related to this change.


@Jeff
Any specific reason for adding the server to be processed (other than RS carrying ROOT or META) to the deadServers.
{code}
 void processDeadServer(final ServerName serverName) {
    this.deadservers.add(serverName);
    this.services.getExecutorService().submit(
      new ServerShutdownHandler(this.master, this.services, this.deadservers, serverName, true));
  }
{code}
I remember we used to track the servers that got expired when master was coming up using deadServers.  See ServerManager.expireServer().  
May be some specific issues you got?  

[~ram_krish]
The reason is that we already recovered META region servers during the initialization so we don't need to keep meta region servers there. The failedServer list is only for log splitting work.Let me see why the test TestMasterFailover.testMasterFailoverWithMockedRITOnDeadRS failed more often. 

Thanks,
-Jeffrey

Yes i can understand that part.  But do we need to explicitly add to deadServers?  Because the deadServers list was like used when an RS goes down just when the master started coming up.

The reason to add those previous dead non-meta region servers into deadServers is to let the new master instance start as a failover such as the following code in AssignmentManager. In addition, we don't want AM assign those regions before log splitting work complete that's why let AM skip them inside function processDeadServersAndRegionsInTransition but handle them in SSH.

{code}
    if (!this.serverManager.getDeadServers().isEmpty()) {
      this.failover = true;
    }
{code} 

Since those failed servers will be processed by SSH so their regions should be online and I did see test log message "Finished processing of shutdown". 

There are couple of regions aren't assigned for some reason and I need to dig more in the test case and keep you updated.

Thanks,
-Jeffrey



I would like to roll 0.94.6 soon.
Should we revert this for 0.94.6 and put it back up for 0.94.7?


[~lhofhansl]I'm fine to revert it for now and put it back up for 0.94.7 because there is no hurry for this.

Thanks,
-Jeffrey

If we can work out the failure that would be preferable of course :)

Yeah, in either way I'll get the bottom of this(hopefully by end of today) so that we can be sure there is no issue. 

 

Thanks [~jeffreyz]!

Talked with Jeffrey.

I reverted the patch for now.

Jeffrey would provide his suggestion on how to make TestMasterFailover more reliable, along with his changes.

I think I found the root cause and I addressed in the trunk patch(https://reviews.apache.org/r/9419/diff/#index_header) where I have the following line:
{code}
 // wait till all dead server are processed	
    ServerManager serverManager = master.getServerManager();
    while (serverManager.areDeadServersInProgress()) {
      Thread.sleep(100);
    }
{code}

Because my change will make master start up quickly with some SSH handling left which changes existing test case assumption a little bit. So I added the above lines to match the exiting test case expectation which that all log splitting work is done & previous dead servers are handled.   

I've run the test case 20 times in a loop without any failure. 

The reason that the test case passed with removing "this.deadservers.add(serverName);". Because it basically assigns regions before master initialization due to waitForActiveAndReadyMaster in the test code. Since it matches old behavior so that test case passed while the log splitting work might not have been done before those regions are assigned.


 



Amend waitForActiveAndReadyMaster so the master ready state will wait for all SSH handing are done to match the old behavior that existing test cases are expecting.

Integrated in HBase-0.94 #879 (See [https://builds.apache.org/job/HBase-0.94/879/])
    HBASE-7824 Revert until TestMasterFailover passes reliably (Revision 1452452)

     Result = FAILURE
tedyu : 
Files : 
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/catalog/CatalogTracker.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperNodeTracker.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java


Integrated in HBase-0.94-security-on-Hadoop-23 #12 (See [https://builds.apache.org/job/HBase-0.94-security-on-Hadoop-23/12/])
    HBASE-7824 Revert until TestMasterFailover passes reliably (Revision 1452452)
HBASE-7824 Improve master start up time when there is log splitting work (Jeffrey Zhong) (Revision 1449920)

     Result = FAILURE
tedyu : 
Files : 
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/catalog/CatalogTracker.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperNodeTracker.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java

tedyu : 
Files : 
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/catalog/CatalogTracker.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperNodeTracker.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java


Integrated in HBase-0.94-security #116 (See [https://builds.apache.org/job/HBase-0.94-security/116/])
    HBASE-7824 Revert until TestMasterFailover passes reliably (Revision 1452452)

     Result = SUCCESS
tedyu : 
Files : 
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/catalog/CatalogTracker.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperNodeTracker.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java


[~ram_krish] Are you all right with my explanation in https://issues.apache.org/jira/browse/HBASE-7824?focusedCommentId=13592721&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13592721? So far the test cases passed with a small modifications in the file src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java.

Thanks,
-Jeffrey

Latest rebased patch. Below are test results:

mvn clean -PrunAllTests -Dmaven.test.redirectTestOutputToFile=true install assembly:single -DskipITs

Results :

Tests run: 1327, Failures: 0, Errors: 0, Skipped: 13

[~lhofhansl]:
What do you think of this one ?

+1 let's try again for 0.94.

Integrated to 0.94

Thanks for the patch, Jeff.

Let's see how it goes.

Integrated in HBase-0.94 #894 (See [https://builds.apache.org/job/HBase-0.94/894/])
    HBASE-7824 Improve master start up time when there is log splitting work (Jeffrey Zhong) (Revision 1455976)

     Result = FAILURE
tedyu : 
Files : 
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/catalog/CatalogTracker.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperNodeTracker.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java


Backed out again due to TestMasterFailover#testMasterFailoverWithMockedRITOnDeadRS test failure.

Since we backed this out twice... -1 on attempting this again.

Thanks for reverting Ted.

Integrated in HBase-0.94 #903 (See [https://builds.apache.org/job/HBase-0.94/903/])
    HBASE-7824 Improve master start up time when there is log splitting work, revert due to TestMasterFailover#testMasterFailoverWithMockedRITOnDeadRS failure (Revision 1456689)

     Result = FAILURE
tedyu : 
Files : 
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/catalog/CatalogTracker.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperNodeTracker.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java


Integrated in HBase-0.94-security #124 (See [https://builds.apache.org/job/HBase-0.94-security/124/])
    HBASE-7824 Improve master start up time when there is log splitting work, revert due to TestMasterFailover#testMasterFailoverWithMockedRITOnDeadRS failure (Revision 1456689)
HBASE-7824 Improve master start up time when there is log splitting work (Jeffrey Zhong) (Revision 1455976)

     Result = FAILURE
tedyu : 
Files : 
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/catalog/CatalogTracker.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperNodeTracker.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java

tedyu : 
Files : 
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/catalog/CatalogTracker.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperNodeTracker.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java


Maybe I was a bit rash here.
You said you worked on figuring out what the issues was with the failed test. Any luck?

The fix that Ram suggests in HBASE-7985 does not work?
This is a good improvement and it would be a shame to miss out on this in 0.94.


[~lhofhansl] Thanks for giving potential another chance:-). I'm still looking for a good solution. The cause of the test failure is what Ram suggested. While the cause leads me suspecting a potential situation that a region could stuck in RIT forever, I need to write a test to verify that and will keep you updated. 


Found some reasons..will keep you updated. Let me understand Jeff's patch also and the idea behind it.


[~ram_krish] Thanks for looking this as well! 




I think the test case fails before with the patch is due to an existing issue which I filed at https://issues.apache.org/jira/browse/HBASE-8127. Please see details there. Basically RITs of disabling(or disabled) table could stuck in RIT state forever for master failover case. The changes in the patch triggers the existing issue so we have the test failures.

Moving to 0.94.8 (along with HBASE-8127). Feel free to pull back in.

Integrated in HBase-0.94-security-on-Hadoop-23 #13 (See [https://builds.apache.org/job/HBase-0.94-security-on-Hadoop-23/13/])
    HBASE-7824 Improve master start up time when there is log splitting work, revert due to TestMasterFailover#testMasterFailoverWithMockedRITOnDeadRS failure (Revision 1456689)
HBASE-7824 Improve master start up time when there is log splitting work (Jeffrey Zhong) (Revision 1455976)

     Result = FAILURE
tedyu : 
Files : 
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/catalog/CatalogTracker.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperNodeTracker.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java

tedyu : 
Files : 
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/catalog/CatalogTracker.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperNodeTracker.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java


The patch is back!

There is one more hanging RIT issue found during tests and I listed below as item 4.

Patch Contents
==============
Reviewed:
1) Adding support to fast master up
2) Adding a test case for new code
3) Fix test function makehlog to creat rows with keys within assigned region's key space

New changes in the v4 Patch(unreviewed):
4) Fix ritsGoingToServer hang issue. You can try the new test case testRSKilledWithMockedOpeningRITGoingToDeadRS in the patch to reproduce the issue against 0.94 branch.
Basically ritsGoingToServer list doesn't handle disabling or disabled case. You can see the fix in SSH for details.

[~rajesh23], [~ram_krish] Could you please review this fix? Thanks in advance.

5) Since 0.94 assignment manager is a different animal than 0.96AM, in the patch I included a config flag "hbase.master.wait.for.log.splitting" to disable the feature in case some users may desperately need it later.

I'll re-run full suite test and integration tests and post results here.

Is there anyway we can remove some comments in this JIRA otherwise it's hard for others to follow?

Thanks,
-Jeffrey




Ok will check this fix.  It is related to MTTR so always it is useful.

[~jeffreyz]
Going through the patch. 
{code}
+    // SSH should enabled before META region assignment
+    // because META region assignment is depending on ROOT server online.
{code}
FYI,There is possible META data loss with this
see chunhui comment
https://issues.apache.org/jira/browse/HBASE-8251?focusedCommentId=13621689&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13621689

[~rajesh23] I saw the similar issue "if the RS who host ROOT dies before step 4, master will be blocked." during my testing since it's pre-existing issue so I guess I can live with it in the patch. Let me try to find a solution otherwise leave the issue as it is. Thanks for the reviewing.

[~rajesh23] I find a solution to deal with the pre-existing master hang issue. The solution is simple and basically enable SSH for ROOT only not others before META assignment.

I'll rerun whole suite test against the latest path and post result here.

Thanks,
-Jeffrey

Test suite result:
{code}Tests run: 1336, Failures: 0, Errors: 0, Skipped: 13{code}

Integration Test:
{code}
Running org.apache.hadoop.hbase.IntegrationTestDataIngestWithChaosMonkey
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 681.593 sec

Results :

Tests run: 1, Failures: 0, Errors: 0, Skipped: 0
{code}

You feel good about this one, Jeffrey?

Yeah. So far all test failures(relating/unrelating to this patch) found in tests of this patch are fixed in this patch or other patches. For example, a recent flaky test case failure http://54.241.6.143/job/HBase-0.94/org.apache.hbase$hbase/60/testReport/junit/org.apache.hadoop.hbase.regionserver/TestRSKilledWhenMasterInitializing/testCorrectnessWhenMasterFailOver/ should be also fixed.

I'll run more rounds of test suite through the weekend to really make it as solid as possible.

I have run the whole test suite with the patch 4 times in a row. Three are clean as following and one with single failure happened in recent builds as well.
{code}
Results :
Tests run: 1339, Failures: 0, Errors: 0, Skipped: 13

Integration Test: IntegrationTestDataIngestWithChaosMonkey
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 905.014 sec
{code}

I also provided a release note in the JIRA.

[~jeffreyz]
IMO, it is still able to cause META data loss as I mentioned in HBASE-8251:
1.Assign ROOT to the RS where META on
2.Enable SSH for ROOT
3.Assign META

If the META RS(it is also the ROOT RS) is dead between step2 and step3, MetaSSH start splitting its hlog.
However step3 will assign META directly(Because HMaster#splitLogAndExpireIfOnline will return null), it means META will loss the data from hlog.

Correct me if wrong, thanks

[~zjushch] The patch already covered the case you mentioned. You can check both v7 & v8 patch. The reason I don't mention the scenario in the above suggestion is to make the idea easier to be accepted.

Yesterday I replied you on hbase-8251 for ROOT & META collocating on one RS scenario. You can check details at MetaSSH in the patch. Basically we only recover ROOT portion and leave META part till master meta assignment completes. Below is related pseudo code snippet, please let me know if you have more questions. Thanks.
{code}
      ...
      re-assign root
      ... 
      
      if(!this.services.isServerShutdownHandlerEnabled()) {
        // resubmit in case we're in master initialization and SSH hasn't been enabled yet.
        this.services.getExecutorService().submit(this);
        this.deadServers.add(serverName);
        return;
      }
      ...
      re-assign meta
      ...
{code}


I think your patch couldn't fix the problem.

As the above mentioned case, I have two question.

1.What will the master initialization thread do when assigning META
2.What is the value of isCarryingMeta in ServerManager#expireServer， I think it's false rather than true

Let me add more clarifications to your first comments to see if you agree firstly:

{quote}
If the META RS(it is also the ROOT RS) is dead between step2 and step3, MetaSSH start splitting its hlog.
{quote}
The root recovery portion in Meta SSH will complete log splitting for both ROOT and META regions. Therefore, all recovered edits files are created before Meta region can be assigned because meta region can only be assigned only when ROOT is online. By then, all recovered edits files are created and they will be replayed when meta region is opened during assignment.

{quote}
However step3 will assign META directly(Because HMaster#splitLogAndExpireIfOnline will return null), it means META will loss the data from hlog.
{quote}
This is all right because the existing log splitting work has already be done and will be replayed during META region open phase.

Thanks for your feedbacks.



bq.Therefore, all recovered edits files are created before Meta region can be assigned because meta region can only be assigned only when ROOT is online.

We can open the META region on RS when ROOT is offline. 
How about if ROOT RS is killed between getMetaLocationOrReadLocationFromRoot and assignMeta?

It means META region is opening on the RS before SSH completed log-split

{quote}
We can open the META region on RS when ROOT is offline. 
{quote}
We need updated META location in ROOT RS when META region is opening on a newly assigned RS. Is that true? Therefore, a ROOT RS has to be online for a successful META assignment.

So the open will fail even if META region can be opened but no one can access it because root is offline and the old location isn't updated to the newly assigned location. Later Meta region will be re-assigned by MetaSSH.

bq.So the open will fail even if META region can be opened but no one can access it because root is offline
We will retry if fail to update META location in ROOT RS.
Root will be online finally, however Meta region won't be re-assigned.

{quote}
We will retry if fail to update META location in ROOT RS.
{quote}
Are you referring to HTable.put internal retries? It seems that in high level you agreed to my pervious statements. 

Let's go back to the possible scenario you mentioned above that a root RS crashed after getMetaLocationOrReadLocationFromRoot. Since ZK session timeout take a while, HMaster#splitLogAndExpireIfOnline will kick in so there won't be any issue.

Let's conclude this issue. I'll change the patch to the following pesudo-code snippet, are you fine with this adjustment?
{code}
  ...
  fileSystemManager.splitAllLogs(sn); 
  if(serverManager.isServerOnline(currentMetaServer)){
    expire(currentMetaServer);
  }
  ...
{code}
  

bq.Since ZK session timeout take a while, HMaster#splitLogAndExpireIfOnline will kick in so there won't be any issue.
1.ZK seession will timeout once java process exit.
2.I think in a complex network we shouldn't assert that ZK session timeout happen after HMaster#splitLogAndExpireIfOnline. e.g. the return of getMetaLocationOrReadLocationFromRoot is hanged for a little time.

bq.are you fine with this adjustment?
Sorry, why do this adjustment?


In addition, is it only for 0.94, no trunk?  If trunk only, I think there is no above trouble since ROOT has dropped in trunk


It's only for 0.94 and the adjustment is guaranteed that splitLog will happen right before {code}assignmentManager.assignMeta();{code} just like before to deal with the possible data loss issue you mentioned. 





{code}
   ServerName currentMetaServer = this.catalogTracker.getMetaLocationOrReadLocationFromRoot();
{code}
This is read in two places. One in finishInitialization() and the other inside assignMEta where the META RS is checked with prev ROOT server.
Can we check this only once and then make the pseudo code change as above  mentioned by Jeffrey?

I pasted the whole related code snippet as below. Ram's suggestion is possible because no one re-assign META till assignmentManager.assignMeta(). The modified logic is same as before the patch.   

{code}
      ...
      ServerName currentMetaServer = this.catalogTracker.getMetaLocationOrReadLocationFromRoot();
      if (currentMetaServer != null && !currentMetaServer.equals(previousRootServer)) {
        fileSystemManager.splitAllLogs(currentMetaServer);
        if (this.serverManager.isServerOnline(currentMetaServer)) {
          this.serverManager.expireServer(currentMetaServer);
        }
      }
      assignmentManager.assignMeta();
      enableSSHandWaitForMeta();
      ...
{code}


bq.fileSystemManager.splitAllLogs(currentMetaServer);
Should we take care of log-split concurrency between master initialization thread and SSH？

Yep, I've taken care of that. Basically, synchronized log split tasks before SSH is enabled. Once you agree the approach in general, I'll submit the modified patch for review.

A question through: Should we do expireServer firstly and then do log splitting after we have the log splitting synchronization mechanism before SSH is enabled.


bq.log splitting synchronization mechanism before SSH is enabled
Yes, it's a solution.  

What's the difference if do expireServer firstly? None? 
Go as your thought

Make sure splitLog happen once before we assign Meta to address data loss concern from [~zjushch]

Thanks [~zjushch] for the reviewing!

Test result for v9 patch:
{code}
Test Suite Results :

Tests run: 1339, Failures: 0, Errors: 0, Skipped: 13

Integration: IntegrationTestDataIngestWithChaosMonkey

Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 353.049 sec
{code}


Minor comments:
{code}+   * @param previousRootServer ServerName of previous root region server before current start up
+   * @return
+   * @throws InterruptedException{code}
remove @return

{code}
+        } catch (Exception ex) {
+          LOG.warn("Retry setClusterDown failed", ex);
+        }
{code}
LOG.error seems more reasonable since using error before

Some doubt:
{code}
+      this.fileSystemManager.splitAllLogs(preRootServer);
+      this.fileSystemManager.splitAllLogs(preMetaServer);
+        fileSystemManager.splitAllLogs(currentMetaServer);
{code}
Should use the flag 'shouldSplitMetaSeparately' like other log-split?

In master#finishInitialization, after handling other dead servers in SSH, we will call assignmentManager.joinCluster(), it seems have some problems, e.g.
1.in AssignmentManager#processDeadServersAndRegionsInTransition, how about if we mark it as a clean cluster startup?
2.if we mark it as a failover, is there any conflict between SSH and AssignmentManager#processDeadServersAndRecoverLostRegions

An important attention:
From DeadServer#cleanPreviousInstance, a deadserver will be removed if the same HostnamePort servername is online.
It means a server will not belong to deadservers even if it is processed in SSH.


[~zjushch] Thanks for the detailed reviewing!

For your first two comments, I'll make corresponding modifications.

{quote}
Should use the flag 'shouldSplitMetaSeparately' like other log-split?
{quote}
A good question. Since splitLog is a sync call, the following two calls 
{code}
      fileSystemManager.splitMetaLog(sn);
      fileSystemManager.splitLog(sn);
{code}
are logically equivalent to one splitAllLogs call while splitAllLogs has a little bit performance advantage because it submits all log splitting logs in one go. 'shouldSplitMetaSeparately' is significant in MetaSSH and SSH while in other places there is no difference logically. 
Being said that, in some places I could take advantage by separating them to improve a little bit more on master start up. As you know both features are new, so I choose conservative way in the beginning and make them less dependent on each other.

{quote}
in AssignmentManager#processDeadServersAndRegionsInTransition, how about if we mark it as a clean cluster startup?
if we mark it as a failover, is there any conflict between SSH and AssignmentManager#processDeadServersAndRecoverLostRegions
{quote}
If we have left log splitting work, it means that the new master start up isn't a clean one. The reason to make it a failover is to let SSH(single place) to handle dead servers including the log splitting we skipped at the very beginning. If we make the start up as a clean one, we could have data loss as log splitting won't be done for some regions. 
During the AssignmentManager#processDeadServersAndRecoverLostRegions, there are existing implementations intentionally skipping all known dead servers and leave them to SSH so there is no conflict.

{quote}
From DeadServer#cleanPreviousInstance, a deadserver will be removed if the same HostnamePort servername is online. 
{quote}
Good concern. The key point is that DeadServer#cleanPreviousInstance will be only called after master initialization. By then, we don't rely on DeadServer much as far as master start up concerns. After master is initialized, DeadServer is basically used in UI to show previously dead servers, "YouAreDeadException" handling and prevent duplicated expireServer calls. As you already know, once a dead server SSH is submitted, it will continue till it's done regardless if it's in the DeadServer or not. This could happen today when a RS crashed sequentially while its previous instances are still in SSH pipe no matter if DeadServer tracks them or not. In short, DeadServer#cleanPreviousInstance doesn't have much impact.


waitingOnLogSplitting - waitOnLogSplitting may be better.
bq.this.catalogTracker.getMetaLocationOrReadLocationFromRoot();
Is it ok to call this in one place as per my yesterday's comment.
If root went down after 
{code}
this.initializationBeforeMetaAssignment = true;
{code}
we call assignRoot.  when we try to split the log we will not do that because SSH is not yet enabled.
{code}
    this.assignmentManager.assignRoot();
      waitForRootAssignment();
{code}
So we expect that though the above step waits, we do 
{code}
this.serverManager.enableSSHForRoot();
{code}
Which will do the assignment? Still sshEnabled is not true right?
Things look fine but still this area is really a big head ache.  Removal of ROOT in trunk is a blessing for developers now.
I think if you are confident on the above comments then let us go for a commit and address if future issues.  Else we are good.

Good stuff Jeff, Everytime I feel that something may be missed out in this area.
@Chunhui
What do you feel?


[~ram_krish] Thanks for the reviewing!
{quote}
Is it ok to call this in one place as per my yesterday's comment.
{quote}
The change was missed and I'll make sure it's in the next patch.

{quote}
Which will do the assignment? Still sshEnabled is not true right?
{quote}
A very good point. In very rare case I did see tests failed tue to this. If no objections, I can move the enableSSHForRoot right after assignRoot(); to close the loophole following the same pattern we do for metaAssignment.



Submit v10 patch to incorporate feedbacks from Chunhui and Ram.

After I moved enableSSHForRoot() right after rootAssignment. I can run TestMasterFailover 10 times in a loop successfully while there may be one failure before.

{code}
Test Suite Result:

Tests run: 1339, Failures: 0, Errors: 0, Skipped: 13

Integration Test: IntegrationTestDataIngestWithChaosMonkey

Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 662.064 sec
{code}

As ram saied, things are easy to be missed out in this area...

Patch v10 seems good for me.

Maybe I have realized one bug case.
Suppose Master,RS1,RS2
1.kill master and RS1
2.start master and RS1
3.master start SSH to process dead server RS1 when initialization
4.RS1 is not in dead server since a new RS1 is online
5.AssignmentManager#joinCluster rebuild user regions, return the dead server RS1 and its regions
6.AssignmentManager#processDeadServersAndRecoverLostRegions will assign the regions carried by RS1
7.However hlogs of RS1 is still being split by SSH, it means data loss since we assign region in step6 before completing log-split

[~jeffreyz]
Please take a check, correct me if wrong

[~zjushch] Could you please clarify RS1 online state from step 4 to step 6? Thanks.

In step4, RS1 is recorded as online by Master while in step 5 we return RS1 as dead. AM#rebuildUserRegions only returns dead servers which are not contained in online servers. 
Since AssignmentManager#processDeadServersAndRecoverLostRegions skips all dead servers for region assignment, it seems you're suggesting RS1 online again in step 6.


RS1,001 is dead server 
RS1,002 is online server

where 001 and 002 represents the start code of regionserver

RS1,001 is being processed by SSH and also marked as dead server in AM#rebuildUserRegions.

However, RS1,001 is not included in ServerManager#getDeadServers, so AssignmentManager#processDeadServersAndRecoverLostRegions won't skip this server

The following clarifications might help:

During Master starts up, function getFailedServersFromLogFolders will return (rs1,001) as part of failedServers. Because start code is part of server name so does hlog file path. Before AM.joinCluser(), the following code in HMaster#finishInitialization will put (rs1,001) into deadservers. {code}
    status.setStatus("Submit log splitting work of non-meta region servers");
    for (ServerName curServer : failedServers) {
      this.serverManager.expireServer(curServer);
    }
{code}



bq.HMaster#finishInitialization will put (rs1,001) into deadservers. 
Yes, it's so.
But (rs1,001) will be removed from deadservers by DeadServer#cleanPreviousInstance, you could take a see about its call hierarchy.

I have poined this in the above comment:
From DeadServer#cleanPreviousInstance, a deadserver will be removed if the same HostnamePort servername is online.
It means a server will not belong to deadservers even if it is being processed in SSH. 

I'm about to send additional notes about DeadServer#cleanPreviousInstance. I think it may help to solve all the confusions:

1) The above steps including AM#JoinCluster are before master.initialized becomes true.
2) Inside function ServerManager#checkIsDead {code}
    // remove dead server with same hostname and port of newly checking in rs after master
    // initialization.See HBASE-5916 for more information.
    if ((this.services == null || ((HMaster) this.services).isInitialized())
        && this.deadservers.cleanPreviousInstance(serverName)) {
{code}
You can see this.deadservers.cleanPreviousInstance won't do anything because master is NOT initialized yet.

Good point, I'm clear about this now, thanks.

+1 from me

Quality works lads (Jeffrey, Ram, and Chunhui).

[~lhofhansl], [~ram_krish]:
Do you have further review comments ?

If above Chunhui's comments are fixed and i see that latest patch V10 has the changes incorporated +1 on the patch. Thanks Jeffrey, continuous persisted efforts on this JIRA.
Thanks to Chunhui for good reviews.

Many thanks to Ram, Chunhui and Rajesh for the latest reviews! 

[~lhofhansl] Are you all right to check the patch v10 in? Thanks.

Patch looks good (although I didn't have time for a detailed review)
+1

Integrated to 0.94

Thanks for the continued effort, Jeff.

Thanks for the reviews, Ram, Chunhui and Rajesh.

Integrated in HBase-0.94 #955 (See [https://builds.apache.org/job/HBase-0.94/955/])
    HBASE-7824 Improve master start up time when there is log splitting work (Jeffrey Zhong) (Revision 1466725)

     Result = SUCCESS
tedyu : 
Files : 
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/catalog/CatalogTracker.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/handler/MetaServerShutdownHandler.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperNodeTracker.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/master/TestMasterFailover.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java


Integrated in HBase-0.94-security #134 (See [https://builds.apache.org/job/HBase-0.94-security/134/])
    HBASE-7824 Improve master start up time when there is log splitting work (Jeffrey Zhong) (Revision 1466725)

     Result = FAILURE
tedyu : 
Files : 
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/catalog/CatalogTracker.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/handler/MetaServerShutdownHandler.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperNodeTracker.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/master/TestMasterFailover.java
* /hbase/branches/0.94/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java


