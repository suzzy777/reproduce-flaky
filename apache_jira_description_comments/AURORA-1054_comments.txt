This test flaked the build twice yesterday (output captured below). [~wickman] how do you think we should proceed?

{noformat}
self = <test_thermos_task_runner.TestThermosTaskRunnerIntegration object at 0x7f5299b93190>

    def test_integration_stop(self):
      with self.yield_sleepy(ThermosTaskRunner, sleep=1000, exit_code=0) as task_runner:
        task_runner.start()
        task_runner.forked.wait()
    
        assert task_runner.status is None
    
>       task_runner.stop()

src/test/python/apache/aurora/executor/test_thermos_task_runner.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <apache.aurora.executor.thermos_task_runner.ThermosTaskRunner object at 0x7f5299b68850>
timeout = Amount(1, mins)

    def stop(self, timeout=MAX_WAIT):
      """Stop the runner.  If it's already completed, no-op.  If it's still running, issue a kill."""
      log.info('ThermosTaskRunner is shutting down.')
    
      if not self.forking.is_set():
        raise TaskError('Failed to call TaskRunner.start.')
    
      log.info('Invoking runner HTTP teardown.')
      self._terminate_http()
    
      log.info('Invoking runner.kill')
      self.kill()
    
      waited = Amount(0, Time.SECONDS)
      while self.is_alive and waited < timeout:
        self._clock.sleep(self.POLL_INTERVAL.as_(Time.SECONDS))
        waited += self.POLL_INTERVAL
    
      if not self.is_alive and self.task_state() != TaskState.ACTIVE:
        return
    
      log.info('Thermos task did not shut down cleanly, rebinding to kill.')
      self.quitquitquit()
    
      while not self._monitor.finished and waited < timeout:
        self._clock.sleep(self.POLL_INTERVAL.as_(Time.SECONDS))
        waited += self.POLL_INTERVAL
    
      if not self._monitor.finished:
>       raise TaskError('Task did not stop within deadline.')
E       TaskError: Task did not stop within deadline.

/tmp/user/20000/tmpbtYWk7/apache/aurora/executor/thermos_task_runner.py:348: TaskError
{noformat}

{noformat}
self = <test_thermos_task_runner.TestThermosTaskRunnerIntegration object at 0x7fc2350691d0>

    def test_integration_stop(self):
      with self.yield_sleepy(ThermosTaskRunner, sleep=1000, exit_code=0) as task_runner:
        task_runner.start()
        task_runner.forked.wait()
    
        assert task_runner.status is None
    
>       task_runner.stop()

src/test/python/apache/aurora/executor/test_thermos_task_runner.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <apache.aurora.executor.thermos_task_runner.ThermosTaskRunner object at 0x7fc235040850>
timeout = Amount(1, mins)

    def stop(self, timeout=MAX_WAIT):
      """Stop the runner.  If it's already completed, no-op.  If it's still running, issue a kill."""
      log.info('ThermosTaskRunner is shutting down.')
    
      if not self.forking.is_set():
        raise TaskError('Failed to call TaskRunner.start.')
    
      log.info('Invoking runner HTTP teardown.')
      self._terminate_http()
    
      log.info('Invoking runner.kill')
      self.kill()
    
      waited = Amount(0, Time.SECONDS)
      while self.is_alive and waited < timeout:
        self._clock.sleep(self.POLL_INTERVAL.as_(Time.SECONDS))
        waited += self.POLL_INTERVAL
    
      if not self.is_alive and self.task_state() != TaskState.ACTIVE:
        return
    
      log.info('Thermos task did not shut down cleanly, rebinding to kill.')
      self.quitquitquit()
    
      while not self._monitor.finished and waited < timeout:
        self._clock.sleep(self.POLL_INTERVAL.as_(Time.SECONDS))
        waited += self.POLL_INTERVAL
    
      if not self._monitor.finished:
>       raise TaskError('Task did not stop within deadline.')
E       TaskError: Task did not stop within deadline.

/tmp/user/20000/tmp3UBcyp/apache/aurora/executor/thermos_task_runner.py:348: TaskError
{noformat}

I *think* understand what's going on now.  This is almost certainly an artifact from the open source refactor (fd241cdd).  Trying to understand the intricacies of the race but the gist is that we fork a runner, it forks a task that swallows SIGTERM, we send SIGUSR1 to the runner which tears its children down by doing the SIGTERM -> SIGKILL escalation, but the escalation grace period is 60s.  This happens to correspond with the default timeout in stop(), when could result in a raised TaskError some of the time depending on whether the executor or runner wins.  Will continue to dig deeper to understand what behavior precisely we're trying to test and targeting that specifically.

