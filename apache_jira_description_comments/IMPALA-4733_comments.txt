So, unfortunately we only seem to have logs from the latest failure, not prior ones. However, a quick scan shows this error in the Zookeeper output:

{noformat}
17/01/04 21:31:35 ERROR server.NIOServerCnxn: Unexpected Exception: 
java.nio.channels.CancelledKeyException
	at sun.nio.ch.SelectionKeyImpl.ensureValid(SelectionKeyImpl.java:73)
	at sun.nio.ch.SelectionKeyImpl.interestOps(SelectionKeyImpl.java:77)
	at org.apache.zookeeper.server.NIOServerCnxn.sendBuffer(NIOServerCnxn.java:153)
	at org.apache.zookeeper.server.NIOServerCnxn.sendResponse(NIOServerCnxn.java:1075)
	at org.apache.zookeeper.server.FinalRequestProcessor.processRequest(FinalRequestProcessor.java:404)
	at org.apache.zookeeper.server.SyncRequestProcessor.run(SyncRequestProcessor.java:138)
{noformat}

The error seems to be recoverable to an extent. For example, I see this in the saved logs from other RHEL7 test runs, even ones where HBase started successfully. Notably however, I don't see it in the log files from other platforms. I wonder if there's something about this platform that makes it especially susceptible to hitting this exception?

This is just an observation. It may or may not turn out to be a red herring.

I think I've seen this again in a private Jenkins run. Please ping me and I can provide access to the artifacts.

[~lv] I just added a comment to ZOOKEEPER-2044 to see if someone can help confirm whether this is that bug.

This seems to be a duplicate of [ZOOKEEPER-2044|https://issues.apache.org/jira/browse/ZOOKEEPER-2044]. A patch has been submitted, but is still in review.

Reopening, since ZOOKEEPER-2044 does not seem to address the underlying issue (but merely improves the error reporting) and we expect it to show up again on RHEL7.

[~srus], [~dhecht] - I'm downgrading this to a P2: it only affects RHEL7, it only affects the test infrastructure (i.e. it makes the tests red, but because of an issue with how we start HBase, not because of a product defect), and it occurs very infrequently. Please let me know if you want us to keep tracking this as a P1.

IMPALA-4733: Change HBase ports to non-ephemeral

We've seen repeated test failures because HBase tries to bind to ports
in the ephemeral port range, which sometimes would already be occupied
by outgoing connections of other proccesses.

This change changes the ports to the new default HBase ports
(HBASE-10123):

HBase Master Port: 60000 -> 16000
HBase Master Web UI Port: 60010 -> 16010
HBase ReqionServer Port: 60020 -> 16020
HBase ReqionServer Web UI Port: 60030 -> 16030
HBase Status Multicast Port: 60100 -> 16100

This made it necessary to change the default KMS port, too
(HADOOP-12811):

KMS HTTP port: 16000 -> 9600

Change-Id: I6f8af325e34b6e352afd75ce5ddd2446ce73d857
Reviewed-on: http://gerrit.cloudera.org:8080/6524
Reviewed-by: Lars Volker <lv@cloudera.com>
Tested-by: Impala Public Jenkins

A similar issue happened again.

The new HBase issue we are seeing is different from this one. Opened IMPALA-5223.

