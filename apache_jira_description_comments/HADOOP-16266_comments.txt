Added a first patch split off from HDFS-14403: still open to what we should do wrt changing the default time units.

Hey [~cgregori], looking good overall! I have some small comments throughout; see below. Besides those, this could use some unit tests. I still like the idea of moving to micro or nanoseconds for the processing time, but am still worried... Ping [~weichiu] again and also [~elgoiri] for thoughts on whether we can change the units of these metrics.

* We typically indent parameter lists by 4, rather than to line up with the first parameter, like:
{code:java}
  @Override
  public void addResponseTime(String name, Schedulable obj,
      ProcessingDetails details) {
  }
{code}
rather than
{code:java}
  @Override
  public void addResponseTime(String name, Schedulable obj,
                              ProcessingDetails details) {
  }
{code}

 * You have some extraneous whitespace formatting changes, unless you're making a change in that line already, it's often better to leave them unchanged (it makes backports easier).
 * I would prefer to avoid the loss of precision by casting to {{int}} in {{DecayRpcScheduler#addResponseTime()}}. Can we simply throw an {{UnsupportedOperationException}} within the old version of the method, and move the implementation to the new one? I don't think the old one will be called anywhere; we are just leaving it for compatibility with the {{RpcScheduler}} interface.
 * Can we add a {{default}} implementation of the new method within {{RpcScheduler}}? Otherwise old implementations of this class which may be floating around will fail. See what I mean [here|https://dzone.com/articles/interface-default-methods-java]. After this you shouldn't need to make changes to {{TestRpcScheduler}}.
 * For the parameter names {{start}} and {{delta}} within {{FSNamesystemLock}}, can we rename them to {{startNanos}} and {{deltaNanos}} ?
 * Does {{ProcessingDetails.Timing.newEnumArray()}} need to be {{public}} ? Does it even need to exist at all? It seems it's only used in one place.
 * Within {{ProtobufRpcEngine}}, we took away the following:
{code:java}
        } finally {
          currentCallInfo.set(null);
{code}
But I think we should still be resetting the current call info. Also, it looks like now we only catch and update the name for {{ServiceException}}, but previously it was for all {{Exception}}, which I think should continue to be the case. Also in this method, can we store {{Server.getCurCall().get()}} before the {{try}} block, and then just re-use it? {{ThreadLocal}} is cheap but not free. (same for {{WritableRpcEngine}})

 * {{Server#logSlowRpcCalls()}} should probably use a {{long}} instead of {{int}} if we are going to use microseconds. Same for the {{RpcMetrics}} methods.
 * Can you add comments describing the various arithmetic ops you do within {{Server#updateMetrics()}}?
 * If we change the {{Call.timestamp}} field from millis to nanos, can we also rename it to {{timestampNanos}}?
 * For {{Call.detailedMetricsName}}, if there are any accesses of {{getDetailedMetricsName()}} in a different thread from the one which called {{setDetailedMetricsName()}}, it needs to be {{volatile}}. I'm not sure if this is the case but it's probably best to do it just in case.
 * Can you add at least some simple Javadoc for the new {{Call}} methods?
 * It seems a {{LOG}} message was removed from both of the {{RpcEngine}} classes. A new one was added within {{Server}}, but it is missing information: the method name, whether it was deferred, and the exception name.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  1m  4s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 36s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 23m 42s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 19m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 49s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 55s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 18m 12s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 59s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 20s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 44s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 15m 23s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 18s{color} | {color:orange} root: The patch generated 9 new + 299 unchanged - 4 fixed = 308 total (was 303) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 25s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 42s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m  0s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 11s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}102m  1s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 47s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}223m 25s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.ipc.TestProtoBufRpc |
|   | hadoop.hdfs.server.blockmanagement.TestBlockManager |
|   | hadoop.hdfs.web.TestWebHdfsTimeouts |
|   | hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade |
|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:bdbca0e |
| JIRA Issue | HADOOP-16266 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12966783/HADOOP-16266.001.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux e63d7885f0cd 4.4.0-141-generic #167~14.04.1-Ubuntu SMP Mon Dec 10 13:20:24 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 59ded76 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_191 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/16180/artifact/out/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/16180/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/16180/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/16180/testReport/ |
| Max. process+thread count | 3064 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/16180/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



At some point I had issues with monotonicNowNanos() and NUMA.
I think [~stevel@apache.org] mentioned this issue in some other JIRA.
I would be careful with that.

Other than that, I think that changing the units might be an issue.
By default, we should leave the interfaces as they were before and make this configurable.

In any case, I think we need to increase the code coverage substantially here.
We can add sleeps and verify that the numbers are larger than the sleep itself for each component.
Similar for coverage for the time units.

Thanks for the comments [~xkrogen]! Addressed most of them: added tests for the ProcessingDetails class but still need tests to ensure that the times are getting populated when a call is processed. Also still need to add comments around the math in {{Server#updateMetrics()}} (trying to understand it better first).

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 49m 28s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  8m 20s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 27m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 27m 51s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 46s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 41s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 20m 44s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m  8s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 50s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 31s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 26s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 23m 21s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 23m 21s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  3m 18s{color} | {color:orange} root: The patch generated 11 new + 307 unchanged - 6 fixed = 318 total (was 313) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 35s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 44s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 35s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 10m 28s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}147m 17s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  1m  6s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}356m 46s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.ipc.TestProtoBufRpc |
|   | hadoop.hdfs.qjournal.server.TestJournalNode |
|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |
|   | hadoop.hdfs.web.TestWebHdfsTimeouts |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:bdbca0e |
| JIRA Issue | HADOOP-16266 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12966810/HADOOP-16266.002.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux b85f8bbfd13b 4.4.0-138-generic #164-Ubuntu SMP Tue Oct 2 17:16:02 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / c504eee |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_191 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/16185/artifact/out/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/16185/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/16185/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/16185/testReport/ |
| Max. process+thread count | 3567 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/16185/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



Thanks [~cgregori]. A few comments on patch v2:
 - I see that with the patch, {{RpcScheduler#addResponseTime(String, int, int, int)}} is no longer used anywhere. Curious what are the risks by removing it?
 - With the default implementation in {{RpcScheduler}}, you should not need to provide another impl in {{DefaultRpcScheduler}}.
 - Unused import in {{TestConsistentReadsObserver}}.
 - Still thinking whether the default time unit for {{ProcessingDetails}} can be nano instead micro. At the moment we are passing nano through {{ProcessingDetails#set()}} and then convert to micro, which seems unnecessary.
 - Some indentation is off such as {{DecayedRpcScheduler#addResponseTime}}.
 - Maybe it's worth pointing out that processing time always equal to {{lock_free + lock_wait + lock_shared + lock_exclusive)}} in {{ProcessingDetails}}?
 - We'll need to add documentation for the newly added metrics [here|https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/site/markdown/Metrics.md].

Added a 3rd patch: addresses [~csun]'s comments :) chose to use nanos within ProcessingDetails to maintain high precision, but the metrics default to using millis to maintain compatibility. Also working on debugging a race condition in {{TestProtobufRpc#testLogSlowRPC}} caused by moving the {{updateMetrics}} call.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 22s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 36s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 20m  5s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 57s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 18m 18s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m  5s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 58s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m  9s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 17m  9s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 21s{color} | {color:orange} root: The patch generated 8 new + 307 unchanged - 6 fixed = 315 total (was 313) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 39s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 39s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 26s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 55s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  9m 38s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}108m 59s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  1m  6s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}230m 25s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.ipc.TestIPCServerResponder |
|   | hadoop.ipc.TestProtoBufRpc |
|   | hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints |
|   | hadoop.hdfs.server.datanode.TestNNHandlesBlockReportPerStorage |
|   | hadoop.hdfs.web.TestWebHdfsTimeouts |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:bdbca0e |
| JIRA Issue | HADOOP-16266 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12966955/HADOOP-16266.003.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux d40eae0215d6 4.4.0-144-generic #170~14.04.1-Ubuntu SMP Mon Mar 18 15:02:05 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / a703dae |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_191 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/16187/artifact/out/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/16187/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/16187/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/16187/testReport/ |
| Max. process+thread count | 2702 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/16187/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



v003 patch is looking really good! The remaining things are mostly pretty minor, besides fixing the test. I think leaving the change to make the metrics time unit to be configurable for a later JIRA is a good move. But this sets up the framework for it to be done.

* In the {{UnsupportedOperationException}} we throw within {{DecayRpcScheduler}}, can we provide a helpful message like "This method has been deprecated, please use the other addResponseTime"
* In {{RpcScheduler}}, can we mark the old {{addResponseTime}} as {{@Deprecated}} and give a pointer to the new version.
* Can we make the {{default}} implementation of {{addResponseTime}} actually a useful implementation:
{code}
  default void addResponseTime(String name, Schedulable obj,
      ProcessingDetails details) {
    addResponseTime(name, obj.getPriorityLevel(),
        (int) details.get(ProcessingDetails.Timing.QUEUE, TimeUnit.MILLISECONDS),
        (int) details.get(ProcessingDetails.Timing.PROCESSING, TimeUnit.MILLISECONDS));
  }
{code}
* In the description for {{RpcLockWaitTimeAvgTime}} within {{Metrics.md}}, you mention "the lock", which is the case for HDFS, but other uses (such as the RM) may have multiple locks. We should make it more like "waiting for lock acquisition"
* Can we add {{@InterfaceAudience.Private}} to {{ProcessingDetails}}
* In {{doPurge}}, can we use {{TimeUnit.NANOSECONDS.convert()}} instead of dividing by a constant

Fixed all those up in .004, as well as fixed the race condition in {{TestProtoBufRpc}} :)

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 27s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 11s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 38s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 18m  4s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 24s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 32s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 17m 24s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 50s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m  1s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 20s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 46s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 24s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 15m 24s{color} | {color:red} root generated 3 new + 1481 unchanged - 0 fixed = 1484 total (was 1481) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 19s{color} | {color:orange} root: The patch generated 8 new + 311 unchanged - 6 fixed = 319 total (was 317) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 24s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  1s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 43s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 15s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  9m 24s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}106m 33s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 57s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}223m 19s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.ipc.TestIPCServerResponder |
|   | hadoop.hdfs.web.TestWebHdfsTimeouts |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:bdbca0e |
| JIRA Issue | HADOOP-16266 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12967054/HADOOP-16266.004.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 7cc326494288 4.4.0-144-generic #170~14.04.1-Ubuntu SMP Mon Mar 18 15:02:05 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / b5dcf64 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_191 |
| findbugs | v3.1.0-RC1 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/16190/artifact/out/diff-compile-javac-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/16190/artifact/out/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/16190/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/16190/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/16190/testReport/ |
| Max. process+thread count | 3028 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/16190/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



[~cgregori] and I noticed an issue that the new code was using {{Time.monotonicNowNanos()}}, but was comparing the resulting value to numbers produced by {{Time.now()}} (after a unit conversion). This will produce wildly wrong results since one is the arbitrary system clock, and one is real time. I think the right way to handle this is to convert all of the timings within {{Server}} to use {{monotonicNowNanos()}}.

[~elgoiri], I saw your concern above about the use of {{monotonicNowNanos()}}. I wonder if this is an outdated concern? I tried to do some reading on the subject and found [this well-written answer|https://stackoverflow.com/questions/510462/is-system-nanotime-completely-useless/54566928#54566928] which sounds like it is no longer a concern in newer JDK versions. It would be great to hear if you have other concerns around the use of {{monotonicNowNanos()}} because I have written lots of other code which uses it as well :)

Thanks [~cgregori] for checking.
I'm not sure myself anymore but it's something that has been bugging me for a while.
I remember [~stevel@apache.org] brought it up in the last year or so in some other JIRA but can't find it now.
It's kind of worrisome that the answer still mentions that we should handle negative values as 0s.
In any case, as you said we should have this problem in many more places.


| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 26s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 28s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 18m 51s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 23m 40s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 25s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 35s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 17m 28s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m  5s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m  1s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 56s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 46s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 39s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 17m 39s{color} | {color:red} root generated 3 new + 1481 unchanged - 0 fixed = 1484 total (was 1481) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 45s{color} | {color:orange} root: The patch generated 8 new + 311 unchanged - 6 fixed = 319 total (was 317) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 52s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 32s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 55s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m  0s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m  2s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}104m 11s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 48s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}229m 23s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.TestRollingUpgrade |
|   | hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes |
|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestSpaceReservation |
|   | hadoop.hdfs.TestDFSClientRetries |
|   | hadoop.hdfs.web.TestWebHdfsTimeouts |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:bdbca0e |
| JIRA Issue | HADOOP-16266 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12967073/HADOOP-16266.005.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 5ecd78523ab6 4.4.0-144-generic #170~14.04.1-Ubuntu SMP Mon Mar 18 15:02:05 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / b5dcf64 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_191 |
| findbugs | v3.1.0-RC1 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/16192/artifact/out/diff-compile-javac-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/16192/artifact/out/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/16192/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/16192/testReport/ |
| Max. process+thread count | 3004 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/16192/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



see: http://steveloughran.blogspot.com/2015/09/time-on-multi-core-multi-socket-servers.html

issues

* if it is single core, then on a multicore system if a thread is rescheduled: different/invalid answers
* if it is single die (as it is on newer parts), then on a two socket system you can have inconsistencies, though much lower risk, even after rescheduling.
* Same issues with execution on VMs and containers: you don't know what is happening, but a -ve value is not to be unexpected

Overall then: a low cost way of microbenchmarking. Not a silver bullet, and when you start yielding the CPU, the risk of invalid answers increases. 

Regarding the patch (BTW, github PRs are now a good way for reviewing), not looked in detail enough to say anything other than: please use SFL4J not commons logging. I'll let people who know the RPC code look at things in more detail.

If you want low cost, fine-grained metrics of CPU perf, nanotime is probably a good fit. If you are trying to measure IPC times, the measuring inconsistencies across cores/dies makes it riskier


Hi [~stevel@apache.org], thanks for sharing your thoughts. I see that blog post is from 2015. Other explanations I have found indicate that what you describe used to be a very significant problem, but that in modern JDKs (7+), the JVM guarantees that System.nanoTime works as you would expect even in the face of multi-cored systems. This guarantee was originally plagued by bugs, but all known outstanding issues have been fixed, so IIUC from my reading, there should be no more issues in using it as such. Do you believe that all of your concerns from 2015 are still relevant in today's world?

In terms of more concrete comments on v005 patch:
* I agree with Steve about slf4j instead of commons-logging in {{ProcessingDetails}}, I did not notice that before.
* We have a lot of {{long}} variable and parameters that used to store millis, but now store nanos. Can we change the name of all of these to have a {{Nanos}} suffix? I would say millis are sort of the de facto default, so if we are using nanos, we should make it obvious.
* I have a concern about where the {{call.isOpen()}} call is performed. Since it is called after {{call.run()}}, the call may have been naturally closed by this point. I think we need to store {{processed = call.isOpen()}} _before_ calling {{call.run()}}.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 22s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 15s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 18m 34s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m  1s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 25s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 17m 29s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 27s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m  4s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 25s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m  0s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 17m  0s{color} | {color:red} root generated 3 new + 1481 unchanged - 0 fixed = 1484 total (was 1481) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 20s{color} | {color:orange} root: The patch generated 8 new + 311 unchanged - 6 fixed = 319 total (was 317) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 45s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 43s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 57s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 55s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}104m 21s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 54s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}222m 13s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.web.TestWebHdfsTimeouts |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:bdbca0e |
| JIRA Issue | HADOOP-16266 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12967159/HADOOP-16266.006.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 5cbea8bd1592 4.4.0-144-generic #170~14.04.1-Ubuntu SMP Mon Mar 18 15:02:05 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 3758270 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_191 |
| findbugs | v3.1.0-RC1 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/16194/artifact/out/diff-compile-javac-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/16194/artifact/out/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/16194/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/16194/testReport/ |
| Max. process+thread count | 2724 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/16194/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



I agree that post is out of date; I'm not sure how things have changed. Links would be good. At the same time, in a world of containers and VMs, the base assumptions we have of time "it moves forwards consistently" may not hold. Just bear that in mind and consider coding for it. (I type, while thinking of those places where I haven't)

I like the idea of using nanos; there's also all of the java 9 time APIs which may be a bit too expensive here, especially as you aren't worrying about "real world" dates and times, just elapsed times.

Given this is just perf metrics, go for the nanotime, use that nano suffix, but add handling for negative values and for any per-op metrics do something to avoid division by zero errors

[~cgregori] is on vacation so I'm taking over for the time being. I put up a v007 patch that cleans up a few more checkstyle issues, and adds a {{default}} implementation of the old {{RpcScheduler.addResponseTime()}} method to make it more obvious that it should no longer be used. I also added a more in-depth test within {{TestRPC}} to confirm that the new metric, {{RpcLockWaitTime}}, is being incremented as expected. This confirms that the {{ProcessingDetails}} are being used properly.

[~stevel@apache.org], thanks for the response. I checked and I don't think there's anywhere here which would have issues if a negative number were returned. I still updated {{ProcessingDetails}} to always return a nonnegative number, even if someone puts a negative number into it, so that accessors always see a nonegative duration.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 36s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 7 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  2m  6s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 24m 31s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 22m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 37s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 24s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 19m  2s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 29s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m  0s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 27s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 25s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 30s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} cc {color} | {color:green} 16m 30s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 16m 30s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 57s{color} | {color:orange} root: The patch generated 10 new + 373 unchanged - 6 fixed = 383 total (was 379) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 26s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 1 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 40s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m  1s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 10m  2s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}112m 22s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 50s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}245m 49s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.TestPread |
|   | hadoop.hdfs.web.TestWebHdfsTimeouts |
|   | hadoop.hdfs.TestBlocksScheduledCounter |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:bdbca0e |
| JIRA Issue | HADOOP-16266 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12967408/HADOOP-16266.007.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  cc  |
| uname | Linux 2d7e0feb4fd7 4.4.0-144-generic #170~14.04.1-Ubuntu SMP Mon Mar 18 15:02:05 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 4b4200f |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_191 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/16203/artifact/out/diff-checkstyle-root.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/16203/artifact/out/whitespace-eol.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/16203/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/16203/testReport/ |
| Max. process+thread count | 2605 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/16203/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



Fixed a few checkstyle issues in v008 patch. [~elgoiri], [~csun], are either of you interested in helping to review again? I have been a little too close to the code to be comfortable with reviewing it myself.

Thanks [~xkrogen]. Will take another pass on this today :)

I don't have fundamental comments.
I like the use of nanos all over and just converting to whatever the admin sets.

Minor comments:
* In {{RpcScheduler#addResponseTime}}, I would extract the variables. Easier to have high level names.
* In the second {{RpcScheduler#addResponseTime}}, it would be good to clarify the use of the deprecated method (kind of confusing to have one deprecated and the other one using it).
* In {{Server}} use the logger style for the warning. Not sure if it needs the {{isWarnEnabled()}} using {}.
* Fix the spacing for the comment in {{Server#750}}.
* In the debug message for {{Server#2931}}, can we leverage the logger format to some degree? All the %s could be {}.
* Can we make {{RpcMetrics#TIMEUNIT}} configurable? Now we would have to change code.
* In the {{Metrics.md}} we could mention that the units now are configurable and not always millseconds.
* In {{RpcMetrics}} can we remove the old {{//@Override}}?
* Add some high level comments to the tests in {{TestProcessingDetails}}.
* Can we do some testing using the {{lockAndSleep()}} for the unit conversion?

Hey [~elgoiri], thanks for looking. I resolved all of your comments in v009 except for the two about making the {{TIMEUNIT}} configurable and documenting it. We decided earlier on not to add the bits to make it configurable since the patch is already getting really large... I created HADOOP-16290 as a follow-up task to take care of these two things. Let me know if you take issue with this.

{quote}
Can we do some testing using the {{lockAndSleep()}} for the unit conversion?
{quote}
I changed the greater-than assertion to an equal-to assertion so that it will check that the units were converted correctly. Let me know if you think that's enough... I tried to think of some other things to do but unfortunately there's no way to get any of the other timings (lockexclusive, enqueue, etc.) at this level.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 22s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 6 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 27s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 18m 44s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 32s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 24s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 28s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 17m 20s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 59s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 20s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 44s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 22s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} cc {color} | {color:green} 15m 22s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 15m 22s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 19s{color} | {color:orange} root: The patch generated 6 new + 352 unchanged - 6 fixed = 358 total (was 358) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 24s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 42s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 15s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 58s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 11s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 98m 25s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 57s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}209m 55s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.ipc.TestRPC |
|   | hadoop.hdfs.web.TestWebHdfsTimeouts |
|   | hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:bdbca0e |
| JIRA Issue | HADOOP-16266 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12967684/HADOOP-16266.008.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  cc  |
| uname | Linux dca86afaae29 4.4.0-141-generic #167~14.04.1-Ubuntu SMP Mon Dec 10 13:20:24 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 865c328 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_191 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/16209/artifact/out/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/16209/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/16209/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/16209/testReport/ |
| Max. process+thread count | 2998 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/16209/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



Looking at the {{TestRPC}} failure in the v008 patch, I realized that the additional test cases I added to assert on {{RpcQueueTimeAvgTime}} and {{RpcProcessingTimeAvgTime}} will be flaky because the numbers are measured in milliseconds, so they may round down to 0. I removed those in v010.

Thanks [~xkrogen] for taking care of the comments.
[^HADOOP-16266.010.patch] looks good.
Let's see what Yetus and others say but this (together with HADOOP-16290) covers my concerns.

Overall looks good to me. Mostly nits:
 - In {{updateMetrics}} we are calling with {{details.get}} with a time unit which is the same as the one in {{details}}. This will unnecessarily call the {{convert}} on time unit. It would be great if we can avoid this.
 - Not sure if we should update the documentation for RPC detailed metrics as they now do not include lock time and is different from RPC metrics.
 - Question on {{RpcCall#isOpen}} - this is used to determine whether a call has been processed or not, but is implemented using {{connection.channel.isOpen()}}, which is a little confusing to me. Isn't a channel being used to serve multiple RPC calls, and is only closed when you run into some errors or timed out? how can it be used to indicate whether a call has been processed or not?
 - Since we are adding quantile metrics for RPC wait time, we may need to document this in {{Metrics.md}} as well. The current way for doing this is kind of tedious though I know :-/

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 27s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 6 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 29s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 21m  4s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 27s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 30s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 17m 20s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m  0s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 23s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 46s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m  6s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} cc {color} | {color:green} 16m  6s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 16m  6s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 21s{color} | {color:orange} root: The patch generated 6 new + 351 unchanged - 7 fixed = 357 total (was 358) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 46s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m  6s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  9m 34s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}106m 38s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  1m  4s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}225m  5s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.ipc.TestRPC |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:bdbca0e |
| JIRA Issue | HADOOP-16266 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12967706/HADOOP-16266.009.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  cc  |
| uname | Linux 47d20d176973 3.13.0-153-generic #203-Ubuntu SMP Thu Jun 14 08:52:28 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / d6b7609 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_191 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/16212/artifact/out/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/16212/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/16212/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/16212/testReport/ |
| Max. process+thread count | 2724 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/16212/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 21s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 6 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 26s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 21m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 18m  8s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 30s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 17m 11s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m  5s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m  3s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 59s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m  5s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 34s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} cc {color} | {color:green} 17m 34s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 17m 34s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 31s{color} | {color:orange} root: The patch generated 6 new + 351 unchanged - 7 fixed = 357 total (was 358) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 36s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 43s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 24s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m  3s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 26s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}102m 51s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 54s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}224m 48s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.tools.TestDFSZKFailoverController |
|   | hadoop.hdfs.TestDFSClientRetries |
|   | hadoop.hdfs.web.TestWebHdfsTimeouts |
|   | hadoop.hdfs.server.namenode.ha.TestHAAppend |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:bdbca0e |
| JIRA Issue | HADOOP-16266 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12967717/HADOOP-16266.010.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  cc  |
| uname | Linux 9efe094c83d8 4.4.0-144-generic #170~14.04.1-Ubuntu SMP Mon Mar 18 15:02:05 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / d6b7609 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_191 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/16215/artifact/out/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/16215/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/16215/testReport/ |
| Max. process+thread count | 2655 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/16215/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



Thanks [~csun], these were very helpful comments. I have addressed all of them in v011.

{quote}
Question on RpcCall#isOpen - this is used to determine whether a call has been processed or not, but is implemented using connection.channel.isOpen(), which is a little confusing to me. Isn't a channel being used to serve multiple RPC calls, and is only closed when you run into some errors or timed out? how can it be used to indicate whether a call has been processed or not?
{quote}
I changed the name of this variable to be more illustrative, and added a comment. Essentially this is checking if the connection was dropped (e.g. due to timeout) while the call was in the queue. If so, the connection was closed, and we did not end up doing any processing.

Glad to see such momentum!  I'll try to review today or early next week.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 20s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 6 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m  7s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 36s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 58s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 25s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 33s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 18m 27s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 30s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 27s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 23m 49s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} cc {color} | {color:green} 23m 49s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 23m 49s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 44s{color} | {color:orange} root: The patch generated 6 new + 351 unchanged - 7 fixed = 357 total (was 358) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 14s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 1 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 44s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 54s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 30s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 10m  3s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 99m 14s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 56s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}230m 18s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeUUID |
|   | hadoop.hdfs.web.TestWebHdfsTimeouts |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:bdbca0e |
| JIRA Issue | HADOOP-16266 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12967791/HADOOP-16266.011.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  cc  |
| uname | Linux 05b94178aeab 4.4.0-141-generic #167~14.04.1-Ubuntu SMP Mon Dec 10 13:20:24 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / f1875b2 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_191 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/16219/artifact/out/diff-checkstyle-root.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/16219/artifact/out/whitespace-eol.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/16219/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/16219/testReport/ |
| Max. process+thread count | 3222 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/16219/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



Hi [~daryn], do you still plan to review?

Ping [~daryn], [~csun] to maybe get some reviews :)

The patch v11 LGTM as all my previous comments on patch v10 were resolved. +1

Fantastic, thank you [~csun]. I just committed to trunk based on this +1 after fixing the one whitespace issue. [~daryn], let me know if you have any follow-on comments and I will be happy to fix them up later. And thank you [~cgregori] for the initial contribution!

SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #16594 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/16594/])
HADOOP-16266. Add more fine-grained processing time metrics to the RPC (xkrogen: rev f96a2df38d889f29314c57f4d94227b2e419a11f)
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestProtoBufRpc.java
* (edit) hadoop-common-project/hadoop-common/src/test/proto/test_rpc_service.proto
* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RpcScheduler.java
* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/metrics/RpcDetailedMetrics.java
* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/WritableRpcEngine.java
* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/DefaultRpcScheduler.java
* (add) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/ProcessingDetails.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestConsistentReadsObserver.java
* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/ExternalCall.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRpcBase.java
* (add) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestProcessingDetails.java
* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/metrics/RpcMetrics.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPC.java
* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/CallQueueManager.java
* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/DecayRpcScheduler.java
* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystemLock.java
* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/ProtobufRpcEngine.java
* (edit) hadoop-common-project/hadoop-common/src/site/markdown/Metrics.md


Thanks [~cgregori] and [~xkrogen]! Is it possible to backport this to branch-2 as well?

Yes, good call. If you're okay with it I think I'll wait until we get HDFS-14403 committed as well then do the backport work for both of them.

This seems to be the patch which is breaking my test runs on a PR now rebased to trunk

{{org.apache.hadoop.fs.s3a.commit.staging.integration.ITestDirectoryCommitMRJob}} works by bringing up a miniYarn cluster, except now it doesn't. Instead I get a stack trace (shortened)
{code}
2019-05-31 21:31:05,544 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,554 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,554 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,554 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,554 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,554 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,554 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,555 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,555 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,542 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,555 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,556 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,556 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,557 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,557 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,557 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,557 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,557 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,557 [IPC Server Responder] WARN  ipc.Server (Server.java:doRunLoop(1546)) - Exception in Responder
java.io.IOException: Invalid argument
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:117)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1485)
	at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1468)
2019-05-31 21:31:05,557 [IPC Server Responder] WARN  ipc.Server (Server
{code}

* This is happening in arg validation in the select() call, which is being caught, swallowed and repeated, forever.
* Searching for "java.io.IOException: Invalid argument" + select I see this surfaces when the timeout is too big [https://bugs.openjdk.java.net/browse/JDK-8165000]
* And looking at our code, I can see this happening in writeSelector.select(PURGE_INTERVAL_NANOS). 
* which is a method that takes milliseconds, not nanos.

This leads to a hypothesis "this patch passes a timeout 10e6 times too big, the native code rejects and then server just retries forever hoping it will somehow recover"

I'm reopening and making it your homework to fix. Sorry.

I had the same problem.

In addition to the IPC server exception, sometimes, I see a null pointer exception
{code:java}
2019-05-31 14:32:10,417 ERROR [main] impl.MetricsSourceAdapter (MetricsSourceAdapter.java:getMetrics(202)) - Error getting metrics from source ipc.8020.FairCallQueue
java.lang.NullPointerException
at org.apache.hadoop.ipc.FairCallQueue$MetricsProxy.getQueueSizes(FairCallQueue.java:382)
at org.apache.hadoop.ipc.FairCallQueue$MetricsProxy.getMetrics(FairCallQueue.java:410)
at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.getMetrics(MetricsSourceAdapter.java:200)
at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.updateJmxCache(MetricsSourceAdapter.java:183)
at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.getMBeanInfo(MetricsSourceAdapter.java:156)
at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getNewMBeanClassName(DefaultMBeanServerInterceptor.java:333)
at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:319)
at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:100)
at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:73)
at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.startMBeans(MetricsSourceAdapter.java:222)
at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.start(MetricsSourceAdapter.java:101)
at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSource(MetricsSystemImpl.java:268)
at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:233)
at org.apache.hadoop.ipc.FairCallQueue$MetricsProxy.<init>(FairCallQueue.java:361)
at org.apache.hadoop.ipc.FairCallQueue$MetricsProxy.getInstance(FairCallQueue.java:368)
at org.apache.hadoop.ipc.FairCallQueue.<init>(FairCallQueue.java:114)
at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
at org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:149)
at org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:79)
at org.apache.hadoop.ipc.Server.<init>(Server.java:3059)
at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1039)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.<init>(ProtobufRpcEngine.java:427)
at org.apache.hadoop.ipc.ProtobufRpcEngine.getServer(ProtobufRpcEngine.java:347)
at org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:848)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:467)
at org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:803)
at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:709)
at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:960)
at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:933)
at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1699)
at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1766)
2019-05-31 14:32:10,418 INFO [main] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class org.apache.hadoop.ipc.FairCallQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DecayRpcScheduler, ipcBackoff: true.
{code}

Thanks for reporting this, [~stevel@apache.org]. That is a good catch. I'm surprised we aren't seeing other test failures as a result... I've attached  [^HADOOP-16266.011-followon.patch] to fix this. Let me know if you agree that it looks good.

[~ahussein], I took a quick look and I am pretty confident that is caused by HADOOP-15481, not this patch. I've filed HADOOP-16345 for this issue since HADOOP-15481 has been closed for a while. Thank you for reporting the issue!

The fix in [^HADOOP-16266.011-followon.patch] seems straightforward.
What worries me is our that we were unable to catch this.
Anything we can do to make sure this does not regress later?

[~xkrogen] , Thanks for the fix!

The {{java.io.IOException: Invalid argument}} disappeared after I have applied patch [^HADOOP-16266.011-followon.patch]
{code:java}
java version "1.8.0_201"
OSName:	Mac OS X
OSVersion:	10.14.5
OSBuildVersion:	18F203
{code}

Thanks [~elgoiri], it's a great point... [~stevel@apache.org], is there anything unusual about your test that was causing it to catch this while other tests were continuing to succeed? Would we expect this to affect any {{MiniYARN}} (or {{MiniDFS}}) cluster?

[~xkrogen] , for me, {{TestRPC}} started to fail after I pulled from trunk.

bq.  Would we expect this to affect any MiniYARN (or MiniDFS) cluster?

not sure. It's working in maven, but not the IDE. I think it runs under a different JVM there, one where the excessivley large number is raising the IOE. Maybe in other JVMs it is just ignored.

oh, looked in more detail. In maven the output file for the test run is now 1.5GB. The test may be completing, but the logs show that in fact things aren't working properly behind the scenes. Maybe the problem has been happening, it just hasn't been noticed.

+1 to the  followon patch

FAILURE: Integrated in Jenkins build Hadoop-trunk-Commit #16664 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/16664/])
HADOOP-16266. Add more fine-grained processing time metrics to the RPC (stevel: rev 827a84778a4e3b8f165806dfd2966f0951a5e575)
* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java


Thanks [~stevel@apache.org]! I took a look at the failure above and it seems that the commit job is failing on the {{H5}} machine due to Maven not being installed. I'm not sure how to fix that but it is certainly not the fault of the patch.

Just noticed this was never re-resolved after the follow-on patch, doing so now.

