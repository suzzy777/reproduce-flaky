We should add an end-to-end test which verifies Flink's integration with Kerberos security. In order to do this, we should start a Kerberos secured Hadoop, ZooKeeper and Kafka cluster. Then we should start a Flink cluster with HA enabled and run a job which reads from and writes to Kafka. We could use a simple pipe job for that purpose which has some state for checkpointing to HDFS.

See [security docs| https://ci.apache.org/projects/flink/flink-docs-master/ops/security-kerberos.html] for how more information about Flink's Kerberos integration.