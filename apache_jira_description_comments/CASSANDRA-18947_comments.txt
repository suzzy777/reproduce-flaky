https://ci-cassandra.apache.org/job/Cassandra-5.0/71/testReport/junit/dtest-novnode.disk_balance_test/TestDiskBalance/test_disk_balance_stress/

Not reproduced in 500 runs here - https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/2551/workflows/d3cd504f-9d09-404a-9d95-76202ea3414c/jobs/45526

Looking at CASSANDRA-16196, we might run in circles with this one again. [~brandonwilliams], can you search for this failure in the broader butler history for more failures, also on other branches?  I cannot search in nightlies and cannot access the Butler db. 

Side note: _dtest-novnode.disk_balance_test.TestDiskBalance.test_disk_balance_after_boundary_change_lcs_ and  _novnode.disk_balance_test.TestDiskBalance.test_disk_balance_after_boundary_change_stcs_

are occasionally failing on all branches with:

 
{code:java}
Failed: Timeout >900.0s{code}
 

Here are CI links to the most recent failures in the disk_balance_test family:

{noformat}
| 2023-10-30 19:09:13 | https://ci-cassandra.apache.org/job/Cassandra-5.0/84     |
| 2023-10-30 19:08:13 | https://ci-cassandra.apache.org/job/Cassandra-trunk/1760 |
| 2023-10-29 11:29:07 | https://ci-cassandra.apache.org/job/Cassandra-5.0/81     |
| 2023-10-26 16:49:25 | https://ci-cassandra.apache.org/job/Cassandra-5.0/79     |
| 2023-10-26 11:12:11 | https://ci-cassandra.apache.org/job/Cassandra-4.0/665    |
| 2023-10-26 11:09:07 | https://ci-cassandra.apache.org/job/Cassandra-4.1/438    |
| 2023-10-25 11:19:19 | https://ci-cassandra.apache.org/job/Cassandra-5.0/77     |
| 2023-10-25 11:18:11 | https://ci-cassandra.apache.org/job/Cassandra-trunk/1753 |
| 2023-10-25 06:48:09 | https://ci-cassandra.apache.org/job/Cassandra-trunk/1752 |
| 2023-10-23 11:49:11 | https://ci-cassandra.apache.org/job/Cassandra-5.0/74     |
| 2023-10-19 13:33:38 | https://ci-cassandra.apache.org/job/Cassandra-5.0/73     |
| 2023-10-18 21:07:30 | https://ci-cassandra.apache.org/job/Cassandra-5.0/72     |
| 2023-10-18 21:07:11 | https://ci-cassandra.apache.org/job/Cassandra-5.0/71     |
| 2023-10-18 07:22:35 | https://ci-cassandra.apache.org/job/Cassandra-trunk/1747 |
| 2023-10-17 10:18:10 | https://ci-cassandra.apache.org/job/Cassandra-trunk/1746 |
| 2023-10-13 02:14:19 | https://ci-cassandra.apache.org/job/Cassandra-trunk/1744 |
| 2023-10-12 20:55:22 | https://ci-cassandra.apache.org/job/Cassandra-5.0/65     |
| 2023-10-10 22:14:07 | https://ci-cassandra.apache.org/job/Cassandra-4.1/433    |
| 2023-10-10 22:08:20 | https://ci-cassandra.apache.org/job/Cassandra-5.0/63     |
| 2023-10-05 13:42:09 | https://ci-cassandra.apache.org/job/Cassandra-4.0/656    |
| 2023-09-27 16:27:33 | https://ci-cassandra.apache.org/job/Cassandra-trunk/1725 |
| 2023-09-25 10:54:11 | https://ci-cassandra.apache.org/job/Cassandra-5.0/45     |
| 2023-09-22 16:28:13 | https://ci-cassandra.apache.org/job/Cassandra-trunk/1718 |
| 2023-09-19 19:02:07 | https://ci-cassandra.apache.org/job/Cassandra-4.0/648    |
| 2023-09-19 04:43:08 | https://ci-cassandra.apache.org/job/Cassandra-trunk/1713 |
| 2023-09-15 18:04:07 | https://ci-cassandra.apache.org/job/Cassandra-5.0/37     |
| 2023-09-14 17:34:09 | https://ci-cassandra.apache.org/job/Cassandra-5.0/34     |
| 2023-09-12 11:19:06 | https://ci-cassandra.apache.org/job/Cassandra-4.1/417    |
| 2023-09-12 09:38:08 | https://ci-cassandra.apache.org/job/Cassandra-trunk/1705 |
| 2023-09-09 05:13:57 | https://ci-cassandra.apache.org/job/Cassandra-trunk/1703 |
| 2023-09-07 10:58:08 | https://ci-cassandra.apache.org/job/Cassandra-trunk/1701 |
| 2023-09-01 13:19:59 | https://ci-cassandra.apache.org/job/Cassandra-trunk/1695 |
| 2023-09-01 04:21:44 | https://ci-cassandra.apache.org/job/Cassandra-5.0/22     |
| 2023-08-30 14:28:10 | https://ci-cassandra.apache.org/job/Cassandra-trunk/1691 |
| 2023-08-30 14:24:07 | https://ci-cassandra.apache.org/job/Cassandra-5.0/19     |
{noformat}

bq. I cannot search in nightlies

One way to do this is webdav mount nightlies and then do a recursive grep.

{code:java}
One way to do this is webdav mount nightlies and then do a recursive grep.{code}
The recursive grep hangs for me and never returns. :( I haven't found a solution yet. 

Thanks for the report. I will look around nightlies, what those builds have for us. 

I could not find any other failures of this test. Mostly:
{code:java}
Failed: Timeout >900.0s{code}

for the two mentioned tests.

I would suggest stopping all nodes before computing sizes, that should stop things moving under our feet. Wdyt?

I may not understand you correctly. At which point do you propose to stop the nodes?

Did you miss [this comment|https://github.com/apache/cassandra-dtest/blob/trunk/disk_balance_test.py#L170-L171]? Or what did *I* miss? :) 

 

 

I don't think we missed anything. C* is just complicated lol!

So my proposal is to stop nodes after this [line|https://github.com/apache/cassandra-dtest/blob/trunk/disk_balance_test.py#L45]. The comment on looping you're referring to, iiuc, is exactly to address the original problem which is having too many moving parts. Stopping the nodes should solve it imo.

So you mean instead of raising the number of loops (the previous hack from CASSANDRA-16196) - to stop the nodes? Do you have a patch to test? I am not complete sure about this solution. 

I tried to find the nodes logs in nightlies, from run #72, but there is only console output. So we can only speculate from the error we see, it is the same issue. We haven't seen it recently. I still see only test timeouts 

 

It's just adding a stop like in this [PR|https://github.com/apache/cassandra-dtest/pull/242]. As we're only looking at _local data folders_ to be balanced having the node stopped seems like a good idea. The other test cases revolve around bootstrap and other operator alike commands so I wouldn't touch them for the time being.



CI
https://app.circleci.com/pipelines/github/michaelsembwever/cassandra/263/workflows/349a08b5-5323-4632-bff7-d40c0de10380

Hi [~mck] thanks for the CI run but I already knew the tests pass. I was looking more into validating the approach. If we're happy I'll then fire runs for 4.0->trunk and do repeats on 5.0 i.e. Wdyt?

yes, go for it. 

4.0 500 repeats [green|https://app.circleci.com/pipelines/github/bereng/cassandra/1124/workflows/c7ba9cef-3d77-4a19-9c73-686e82961bf3/jobs/34819]
4.1 500 repeats [green|https://app.circleci.com/pipelines/github/bereng/cassandra/1127/workflows/19d0965c-b50d-4d5d-a16f-07c75b64a5a9/jobs/35124]
5.0 500 repeats [green|https://app.circleci.com/pipelines/github/bereng/cassandra/1125/workflows/1fd4498b-4fef-41d5-9419-58fff4463407/jobs/35126]
trunk 500 repeats not [green|https://app.circleci.com/pipelines/github/bereng/cassandra/1126/workflows/ce4c7dda-c8e0-4452-9ba7-b8f67432d682/jobs/35125] but failures seem unrelated to this ticket, of different nature and trunk is getting lots of changes in at the moment.



Repeated run on trunk without the patch is green - [https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/2569/workflows/96e8cf45-0d10-4ae0-b4a0-9403429d2335]

Also, the failures might be coming from the stop of the cluster.

I am not convinced this was the right way to do it. Should we raise the loop iterations to ensure no random failures in a slow environment, WDYT?

What bothers me here is that stopping a cluster shouldn't produce errors. It's a perfectly valid and normal operation, we are not doing any fancy stuff. We can increase the timeout indeed but I wonder if we have a legit new bug in trunk when stopping nodes. Let me think a bit more here...

Ok so let's do this:
A. More iterations and a longer sleep to catch more potential instabilities
B. Trunk indeed fails stopping the cluster as I tested [again|https://app.circleci.com/pipelines/github/bereng/cassandra/1128/workflows/44d82c9a-ca4c-4de6-85b5-b3e2f375bde6/jobs/35231] and you showed thx. This bothers me because the test it's quite simple and I think we might have a problem in trunk when stopping nodes, specially since it didn't fail on the other branches. I think this grants a new ticket to investigate that.

So I propose we merge the current PR with extended looping and open a new ticket for the cluster.stop() problem (we can't be failing on a vanilla start/insert/stop scenario), wdyt?

This is the error reported in CASSANDRA-19092 which has a patch available and for which CI is currently running.

The issue is an overzealous error from the failure detector and is quite harmless. As you can see from the output, there is no problem stopping the node or otherwise running the test (it reports {{PASSED}}) but the unexpected logging causes the failure.

^Aha! thx a lot [~samt]. Then I retract and propose we merge the [original solution|https://github.com/apache/cassandra-dtest/pull/242/commits/b150b19c1739f02a9d3619fd1801bdcca9d1ebad] of stopping the cluster.

bq. ^Aha! thx a lot Sam Tunnicliffe. Then I retract and propose we merge the original solution of stopping the cluster.


Yup, +1. 

Great, thanks [~samt] !

[~Bereng] I have one question - why do we need to keep the loop for this particular test if we believe the stop will solve the test flakiness?
I agree, that approach shouldn't be touched for the other tests, totally. But that is not what I am asking about. Why this test should still go through that path? Isn't it confusing?

Oh so you'd rather use {{async_almost_equal}} directly? Or you can use it as it is now for consistency with the rest of the test class, if sbdy improves/fixes {{assert_balanced}} in the future, which is the most probable, this test method would not benefit from that,.. To me it's not confusing. ICWYM but the little extra loop vs benefits... There are arguments both sides imo. I don't have a strong preference here.

bq. Oh so you'd rather use async_almost_equal directly? Or you can use it as it is now for consistency with the rest of the test class, if sbdy improves/fixes assert_balanced in the future, which is the most probable, this test method would not benefit from that,.. To me it's not confusing. ICWYM but the little extra loop vs benefits... There are arguments both sides imo. I don't have a strong preference here.

Well, to me, it was a matter of clean code, and if we were thinking of fixing it, then better to fix it or go to the increased loop path until it is fixed. But if it is only me finding this confusing - +1. The repeated runs also LGTM. Thanks for looking into the problem. (ignoring the problem that was already mentioned to be solved in another ticket)

bq. it was a matter of clean code

Yep correct, that's important. But as it is now there's only an extra tiny loop, which hardly affects readability imo, but it gives you better maintainability. So... pick your posion lol

Thx for all the reviews.

