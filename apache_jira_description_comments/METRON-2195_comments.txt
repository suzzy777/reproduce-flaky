Looks like that’s already fine to me. The log4j parameters pattern means those calls shouldn’t be executed. Are you seeing the call to message.toJsonString being made with log level less than trace? Or is this about finding other instances that don’t follow the example you give here?

[~mmiklavcic] has seen it, did you see the links?
I don't know what you mean by the log4j parameters pattern there, can you elaborate?  From mike's tests it IS getting called.  I don't see how it wouldn't be.

[https://logging.apache.org/log4j/2.x/performance.html]

See the section on asynchronous parameter evaluation. That said, method calls may not be lazy evaluated in that case judging by Mike's results. Has anyone ever tried running this code through an actual profiler?

Perhaps we do have to revert to doing what the library should be doing for us (long live proper functional programming and async programming, and soon may it come to our corner of java). While we're at it, should we look at an async logger on the backend?

Simon, that has to do the the formatting of the string.  The toJSONString() execution is NOT under the domain of log4j, rather the result of the execution is passed as the parameter input.


Yeah, you’re right, hence my complaint about it being typical java and not a proper functional lazy evaluating thing. The double call to level evaluation is a much better trade off, so yeah, agreed we have to defend against this manually. Of for a better JIT. I’d defiantly support this idea though.

[~tigerquoll] ( METRON-2196 )

Trace logging messages such as at https://github.com/apache/metron/blob/master/metron-platform/metron-writer/metron-writer-storm/src/main/java/org/apache/metron/writer/hdfs/HdfsWriter.java#L127
are causing a performance regression due to the logging function arguments not being lazily evaluated (the logging string is lazily constructed, but largeObject.toJsonString() calls are being evaluated (with all the performance and GC overhead) even if the log message is not going to be emitted due to the configured log level.
Potential fixes include:
* "If" statements around logging messages, testing for log level before proceeding
* Using native java logging with slf4j bridge with JDK8+ which supports lazily evaluating logging method parameters.
* Upgrade slf4j to version 2.x which supports lazily evaluating logging method parameters.
* Create or use an existing custom log function wrapper around our existing slf4j 1.x version that will support lazily evaluation of logging method parameters. 

Options 2 or 3 is the architecturally cleaner solutions.  Option 4 is the lightest touch solution classpath wise.  Option 1 should not be considered by anybody who values the lives of kittens.


[~tigerquoll], as with [~simonellistonball]'s comments I'm confused here.

Lazy evaluation of function parameters does not, as far as I know stop the evaluation of methods that are written as the parameters themselves, since it is the result of that method that is actually seen by the called method, not the method itself.

It seems that we are confusing things here.  I would like some reference to some documentation that says that there is a way in java ( or any language really ) where


{code:java}
object.functionCall( otherObject.otherFunctionCall());
{code}

Does not result in otherFunctionCall() being executed, because as far as I know it will always be evaluated by the compiler as

{code:java}
object.functionCall( result object of otherObject.otherFunctionCall )
{code}

In which case the lazy evaluation INSIDE the function does not matter.

Please refer to attached [GitHub Pull Request #1472|https://github.com/apache/metron/pull/1472]

[~otto] you are technique correct.  Java does not natively support lazy evaluation.  You can fudge the line a little bit and update the API to accept a lambda function which wraps your expensive operation. The lambda gets executed only if the logging level says it's required.  Otherwise the cost of evaluation of the lambda body is not incurred.

But to get this you explicitly have to update your API to take a lambda, and you have to explicitly check the logging level and explicitly execute the lambda only when the result is required.  So definitely not "native support", but the end result is the same.

OK,
Sorry, I would usually explicitly state that we need to use lambdas when introducing them. I understand what you are proposing, I'll comment on the pr

I added you as a contributor and assigned this jira to you

Thanks.  Updated PR rebased on master at [GitHub Pull Request #1473|https://github.com/apache/metron/pull/1473].

Related to this SLF4J work that is not available in 1.x, only 2.x

Ok, we seem to have some consensus to use this technique.  My next question is does anybody have a prioritised list of performance sensitive areas I should be hunting through to update to the new logging wrapper?

As I stated in the PR, I would like to see the performance test code ( linked above ) integrated and extended and used to test this.

We probably need to tweak that code a bit. Putting hard time limits into the code is going to be problematic because every machine or environment is going to be a little different, and we don't want flaky tests. I would suggest we do a general result comparison, e.g. timeWithSupplier < timeNoSupplier. Also, let's be careful here because the more egregious case takes 50+ seconds to complete and we really don't want to do that to the test suite.

We have other on demand testing code for performance I think, this could be like that code and not run as part of the build

{quote}My next question is does anybody have a prioritised list of performance sensitive areas I should be hunting through to update to the new logging wrapper?
{quote}
I would look at the writers, for starters. Beyond that, I think it's going to be a trial and error exercise. Minimally, address the HDFSWriter logging statement in the original example. One option that's a bit brute force could be doing a grep in the full code base on LOG.trace( and LOG.debug( and looking for any obvious complex calls. I just ran this locally and trace appears to be quite manageable. grep --include *.java -R LOG.trace .|wc -l
 50

Debug came up with 264 results, but that's still not egregious to look for low hanging fruit. I agree with your conclusion that we should not worry as much about "error" logging, because those are typically already gated by try/catch blocks.

One additional note about this API - I think we need to be conspicuously clear that this is a temporary solution and add appropriate javadoc warnings to the interface that references this ticket. We might also consider adopting the Hadoop API annotation approach (i.e. @ Unstable), but that's probably overkill for a private API. The last piece of this should be to create a Jira for upgrading SLF4J. Here's an example for upgrading JUnit - https://issues.apache.org/jira/browse/METRON-2037

{quote}We have other on demand testing code for performance I think, this could be like that code and not run as part of the build{quote}

[~otto] not an unreasonable suggestion, I'd be supportive of this approach as well. I did this when developing the HLLP Stellar implementation, e.g. - [https://github.com/apache/metron/blob/master/metron-analytics/metron-statistics/src/main/java/org/apache/metron/statistics/approximation/HLLPMeasurement.java|https://github.com/apache/metron/blob/master/metron-analytics/metron-statistics/src/main/java/org/apache/metron/statistics/approximation/HLLPMeasurement.java]

There are a couple of angles to search for
all debug/trace statements
all toJSONString occurrences

We can start with the toJSONString, i think there are 30 odd instances.


Honestly, anywhere in any topology pipeline where we are serializing or deserializing to and from json should be looked at for optimization and necessity

I created and linked a separate ticket for the general issue of addressing efficient serialization and deserialization. The 34 toJSONString instances I turned up do not have any overlap with this logging Jira. I think they can be addressed independently and each have their own potential solutions and benefits.

I'm fine with however you want to slice the work up. 


Performance test with lazy logging added: added as a disabled unit test.

The results of a test run on my machine shown below:

 ===============================
 Total trial time (ms): 22.752827
 ===============================
 Small object 1000 times
 DescriptiveStatistics:
 n: 1000
 min: 0.007333
 max: 0.667019
 mean: 0.018786147000000003
 std dev: 0.023760301192959944
 median: 0.014077
 skewness: 20.761050581381458
 kurtosis: 556.2525388151329

===============================
 Total trial time (ms): 2.827201
 ===============================
 Small object 1000 times using lazy logging
 DescriptiveStatistics:
 n: 1000
 min: 4.99E-4
 max: 1.607847
 mean: 0.002565500000000002
 std dev: 0.05084386966162362
 median: 7.01E-4
 skewness: 31.567931477605043
 kurtosis: 997.6667296992453

===============================
 Total trial time (ms): 28190.98512
 ===============================
 Large object 1000 times
 DescriptiveStatistics:
 n: 1000
 min: 24.834654
 max: 154.110025
 mean: 28.185177632
 std dev: 5.750345163228156
 median: 27.031372
 skewness: 13.401082278526083
 kurtosis: 253.2784266258804

===============================
 Total trial time (ms): 1.086161
 ===============================
 Large object 1000 times using lazy logging
 DescriptiveStatistics:
 n: 1000
 min: 2.34E-4
 max: 0.463436
 mean: 9.264779999999996E-4
 std dev: 0.014714673562929612
 median: 3.565E-4
 skewness: 31.16228339668676
 kurtosis: 979.9505834291792

===============================
 Total trial time (ms): 0.415353
 ===============================
 Simple string 1000 times
 DescriptiveStatistics:
 n: 1000
 min: 1.91E-4
 max: 0.018793
 mean: 2.84338E-4
 std dev: 7.675489085935066E-4
 median: 2.29E-4
 skewness: 19.097139802144284
 kurtosis: 403.0772650972191

===============================
Total trial time (ms): 1.076497
 ===============================
 Simple string 1000 times using lazy logging
 DescriptiveStatistics:
 n: 1000
 min: 2.45E-4
 max: 0.371249
 mean: 8.975510000000001E-4
 std dev: 0.012477908060045725
 median: 3.885E-4
 skewness: 27.454079996752938
 kurtosis: 791.6760062810134

===============================

