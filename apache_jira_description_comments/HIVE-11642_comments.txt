Branch patch

somebody confessed to nuking my QA run 0_o Reattaching the patch



{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12752363/HIVE-11642.01.patch

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5072/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5072/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5072/

Messages:
{noformat}
**** This message was trimmed, see log for full details ****
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/shims/scheduler/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-scheduler ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-scheduler ---
[INFO] Compiling 1 source file to /data/hive-ptest/working/apache-github-source-source/shims/scheduler/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-shims-scheduler ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/shims/scheduler/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-scheduler ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/shims/scheduler/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/shims/scheduler/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/shims/scheduler/target/tmp/conf
     [copy] Copying 10 files to /data/hive-ptest/working/apache-github-source-source/shims/scheduler/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-scheduler ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-scheduler ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-scheduler ---
[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/shims/scheduler/target/hive-shims-scheduler-2.0.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-shims-scheduler ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-scheduler ---
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/shims/scheduler/target/hive-shims-scheduler-2.0.0-SNAPSHOT.jar to /home/hiveptest/.m2/repository/org/apache/hive/shims/hive-shims-scheduler/2.0.0-SNAPSHOT/hive-shims-scheduler-2.0.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/shims/scheduler/pom.xml to /home/hiveptest/.m2/repository/org/apache/hive/shims/hive-shims-scheduler/2.0.0-SNAPSHOT/hive-shims-scheduler-2.0.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 2.0.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims ---
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/shims/aggregator/target
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/shims/aggregator (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-shims ---
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-shims ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-shims ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/shims/aggregator/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-shims ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/shims/aggregator/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/shims/aggregator/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/shims/aggregator/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/shims/aggregator/target/tmp/conf
     [copy] Copying 10 files to /data/hive-ptest/working/apache-github-source-source/shims/aggregator/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims ---
[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/shims/aggregator/target/hive-shims-2.0.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-shims ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims ---
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/shims/aggregator/target/hive-shims-2.0.0-SNAPSHOT.jar to /home/hiveptest/.m2/repository/org/apache/hive/hive-shims/2.0.0-SNAPSHOT/hive-shims-2.0.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/shims/aggregator/pom.xml to /home/hiveptest/.m2/repository/org/apache/hive/hive-shims/2.0.0-SNAPSHOT/hive-shims-2.0.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Storage API 2.0.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-storage-api ---
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/storage-api/target
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/storage-api (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-storage-api ---
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-storage-api ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-storage-api ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/storage-api/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-storage-api ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-storage-api ---
[INFO] Compiling 20 source files to /data/hive-ptest/working/apache-github-source-source/storage-api/target/classes
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-github-source-source/storage-api/src/java/org/apache/hadoop/hive/common/io/DiskRangeList.java:[23,37] package com.google.common.annotations does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/storage-api/src/java/org/apache/hadoop/hive/common/io/DiskRangeList.java:[121,4] cannot find symbol
  symbol:   class VisibleForTesting
  location: class org.apache.hadoop.hive.common.io.DiskRangeList
[ERROR] /data/hive-ptest/working/apache-github-source-source/storage-api/src/java/org/apache/hadoop/hive/common/io/DiskRangeList.java:[142,4] cannot find symbol
  symbol:   class VisibleForTesting
  location: class org.apache.hadoop.hive.common.io.DiskRangeList
[INFO] 3 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [12.742s]
[INFO] Hive Shims Common ................................. SUCCESS [14.675s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [4.072s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [3:13.646s]
[INFO] Hive Shims Scheduler .............................. SUCCESS [2.468s]
[INFO] Hive Shims ........................................ SUCCESS [2.914s]
[INFO] Hive Storage API .................................. FAILURE [2.101s]
[INFO] Hive Common ....................................... SKIPPED
[INFO] Hive Serde ........................................ SKIPPED
[INFO] Hive Metastore .................................... SKIPPED
[INFO] Hive Ant Utilities ................................ SKIPPED
[INFO] Hive Llap Client .................................. SKIPPED
[INFO] Spark Remote Client ............................... SKIPPED
[INFO] Hive Query Language ............................... SKIPPED
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive Accumulo Handler ............................. SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HPL/SQL ...................................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 3:55.858s
[INFO] Finished at: Wed Aug 26 03:37:42 EDT 2015
[INFO] Final Memory: 48M/115M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-storage-api: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-github-source-source/storage-api/src/java/org/apache/hadoop/hive/common/io/DiskRangeList.java:[23,37] package com.google.common.annotations does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/storage-api/src/java/org/apache/hadoop/hive/common/io/DiskRangeList.java:[121,4] cannot find symbol
[ERROR] symbol:   class VisibleForTesting
[ERROR] location: class org.apache.hadoop.hive.common.io.DiskRangeList
[ERROR] /data/hive-ptest/working/apache-github-source-source/storage-api/src/java/org/apache/hadoop/hive/common/io/DiskRangeList.java:[142,4] cannot find symbol
[ERROR] symbol:   class VisibleForTesting
[ERROR] location: class org.apache.hadoop.hive.common.io.DiskRangeList
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-storage-api
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12752363 - PreCommit-HIVE-TRUNK-Build

Again



{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12752547/HIVE-11642.02.patch

{color:red}ERROR:{color} -1 due to 17 failed/errored test(s), 9416 tests executed
*Failed tests:*
{noformat}
TestCliDriver-fileformat_sequencefile.q-repair.q-fouter_join_ppr.q-and-12-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_char_mapjoin1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_varchar_mapjoin1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_dynpart_hashjoin_1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_vector_dynpart_hashjoin_1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_vector_dynpart_hashjoin_2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_count_distinct
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_decimal_mapjoin
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_left_outer_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_mapjoin_reduce
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_mapjoin
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_nested_mapjoin
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_ptf
org.apache.hadoop.hive.llap.daemon.impl.TestTaskExecutorService.testWaitQueuePreemption
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5078/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5078/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5078/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 17 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12752547 - PreCommit-HIVE-TRUNK-Build

Again

Fixed all out files, trivial changes; cannot repro HCat test; filed bug for the other test that used to be flaky and appears to still be flaky



{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12752643/HIVE-11642.03.patch

{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 9434 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
org.apache.tez.dag.app.rm.TestLlapTaskSchedulerService.testPreemption
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5089/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5089/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5089/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12752643 - PreCommit-HIVE-TRUNK-Build

I see TestHCatClient.testTableSchemaPropagation fails on regular master runs. Filed bug for flaky unit test. The q test is another trivial out file diff. Almost there :)

Will wait for Tez release, do another master merge and rerun; unit test issue is the test issue, will comment this test out unless it's fixed

Next iteration



{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12754131/HIVE-11642.04.patch

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5174/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5174/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5174/

Messages:
{noformat}
**** This message was trimmed, see log for full details ****
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/target/tmp/conf
     [copy] Copying 12 files to /data/hive-ptest/working/apache-github-source-source/itests/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-it ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-it ---
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/pom.xml to /home/hiveptest/.m2/repository/org/apache/hive/hive-it/2.0.0-SNAPSHOT/hive-it-2.0.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Custom Serde 2.0.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-custom-serde ---
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/custom-serde/target
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/custom-serde (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-it-custom-serde ---
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (download-spark) @ hive-it-custom-serde ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-it-custom-serde ---
Downloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/pentaho/pentaho-aggdesigner/5.1.5-jhyde/pentaho-aggdesigner-5.1.5-jhyde.pom

[WARNING] Invalid project model for artifact [pentaho-aggdesigner-algorithm:org.pentaho:5.1.5-jhyde]. It will be ignored by the remote resources Mojo.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-it-custom-serde ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-custom-serde ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-custom-serde ---
[INFO] Compiling 10 source files to /data/hive-ptest/working/apache-github-source-source/itests/custom-serde/target/classes
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/custom-serde/src/main/java/org/apache/hadoop/hive/serde2/CustomSerDe2.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/custom-serde/src/main/java/org/apache/hadoop/hive/serde2/CustomSerDe2.java: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-it-custom-serde ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/custom-serde/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-custom-serde ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/custom-serde/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/custom-serde/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/custom-serde/target/tmp/conf
     [copy] Copying 12 files to /data/hive-ptest/working/apache-github-source-source/itests/custom-serde/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-custom-serde ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-it-custom-serde ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-it-custom-serde ---
[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/itests/custom-serde/target/hive-it-custom-serde-2.0.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-it-custom-serde ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-it-custom-serde ---
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/custom-serde/target/hive-it-custom-serde-2.0.0-SNAPSHOT.jar to /home/hiveptest/.m2/repository/org/apache/hive/hive-it-custom-serde/2.0.0-SNAPSHOT/hive-it-custom-serde-2.0.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/custom-serde/pom.xml to /home/hiveptest/.m2/repository/org/apache/hive/hive-it-custom-serde/2.0.0-SNAPSHOT/hive-it-custom-serde-2.0.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - HCatalog Unit Tests 2.0.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hcatalog-it-unit ---
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/target
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-hcatalog-it-unit ---
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (download-spark) @ hive-hcatalog-it-unit ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-hcatalog-it-unit ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-hcatalog-it-unit ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog-it-unit ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hcatalog-it-unit ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-hcatalog-it-unit ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog-it-unit ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/target/tmp/conf
     [copy] Copying 12 files to /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hcatalog-it-unit ---
[INFO] Compiling 8 source files to /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/target/test-classes
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/api/TestHCatClientNotification.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/api/TestHCatClientNotification.java: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hcatalog-it-unit ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hcatalog-it-unit ---
[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/target/hive-hcatalog-it-unit-2.0.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-hcatalog-it-unit ---
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-hcatalog-it-unit ---
[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/target/hive-hcatalog-it-unit-2.0.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hcatalog-it-unit ---
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/target/hive-hcatalog-it-unit-2.0.0-SNAPSHOT.jar to /home/hiveptest/.m2/repository/org/apache/hive/hive-hcatalog-it-unit/2.0.0-SNAPSHOT/hive-hcatalog-it-unit-2.0.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/pom.xml to /home/hiveptest/.m2/repository/org/apache/hive/hive-hcatalog-it-unit/2.0.0-SNAPSHOT/hive-hcatalog-it-unit-2.0.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/target/hive-hcatalog-it-unit-2.0.0-SNAPSHOT-tests.jar to /home/hiveptest/.m2/repository/org/apache/hive/hive-hcatalog-it-unit/2.0.0-SNAPSHOT/hive-hcatalog-it-unit-2.0.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Testing Utilities 2.0.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
Downloading: http://repository.apache.org/snapshots/org/apache/hive/hive-llap-server/2.0.0-SNAPSHOT/maven-metadata.xml

Downloading: http://repository.apache.org/snapshots/org/apache/hive/hive-llap-server/2.0.0-SNAPSHOT/hive-llap-server-2.0.0-SNAPSHOT.pom

[WARNING] The POM for org.apache.hive:hive-llap-server:jar:2.0.0-SNAPSHOT is missing, no dependency information available
[WARNING] The POM for org.apache.hive:hive-llap-server:jar:tests:2.0.0-SNAPSHOT is missing, no dependency information available
Downloading: http://repository.apache.org/snapshots/org/apache/hive/hive-llap-server/2.0.0-SNAPSHOT/hive-llap-server-2.0.0-SNAPSHOT.jar
Downloading: http://repository.apache.org/snapshots/org/apache/hive/hive-llap-server/2.0.0-SNAPSHOT/hive-llap-server-2.0.0-SNAPSHOT-tests.jar


[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive Integration - Parent ......................... SUCCESS [8.803s]
[INFO] Hive Integration - Custom Serde ................... SUCCESS [20.001s]
[INFO] Hive Integration - HCatalog Unit Tests ............ SUCCESS [14.667s]
[INFO] Hive Integration - Testing Utilities .............. FAILURE [2.571s]
[INFO] Hive Integration - Unit Tests ..................... SKIPPED
[INFO] Hive Integration - Test Serde ..................... SKIPPED
[INFO] Hive Integration - QFile Tests .................... SKIPPED
[INFO] Hive Integration - QFile Accumulo Tests ........... SKIPPED
[INFO] JMH benchmark: Hive ............................... SKIPPED
[INFO] Hive Integration - QFile Spark Tests .............. SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 48.543s
[INFO] Finished at: Fri Sep 04 00:12:28 EDT 2015
[INFO] Final Memory: 47M/141M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal on project hive-it-util: Could not resolve dependencies for project org.apache.hive:hive-it-util:jar:2.0.0-SNAPSHOT: The following artifacts could not be resolved: org.apache.hive:hive-llap-server:jar:2.0.0-SNAPSHOT, org.apache.hive:hive-llap-server:jar:tests:2.0.0-SNAPSHOT: Could not find artifact org.apache.hive:hive-llap-server:jar:2.0.0-SNAPSHOT in apache.snapshots (http://repository.apache.org/snapshots) -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-it-util
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12754131 - PreCommit-HIVE-TRUNK-Build

[~sershe] QTestUtil depends on MiniLlapCluster from llap-server-tests jar. Its a compile time dependency. We cannot shim this layer as shim will depend on llap-server and vice-versa creating circular dependency. Since llap-server is compiled only for hadoop-2 I am not sure how to make itests compile for hadoop-1. Any thoughts/idea?

Reflection :)

Filed a separate JIRA for this

Retry with the build fixed and branch-specific tests presumably enabled



{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12754794/HIVE-11642.05.patch

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 9476 tests executed
*Failed tests:*
{noformat}
TestMiniLlapCliDriver - did not produce a TEST-*.xml file
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5214/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5214/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5214/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12754794 - PreCommit-HIVE-TRUNK-Build

Rinse, repeat, with new out files!



{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12761232/HIVE-11642.06.patch

{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 9510 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_orc_llap
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.initializationError
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_llapdecider
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
org.apache.hive.hcatalog.streaming.TestStreaming.testTimeOutReaper
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5344/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5344/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5344/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12761232 - PreCommit-HIVE-TRUNK-Build



{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12761514/HIVE-11642.07.patch

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5371/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5371/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5371/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-5371/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 5238303 HIVE-11711: Merge hbase-metastore branch to trunk
+ git clean -f -d
+ git checkout master
Already on 'master'
+ git reset --hard origin/master
HEAD is now at 5238303 HIVE-11711: Merge hbase-metastore branch to trunk
+ git merge --ff-only origin/master
Already up-to-date.
+ git gc
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12761514 - PreCommit-HIVE-TRUNK-Build

Updated the patch - some conflicts with metastore branch merge



{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12761738/HIVE-11642.08.patch

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5384/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5384/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5384/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-5384/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 7cfe374 HIVE-11468: Vectorize Struct IN() clauses (Matt McCline, via Gopal V)
+ git clean -f -d
+ git checkout master
Already on 'master'
+ git reset --hard origin/master
HEAD is now at 7cfe374 HIVE-11468: Vectorize Struct IN() clauses (Matt McCline, via Gopal V)
+ git merge --ff-only origin/master
Already up-to-date.
+ git gc
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12761738 - PreCommit-HIVE-TRUNK-Build

And again

A more recent diff in case some conflicts accrued during the queue time



{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12762284/HIVE-11642.10.patch

{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 9634 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.initializationError
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
org.apache.hive.hcatalog.streaming.TestStreaming.testEndpointConnection
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5407/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5407/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5407/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12762284 - PreCommit-HIVE-TRUNK-Build



{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12762448/HIVE-11642.11.patch

{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 9667 tests executed
*Failed tests:*
{noformat}
TestMiniLlapCliDriver - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_groupby_reduce
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_groupby_reduce
org.apache.hadoop.hive.ql.optimizer.ppr.TestPositivePartitionPrunerCompactExpr.initializationError
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5447/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5447/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5447/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12762448 - PreCommit-HIVE-TRUNK-Build

3 test failures are known issues on master.
Fixing one remaining test failure, plus an update to recent master.

[~sershe] I don't see any tests being run for MiniLlapCliDriver. Do we need to do something special for enabling it in PTest2?

Well, it ran last time, when the initialization error happened. Does it run by default when you run mvn test? Can you check that whatever is present in poms for e.g. MiniTez is also present for MiniLlap?

[~sershe] The last line of this http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5447/failed/TestMiniLlapCliDriver/maven-test.txt

says its running the test but then no reports were produced.

Generated diff after committing HIVE-11923 patch to llap branch.

A more recent diff



{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12764316/HIVE-11642.14.patch

{color:red}ERROR:{color} -1 due to 13 failed/errored test(s), 9986 tests executed
*Failed tests:*
{noformat}
TestCliDriver-orc_ppd_decimal.q-vector_decimal_round.q-metadata_export_drop.q-and-12-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_groupby_reduce
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_dynpart_sort_optimization
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_explainuser_1
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_metadata_only_queries
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_vector_auto_smb_mapjoin_14
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_vector_groupby_reduce
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_vectorization_limit
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_scriptfile1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_groupby_reduce
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_schemeAuthority
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5464/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5464/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5464/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 13 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12764316 - PreCommit-HIVE-TRUNK-Build

Updated some out files and merged master again.

Update patch to avoid conflicts



{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12764669/HIVE-11642.16.patch

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 9696 tests executed
*Failed tests:*
{noformat}
TestMiniLlapCliDriver - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_scriptfile1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_groupby_reduce
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5488/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5488/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5488/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12764669 - PreCommit-HIVE-TRUNK-Build

Update the patch for conflicts. We will eventually do the merge again but I don't want to do them twice a day...



{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12764884/HIVE-11642.18.patch

{color:green}SUCCESS:{color} +1 due to 49 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 852 failed/errored test(s), 6010 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.initializationError
org.apache.hadoop.hive.cli.TestCompareCliDriver.initializationError
org.apache.hadoop.hive.cli.TestContribCliDriver.initializationError
org.apache.hadoop.hive.cli.TestContribNegativeCliDriver.initializationError
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_dynamic
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_static
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_external_table_ppd
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_binary_external_table_queries
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_binary_map_queries
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_binary_map_queries_prefix
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_binary_storage_queries
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_custom_key
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_custom_key2
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_custom_key3
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_handler_bulk
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_handler_snapshot
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_joins
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_null_first_col
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_ppd_join
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_ppd_key_range
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_pushdown
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_queries
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_scan_params
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_single_sourced_multi_insert
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_stats3
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_timestamp
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_timestamp_format
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_ppd_key_ranges
org.apache.hadoop.hive.cli.TestHBaseMinimrCliDriver.testCliDriver_hbase_bulk
org.apache.hadoop.hive.cli.TestHBaseNegativeCliDriver.testCliDriver_cascade_dbdrop
org.apache.hadoop.hive.cli.TestHBaseNegativeCliDriver.testCliDriver_generatehfiles_require_family_path
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.initializationError
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.initializationError
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.initializationError
org.apache.hadoop.hive.cli.TestMinimrCliDriver.initializationError
org.apache.hadoop.hive.cli.TestNegativeCliDriver.initializationError
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.initializationError
org.apache.hadoop.hive.cli.TestSparkCliDriver.initializationError
org.apache.hadoop.hive.cli.TestSparkNegativeCliDriver.initializationError
org.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1
org.apache.hadoop.hive.ql.TestTxnCommands.testDelete
org.apache.hadoop.hive.ql.TestTxnCommands.testDeleteIn
org.apache.hadoop.hive.ql.TestTxnCommands.testErrors
org.apache.hadoop.hive.ql.TestTxnCommands.testExplicitRollback
org.apache.hadoop.hive.ql.TestTxnCommands.testImplicitRollback
org.apache.hadoop.hive.ql.TestTxnCommands.testInsertOverwrite
org.apache.hadoop.hive.ql.TestTxnCommands.testMultipleDelete
org.apache.hadoop.hive.ql.TestTxnCommands.testMultipleInserts
org.apache.hadoop.hive.ql.TestTxnCommands.testReadMyOwnInsert
org.apache.hadoop.hive.ql.TestTxnCommands.testSimpleAcidInsert
org.apache.hadoop.hive.ql.TestTxnCommands.testTimeOutReaper
org.apache.hadoop.hive.ql.TestTxnCommands.testUpdateDeleteOfInserts
org.apache.hadoop.hive.ql.TestTxnCommands.testUpdateOfInserts
org.apache.hadoop.hive.ql.TestTxnCommands2.testBucketizedInputFormat
org.apache.hadoop.hive.ql.TestTxnCommands2.testDeleteIn
org.apache.hadoop.hive.ql.TestTxnCommands2.testInsertOverwriteWithSelfJoin
org.apache.hadoop.hive.ql.TestTxnCommands2.testOrcNoPPD
org.apache.hadoop.hive.ql.TestTxnCommands2.testOrcPPD
org.apache.hadoop.hive.ql.TestTxnCommands2.testUpdateMixedCase
org.apache.hadoop.hive.ql.io.orc.TestBitPack.testBitPack64Large
org.apache.hadoop.hive.ql.io.orc.TestColumnStatistics.testHasNull
org.apache.hadoop.hive.ql.io.orc.TestFileDump.testBloomFilter
org.apache.hadoop.hive.ql.io.orc.TestFileDump.testBloomFilter2
org.apache.hadoop.hive.ql.io.orc.TestFileDump.testDataDump
org.apache.hadoop.hive.ql.io.orc.TestFileDump.testDataDumpThrowsIOException
org.apache.hadoop.hive.ql.io.orc.TestFileDump.testDictionaryThreshold
org.apache.hadoop.hive.ql.io.orc.TestFileDump.testDump
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormat
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testDefaultTypes
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testEmptyFile
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testInOutFormat
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testMROutput
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testProjectedColumnSize
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testSplitElimination
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testSplitEliminationNullStats
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testSplitGenFailure
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testSplitGenerator
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testVectorization
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testVectorizationWithAcid
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testVectorizationWithBuckets
org.apache.hadoop.hive.ql.io.orc.TestJsonFileDump.testJsonDump
org.apache.hadoop.hive.ql.io.orc.TestNewInputOutputFormat.testNewInputFormat
org.apache.hadoop.hive.ql.io.orc.TestNewInputOutputFormat.testNewInputFormatPruning
org.apache.hadoop.hive.ql.io.orc.TestNewInputOutputFormat.testNewOutputFormat
org.apache.hadoop.hive.ql.io.orc.TestNewInputOutputFormat.testNewOutputFormatComplex
org.apache.hadoop.hive.ql.io.orc.TestNewInputOutputFormat.testNewOutputFormatWithCompression
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testBasicDelta1[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testBasicDelta1[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testBasicDelta2[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testBasicDelta2[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testBasicDelta3[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testBasicDelta3[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testBasicDelta4[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testBasicDelta4[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testBasicNew[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testBasicNew[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testBasicOld[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testBasicOld[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testBasicRow[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testBasicRow[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testDeltaOverflow2[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testDeltaOverflow2[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testDeltaOverflow3[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testDeltaOverflow3[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testDeltaOverflow[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testDeltaOverflow[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testDirectLargeNegatives[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testDirectLargeNegatives[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testIntegerMax[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testIntegerMax[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testIntegerMin[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testIntegerMin[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testLongMax[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testLongMax[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testLongMin[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testLongMin[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBase510[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBase510[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBase511[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBase511[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseAt0[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseAt0[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseAt1[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseAt1[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseAt255[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseAt255[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseAt256[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseAt256[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseMax1[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseMax1[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseMax2[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseMax2[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseMax3[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseMax3[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseMax4[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseMax4[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseNegativeMin2[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseNegativeMin2[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseNegativeMin3[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseNegativeMin3[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseNegativeMin4[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseNegativeMin4[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseNegativeMin[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseNegativeMin[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseTimestamp[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testPatchedBaseTimestamp[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testRandomInt[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testRandomInt[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testRandomLong[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testRandomLong[1]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testSeek[0]
org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.testSeek[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.columnProjection[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.columnProjection[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.emptyFile[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.emptyFile[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.metaData[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.metaData[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.test1[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.test1[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testDate1900[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testDate1900[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testDate2038[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testDate2038[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testMemoryManagementV11[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testMemoryManagementV11[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testMemoryManagementV12[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testMemoryManagementV12[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testPredicatePushdown[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testPredicatePushdown[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testReadFormat_0_11[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testReadFormat_0_11[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testSeek[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testSeek[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testSnappy[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testSnappy[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testStringAndBinaryStatistics[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testStringAndBinaryStatistics[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testStripeLevelStats[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testStripeLevelStats[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testTimestamp[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testTimestamp[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testUnionAndTimestamp[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testUnionAndTimestamp[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testWithoutIndex[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testWithoutIndex[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testZeroCopySeek[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testZeroCopySeek[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcNullOptimization.testColumnsWithNullAndCompression
org.apache.hadoop.hive.ql.io.orc.TestOrcNullOptimization.testMultiStripeWithNull
org.apache.hadoop.hive.ql.io.orc.TestOrcNullOptimization.testMultiStripeWithoutNull
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testEmpty
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderDelta
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderIncompleteDelta
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderOldBaseAndDelta
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testUpdates
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriter
org.apache.hadoop.hive.ql.io.orc.TestOrcSerDeStats.testOrcSerDeStatsComplex
org.apache.hadoop.hive.ql.io.orc.TestOrcSerDeStats.testOrcSerDeStatsComplexOldFormat
org.apache.hadoop.hive.ql.io.orc.TestOrcSerDeStats.testOrcSerDeStatsList
org.apache.hadoop.hive.ql.io.orc.TestOrcSerDeStats.testOrcSerDeStatsMap
org.apache.hadoop.hive.ql.io.orc.TestOrcSerDeStats.testOrcSerDeStatsSimpleWithNulls
org.apache.hadoop.hive.ql.io.orc.TestOrcSerDeStats.testSerdeStatsOldFormat
org.apache.hadoop.hive.ql.io.orc.TestOrcSerDeStats.testStringAndBinaryStatistics
org.apache.hadoop.hive.ql.io.orc.TestOrcSplitElimination.testSplitEliminationComplexExpr
org.apache.hadoop.hive.ql.io.orc.TestOrcSplitElimination.testSplitEliminationLargeMaxSplit
org.apache.hadoop.hive.ql.io.orc.TestOrcSplitElimination.testSplitEliminationSmallMaxSplit
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testReadTimestampFormat_0_11[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testReadTimestampFormat_0_11[10]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testReadTimestampFormat_0_11[11]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testReadTimestampFormat_0_11[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testReadTimestampFormat_0_11[2]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testReadTimestampFormat_0_11[3]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testReadTimestampFormat_0_11[4]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testReadTimestampFormat_0_11[5]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testReadTimestampFormat_0_11[6]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testReadTimestampFormat_0_11[7]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testReadTimestampFormat_0_11[8]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testReadTimestampFormat_0_11[9]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testTimestampWriter[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testTimestampWriter[10]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testTimestampWriter[11]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testTimestampWriter[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testTimestampWriter[2]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testTimestampWriter[3]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testTimestampWriter[4]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testTimestampWriter[5]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testTimestampWriter[6]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testTimestampWriter[7]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testTimestampWriter[8]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.testTimestampWriter[9]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[100]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[101]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[102]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[103]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[104]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[105]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[106]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[107]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[108]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[109]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[10]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[110]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[111]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[112]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[113]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[114]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[115]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[116]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[117]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[118]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[119]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[11]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[120]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[121]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[122]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[123]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[124]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[125]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[126]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[127]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[128]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[129]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[12]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[130]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[131]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[132]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[133]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[134]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[135]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[136]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[137]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[138]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[139]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[13]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[140]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[141]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[142]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[143]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[144]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[145]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[146]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[147]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[148]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[149]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[14]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[150]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[151]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[152]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[153]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[154]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[155]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[156]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[157]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[158]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[159]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[15]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[160]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[161]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[162]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[163]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[164]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[165]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[166]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[167]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[168]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[169]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[16]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[170]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[171]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[172]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[173]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[174]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[175]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[176]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[177]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[178]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[179]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[17]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[180]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[181]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[182]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[183]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[184]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[185]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[186]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[187]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[188]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[189]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[18]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[190]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[191]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[192]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[193]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[194]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[195]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[196]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[197]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[198]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[199]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[19]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[200]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[201]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[202]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[203]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[204]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[205]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[206]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[207]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[208]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[209]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[20]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[210]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[211]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[212]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[213]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[214]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[215]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[216]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[217]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[218]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[219]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[21]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[220]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[221]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[222]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[223]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[224]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[225]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[226]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[227]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[228]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[229]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[22]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[230]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[231]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[232]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[233]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[234]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[235]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[236]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[237]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[238]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[239]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[23]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[240]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[241]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[242]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[243]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[244]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[245]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[246]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[247]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[248]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[249]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[24]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[250]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[251]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[252]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[253]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[254]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[255]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[256]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[257]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[258]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[259]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[25]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[260]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[261]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[262]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[263]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[264]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[265]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[266]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[267]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[268]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[269]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[26]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[270]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[271]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[272]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[273]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[274]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[275]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[276]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[277]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[278]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[279]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[27]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[280]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[281]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[282]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[283]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[284]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[285]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[286]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[287]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[288]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[289]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[28]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[290]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[291]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[292]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[293]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[294]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[295]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[296]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[297]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[298]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[299]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[29]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[2]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[300]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[301]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[302]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[303]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[304]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[305]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[306]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[307]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[308]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[309]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[30]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[310]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[311]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[312]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[313]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[314]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[315]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[316]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[317]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[318]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[319]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[31]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[320]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[321]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[322]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[323]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[324]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[325]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[326]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[327]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[328]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[329]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[32]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[330]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[331]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[332]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[333]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[334]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[335]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[336]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[337]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[338]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[339]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[33]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[340]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[341]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[342]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[343]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[344]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[345]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[346]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[347]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[348]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[349]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[34]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[350]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[351]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[352]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[353]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[354]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[355]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[356]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[357]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[358]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[359]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[35]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[360]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[361]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[362]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[363]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[364]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[365]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[366]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[367]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[368]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[369]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[36]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[370]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[371]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[372]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[373]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[374]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[375]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[376]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[377]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[378]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[379]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[37]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[380]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[381]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[382]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[383]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[384]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[385]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[386]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[387]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[388]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[389]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[38]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[390]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[391]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[392]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[393]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[394]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[395]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[396]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[397]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[398]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[399]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[39]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[3]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[400]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[401]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[402]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[403]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[404]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[405]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[406]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[407]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[408]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[409]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[40]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[410]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[411]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[412]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[413]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[414]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[415]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[416]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[417]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[418]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[419]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[41]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[420]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[421]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[422]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[423]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[424]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[425]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[426]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[427]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[428]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[429]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[42]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[430]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[431]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[432]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[433]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[434]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[435]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[436]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[437]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[438]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[439]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[43]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[440]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[441]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[442]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[443]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[444]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[445]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[446]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[447]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[448]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[449]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[44]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[450]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[451]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[452]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[453]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[454]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[455]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[456]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[457]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[458]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[459]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[45]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[460]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[461]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[462]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[463]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[464]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[465]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[466]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[467]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[468]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[469]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[46]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[470]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[471]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[472]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[473]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[474]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[475]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[476]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[477]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[478]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[479]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[47]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[480]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[481]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[482]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[483]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[484]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[485]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[486]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[487]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[488]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[489]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[48]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[490]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[491]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[492]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[493]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[494]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[495]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[496]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[497]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[498]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[499]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[49]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[4]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[50]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[51]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[52]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[53]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[54]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[55]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[56]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[57]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[58]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[59]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[5]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[60]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[61]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[62]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[63]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[64]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[65]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[66]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[67]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[68]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[69]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[6]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[70]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[71]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[72]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[73]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[74]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[75]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[76]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[77]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[78]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[79]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[7]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[80]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[81]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[82]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[83]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[84]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[85]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[86]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[87]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[88]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[89]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[8]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[90]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[91]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[92]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[93]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[94]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[95]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[96]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[97]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[98]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[99]
org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.testTimestampWriter[9]
org.apache.hadoop.hive.ql.io.orc.TestRecordReaderImpl.testMaxLengthToReader
org.apache.hadoop.hive.ql.io.orc.TestStringDictionary.testHalfDistinct
org.apache.hadoop.hive.ql.io.orc.TestStringDictionary.testHalfDistinctCheckDisabled
org.apache.hadoop.hive.ql.io.orc.TestStringDictionary.testTooManyDistinct
org.apache.hadoop.hive.ql.io.orc.TestStringDictionary.testTooManyDistinctCheckDisabled
org.apache.hadoop.hive.ql.io.orc.TestStringDictionary.testTooManyDistinctV11AlwaysDictionary
org.apache.hadoop.hive.ql.io.orc.TestUnrolledBitPack.testBitPacking[0]
org.apache.hadoop.hive.ql.io.orc.TestUnrolledBitPack.testBitPacking[10]
org.apache.hadoop.hive.ql.io.orc.TestUnrolledBitPack.testBitPacking[1]
org.apache.hadoop.hive.ql.io.orc.TestUnrolledBitPack.testBitPacking[2]
org.apache.hadoop.hive.ql.io.orc.TestUnrolledBitPack.testBitPacking[3]
org.apache.hadoop.hive.ql.io.orc.TestUnrolledBitPack.testBitPacking[4]
org.apache.hadoop.hive.ql.io.orc.TestUnrolledBitPack.testBitPacking[5]
org.apache.hadoop.hive.ql.io.orc.TestUnrolledBitPack.testBitPacking[6]
org.apache.hadoop.hive.ql.io.orc.TestUnrolledBitPack.testBitPacking[7]
org.apache.hadoop.hive.ql.io.orc.TestUnrolledBitPack.testBitPacking[8]
org.apache.hadoop.hive.ql.io.orc.TestUnrolledBitPack.testBitPacking[9]
org.apache.hadoop.hive.ql.io.orc.TestVectorizedORCReader.createFile
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_ambiguous_join_col
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_duplicate_alias
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_garbage
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_insert_wrong_number_columns
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_invalid_create_table
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_invalid_dot
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_invalid_function_param2
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_invalid_index
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_invalid_select
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_macro_reserved_word
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_missing_overwrite
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_nonkey_groupby
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_quoted_string
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_unknown_column1
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_unknown_column2
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_unknown_column3
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_unknown_column4
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_unknown_column5
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_unknown_column6
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_unknown_function1
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_unknown_function2
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_unknown_function3
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_unknown_function4
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_unknown_table1
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_unknown_table2
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_wrong_distinct1
org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_wrong_distinct2
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningDelete
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningInsert
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningUpdate
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler
org.apache.hive.hcatalog.mapreduce.TestHCatDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask[3]
org.apache.hive.hcatalog.mapreduce.TestHCatDynamicPartitioned.testHCatDynamicPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask[3]
org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatDynamicPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatExternalDynamicCustomLocation[3]
org.apache.hive.hcatalog.mapreduce.TestHCatExternalNonPartitioned.testHCatNonPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned.testHCatPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatMutableDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask[3]
org.apache.hive.hcatalog.mapreduce.TestHCatMutableDynamicPartitioned.testHCatDynamicPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatMutableNonPartitioned.testHCatNonPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatMutablePartitioned.testHCatPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatNonPartitioned.testHCatNonPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable[3]
org.apache.hive.hcatalog.pig.TestE2EScenarios.testReadOrcAndRCFromPig
org.apache.hive.hcatalog.pig.TestHCatLoader.testProjectionsBasic[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataBasic[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadPartitionedBasic[3]
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testMapNullKey[3]
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testMapWithComplexData[3]
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testSyntheticComplexSchema[3]
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testTupleInBagInTupleInBag[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testBagNStruct[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDateCharTypes[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataNoSpec[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataPartialSpec[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testMultiPartColsInData[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testPartColsInData[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncAllSimpleTypes[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncSimple[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreInPartiitonedTbl[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreMultiTables[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoCtorArgs[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoSchema[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteChar[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate2[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate3[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalXY[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalX[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimal[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteSmallint[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTimestamp[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTinyint[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteVarchar[3]
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreBasicTable[3]
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStorePartitionedTable[3]
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreTableMulti[3]
org.apache.hive.hcatalog.streaming.TestStreaming.testConcurrentTransactionBatchCommits
org.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits
org.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits
org.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions
org.apache.hive.hcatalog.streaming.TestStreaming.testTimeOutReaper
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyAbort
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyCommit
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5519/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5519/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5519/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 852 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12764884 - PreCommit-HIVE-TRUNK-Build

Broken by HIVE-4243

Merge from master and fix the issue



{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12765060/HIVE-11642.19.patch

{color:green}SUCCESS:{color} +1 due to 44 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 9 failed/errored test(s), 9735 tests executed
*Failed tests:*
{noformat}
TestMiniTezCliDriver-vector_distinct_2.q-vector_interval_2.q-bucket3.q-and-12-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_mult_tables
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_explainuser_1
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_vectorized_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_groupby_reduce
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_index_bitmap_auto
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5539/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5539/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5539/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 9 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12765060 - PreCommit-HIVE-TRUNK-Build

Updated some files. Some I cannot repro.



{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12765113/HIVE-11642.20.patch

{color:green}SUCCESS:{color} +1 due to 44 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 9750 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_orc_llap
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_explainuser_1
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5543/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5543/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5543/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12765113 - PreCommit-HIVE-TRUNK-Build

Both tests are simple out file changes.



{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12765215/HIVE-11642.21.patch

{color:green}SUCCESS:{color} +1 due to 44 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 6 failed/errored test(s), 9720 tests executed
*Failed tests:*
{noformat}
TestMiniTezCliDriver-vector_partition_diff_num_cols.q-orc_merge9.q-vector_decimal_aggregate.q-and-12-more - did not produce a TEST-*.xml file
TestMiniTezCliDriver-vectorization_10.q-vector_partitioned_date_time.q-vector_non_string_partition.q-and-12-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_explainuser_1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_scriptfile1
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5552/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5552/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5552/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 6 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12765215 - PreCommit-HIVE-TRUNK-Build

Not sure why some processes failed

Cannot repro either of these tests. Will try again... we might just disable explain test for minillap, I have no idea why stats keep changing.



{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12765480/HIVE-11642.22.patch

{color:green}SUCCESS:{color} +1 due to 47 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 7 failed/errored test(s), 9752 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_dynamic_partition_pruning_2
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_explainuser_1
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_vectorized_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_scriptfile1
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5571/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5571/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5571/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 7 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12765480 - PreCommit-HIVE-TRUNK-Build

HIVE-12081 should fix inconsistency with explainuser_1.q test.

Incorporating HIVE-12081



{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12765910/HIVE-11642.24.patch

{color:green}SUCCESS:{color} +1 due to 47 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 9738 tests executed
*Failed tests:*
{noformat}
TestMiniTezCliDriver-auto_join30.q-vector_data_types.q-filter_join_breaktask.q-and-12-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_histogram_numeric
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_schemeAuthority2
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5590/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5590/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5590/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12765910 - PreCommit-HIVE-TRUNK-Build

Looks like MiniTez tests get stuck on master too, such as, recently, in HIVE-11609, HIVE-12032, HIVE-12065 etc. There were also no stuck tests on HIVE-12060.
Also, udaf_histogram_numeric has different diffs in many recent JIRAs such as HIVE-12074, HIVE-12084, HIVE-11954, HIVE-12065; and it has a different diff on HIVE-12060 with the branch patch. I've run this test on Mac and Linux machines with Java 7 and 8 and I cannot repro the diff in this JIRA.

Other tests are known unstable tests. 

