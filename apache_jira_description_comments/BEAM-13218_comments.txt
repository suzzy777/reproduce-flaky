Note this doesn't seem to be a hard failure, but it's very flaky: https://ci-beam.apache.org/job/beam_PostCommit_Python38/lastCompletedBuild/testReport/junit/apache_beam.io.gcp.pubsub_integration_test/PubSubIntegrationTest/test_streaming_with_attributes/history/

Looks like it started suddenly, somewhere around https://ci-beam.apache.org/job/beam_PostCommit_Python38/1891/

This error is complaining because the actual received messages don't have a timestamp attribute. Apparently PubsubMessageMatcher considers it an error if one of the attributes in listed in strip_attributes is not found, and it adds the string "PubSubMessageMatcher error: expected attribute not found.": https://github.com/apache/beam/blob/8da177f64d314cf72e89a51e51fb0915f706a784/sdks/python/apache_beam/io/gcp/tests/pubsub_matcher.py#L146

Disregard my first comment, this seems to be a hard failure. It just looks like flake in the Jenkins UI because it doesn't differentiate between the directrunner execution and the dataflow execution. A better history view is here: https://ci-beam.apache.org/job/beam_PostCommit_Python38/lastCompletedBuild/testReport/junit/apache_beam.io.gcp.pubsub_integration_test/PubSubIntegrationTest/history/

We can see the test has failed consistently since https://ci-beam.apache.org/job/beam_PostCommit_Python38/1891/, except for executions that timed out.

At first I couldn't make sense of this failure mode. The two messages referenced in the error don't have timestamps when they are injected in the test, so why do we expect them to have timestamp at the end?

The answer is that the WriteToPubsub() transform has timestamp_attribute= set. So the WriteToPubsub transform should be adding the attribute.

The test has been sickbayed

This Jira ticket has a pull request attached to it, but is still open. Did the pull request resolve the issue? If so, could you please mark it resolved? This will help the project have a clear view of its open issues.

The issue has not been fully resolved. We merged [PR16251|https://github.com/apache/beam/pull/16251] to skip the flaky test while we investigate the issue. I've downgraded it to P2 for now.

We have identified this issue as a bug in the Dataflow service backend. Once the fix gets deployed, we can un-skip the test.

