Seen also in trunk:
* https://app.circleci.com/pipelines/github/mike-tr-adamson/cassandra/332/workflows/946e28f4-2dec-4384-ac38-de011093f6c6/jobs/25738/tests
* https://app.circleci.com/pipelines/github/adelapena/cassandra/3254/workflows/69f451ef-fb39-48e4-b1d1-40ee4141b0c1/jobs/83737/tests
* https://app.circleci.com/pipelines/github/adelapena/cassandra/3254/workflows/69f451ef-fb39-48e4-b1d1-40ee4141b0c1/jobs/83738/tests

{code}
java.lang.IllegalStateException: Could not achieve schema readiness in PT30S
	at org.apache.cassandra.service.StorageService.waitForSchema(StorageService.java:1194)
	at org.apache.cassandra.service.StorageService.prepareForBootstrap(StorageService.java:1967)
	at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:1238)
	at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:1199)
	at org.apache.cassandra.service.StorageService.initServer(StorageService.java:978)
	at org.apache.cassandra.service.StorageService.initServer(StorageService.java:895)
	at org.apache.cassandra.distributed.impl.Instance.lambda$startup$12(Instance.java:701)
	at org.apache.cassandra.concurrent.FutureTask$1.call(FutureTask.java:96)
	at org.apache.cassandra.concurrent.FutureTask.call(FutureTask.java:61)
	at org.apache.cassandra.concurrent.FutureTask.run(FutureTask.java:71)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:833)
	Suppressed: org.apache.cassandra.distributed.shared.ShutdownException: Uncaught exceptions were thrown during test
		at org.apache.cassandra.distributed.impl.AbstractCluster.checkAndResetUncaughtExceptions(AbstractCluster.java:1117)
		at org.apache.cassandra.distributed.impl.AbstractCluster.close(AbstractCluster.java:1103)
		at org.apache.cassandra.distributed.test.MigrationCoordinatorTest.explicitEndpointIgnore(MigrationCoordinatorTest.java:78)
		at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
		at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		Suppressed: java.lang.AssertionError: Release version is unknown
			at org.apache.cassandra.utils.FBUtilities.getReleaseVersionMajor(FBUtilities.java:473)
			at org.apache.cassandra.schema.MigrationCoordinator.shouldPullFromEndpoint(MigrationCoordinator.java:371)
			at org.apache.cassandra.schema.MigrationCoordinator.maybePullSchema(MigrationCoordinator.java:303)
			at org.apache.cassandra.schema.MigrationCoordinator.pullComplete(MigrationCoordinator.java:686)
			at org.apache.cassandra.schema.MigrationCoordinator$Callback.fail(MigrationCoordinator.java:615)
			at org.apache.cassandra.schema.MigrationCoordinator$Callback.onFailure(MigrationCoordinator.java:610)
			at org.apache.cassandra.schema.MigrationCoordinator.pullSchema(MigrationCoordinator.java:654)
			at org.apache.cassandra.schema.MigrationCoordinator.lambda$scheduleSchemaPull$2(MigrationCoordinator.java:548)
			at org.apache.cassandra.concurrent.FutureTask$1.call(FutureTask.java:96)
			at org.apache.cassandra.concurrent.FutureTask.call(FutureTask.java:61)
			at org.apache.cassandra.concurrent.FutureTask.run(FutureTask.java:71)
			at org.apache.cassandra.concurrent.FutureTask$1.call(FutureTask.java:96)
			at org.apache.cassandra.concurrent.FutureTask.call(FutureTask.java:61)
			at org.apache.cassandra.concurrent.FutureTask.run(FutureTask.java:71)
			at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
			at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
			at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
			at java.base/java.lang.Thread.run(Thread.java:833)
{code}
I haven't seen it yet on Butler. The repeated runs above have been generated with:
{code}
.circleci/generate.sh -sp \
  -e REPEATED_JVM_DTESTS=org.apache.cassandra.distributed.test.MigrationCoordinatorTest \
  -e REPEATED_JVM_DTESTS_COUNT=500 \
{code}
Flakiness seem to be lower than 1%. Probably we will need a higher number of repetitions to be sure to reproduce it.
 

Checking whether it is flaky also on 4.1. Started repeated run here: https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra?branch=18902-4.1

It seems if one of the tests in that class fails with the pointed error, then we see others falling with:
{code:java}
org.apache.cassandra.exceptions.ConfigurationException: /127.0.0.3:7012 is in use by another process. Change listen_address:storage_port in cassandra.yaml to values that do not conflict with other services{code}
 While the error was not seen with the explicitEndpointIgnore, but with others in the class in 4.1, this is not like a regression but a flaky test suite and probably some timing error.

WDYT [~adelapena] , [~jlewandowski] ? Shall we mark this one as affecting earlier versions, or is it a different issue, and I am missing something here?

[~adelapena] noticed that both branches fail on {{FBUtilities#getReleaseVersionMajor}} , but 4.1 seems to get a release version different to {{UNKNOWN_RELEASE_VERSION = "Unknown"}} that doesn’t contain dots, whereas 5.0 fails because it gets {{{}UNKNOWN_RELEASE_VERSION{}}}. I missed seeing that last week.  

[~e.dimitrova], [~adelapena] - according to your findings, it looks like it fails to resolve the version string. I'm wondering how it could be possible - some class loader related issue with dtest framework?

I couldn't reproduce it with 500 runs on 5.0, https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/1147/workflows/bce2802a-567f-412c-bd2d-0311f711166a/jobs/53881

I'd fix this ticket by adding some assertion to the cluster startup code so that it fails when the version is not set - this way we will be able to separate further failures from exact tests - wdyt?

{quote}I'd fix this ticket by adding some assertion to the cluster startup code so that it fails when the version is not set - this way we will be able to separate further failures from exact tests - wdyt?
{quote}
That sounds reasonable to me.

{quote}{quote}I'd fix this ticket by adding some assertion to the cluster startup code so that it fails when the version is not set - this way we will be able to separate further failures from exact tests - wdyt?
{quote}
That sounds reasonable to me.
{quote}
+1, thanks!

unfortunately... it does not seem to help: https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/1148/workflows/f18eb2bc-4bb2-4377-b3ba-5d1dc2bb03ff/jobs/53974

{noformat}
WARN  [node3_MigrationStage:1] node3 2023-12-05 11:30:22,521 Unable to load version.properties
java.lang.NullPointerException: null
	at sun.net.www.protocol.jar.JarURLConnection.connect(JarURLConnection.java:130)
	at sun.net.www.protocol.jar.JarURLConnection.getInputStream(JarURLConnection.java:152)
	at java.net.URLClassLoader.getResourceAsStream(URLClassLoader.java:239)
	at org.apache.cassandra.utils.FBUtilities.getReleaseVersionString(FBUtilities.java:424)
	at org.apache.cassandra.utils.FBUtilities.getReleaseVersionMajor(FBUtilities.java:444)
	at org.apache.cassandra.schema.MigrationCoordinator.shouldPullFromEndpoint(MigrationCoordinator.java:370)
	at org.apache.cassandra.schema.MigrationCoordinator.maybePullSchema(MigrationCoordinator.java:302)
	at org.apache.cassandra.schema.MigrationCoordinator.pullComplete(MigrationCoordinator.java:685)
	at org.apache.cassandra.schema.MigrationCoordinator.access$100(MigrationCoordinator.java:98)
	at org.apache.cassandra.schema.MigrationCoordinator$Callback.fail(MigrationCoordinator.java:614)
	at org.apache.cassandra.schema.MigrationCoordinator$Callback.onFailure(MigrationCoordinator.java:609)
	at org.apache.cassandra.schema.MigrationCoordinator.pullSchema(MigrationCoordinator.java:653)
	at org.apache.cassandra.schema.MigrationCoordinator.lambda$scheduleSchemaPull$2(MigrationCoordinator.java:547)
	at org.apache.cassandra.concurrent.FutureTask$1.call(FutureTask.java:96)
	at org.apache.cassandra.concurrent.FutureTask.call(FutureTask.java:61)
	at org.apache.cassandra.concurrent.FutureTask.run(FutureTask.java:71)
	at org.apache.cassandra.concurrent.FutureTask$1.call(FutureTask.java:96)
	at org.apache.cassandra.concurrent.FutureTask.call(FutureTask.java:61)
	at org.apache.cassandra.concurrent.FutureTask.run(FutureTask.java:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:750)
{noformat}

:(

In case it happens, the method returns "debug version" as a version string, which is obviously different than "Unknown" but it also has no dot

I suppose this is unrelated - it may happen as that method is called asynchronously during tear down. The nodes are running in isolated class loaders so when the node is destroyed, the class loader is wiped and the resources disappear. IDK, but it looks to me as such. Though the core problem is that the node failed to start because it could not achieve the schema agreement in 30 seconds.


I changed the following things:
- the version is not re-read from the properties files - once it has been read, its value is memoized
- migration coordinator adds some small backoff delay after a failed fetch from other node (this allows to avoid flooding logs)
- fixed one system property that wasn't cleared in the test after being set
- fixed dtest framework to not overwrite system properties which were explicitly set in the test case
- fixed a nit timing issue in MigrationCoordinator (unit test)

Also, regarding that failure with address being unavailable, I managed to reproduce the problem - it looks like a dtest framework problem so I created https://issues.apache.org/jira/browse/CASSANDRA-19181 to address that.

So far, I've run the whole MigrationCoordinator class 1000 times and also other 1000 time the test case which failed alone


https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/1157/workflows/db16c4ca-a05b-4bdb-9627-fc587e87ce4c

https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra?branch=CASSANDRA-18902-4.1

I couldn't reproduce it so far, also the other test results looks good
there are already 3500 runs without a failure of that test


-I will be looking into this patch today. I found a repeated run only for the unit test but not for the java distributed one. Did I miss it?-
You opened CASSANDRA-19181 for that one. Sorry, I missed that comment
-EDIT: It seems there are changes to the java dtest still, so I guess we still want to check a repeated run-

[~e.dimitrova] I've applied your comments - removed those CassandraRelevantProperties additional entries from 4.1 and removed configuration for back off interval.  Created PRs for 5.0 and trunk (actually almost no changes for trunk, there is no migration coordinator any longer). Please have a look before I run all tests

[~jlewandowski] , thank you. Everything looks good except for one small comment. 
{quote} - the version is not re-read from the properties files - once it has been read, its value is memoized{quote}
This is a nice improvement, and those should go only to trunk. Also, I left [this|https://github.com/apache/cassandra/pull/2984#discussion_r1430762476] and [this|https://github.com/apache/cassandra/pull/2984#discussion_r1430762476] comment, why getting rid of the "debug_version"?

debug version was kept in 4.1, and it doesn't exist in 5.0+.
+1, please commit on green CI for all branches (green from the perspective of this ticket)

Thanks [~e.dimitrova]

The CI links will be in the PRs

