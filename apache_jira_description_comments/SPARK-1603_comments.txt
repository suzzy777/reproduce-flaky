I ran into this myself as well. From the code I can see that actor should be shut down correctly when streaming context is shutdown. So there should not be lingering actors. I think this is happening because of the clearing of "JobScheduler" from the actorSystem's name space is done lazily after the actorSystem.stop(<actor>) returns.

Autogenerated name, or JobScheduler-<current-system-time> may be the solution. 

[~tdas], I checked the code, the fix itself should be pretty easy, just use autogenerated name is OK, 

the reason is that akka.system.stop() is an asynchronous method, which means that you have no guarantee on when the actor is really stopped...

I think I made a temporary fix for now for that test. Bundled it with this PR.
https://github.com/apache/spark/pull/652/files#diff-e144dbee130ed84f9465853ddce65f8eR186 

I am a little afraid that there is some corner case that leads to actors being leaked and adding auto-generated names would mask that problem. So I just added a Thread.sleep(100) in that graceful shutdown test so that it gives the system time to stop and cleanup the actor before a new StreamingContext is started (100 ms should be enough). If the problem persists (test is still flaky) then it is more likely that there is corner where the actor is not being stopped every time.

Will close this JIRA after a few days of observation.

Ah, just made a PR at the same time, https://github.com/apache/spark/pull/659

I'm afraid a fixed time threshold cannot resolve the problem (especially that this case is hard to reproduce, always happen when Jenkins is super overloaded)....I once met the similar problem in another PR: https://github.com/apache/spark/pull/186, there, we have an asynchronous    constructor...

you are right, we should check if there are some cases we forgot to close the actor (but I think since you call ssc.stop() after each test case, the actor should be closed eventually)

I think we havent seen the flakiness since then. So I am marking this as resolved. 

Reopening caused it failed here:

https://amplab.cs.berkeley.edu/jenkins/job/Spark-Master-Maven-pre-YARN/hadoop.version=2.0.0-mr1-cdh4.1.2,label=centos/1656/
https://amplab.cs.berkeley.edu/jenkins/job/Spark-1.3-SBT/AMPLAB_JENKINS_BUILD_PROFILE=hadoop2.3,label=centos/139/
https://amplab.cs.berkeley.edu/jenkins/job/Spark-1.3-Maven-with-YARN/HADOOP_PROFILE=hadoop-2.4,label=centos/179/

{code}
Error Message

10431395 did not equal 6237090, and 10431395 did not equal 6237091 Received records = 10431395, processed records = 6237089
Stacktrace

      org.scalatest.exceptions.TestFailedException: 10431395 did not equal 6237090, and 10431395 did not equal 6237091 Received records = 10431395, processed records = 6237089
      at org.scalatest.Assertions$class.newAssertionFailedException(Assertions.scala:500)
      at org.scalatest.FunSuite.newAssertionFailedException(FunSuite.scala:1555)
      at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:466)
      at org.apache.spark.streaming.StreamingContextSuite$$anonfun$16$$anonfun$apply$mcV$sp$3.apply$mcVI$sp(StreamingContextSuite.scala:198)
      at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
      at org.apache.spark.streaming.StreamingContextSuite$$anonfun$16.apply$mcV$sp(StreamingContextSuite.scala:181)
      at org.apache.spark.streaming.StreamingContextSuite$$anonfun$16.apply(StreamingContextSuite.scala:177)
      at org.apache.spark.streaming.StreamingContextSuite$$anonfun$16.apply(StreamingContextSuite.scala:177)
      at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
      at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
      at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
      at org.scalatest.Transformer.apply(Transformer.scala:22)
      at org.scalatest.Transformer.apply(Transformer.scala:20)
      at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
      at org.scalatest.Suite$class.withFixture(Suite.scala:1122)
      at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
{code}

and

{code}
Error Message

The code passed to failAfter did not complete within 10000 milliseconds.
Stacktrace

      org.scalatest.exceptions.TestFailedDueToTimeoutException: The code passed to failAfter did not complete within 10000 milliseconds.
      at org.scalatest.concurrent.Timeouts$$anonfun$failAfter$1.apply(Timeouts.scala:249)
      at org.scalatest.concurrent.Timeouts$$anonfun$failAfter$1.apply(Timeouts.scala:249)
      at org.scalatest.concurrent.Timeouts$class.timeoutAfter(Timeouts.scala:345)
      at org.scalatest.concurrent.Timeouts$class.failAfter(Timeouts.scala:245)
{code}

[~andrewor14] Do you see this error any more?

