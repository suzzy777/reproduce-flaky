Looking into this now.

This is caused by executing the state completion request in {{GrpcStateService}} asynchronously with the default threadpool. I think this wasn't intended because {{whenCompleteAsync}} was used instead of {{whenComplete}}. The default thread pool in the test is Flink's thread pool which doesn't take care to log exceptions.

https://github.com/apache/beam/blob/c526f6bf62a1d63c7181eb7252c134e42d5c8677/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/state/GrpcStateService.java#L82

With the current implementation the StateRequest will always be a completed CompleteableFuture anyways, so there is no need to schedule asynchronously.

The following exception was thrown here: https://github.com/apache/beam/blob/c526f6bf62a1d63c7181eb7252c134e42d5c8677/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/state/GrpcStateService.java#L85

{noformat}
java.lang.IllegalStateException: sendHeaders has already been called
    at org.apache.beam.vendor.grpc.v1_13_1.com.google.common.base.Preconditions.checkState(Preconditions.java:444)
    at org.apache.beam.vendor.grpc.v1_13_1.io.grpc.internal.ServerCallImpl.sendHeaders(ServerCallImpl.java:88)
    at org.apache.beam.vendor.grpc.v1_13_1.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onNext(ServerCalls.java:338)
    at org.apache.beam.runners.fnexecution.state.GrpcStateService$Inbound.lambda$onNext$0(GrpcStateService.java:142)
    at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760)
    at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736)
    at java.util.concurrent.CompletableFuture$Completion.exec(CompletableFuture.java:443)
    at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
    at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
    at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
    at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157) 
{noformat}

By default, gRPC provides outbound stream observers that aren't thread safe (for perf reasons) and expects people interacting with them to make them thread safe. The issue seems to be that GrpcStateService assumes that the outbound stream observer is thread safe but by default it is not.

In addition to what you have added, we should also make the GrpcStateService take in an OutboundObserverFactory that allows the person constructing it to choose whether they want a "buffered and thread safe outbound observer" or a "non thread safe (aka direct)" observer and then the GrpcStateService will provide the necessary hooks for allowing runners to choose whether state requests are handled in parallel or not.

Closing this as the underlying issue for test failures are fixed. Follow-up is BEAM-6166.

