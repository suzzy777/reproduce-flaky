Any clue on what's the difference that makes trunk complete in contrast to branch-2?
[~xkrogen] had done a bunch of improvement to {{MiniDFSCluster}} and others trying to reduce the load.
Most of those are in branch-2 AFAIK.

HDFS-13265 is still outstanding pending some cleanup from my end... But it is not in branch-2 or trunk at this time, so it shouldn't make a big difference between the two. I can try to see if branch-2 is able to run successfully with that patch applied, let me submit a rebased patch there...

This is pretty much the continuing story of HDFS-12711 and friends.

But please please please do not increase the process limits on the ASF Jenkins jobs.  Process limits were added to Yetus specifically because the Hadoop unit tests were crashing Jenkins build nodes.



Let's see if HDFS-13265 helps; I think that's a good start to reduce the number of processes.

Looks like the same problem still occurs after HDFS-13265 is [applied to branch-2|https://builds.apache.org/job/PreCommit-HDFS-Build/24928]:
{code}
============================================================================
============================================================================
                            Running unit tests
============================================================================
============================================================================


unit test pre-reqs:
cd /testptch/hadoop/hadoop-common-project/hadoop-common
/opt/maven/bin/mvn --batch-mode -Dmaven.repo.local=/home/jenkins/jenkins-slave/workspace/PreCommit-HDFS-Build/yetus-m2/hadoop-branch-2-patch-1 install -DskipTests -Pnative -Drequire.fuse -Drequire.openssl -Drequire.snappy -Drequire.valgrind -Drequire.test.libhadoop -Pyarn-ui > /testptch/patchprocess/maven-unit-prereq-hadoop-common-project_hadoop-common-install.txt 2>&1
cd /testptch/hadoop/hadoop-hdfs-project/hadoop-hdfs
/opt/maven/bin/mvn --batch-mode -Dmaven.repo.local=/home/jenkins/jenkins-slave/workspace/PreCommit-HDFS-Build/yetus-m2/hadoop-branch-2-patch-1 -Ptest-patch -Pparallel-tests -P!shelltest -Pnative -Drequire.fuse -Drequire.openssl -Drequire.snappy -Drequire.valgrind -Drequire.test.libhadoop -Pyarn-ui clean test -fae > /testptch/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt 2>&1
Build timed out (after 300 minutes). Marking the build as aborted.
Build was aborted
{code}

Even while HDFS is breaking, can we @ least have everything else up & running?

It depends upon what you mean by "everything else."

test-patch still "functions."

There is zero point in running qbt on branch-2.  It will go up until HDFS then sit eating resources for the remaining 10 hours (or whatever).  The job times out and the email output won't be generated.  That only hurts the ASF as a whole.

Also, given that no one appears to have noticed that there hasn't been an email from the trunk qbt run, I still posit that no one pays attention to them anyway.  (It would appear that Jenkins has lost the ability to send email because everything else is working as expected.)

FYI I am also seeing something similar in hadoop-yarn-client module - https://issues.apache.org/jira/browse/YARN-8200?focusedCommentId=16607445&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-16607445

I suggest we do two things:
# Isolate a commit which caused stopping sending the emails when the build finishes.
# Identify issues that improved running tests on trunk compared to branch-2.

Alternatively we can just switch to old-fashioned test-patch build in favor of yetus. It seems that our local Jenkins with test-patch based build is succeeding on branch-2, that is, some tests are failing, but the build does not timeout.

bq. Isolate a commit which caused stopping sending the emails when the build finishes.

Jenkins will send an email if the build finishes.  This job doesn't finish in the allotted time. Increasing the allotted time just makes it spin longer.  The only "commit" would be to rewrite parts of Yetus to write partial report files.

bq. Alternatively we can just switch to old-fashioned test-patch build in favor of yetus. It seems that our local Jenkins with test-patch based build is succeeding on branch-2, that is, some tests are failing, but the build does not timeout.

Pre-yetus test-patch doesn't know how to do full builds.  So I don't know what is running on your local instance. The "full" builds[1] that the ASF used to run prior to Yetus (about 3 years ago...) were literally:

cd hadoop-(common|hdfs|mapreduce|yarn)-project
mvn test (options)

This means that if there was ANY failure in a module, the whole mvn process died.  As soon as the mvn process dies, the build is dead and the job is closed off.  Yetus actually knows to break builds up by module, so one module failing will not prevent the other modules from getting tested, regardless of the normal maven dependency checks.

Additionally, your local Jenkins instance is likely running on something significantly bigger/less busy than the ASF node. When I played with this last year I could absolutely get branch-2 to exhaust system resources without Yetus running on my own gear. In fact, the Yetus barrier code was able to be written because I was able to duplicate the failures.  If Yetus is removed, then someone needs to help Infra babysit the dead nodes that will likely be created.

I seem to recall that the last time I tried these experiments, branch-2.7 was OK.  So there is something in 2.8 and up that is messed up.

1 - They weren't actually full builds and large swaths of code went untested, including all of hadoop-tools.

[~asuresh]/[~xkrogen]/[~shv] helped me investigate, basically the last email we got from hadoop-qbt-branch2-java7-linux-x86  which actually ran unit tests was on Feb 26. I see this was committed on Feb 26 to branch-2/branch-2.9 as well: {noformat}commit 762125b864ab812512bad9a59344ca79af7f43ac
Author: Chris Douglas <cdouglas@apache.org>
Date:   Mon Feb 26 16:32:06 2018 -0800

    Backport HADOOP-13514 (surefire upgrade) to branch-2{noformat}

I see this was committed to branch-2.8 as well but eventually reverted.

So I am wondering if we can try a test run with this patch reverted so we can see the results. [~aw] thoughts on this? Do you know if reverting this will cause issues on the jenkins infra?

[Ran a build for branch-2.7|https://builds.apache.org/view/H-L/view/Hadoop/job/hadoop-qbt-branch2-java7-linux-x86-jhung/11/], which doesn't have the HADOOP-13514 backport. It was aborted after 1200 minutes, but it was running fine, completed all HDFS and MAPREDUCED tests, and most of the YARN tests. Given more time I think it would have succeeded.
 It is still not clear why trunk succeeds with this patch in. But if we revert it from branch-2 we may at least be able to restore the pre-commit builds on it. What people think?

I propose to attach a patch reverting HADOOP-15251 to this jira and try the pre-commit build. 

Thanks [~shv], let's try attaching the revert of HADOOP-15251 to this JIRA and see if Yetus goes through.

Attached a revert patch...

FWIW, I care about those yetus complains on patch submit, but there's always some flaky tests, especially if your code goes near HDFS, and so we aren't caring properly about the entire end-to-end build & test

bq. Ran a build for branch-2.7... but it was running fine

Thanks for confirming exactly what I said above:  2.7 does not suffer from the same sets of problems that 2.8 and up do. The irony is that it's not running fine.  (More below)

bq. So I am wondering if we can try a test run with this patch reverted so we can see the results. Allen Wittenauer thoughts on this? Do you know if reverting this will cause issues on the jenkins infra?

Did anyone even bother to follow to the chain as to WHY that JIRA exists?  I'm guessing no, because if anyone did they would have realized this:

2.7 suffers from the exact problem that HADOOP-15251 fixes.

{code}
Found and killed 14 left over processes
{code}

This means that surefire is not properly killing the JVMs that are spawned for unit tests.  Those unit tests that are killed in this way are NOT reported.  This, in turn, means that unit test results are COMPLETELY UNRELIABLE.  So yes, you get a report (usually...), but with large chunks of missing data.  In some cases, up to 70% of the unit tests are never executed and never reported.  [This was specifically reported in HDFS-12711.]

FWIW: Hadoop is no longer my day job.  So someone needs to sit down and really comprehend all the bits and pieces in play here.  It's a lot more complex than just a surface reading of one JIRA.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 21m  2s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} branch-2 Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 53s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 12m 52s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 55s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 11m 54s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  6m 44s{color} | {color:green} branch-2 passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 11m 41s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 34s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 12m 34s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 11m 55s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m 12s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 45m 28s{color} | {color:red} root in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 55s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}159m 20s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Unreaped Processes | root:1 |
| Timed out junit tests | org.apache.hadoop.log.TestLogLevel |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:a716388 |
| JIRA Issue | HADOOP-15711 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12940623/HADOOP-15711.001.branch-2.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  xml  |
| uname | Linux fbd891ece60d 3.13.0-144-generic #193-Ubuntu SMP Thu Mar 15 17:03:53 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | branch-2 / 3a6ad9c |
| maven | version: Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-10T16:41:47+00:00) |
| Default Java | 1.7.0_181 |
| Unreaped Processes Log | https://builds.apache.org/job/PreCommit-HADOOP-Build/15238/artifact/out/patch-unit-root-reaper.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/15238/artifact/out/patch-unit-root.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/15238/testReport/ |
| Max. process+thread count | 1702 (vs. ulimit of 10000) |
| modules | C: hadoop-project hadoop-tools/hadoop-aws hadoop-tools/hadoop-azure . U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15238/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 15m 15s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} branch-2 Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 57s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m  3s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 51s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 11m 44s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  6m 42s{color} | {color:green} branch-2 passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 11m 35s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 15s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 15s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 11m 42s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  6m 42s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}200m 12s{color} | {color:red} root in the patch failed. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  2m 21s{color} | {color:red} The patch generated 258 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}305m 59s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Unreaped Processes | root:45 |
| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeUUID |
|   | hadoop.hdfs.server.namenode.TestFSImageWithXAttr |
|   | hadoop.hdfs.server.namenode.TestAuditLogAtDebug |
|   | hadoop.hdfs.server.namenode.TestNameNodeAcl |
|   | hadoop.hdfs.server.datanode.TestDataNodeReconfiguration |
| Timed out junit tests | org.apache.hadoop.hdfs.server.datanode.TestHSync |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeMetrics |
|   | org.apache.hadoop.hdfs.TestWriteRead |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | org.apache.hadoop.hdfs.server.datanode.TestDeleteBlockPool |
|   | org.apache.hadoop.hdfs.server.datanode.TestNNHandlesBlockReportPerStorage |
|   | org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes |
|   | org.apache.hadoop.hdfs.server.datanode.TestNNHandlesCombinedBlockReport |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeMetrics |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeExit |
|   | org.apache.hadoop.hdfs.TestDFSClientFailover |
|   | org.apache.hadoop.fs.TestEnhancedByteBufferAccess |
|   | org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement |
|   | org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes |
|   | org.apache.hadoop.hdfs.qjournal.server.TestJournalNode |
|   | org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery |
|   | org.apache.hadoop.hdfs.server.datanode.TestTriggerBlockReport |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeFaultInjector |
|   | org.apache.hadoop.hdfs.server.datanode.TestLargeBlockReport |
|   | org.apache.hadoop.hdfs.TestFileAppend4 |
|   | org.apache.hadoop.hdfs.qjournal.client.TestQJMWithFaults |
|   | org.apache.hadoop.hdfs.server.datanode.TestBatchIbr |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeTransferSocketSize |
|   | org.apache.hadoop.hdfs.server.datanode.web.TestDatanodeHttpXFrame |
|   | org.apache.hadoop.hdfs.qjournal.TestSecureNNWithQJM |
|   | org.apache.hadoop.hdfs.TestDFSMkdirs |
|   | org.apache.hadoop.hdfs.TestDFSInputStream |
|   | org.apache.hadoop.hdfs.qjournal.TestNNWithQJM |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations |
|   | org.apache.hadoop.hdfs.server.datanode.TestDiskError |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration |
|   | org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold |
|   | org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache |
|   | org.apache.hadoop.hdfs.server.datanode.TestIncrementalBrVariations |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeMetricsLogger |
|   | org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithHdfs |
|   | org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner |
|   | org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCacheRevocation |
|   | org.apache.hadoop.hdfs.server.datanode.TestBlockScanner |
|   | org.apache.hadoop.hdfs.server.datanode.TestCachingStrategy |
|   | org.apache.hadoop.fs.permission.TestStickyBit |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:a716388 |
| JIRA Issue | HADOOP-15711 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12940623/HADOOP-15711.001.branch-2.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  xml  |
| uname | Linux 43a1844228a5 4.4.0-134-generic #160~14.04.1-Ubuntu SMP Fri Aug 17 11:07:07 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | branch-2 / 3a6ad9c |
| maven | version: Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-10T16:41:47+00:00) |
| Default Java | 1.7.0_181 |
| Unreaped Processes Log | https://builds.apache.org/job/PreCommit-HADOOP-Build/15239/artifact/out/patch-unit-root-reaper.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/15239/artifact/out/patch-unit-root.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/15239/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/15239/artifact/out/patch-asflicense-problems.txt |
| Max. process+thread count | 9927 (vs. ulimit of 10000) |
| modules | C: hadoop-project hadoop-tools/hadoop-aws hadoop-tools/hadoop-azure . U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15239/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



While I agree with [~aw]'s reservations.
* Partial information from the tests that do get run is better than no information at all.
* Folks are working on patches/features targeting branch-2 that do not touch HDFS code and hence probably the tests wont get executed anyway - atleast for most YARN patches.

My vote is to commit the revert patch as part of this JIRA, \@ Ignore offending tests for now and get them fixed as soon as possible ?





That's not how any of this works. People need to stop skimming and actually _READ_ the damn logs.

bq. Folks are working on patches/features targeting branch-2 that do not touch HDFS code and hence probably the tests wont get executed anyway - atleast for most YARN patches.

It's a race condition in surefire.  YARN patches ARE impacted.   HDFS is just impacted more often than not because there are so many in one maven module.   Go look at the ENTIRE log that shv posted:

hadoop-hdfs
bkjournal
mapreduce-client-jobclient
hadoop-archives
hadoop-extras
yarn-distributedshell
yarn-client

Hey look, two YARN modules.  

Hell, this revert triggered one in hadoop-common in its very first run.  

bq. @ Ignore offending tests for now

You can't.  There is no identifier as to which tests actually trigger the dead JVM bug because it's random.  Worse still, the XML data that Surefire, Yetus, and Jenkins relies upon isn't written down when the JVM crash occurs so no clue as to which tests didn't run.  That's why this bug is so deadly.

One can either have a good run (like this revert patch's first run--only one JVM crashed!) or a bad one where the whole house of cards come crumbling down (like the second one).

Personally:  I know that reverting surefire upgrades are just going to make things worse.  Upgrading surefire helped stabilize things tremendously in trunk. It might be that surefire needs to get upgraded to an even higher rev.

If everyone is just worried about getting patch results and not full builds then with the exception of HDFS, everything should be working fairly well so long as committers keep branch-2's Dockerfile updated correctly. (e.g., YARN-8658 generated branch-2 results for a patch)  HDFS has some other issue in branch-2.8 and up that causes it to just go out of control randomly, especially when the unit tests are run in parallel.

Yeah... figured out with [~jhung] that isolating and ignoring specific tests wont work since as you mentioned, when executed in the parallel, a thread running a random batch of tests might go down.

Given that single YARN patch testing for instance  should run fine (Am assuming branch-2 Dockerfile is good currently since YARN-8658 ran fine), Can we disable parallel tests for full builds then ? Will that help track down specific tests that go OOM for instance ?

bq. Can we disable parallel tests for full builds then ?

I don't even want to contemplate the runtime.  With parallelization, it is already in the 14-15 hour mark, easily.  

[BTW, have a client that was using Yetus internally for 2.7.  As a result, one of the changes in Yetus 0.8.0 was to disable parallelization for 2.7 and lower since those aren't thread safe anyway.  That's why the 2.7 run timed out after 20 hours. ]

bq. Will that help track down specific tests that go OOM for instance ?

Probably not, and definitely not without also setting the test order.  Also: no one has really done the homework to figure out why things are going catatonic.  My guess is something in hadoop-common (and FileSystem in particular) that doesn't work well on JDK7.  That's why trunk doesn't have these issues.  My other hunch is that commit date of the problematic code is was committed between June 2016-June 2017.  Because we had other issues and no one was aware of how bad SUREFIRE-524 was, the issues had been hidden.

bq. My guess is something in hadoop-common (and FileSystem in particular) that doesn't work well on JDK7. 

something in the native code binding? As I can't imagine much else

[~aw] thanks a lot for your insight, this helps understanding the problem and differences between the branches.

Looked at the PreCommit runs with the attached patch more closely. Definitely some cheating there, as many tests were not executed at all (Just as [~aw] commented). This explains fast running time.
 I also made Jenkins [execute branch-3.1 build|https://builds.apache.org/view/H-L/view/Hadoop/job/hadoop-qbt-branch2-java7-linux-x86-jhung/12/console], which completed in 12 hours.

I don't see any shortcut solutions to the branch-2 build problem at this point. We should probably take the long path and understand the fixes that were done to unit tests on branch-3, that were not backported to branch-2.

| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} branch-2 Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 44s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 10m 36s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 52s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 12m  0s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m 27s{color} | {color:green} branch-2 passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 20s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 12m 26s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 15s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 15s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 11m 45s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  6m 41s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}207m 31s{color} | {color:red} root in the patch failed. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  2m 33s{color} | {color:red} The patch generated 352 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}296m 51s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Unreaped Processes | root:46 |
| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeUUID |
|   | hadoop.hdfs.server.namenode.ha.TestBootstrapStandbyWithQJM |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.server.namenode.TestNamenodeCapacityReport |
| Timed out junit tests | org.apache.hadoop.hdfs.server.datanode.TestHSync |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeMetrics |
|   | org.apache.hadoop.hdfs.TestWriteRead |
|   | org.apache.hadoop.hdfs.server.datanode.TestDeleteBlockPool |
|   | org.apache.hadoop.hdfs.server.datanode.TestNNHandlesBlockReportPerStorage |
|   | org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes |
|   | org.apache.hadoop.hdfs.server.datanode.TestNNHandlesCombinedBlockReport |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeMetrics |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeExit |
|   | org.apache.hadoop.hdfs.TestDFSClientFailover |
|   | org.apache.hadoop.fs.TestEnhancedByteBufferAccess |
|   | org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement |
|   | org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes |
|   | org.apache.hadoop.hdfs.qjournal.server.TestJournalNode |
|   | org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery |
|   | org.apache.hadoop.hdfs.server.datanode.TestTriggerBlockReport |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeFaultInjector |
|   | org.apache.hadoop.hdfs.TestFileAppend4 |
|   | org.apache.hadoop.hdfs.qjournal.client.TestQJMWithFaults |
|   | org.apache.hadoop.hdfs.server.datanode.TestBatchIbr |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeTransferSocketSize |
|   | org.apache.hadoop.hdfs.server.datanode.web.TestDatanodeHttpXFrame |
|   | org.apache.hadoop.hdfs.qjournal.TestSecureNNWithQJM |
|   | org.apache.hadoop.hdfs.TestDFSMkdirs |
|   | org.apache.hadoop.hdfs.TestDFSInputStream |
|   | org.apache.hadoop.hdfs.qjournal.TestNNWithQJM |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations |
|   | org.apache.hadoop.hdfs.server.datanode.TestDiskError |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration |
|   | org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold |
|   | org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache |
|   | org.apache.hadoop.hdfs.server.datanode.TestIncrementalBrVariations |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeMetricsLogger |
|   | org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithHdfs |
|   | org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner |
|   | org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCacheRevocation |
|   | org.apache.hadoop.hdfs.server.datanode.TestBlockScanner |
|   | org.apache.hadoop.fs.permission.TestStickyBit |
|   | org.apache.hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics |
|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |
|   | org.apache.hadoop.cli.TestHDFSCLI |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:a716388 |
| JIRA Issue | HADOOP-15711 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12940623/HADOOP-15711.001.branch-2.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  xml  |
| uname | Linux f21eefb9d4e4 4.4.0-134-generic #160~14.04.1-Ubuntu SMP Fri Aug 17 11:07:07 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | branch-2 / eb8b1ea |
| maven | version: Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-10T16:41:47+00:00) |
| Default Java | 1.7.0_181 |
| Unreaped Processes Log | https://builds.apache.org/job/PreCommit-HADOOP-Build/15650/artifact/out/patch-unit-root-reaper.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/15650/artifact/out/patch-unit-root.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/15650/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/15650/artifact/out/patch-asflicense-problems.txt |
| Max. process+thread count | 9931 (vs. ulimit of 10000) |
| modules | C: hadoop-project hadoop-tools/hadoop-aws hadoop-tools/hadoop-azure . U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15650/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



{code}
YETUS_ARGS+=("--proclimit=7000")
{code}

... is causing other jobs to fail, including mine:  https://builds.apache.org/job/yetus-github-multibranch/job/PR-26/10/artifact/out/coprocessors.txt

Please lower it back down. 

Thanks.

Sure [~aw], set it back to 5000

In the qbt runs there's fatal errors in the logs such as
{noformat}
#
# A fatal error has been detected by the Java Runtime Environment:
#
#  Internal Error (safepoint.cpp:325), pid=30102, tid=140265819887360
#  guarantee(PageArmed == 0) failed: invariant
#
# JRE version: OpenJDK Runtime Environment (7.0_181-b01) (build 1.7.0_181-b01)
# Java VM: OpenJDK 64-Bit Server VM (24.181-b01 mixed mode linux-amd64 compressed oops)
# Derivative: IcedTea 2.6.14
# Distribution: Ubuntu 14.04 LTS, package 7u181-2.6.14-0ubuntu0.3
# Core dump written. Default location: /testptch/hadoop/hadoop-hdfs-project/hadoop-hdfs/core or core.30102
#
# If you would like to submit a bug report, please include
# instructions on how to reproduce the bug and visit:
#   http://icedtea.classpath.org/bugzilla
#

---------------  T H R E A D  ---------------

Current thread (0x00007f923c31d800):  VMThread [stack: 0x00007f922e4e5000,0x00007f922e5e6000] [id=30122]


Stack: [0x00007f922e4e5000,0x00007f922e5e6000],  sp=0x00007f922e5e4b10,  free space=1022k
Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)
V  [libjvm.so+0x966c25]
V  [libjvm.so+0x49b96e]
V  [libjvm.so+0x872b51]
V  [libjvm.so+0x96b69a]
V  [libjvm.so+0x96baf2]
V  [libjvm.so+0x7da992]

VM_Operation (0x00007f9210b2b920): RevokeBias, mode: safepoint, requested by thread 0x00007f923dd0f800

{noformat}
Suspected it might be related to [https://bugs.openjdk.java.net/browse/JDK-6869327,] so I tried adding {{-XX:+UseCountedLoopSafepoints}} to one of the runs but it didn't seem to do anything

Then tried porting HADOOP-14816 (and HADOOP-15610) to a test branch forked off branch-2, getting similar results as reported in HDFS-12711, here's a test run : [https://builds.apache.org/view/H-L/view/Hadoop/job/hadoop-qbt-branch2-java7-linux-x86-jhung/39/] (run with openjdk8) - so at least it appears the unit tests are running to completion with openjdk8.

My proposal is to port  HADOOP-14816 and -HADOOP-15610- to branch-2 to use openjdk8 in branch-2 instead of openjdk7. Any objections?

Granted, I haven't used Hadoop in months and months, but ...

That's probably a discussion for common.  It's a pseudo-incompatible change.  It carries quite a few risks.  branch-2 is supposed to be JDK7 compatible and it might be possible for JDK8 code to slip in.  Committing those changes will also make the binary releases built on JDK8 and require newer versions of Linux shared libraries.  On the flip side, Trusty goes EOL in a few months and there should be some work on moving to something newer on the OS side anyway.

Frankly, it might be an easier discussion to finally just EOL all of branch-2, given some of the other problems.   [~ajisakaa] can shed more light on those issues.  

Given Trusty goes EOL in a few months, I filed HADOOP-16053 to backport HADOOP-14816 to branch-2 and attached a patch. In this patch, the java version is still 7. Regarding the java version, I'm thinking it's okay to built binary release using Java 8 because Java 7 is already EOL.

Anyway, I'm thinking we must discuss both OS version and Java version in common-dev ML.

bq. Frankly, it might be an easier discussion to finally just EOL all of branch-2, given some of the other problems. Akira Ajisaka can shed more light on those issues.
There is another problem (HADOOP-16055), so I suggested branch-2.7 EoL in common-dev ML. https://lists.apache.org/thread.html/d1f98c2c386f2f4b980489b543db3d0bb7bdb94ea12f8fc5a90f527b@%3Ccommon-dev.hadoop.apache.org%3E

Thanks Allen and Akira for the thoughts. I agree with the risks. Just started a discuss thread on [common|yarn|hdfs]-dev for this.

I don't think we should drastically change the dependency for branch-2 from Java 7 to Java 8.
We only want to fix the precommit test builds on Jenkins to use openJDK-8. When we release branch-2 we should still use Java 7 to generate binaries, and compatibility with Java 7 should not be affected.

EOL for branch-2 will just mean that everybody will switch to their local branches, as all major clusters still run on Hadoop 2. This will be self-destructive for everybody: the community, vendors, all consumers of Hadoop. I suggest we just focus on fixing the builds here as the jira states.

Attached 002 patch:
 * Install openjdk8 in Dockerfile
 * Set default to openjdk7
 * add -Dhttps.protocols=TLSv1.2 to MAVEN_OPTS (hit an issue similar to HBASE-21074):
{noformat}
ERROR] [ERROR] Some problems were encountered while processing the POMs:
[ERROR] Unresolveable build extension: Plugin org.apache.felix:maven-bundle-plugin:2.5.0 or one of its dependencies could not be resolved: Failed to read artifact descriptor for org.apache.felix:maven-bundle-plugin:jar:2.5.0 @
@
[ERROR] The build could not read 1 project -> [Help 1]
[ERROR]   
[ERROR]   The project org.apache.hadoop:hadoop-main:2.10.0-SNAPSHOT (/build/source/pom.xml) has 1 error
[ERROR]     Unresolveable build extension: Plugin org.apache.felix:maven-bundle-plugin:2.5.0 or one of its dependencies could not be resolved: Failed to read artifact descriptor for org.apache.felix:maven-bundle-plugin:jar:2.5.0: Could not transfer artifact org.apache.felix:maven-bundle-plugin:pom:2.5.0 from/to central (https://repo.maven.apache.org/maven2): Received fatal alert: protocol_version -> [Help 2]{noformat}
Also set these configs in the [precommit-HADOOP|https://builds.apache.org/view/H-L/view/Hadoop/job/PreCommit-HADOOP-Build/] jenkins job: 
 * 
{noformat}
YETUS_ARGS+=("--java-home=/usr/lib/jvm/java-8-openjdk-amd64")
YETUS_ARGS+=("--multijdkdirs=/usr/lib/jvm/java-7-openjdk-amd64")
YETUS_ARGS+=("--multijdktests=compile"){noformat}
Assuming all goes well, I will set these configs in [precommit-HDFS|https://builds.apache.org/view/H-L/view/Hadoop/job/PreCommit-HDFS-Build/], [precommit-YARN|https://builds.apache.org/view/H-L/view/Hadoop/job/PreCommit-YARN-Build/], [precommit-MAPREDUCE|https://builds.apache.org/view/H-L/view/Hadoop/job/PreCommit-MAPREDUCE-Build/], and the nightly [branch-2 build|https://builds.apache.org/view/H-L/view/Hadoop/job/hadoop-qbt-branch2-java7-linux-x86] (and re-enable the latter).

(!) A patch to the testing environment has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/15899/console in case of problems.


| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 22s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
|| || || || {color:brown} branch-2 Compile Tests {color} ||
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} hadolint {color} | {color:green}  0m  2s{color} | {color:green} There were no new hadolint issues. {color} |
| {color:green}+1{color} | {color:green} shellcheck {color} | {color:green}  0m  0s{color} | {color:green} There were no new shellcheck issues. {color} |
| {color:green}+1{color} | {color:green} shelldocs {color} | {color:green}  0m  9s{color} | {color:green} There were no new shelldocs issues. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 32s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}  1m 39s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:651d050 |
| JIRA Issue | HADOOP-15711 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12958002/HADOOP-15711-branch-2.002.patch |
| Optional Tests |  dupname  asflicense  hadolint  shellcheck  shelldocs  |
| uname | Linux e2dd04a7a7ba 4.4.0-139-generic #165~14.04.1-Ubuntu SMP Wed Oct 31 10:55:11 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | branch-2 / 2a7dcc5 |
| maven | version: Apache Maven 3.3.9 |
| shellcheck | v0.4.6 |
| Max. process+thread count | 43 (vs. ulimit of 10000) |
| modules | C: . U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15899/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



(!) A patch to the testing environment has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/15900/console in case of problems.


| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 10m  9s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
|| || || || {color:brown} branch-2 Compile Tests {color} ||
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} hadolint {color} | {color:green}  0m  2s{color} | {color:green} There were no new hadolint issues. {color} |
| {color:green}+1{color} | {color:green} shellcheck {color} | {color:green}  0m  0s{color} | {color:green} There were no new shellcheck issues. {color} |
| {color:green}+1{color} | {color:green} shelldocs {color} | {color:green}  0m 10s{color} | {color:green} There were no new shelldocs issues. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 11m 17s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:651d050 |
| JIRA Issue | HADOOP-15711 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12958002/HADOOP-15711-branch-2.002.patch |
| Optional Tests |  dupname  asflicense  hadolint  shellcheck  shelldocs  |
| uname | Linux 991c0fae0694 4.4.0-138-generic #164-Ubuntu SMP Tue Oct 2 17:16:02 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | branch-2 / 2a7dcc5 |
| maven | version: Apache Maven 3.3.9 |
| shellcheck | v0.4.6 |
| Max. process+thread count | 48 (vs. ulimit of 10000) |
| modules | C: . U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15900/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.



+1 from me (non-binding).

Given the discussion in the vote [thread|https://lists.apache.org/thread.html/734c73111c17663675a76f0355f4f4bce630ef3b9084d588e04006d2@%3Cyarn-dev.hadoop.apache.org%3E]
+1, Thanks [~jhung]

Thanks Anthony/Arun, will make the changes EOD unless there's any objections.

Committed to branch-2.

I'd like to backport this change to branch-2.9 and branch-2.8 to run precommit job with Java 8. Any thoughts?

Cherry-picked this to branch-2.9 and branch-2.8.

