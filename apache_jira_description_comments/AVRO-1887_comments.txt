So i wrote the plugin for the yetus usage.
{code}
[root@sacharya-docker avro]# test-patch.sh --plugins=all --user-plugins=/root/avro/pre_commit/  --list-plugins
Reminder: every plug-in may be enabled via 'all'.
 
BUILDTOOLS:
    ant autoconf cmake gradle make maven nobuild build
TESTTYPES:
    asflicense author cc checkstyle findbugs javac javadoc mvnsite mvneclipse perlcritic pylint rubocop ruby_lint scalac scaladoc shellcheck shelldocs test4tests unitveto whitespace xml buildtest
BUGSYSTEMS:
    brieftext bugzilla github htmlout jira
TESTFORMATS:
    ctest junit tap
{code}
The build tool is build and the build test tool is buildtest.
I tried with a couple different patches and found the results to be pretty consistent.
{code}
| Vote |      Subsystem |  Runtime   | Comment
============================================================================
|   0  |        pylint  |   0m  4s   | Pylint was not available.
|  +1  |       @author  |   0m  0s   | The patch does not contain any @author
|      |                |            | tags.
|  +1  |     buildtest  |   0m  0s   | master passed
|  -1  |    whitespace  |   0m  0s   | The patch has 3 line(s) that end in
|      |                |            | whitespace. Use git apply
|      |                |            | --whitespace=fix <<patch_file>>. Refer
|      |                |            | https://git-scm.com/docs/git-apply
|  +1  |     buildtest  |   0m 18s   | the patch passed
|      |                |   0m 24s   |
{code}

The usage is something like :
{code}
test-patch.sh --plugins=all --user-plugins=/root/avro/pre_commit/    --build-tool=build   <PATCH FILE>   --robot
{code}

Currently I havent givent any JIRA credentials but the same can be passed to the builds.apache machine.


Initial patch.

Updated some incorrect comment.

Also tagging [~aw] to do some code review since he helped with some yetus implementation.

looks good. I'll play with this a bit before committing.

One small change, could you locate this in {{share/pre_commit}} instead of the top-level {{pre_commit}}?

That will put it near the other help-run-the-project stuff we have for e.g. Docker and git.

Have you gotten to try out using our Dockerfile to ensure the yetus run has all of our needed dependencies?

I tried it with docker.
However, there is a bug in yetus.
YETUS-470 is a requirement for using yetus with Docker.

Now that Yetus 0.4.0 is out, can we move forward with this?

Created a pull request here : https://github.com/apache/avro/pull/196
I have added some comments in the pull request.
Please test it and let me know your comments.

Fokko opened a new pull request #344: [AVRO-1887][WIP] Setup precommit hooks using Apache Yetus
URL: https://github.com/apache/avro/pull/344
 
 
   Based on the earlier work of @spacharya 
   
   The current configuration does not kick off the tests:
   ```
   | Vote |      Subsystem |  Runtime   | Comment
   ============================================================================
   |   0  |        reexec  |   0m  9s   | Docker mode activated. 
   |      |                |            | Prechecks 
   |   0  |     shelldocs  |   0m 25s   | Shelldocs was not available. 
   |      |                |            | Compile Tests 
   |  -1  |       @author  |   0m 46s   | The source tree appears to contain 4 
   |      |                |            | @author tags which the community has
   |      |                |            | agreed to not allow in code
   |      |                |            | contributions.
   |  -1  |      hadolint  |   0m  1s   | The source tree has 4 issues. 
   |  -1  |    perlcritic  |   0m 13s   | The source tree has 456 issues. 
   |  -1  |        pylint  |   2m 14s   | The source tree has 7623 issues. 
   |  -1  |       rubocop  |   0m 28s   | The source tree has 1053 issues. 
   |  -1  |     ruby-lint  |   0m 15s   | The source tree has 885 issues. 
   |  -1  |    shellcheck  |   0m  3s   | The source tree has 126 issues. 
   |  -1  |    whitespace  |   0m  3s   | The source tree has 1229 line(s) that 
   |      |                |            | end in whitespace.
   |  -1  |    whitespace  |   0m 14s   | The source tree 22503 line(s) with tabs. 
   |  -1  |           xml  |   1m 40s   | The source tree has 9 ill-formed XML 
   |      |                |            | file(s).
   |  +1  |     buildtest  |   0m  0s   | the source passed 
   |      |                |            | Other Tests 
   |      |                |   9m 22s   | 
   ```
   The buildstep `buildtest` takes `0m 0s`.

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


Fokko commented on issue #344: [AVRO-1887][WIP] Setup precommit hooks using Apache Yetus
URL: https://github.com/apache/avro/pull/344#issuecomment-429012884
 
 
   @busbey I've got a first version of the Apache Yetus script working. It took me a while since it is new to me, so be gentle on the review ;)
   I've written a small plugin that will locate all the `build.sh` scripts, and subsequently invoke the `test` step. I know this is still a bit crude, but this allows us to reuse the existing build scripts.
   
   Please note that the tests are still failing, but I'm working on patches in a new PR.
   
   ```
    _____     _ _                _ 
   |  ___|_ _(_) |_   _ _ __ ___| |
   | |_ / _` | | | | | | '__/ _ \ |
   |  _| (_| | | | |_| | | |  __/_|
   |_|  \__,_|_|_|\__,_|_|  \___(_)
                                   
   
   
   | Vote |     Subsystem |  Runtime   | Comment
   ============================================================================
   |   0  |       reexec  |   0m  9s   | Docker mode activated. 
   |      |               |            | Prechecks 
   |      |               |            | Compile Tests 
   |  -1  |    buildtest  |  14m 46s   | The testsuite failed, please check the 
   |      |               |            | output
   |      |               |            | Other Tests 
   |      |               |  14m 55s   | 
   ```
   
   

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


Fokko opened a new pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353
 
 
   All,
   
   First PR that will kick off the tests using Apache Yetus. It is a crude implementation since it will only kick off the `./build.sh`, but this will be refined later on. 
   
   The C++ and the interop tests are failing and are therefore disabled for now. 
   
   cc @kojiromike
   
   Cheers, Fokko

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


cutting commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228252518
 
 

 ##########
 File path: build.sh
 ##########
 @@ -54,25 +56,26 @@ do
 
       # create interop test data
       mkdir -p build/interop/data
-      (cd lang/java/avro; mvn -P interop-data-generate generate-resources)
+      (cd lang/java/avro; mvn -B -P interop-data-generate generate-resources)
       (cd lang/py; ant interop-data-generate)
       (cd lang/c; ./build.sh interop-data-generate)
       #(cd lang/c++; make interop-data-generate)
       (cd lang/ruby; rake generate_interop)
       (cd lang/php; ./build.sh interop-data-generate)
 
       # run interop data tests
-      (cd lang/java; mvn test -P interop-data-test)
+      (cd lang/java; mvn -B test -P interop-data-test)
       (cd lang/py; ant interop-data-test)
       (cd lang/c; ./build.sh interop-data-test)
       #(cd lang/c++; make interop-data-test)
       (cd lang/ruby; rake interop)
       (cd lang/php; ./build.sh test-interop)
 
       # java needs to package the jars for the interop rpc tests
-      (cd lang/java; mvn package -DskipTests)
+      (cd lang/java; mvn -B package -DskipTests)
       # run interop rpc test
-      /bin/bash share/test/interop/bin/test_rpc_interop.sh
+      # This is not working for now
+      # /bin/bash share/test/interop/bin/test_rpc_interop.sh
 
 Review comment:
   Are all interop tests failing, or only a few?  If only a few, I'd rather disable just those.

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


cutting commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228251149
 
 

 ##########
 File path: build.sh
 ##########
 @@ -41,11 +41,13 @@ do
       # run lang-specific tests
       (cd lang/java; ./build.sh test)
       # install java artifacts required by other builds and interop tests
-      mvn install -DskipTests
+      mvn -B install -DskipTests
       (cd lang/py; ./build.sh test)
       (cd lang/py3; ./build.sh test)
       (cd lang/c; ./build.sh test)
-      (cd lang/c++; ./build.sh test)
+      # The C++ tests are failing
+      # https://issues.apache.org/jira/projects/AVRO/issues/AVRO-2230
 
 Review comment:
   AVRO-2230 is now marked as fixed in Jira.

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


cutting commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228252951
 
 

 ##########
 File path: lang/java/ipc/src/test/java/org/apache/avro/DataFileInteropTest.java
 ##########
 @@ -40,27 +40,27 @@ public static void printDir() {
         + DATAFILE_DIR.getAbsolutePath());
   }
 
-  @Test
-  public void testGeneratedGeneric() throws IOException {
-    System.out.println("Reading with generic:");
-    DatumReaderProvider<Object> provider = new DatumReaderProvider<Object>() {
-      @Override public DatumReader<Object> get() {
-        return new GenericDatumReader<>();
-        }
-      };
-    readFiles(provider);
-  }
-
-  @Test
-  public void testGeneratedSpecific() throws IOException {
-    System.out.println("Reading with specific:");
-    DatumReaderProvider<Interop> provider = new DatumReaderProvider<Interop>() {
-      @Override public DatumReader<Interop> get() {
-        return new SpecificDatumReader<>();
-        }
-      };
-    readFiles(provider);
-  }
+  // @Test
 
 Review comment:
   Why are these commented out?  Are they failing?  If they're no longer required then we should just delete them.

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


cutting commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228253247
 
 

 ##########
 File path: lang/java/tools/src/test/compiler/output-string/avro/examples/baseball/Player.java
 ##########
 @@ -541,13 +541,3 @@ public Player build() {
     }
   }
 }
-
 
 Review comment:
   Not sure it's worth cleaning up auto-generated files...

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


Fokko commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228501492
 
 

 ##########
 File path: build.sh
 ##########
 @@ -41,11 +41,13 @@ do
       # run lang-specific tests
       (cd lang/java; ./build.sh test)
       # install java artifacts required by other builds and interop tests
-      mvn install -DskipTests
+      mvn -B install -DskipTests
       (cd lang/py; ./build.sh test)
       (cd lang/py3; ./build.sh test)
       (cd lang/c; ./build.sh test)
-      (cd lang/c++; ./build.sh test)
+      # The C++ tests are failing
+      # https://issues.apache.org/jira/projects/AVRO/issues/AVRO-2230
 
 Review comment:
   Still failing :'(
   ```
   Scanning dependencies of target avrocpp_s
   [  1%] Building CXX object CMakeFiles/avrocpp_s.dir/impl/Compiler.cc.o
   /testptch/unknown/lang/c++/impl/Compiler.cc:174:15: warning: â€˜std::string avro::nameof(const NodePtr&)â€™ defined but not used [-Wunused-function]
    static string nameof(const NodePtr& n)
                  ^
   [  2%] Building CXX object CMakeFiles/avrocpp_s.dir/impl/Node.cc.o
   [  4%] Building CXX object CMakeFiles/avrocpp_s.dir/impl/NodeImpl.cc.o
   /testptch/unknown/lang/c++/impl/NodeImpl.cc: In function â€˜std::string avro::{anonymous}::escape(const string&)â€™:
   /testptch/unknown/lang/c++/impl/NodeImpl.cc:31:8: warning: â€˜autoâ€™ changes meaning in C++11; please remove it [-Wc++0x-compat]
      for (auto c : unescaped) {
           ^
   /testptch/unknown/lang/c++/impl/NodeImpl.cc:31:13: error: â€˜câ€™ does not name a type
      for (auto c : unescaped) {
                ^
   /testptch/unknown/lang/c++/impl/NodeImpl.cc:67:3: error: expected â€˜;â€™ before â€˜returnâ€™
      return s;
      ^
   /testptch/unknown/lang/c++/impl/NodeImpl.cc:67:3: error: expected primary-expression before â€˜returnâ€™
   /testptch/unknown/lang/c++/impl/NodeImpl.cc:67:3: error: expected â€˜;â€™ before â€˜returnâ€™
   /testptch/unknown/lang/c++/impl/NodeImpl.cc:67:3: error: expected primary-expression before â€˜returnâ€™
   /testptch/unknown/lang/c++/impl/NodeImpl.cc:67:3: error: expected â€˜)â€™ before â€˜returnâ€™
   In file included from /usr/include/boost/assert.hpp:51:0,
                    from /usr/include/boost/format/parsing.hpp:21,
                    from /usr/include/boost/format.hpp:50,
                    from /testptch/unknown/lang/c++/api/Exception.hh:24,
                    from /testptch/unknown/lang/c++/api/Node.hh:28,
                    from /testptch/unknown/lang/c++/api/GenericDatum.hh:29,
                    from /testptch/unknown/lang/c++/api/NodeImpl.hh:23,
                    from /testptch/unknown/lang/c++/impl/NodeImpl.cc:21:
   /testptch/unknown/lang/c++/impl/NodeImpl.cc: In member function â€˜virtual void avro::NodeRecord::printJson(std::ostream&, int) constâ€™:
   /testptch/unknown/lang/c++/impl/NodeImpl.cc:247:59: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
        assert(defaultValues.empty() || (defaultValues.size() == fields));
                                                              ^
   /testptch/unknown/lang/c++/impl/NodeImpl.cc: In member function â€˜virtual void avro::NodePrimitive::printDefaultToJson(const avro::GenericDatum&, std::ostream&, int) constâ€™:
   /testptch/unknown/lang/c++/impl/NodeImpl.cc:292:13: error: â€˜to_stringâ€™ is not a member of â€˜stdâ€™
          os << std::to_string(g.value<float>());
                ^
   /testptch/unknown/lang/c++/impl/NodeImpl.cc:295:13: error: â€˜to_stringâ€™ is not a member of â€˜stdâ€™
          os << std::to_string(g.value<double>());
                ^
   /testptch/unknown/lang/c++/impl/NodeImpl.cc: In function â€˜std::string avro::{anonymous}::escape(const string&)â€™:
   /testptch/unknown/lang/c++/impl/NodeImpl.cc:68:1: warning: control reaches end of non-void function [-Wreturn-type]
    }
    ^
   CMakeFiles/avrocpp_s.dir/build.make:100: recipe for target 'CMakeFiles/avrocpp_s.dir/impl/NodeImpl.cc.o' failed
   make[2]: *** [CMakeFiles/avrocpp_s.dir/impl/NodeImpl.cc.o] Error 1
   make[1]: *** [CMakeFiles/avrocpp_s.dir/all] Error 2
   CMakeFiles/Makefile2:425: recipe for target 'CMakeFiles/avrocpp_s.dir/all' failed
   make: *** [all] Error 2
   Makefile:147: recipe for target 'all' failed
   ```

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


Fokko commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228505487
 
 

 ##########
 File path: build.sh
 ##########
 @@ -41,11 +41,13 @@ do
       # run lang-specific tests
       (cd lang/java; ./build.sh test)
       # install java artifacts required by other builds and interop tests
-      mvn install -DskipTests
+      mvn -B install -DskipTests
       (cd lang/py; ./build.sh test)
       (cd lang/py3; ./build.sh test)
       (cd lang/c; ./build.sh test)
-      (cd lang/c++; ./build.sh test)
+      # The C++ tests are failing
+      # https://issues.apache.org/jira/projects/AVRO/issues/AVRO-2230
 
 Review comment:
   I've created [a new ticket](https://issues.apache.org/jira/browse/AVRO-2249) on Jira, the tests are still failing :(

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


kojiromike commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228771737
 
 

 ##########
 File path: build.sh
 ##########
 @@ -40,39 +40,43 @@ do
     test)
       # run lang-specific tests
       (cd lang/java; ./build.sh test)
+
+      # create interop test data
+      mkdir -p build/interop/data
+      (cd lang/java/avro; mvn -B -P interop-data-generate generate-resources)
 
 Review comment:
   Shouldn't these be written as `cd ... &&` rather than `cd ...;`?

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


kojiromike commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228771744
 
 

 ##########
 File path: build.sh
 ##########
 @@ -40,39 +40,43 @@ do
     test)
       # run lang-specific tests
       (cd lang/java; ./build.sh test)
+
+      # create interop test data
+      mkdir -p build/interop/data
+      (cd lang/java/avro; mvn -B -P interop-data-generate generate-resources)
+      
       # install java artifacts required by other builds and interop tests
-      mvn install -DskipTests
+      mvn -B install -DskipTests
       (cd lang/py; ./build.sh test)
       (cd lang/py3; ./build.sh test)
       (cd lang/c; ./build.sh test)
-      (cd lang/c++; ./build.sh test)
+      # https://issues.apache.org/jira/browse/AVRO-2249
+      # (cd lang/c++; ./build.sh test)
 
 Review comment:
   :(

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


kojiromike commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228771815
 
 

 ##########
 File path: share/precommit/buildtest.sh
 ##########
 @@ -0,0 +1,81 @@
+#!/usr/bin/env bash
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRCMAKEIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+add_test_type buildtest
+
+VERBOSE=false
+
+# files that we want to kick off
+BUILD_FILES=( build.sh )
+
+
+function buildtest_usage
+{
+  yetus_add_option "--verbose=<true|false>" "print output to console (default: false)"
+}
 
 Review comment:
   Please consider the more portable function definition form
   
   ```bash
   buildtest_usage() {
   ...
   }
   ```

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


kojiromike commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228772032
 
 

 ##########
 File path: share/precommit/buildtest.sh
 ##########
 @@ -0,0 +1,81 @@
+#!/usr/bin/env bash
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRCMAKEIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+add_test_type buildtest
+
+VERBOSE=false
+
+# files that we want to kick off
+BUILD_FILES=( build.sh )
+
+
+function buildtest_usage
+{
+  yetus_add_option "--verbose=<true|false>" "print output to console (default: false)"
+}
+
+function buildtest_parse_args
+{
+  local i
+
+  for i in "$@"; do
 
 Review comment:
   Is it important to have the form `--verbose=true` instead of just `--verbose`?

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


kojiromike commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228772674
 
 

 ##########
 File path: share/precommit/buildtest.sh
 ##########
 @@ -0,0 +1,81 @@
+#!/usr/bin/env bash
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRCMAKEIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+add_test_type buildtest
+
+VERBOSE=false
+
+# files that we want to kick off
+BUILD_FILES=( build.sh )
+
+
+function buildtest_usage
+{
+  yetus_add_option "--verbose=<true|false>" "print output to console (default: false)"
+}
+
+function buildtest_parse_args
+{
+  local i
+
+  for i in "$@"; do
+    case ${i} in
+    --verbose=*)
+      VERBOSE=${i#*=}
+    ;;
+    esac
+  done
+}
+
+# For now we only kick off the root build.sh
+# function buildtest_filefilter
+# {
+#   local filename=$1
+#
+#   if [[ ${filename} =~ build\.sh$ ]]; then
+#     yetus_debug "Buildtest: run the tests for ${filename}"
+#     add_test buildtest
+#     yetus_add_array_element BUILD_FILES "${filename}"
+#   fi
+# }
+
+function buildtest_postcompile
+{
+  for file in "${BUILD_FILES[@]}"; do
+
+    big_console_header "Running ${file}"
+
+    #shellcheck disable=SC2001
+    sanitized_filename=$(echo "${file}" | sed -e 's,[/\.],-,g')
 
 Review comment:
   ```bash
   $ file=$file f=${file//[.\\\/]/-}
   + file='this.is\a/file.with\many/strange\characters/in.it'
   + f=this-is-a-file-with-many-strange-characters-in-it
   ```

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


kojiromike commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228772740
 
 

 ##########
 File path: share/precommit/buildtest.sh
 ##########
 @@ -0,0 +1,81 @@
+#!/usr/bin/env bash
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRCMAKEIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+add_test_type buildtest
+
+VERBOSE=false
+
+# files that we want to kick off
+BUILD_FILES=( build.sh )
+
+
+function buildtest_usage
+{
+  yetus_add_option "--verbose=<true|false>" "print output to console (default: false)"
+}
+
+function buildtest_parse_args
+{
+  local i
+
+  for i in "$@"; do
+    case ${i} in
+    --verbose=*)
+      VERBOSE=${i#*=}
+    ;;
+    esac
+  done
+}
+
+# For now we only kick off the root build.sh
+# function buildtest_filefilter
+# {
+#   local filename=$1
+#
+#   if [[ ${filename} =~ build\.sh$ ]]; then
+#     yetus_debug "Buildtest: run the tests for ${filename}"
+#     add_test buildtest
+#     yetus_add_array_element BUILD_FILES "${filename}"
+#   fi
+# }
+
+function buildtest_postcompile
+{
+  for file in "${BUILD_FILES[@]}"; do
+
+    big_console_header "Running ${file}"
+
+    #shellcheck disable=SC2001
+    sanitized_filename=$(echo "${file}" | sed -e 's,[/\.],-,g')
+
+    if [ "$VERBOSE" == "true" ]; then
+      # Write both to stdout and the file using tee
+      eval "cd ${BASEDIR}; ./${file} test" | tee -a "${PATCH_DIR}/build-${sanitized_filename}.txt"
 
 Review comment:
   Why `eval` and not a subshell?

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


kojiromike commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228772765
 
 

 ##########
 File path: share/precommit/buildtest.sh
 ##########
 @@ -0,0 +1,81 @@
+#!/usr/bin/env bash
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRCMAKEIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+add_test_type buildtest
+
+VERBOSE=false
+
+# files that we want to kick off
+BUILD_FILES=( build.sh )
+
+
+function buildtest_usage
+{
+  yetus_add_option "--verbose=<true|false>" "print output to console (default: false)"
+}
+
+function buildtest_parse_args
+{
+  local i
+
+  for i in "$@"; do
+    case ${i} in
+    --verbose=*)
+      VERBOSE=${i#*=}
+    ;;
+    esac
+  done
+}
+
+# For now we only kick off the root build.sh
+# function buildtest_filefilter
+# {
+#   local filename=$1
+#
+#   if [[ ${filename} =~ build\.sh$ ]]; then
+#     yetus_debug "Buildtest: run the tests for ${filename}"
+#     add_test buildtest
+#     yetus_add_array_element BUILD_FILES "${filename}"
+#   fi
+# }
+
+function buildtest_postcompile
+{
+  for file in "${BUILD_FILES[@]}"; do
+
+    big_console_header "Running ${file}"
+
+    #shellcheck disable=SC2001
+    sanitized_filename=$(echo "${file}" | sed -e 's,[/\.],-,g')
+
+    if [ "$VERBOSE" == "true" ]; then
 
 Review comment:
   ```bash
   if [[ $VERBOSE = true ]]; then
   ```
   
   but it would be better, in my opinion, to consider VERBOSE as true if it's set at all.

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


kojiromike commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228772794
 
 

 ##########
 File path: share/precommit/buildtest.sh
 ##########
 @@ -0,0 +1,81 @@
+#!/usr/bin/env bash
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRCMAKEIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+add_test_type buildtest
+
+VERBOSE=false
+
+# files that we want to kick off
+BUILD_FILES=( build.sh )
+
+
+function buildtest_usage
+{
+  yetus_add_option "--verbose=<true|false>" "print output to console (default: false)"
+}
+
+function buildtest_parse_args
+{
+  local i
+
+  for i in "$@"; do
+    case ${i} in
+    --verbose=*)
+      VERBOSE=${i#*=}
+    ;;
+    esac
+  done
+}
+
+# For now we only kick off the root build.sh
+# function buildtest_filefilter
+# {
+#   local filename=$1
+#
+#   if [[ ${filename} =~ build\.sh$ ]]; then
+#     yetus_debug "Buildtest: run the tests for ${filename}"
+#     add_test buildtest
+#     yetus_add_array_element BUILD_FILES "${filename}"
+#   fi
+# }
+
+function buildtest_postcompile
+{
+  for file in "${BUILD_FILES[@]}"; do
+
+    big_console_header "Running ${file}"
+
+    #shellcheck disable=SC2001
+    sanitized_filename=$(echo "${file}" | sed -e 's,[/\.],-,g')
+
+    if [ "$VERBOSE" == "true" ]; then
+      # Write both to stdout and the file using tee
+      eval "cd ${BASEDIR}; ./${file} test" | tee -a "${PATCH_DIR}/build-${sanitized_filename}.txt"
+      result=${PIPESTATUS[0]}
+    else
+      eval "cd ${BASEDIR}; ./${file} test" >> "${PATCH_DIR}/build-${sanitized_filename}.txt"
+      result=$?
+    fi
+
+    if [[ ${result} -ne 0 ]]; then
 
 Review comment:
   Consider arithmetic expression here:
   
   ```bash
   if (( result != 0 )); then
   ```

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


kojiromike commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228772835
 
 

 ##########
 File path: share/test/interop/bin/test_rpc_interop.sh
 ##########
 @@ -21,29 +21,33 @@ cd `dirname "$0"`/../../../..   # connect to root
 
 VERSION=`cat share/VERSION.txt`
 
 Review comment:
   ```bash
   VERSION=$(<share/VERSION.txt)
   ```
   
   would be a little nicer here. (Obviously take it or leave it since this isn't actually part of this PR.)

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


kojiromike commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228773024
 
 

 ##########
 File path: share/test/interop/bin/test_rpc_interop.sh
 ##########
 @@ -21,29 +21,33 @@ cd `dirname "$0"`/../../../..   # connect to root
 
 VERSION=`cat share/VERSION.txt`
 
-#set -x                          # echo commands
+set -x                          # echo commands
 
 java_client="java -jar lang/java/tools/target/avro-tools-$VERSION.jar rpcsend"
 java_server="java -jar lang/java/tools/target/avro-tools-$VERSION.jar rpcreceive"
 
 py_client="python lang/py/build/src/avro/tool.py rpcsend"
 py_server="python lang/py/build/src/avro/tool.py rpcreceive"
 
-ruby_client="ruby -rubygems -Ilang/ruby/lib lang/ruby/test/tool.rb rpcsend"
-ruby_server="ruby -rubygems -Ilang/ruby/lib lang/ruby/test/tool.rb rpcreceive"
+#ruby_client="ruby -rubygems -Ilang/ruby/lib lang/ruby/test/tool.rb rpcsend"
+#ruby_server="ruby -rubygems -Ilang/ruby/lib lang/ruby/test/tool.rb rpcreceive"
 
 export PYTHONPATH=lang/py/build/src      # path to avro Python module
 
-clients=("$java_client" "$py_client" "$ruby_client")
-servers=("$java_server" "$py_server" "$ruby_server")
+#clients=("$java_client" "$py_client" "$ruby_client")
+#servers=("$java_server" "$py_server" "$ruby_server")
+clients=("$java_client" "$py_client")
+servers=("$java_server" "$py_server")
 
 proto=share/test/schemas/simple.avpr
 
 portfile=/tmp/interop_$$
 
 function cleanup() {
   rm -rf $portfile
 
 Review comment:
   Please quote this expansion. An unquoted expansion after `rm -rf` is dangerous.

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


kojiromike commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228773503
 
 

 ##########
 File path: share/test/interop/bin/test_rpc_interop.sh
 ##########
 @@ -21,29 +21,33 @@ cd `dirname "$0"`/../../../..   # connect to root
 
 VERSION=`cat share/VERSION.txt`
 
-#set -x                          # echo commands
+set -x                          # echo commands
 
 java_client="java -jar lang/java/tools/target/avro-tools-$VERSION.jar rpcsend"
 java_server="java -jar lang/java/tools/target/avro-tools-$VERSION.jar rpcreceive"
 
 py_client="python lang/py/build/src/avro/tool.py rpcsend"
 py_server="python lang/py/build/src/avro/tool.py rpcreceive"
 
-ruby_client="ruby -rubygems -Ilang/ruby/lib lang/ruby/test/tool.rb rpcsend"
-ruby_server="ruby -rubygems -Ilang/ruby/lib lang/ruby/test/tool.rb rpcreceive"
+#ruby_client="ruby -rubygems -Ilang/ruby/lib lang/ruby/test/tool.rb rpcsend"
+#ruby_server="ruby -rubygems -Ilang/ruby/lib lang/ruby/test/tool.rb rpcreceive"
 
 export PYTHONPATH=lang/py/build/src      # path to avro Python module
 
-clients=("$java_client" "$py_client" "$ruby_client")
-servers=("$java_server" "$py_server" "$ruby_server")
+#clients=("$java_client" "$py_client" "$ruby_client")
+#servers=("$java_server" "$py_server" "$ruby_server")
+clients=("$java_client" "$py_client")
+servers=("$java_server" "$py_server")
 
 proto=share/test/schemas/simple.avpr
 
 portfile=/tmp/interop_$$
 
 function cleanup() {
   rm -rf $portfile
-  for job in `jobs -p` ; do kill $job; done
+  for job in `jobs -p` ; do
 
 Review comment:
   You can do `kill $(jobs -p) 2>/dev/null || true` here.

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


Fokko commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228963990
 
 

 ##########
 File path: build.sh
 ##########
 @@ -40,39 +40,43 @@ do
     test)
       # run lang-specific tests
       (cd lang/java; ./build.sh test)
+
+      # create interop test data
+      mkdir -p build/interop/data
+      (cd lang/java/avro; mvn -B -P interop-data-generate generate-resources)
 
 Review comment:
   Good point

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


Fokko commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228964128
 
 

 ##########
 File path: build.sh
 ##########
 @@ -40,39 +40,43 @@ do
     test)
       # run lang-specific tests
       (cd lang/java; ./build.sh test)
+
+      # create interop test data
+      mkdir -p build/interop/data
+      (cd lang/java/avro; mvn -B -P interop-data-generate generate-resources)
+      
       # install java artifacts required by other builds and interop tests
-      mvn install -DskipTests
+      mvn -B install -DskipTests
       (cd lang/py; ./build.sh test)
       (cd lang/py3; ./build.sh test)
       (cd lang/c; ./build.sh test)
-      (cd lang/c++; ./build.sh test)
+      # https://issues.apache.org/jira/browse/AVRO-2249
+      # (cd lang/c++; ./build.sh test)
 
 Review comment:
   These tests should be fixed, but I'm resolving some other stuff with the Java tests first.

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


Fokko commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228964567
 
 

 ##########
 File path: share/precommit/buildtest.sh
 ##########
 @@ -0,0 +1,81 @@
+#!/usr/bin/env bash
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRCMAKEIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+add_test_type buildtest
+
+VERBOSE=false
+
+# files that we want to kick off
+BUILD_FILES=( build.sh )
+
+
+function buildtest_usage
+{
+  yetus_add_option "--verbose=<true|false>" "print output to console (default: false)"
+}
 
 Review comment:
   Thanks

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


Fokko commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228964720
 
 

 ##########
 File path: share/precommit/buildtest.sh
 ##########
 @@ -0,0 +1,81 @@
+#!/usr/bin/env bash
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRCMAKEIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+add_test_type buildtest
+
+VERBOSE=false
+
+# files that we want to kick off
+BUILD_FILES=( build.sh )
+
+
+function buildtest_usage
+{
+  yetus_add_option "--verbose=<true|false>" "print output to console (default: false)"
+}
+
+function buildtest_parse_args
+{
+  local i
+
+  for i in "$@"; do
 
 Review comment:
   Good point

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


Fokko commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228965161
 
 

 ##########
 File path: share/precommit/buildtest.sh
 ##########
 @@ -0,0 +1,81 @@
+#!/usr/bin/env bash
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRCMAKEIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+add_test_type buildtest
+
+VERBOSE=false
+
+# files that we want to kick off
+BUILD_FILES=( build.sh )
+
+
+function buildtest_usage
+{
+  yetus_add_option "--verbose=<true|false>" "print output to console (default: false)"
+}
+
+function buildtest_parse_args
+{
+  local i
+
+  for i in "$@"; do
+    case ${i} in
+    --verbose=*)
+      VERBOSE=${i#*=}
+    ;;
+    esac
+  done
+}
+
+# For now we only kick off the root build.sh
+# function buildtest_filefilter
+# {
+#   local filename=$1
+#
+#   if [[ ${filename} =~ build\.sh$ ]]; then
+#     yetus_debug "Buildtest: run the tests for ${filename}"
+#     add_test buildtest
+#     yetus_add_array_element BUILD_FILES "${filename}"
+#   fi
+# }
+
+function buildtest_postcompile
+{
+  for file in "${BUILD_FILES[@]}"; do
+
+    big_console_header "Running ${file}"
+
+    #shellcheck disable=SC2001
+    sanitized_filename=$(echo "${file}" | sed -e 's,[/\.],-,g')
+
+    if [ "$VERBOSE" == "true" ]; then
+      # Write both to stdout and the file using tee
+      eval "cd ${BASEDIR}; ./${file} test" | tee -a "${PATCH_DIR}/build-${sanitized_filename}.txt"
 
 Review comment:
   Good point

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


Fokko commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r228965441
 
 

 ##########
 File path: share/precommit/buildtest.sh
 ##########
 @@ -0,0 +1,81 @@
+#!/usr/bin/env bash
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRCMAKEIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+add_test_type buildtest
+
+VERBOSE=false
+
+# files that we want to kick off
+BUILD_FILES=( build.sh )
+
+
+function buildtest_usage
+{
+  yetus_add_option "--verbose=<true|false>" "print output to console (default: false)"
+}
+
+function buildtest_parse_args
+{
+  local i
+
+  for i in "$@"; do
+    case ${i} in
+    --verbose=*)
+      VERBOSE=${i#*=}
+    ;;
+    esac
+  done
+}
+
+# For now we only kick off the root build.sh
+# function buildtest_filefilter
+# {
+#   local filename=$1
+#
+#   if [[ ${filename} =~ build\.sh$ ]]; then
+#     yetus_debug "Buildtest: run the tests for ${filename}"
+#     add_test buildtest
+#     yetus_add_array_element BUILD_FILES "${filename}"
+#   fi
+# }
+
+function buildtest_postcompile
+{
+  for file in "${BUILD_FILES[@]}"; do
+
+    big_console_header "Running ${file}"
+
+    #shellcheck disable=SC2001
+    sanitized_filename=$(echo "${file}" | sed -e 's,[/\.],-,g')
+
+    if [ "$VERBOSE" == "true" ]; then
+      # Write both to stdout and the file using tee
+      eval "cd ${BASEDIR}; ./${file} test" | tee -a "${PATCH_DIR}/build-${sanitized_filename}.txt"
+      result=${PIPESTATUS[0]}
+    else
+      eval "cd ${BASEDIR}; ./${file} test" >> "${PATCH_DIR}/build-${sanitized_filename}.txt"
+      result=$?
+    fi
+
+    if [[ ${result} -ne 0 ]]; then
 
 Review comment:
   Thanks

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


Fokko commented on issue #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#issuecomment-433946587
 
 
   Thanks for the review @kojiromike 
   
   Enabling `shellcheck` is easy by adding it in the list of plugins: https://github.com/Fokko/avro/blob/fd-fix-tests/.travis.yml#L34
   
   There is also support for hadolint etc.

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


kojiromike commented on a change in pull request #353: AVRO-1887 Integrate Yetus
URL: https://github.com/apache/avro/pull/353#discussion_r229058535
 
 

 ##########
 File path: build.sh
 ##########
 @@ -40,39 +40,43 @@ do
     test)
       # run lang-specific tests
       (cd lang/java; ./build.sh test)
+
+      # create interop test data
+      mkdir -p build/interop/data
+      (cd lang/java/avro; mvn -B -P interop-data-generate generate-resources)
+      
       # install java artifacts required by other builds and interop tests
-      mvn install -DskipTests
+      mvn -B install -DskipTests
       (cd lang/py; ./build.sh test)
       (cd lang/py3; ./build.sh test)
       (cd lang/c; ./build.sh test)
-      (cd lang/c++; ./build.sh test)
+      # https://issues.apache.org/jira/browse/AVRO-2249
+      # (cd lang/c++; ./build.sh test)
 
 Review comment:
   I've actually been thinking we should have two run modes for this:
   
   1. Exit as soon as something fails
   2. Keep going, and report all failures at the end.

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


Fokko closed pull request #344: AVRO-1887. Setup precommit hooks using Apache Yetus
URL: https://github.com/apache/avro/pull/344
 
 
   

This is a PR merged from a forked repository.
As GitHub hides the original diff on merge, it is displayed below for
the sake of provenance:

As this is a foreign pull request (from a fork), the diff is supplied
below (as it won't show otherwise due to GitHub magic):

diff --git a/build.sh b/build.sh
index 8810d6bfa..2abb45aba 100755
--- a/build.sh
+++ b/build.sh
@@ -38,6 +38,8 @@ do
   case "$target" in
 
     test)
+      java -version
+
       # run lang-specific tests
       (cd lang/java; ./build.sh test)
       # install java artifacts required by other builds and interop tests
diff --git a/pom.xml b/pom.xml
index e3f48442c..d0c9d274b 100644
--- a/pom.xml
+++ b/pom.xml
@@ -281,6 +281,7 @@
                 <exclude>lang/csharp/Avro.sln</exclude> <!-- visual studio -->
                 <!-- build-related files -->
                 <exclude>BUILD.md</exclude>
+                <exclude>share/precommit/README.md</exclude>
                 <exclude>**/VERSION.txt</exclude>
                 <exclude>**/dependency-reduced-pom.xml</exclude>
                 <exclude>lang/perl/.shipit</exclude>
diff --git a/share/precommit/README.md b/share/precommit/README.md
new file mode 100644
index 000000000..0219c172e
--- /dev/null
+++ b/share/precommit/README.md
@@ -0,0 +1,9 @@
+# Apache Yetus integration
+
+The plugin under `buildtest.sh` will provide the plugin to run the base `build.sh test` which will trigger the tests of the main Avro projects, and the sections below `lang/*/build.sh`. To run this, use:
+
+```bash
+test-patch --plugins=buildtest --user-plugins=share/precommit/ --run-tests --empty-patch --docker --dockerFile=share/docker/Dockerfile --dirty-workspace --verbose=true
+```
+
+Note, that this is still a very crude implementation of Apache Yetus, and in the future we would like to refine this to provide plugins for the different languages.
diff --git a/share/precommit/buildtest.sh b/share/precommit/buildtest.sh
new file mode 100644
index 000000000..86a82865d
--- /dev/null
+++ b/share/precommit/buildtest.sh
@@ -0,0 +1,80 @@
+#!/usr/bin/env bash
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRCMAKEIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+add_test_type buildtest
+
+VERBOSE=false
+
+# files that we want to kick off
+BUILD_FILES=()
+
+
+function buildtest_usage
+{
+  yetus_add_option "--verbose=<true|false>" "print output to console (default: false)"
+}
+
+function buildtest_parse_args
+{
+  local i
+
+  for i in "$@"; do
+    case ${i} in
+    --verbose=*)
+      VERBOSE=${i#*=}
+    ;;
+    esac
+  done
+}
+
+function buildtest_filefilter
+{
+  local filename=$1
+
+  if [[ ${filename} =~ build\.sh$ ]]; then
+    yetus_debug "Buildtest: run the tests for ${filename}"
+    add_test buildtest
+    yetus_add_array_element BUILD_FILES "${filename}"
+  fi
+}
+
+function buildtest_postcompile
+{
+  for file in "${BUILD_FILES[@]}}"; do
+
+    big_console_header "Running ${file}"
+
+    #shellcheck disable=SC2001
+    sanitized_filename=$(echo "${file}" | sed -e 's,[/\.],-,g')
+
+    if [ "$VERBOSE" == "true" ]; then
+      # Write both to stdout and the file using tee
+      eval "cd ${BASEDIR}; ./${file} test" | tee -a "${PATCH_DIR}/build-${sanitized_filename}.txt"
+      result=${PIPESTATUS[0]}
+    else
+      eval "cd ${BASEDIR}; ./${file} test" >> "${PATCH_DIR}/build-${sanitized_filename}.txt"
+      result=$?
+    fi
+
+    if [[ ${result} -ne 0 ]]; then
+      add_vote_table -1 buildtest "The testsuite failed, please check the output"
+      add_footer_table buildtest "@@BASE@@/build-${sanitized_filename}.txt"
+      return 1
+    fi
+
+    add_vote_table +1 buildtest "The build has passed"
+  done
+}


 

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


Fokko commented on issue #353: AVRO-1887 Integrate Yetus and fix tests
URL: https://github.com/apache/avro/pull/353#issuecomment-435909844
 
 
   @kojiromike @cutting PTAL.
   
   I know there are a crazy amount of changes. Instead of having fixed paths, I updated all the tests to use TemporaryDirectories using junit. Also, I've rewritten a lot of the file operations using `try-with-resource`. A lot of the streams weren't closed at all.

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


Fokko commented on issue #353: AVRO-1887 Integrate Yetus and fix tests
URL: https://github.com/apache/avro/pull/353#issuecomment-435911385
 
 
   @kojiromike My suggestion would be to merge this first, and then you can freely rework the shell scripts. You're much better at it than me :-)

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


Fokko closed pull request #353: AVRO-1887 Integrate Yetus and fix tests
URL: https://github.com/apache/avro/pull/353
 
 
   

This is a PR merged from a forked repository.
As GitHub hides the original diff on merge, it is displayed below for
the sake of provenance:

As this is a foreign pull request (from a fork), the diff is supplied
below (as it won't show otherwise due to GitHub magic):

diff --git a/.gitignore b/.gitignore
index a9fa766f9..83e7336c3 100644
--- a/.gitignore
+++ b/.gitignore
@@ -15,4 +15,4 @@ test-output
 /dist
 /lang/java/compiler/nbactions.xml
 /lang/java/compiler/nb-configuration.xml
-/lang/java/compiler/nbproject/
\ No newline at end of file
+/lang/java/compiler/nbproject/
diff --git a/.travis.yml b/.travis.yml
new file mode 100644
index 000000000..defdcfb78
--- /dev/null
+++ b/.travis.yml
@@ -0,0 +1,34 @@
+#
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#   http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing,
+# software distributed under the License is distributed on an
+# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+# KIND, either express or implied.  See the License for the
+# specific language governing permissions and limitations
+# under the License.
+#
+
+sudo: required
+
+services:
+  - docker
+
+language: generic
+
+before_install:
+  - sudo apt-get -q update
+  - sudo apt-get -q install --no-install-recommends -y curl git gnupg-agent locales pinentry-curses pkg-config rsync software-properties-common
+  - sudo apt-get -q clean
+  - sudo rm -rf /var/lib/apt/lists/*
+  - curl -L https://www-us.apache.org/dist/yetus/0.8.0/yetus-0.8.0-bin.tar.gz | tar xvz -C /tmp/
+
+script: /tmp/yetus-0.8.0/bin/test-patch --plugins=buildtest --user-plugins=share/precommit/ --run-tests --empty-patch --docker --dockerfile=share/docker/Dockerfile --dirty-workspace --verbose=true
diff --git a/README.txt b/README.md
similarity index 65%
rename from README.txt
rename to README.md
index 566f192c6..a8878a157 100644
--- a/README.txt
+++ b/README.md
@@ -1,3 +1,7 @@
+[![Build Status](https://travis-ci.org/apache/avro.svg?branch=master)](https://travis-ci.org/apache/avro)
+
+# Apache Avro™
+
 Apache Avro™ is a data serialization system.
 
 Learn more about Avro, please visit our website at:
diff --git a/build.sh b/build.sh
index 8810d6bfa..9ce4ae683 100755
--- a/build.sh
+++ b/build.sh
@@ -40,21 +40,23 @@ do
     test)
       # run lang-specific tests
       (cd lang/java; ./build.sh test)
+
+      # create interop test data
+      mkdir -p build/interop/data
+      (cd lang/java/avro; mvn -B -P interop-data-generate generate-resources)
+
       # install java artifacts required by other builds and interop tests
-      mvn install -DskipTests
+      mvn -B install -DskipTests
       (cd lang/py; ./build.sh test)
       (cd lang/py3; ./build.sh test)
       (cd lang/c; ./build.sh test)
-      (cd lang/c++; ./build.sh test)
+      #(cd lang/c++; ./build.sh test)
       (cd lang/csharp; ./build.sh test)
       (cd lang/js; ./build.sh test)
       (cd lang/ruby; ./build.sh test)
       (cd lang/php; ./build.sh test)
       (cd lang/perl; ./build.sh test)
 
-      # create interop test data
-      mkdir -p build/interop/data
-      (cd lang/java/avro; mvn -P interop-data-generate generate-resources)
       (cd lang/py; ant interop-data-generate)
       (cd lang/c; ./build.sh interop-data-generate)
       #(cd lang/c++; make interop-data-generate)
@@ -62,7 +64,7 @@ do
       (cd lang/php; ./build.sh interop-data-generate)
 
       # run interop data tests
-      (cd lang/java; mvn test -P interop-data-test)
+      (cd lang/java; mvn -B test -P interop-data-test)
       (cd lang/py; ant interop-data-test)
       (cd lang/c; ./build.sh interop-data-test)
       #(cd lang/c++; make interop-data-test)
@@ -70,9 +72,10 @@ do
       (cd lang/php; ./build.sh test-interop)
 
       # java needs to package the jars for the interop rpc tests
-      (cd lang/java; mvn package -DskipTests)
+      (cd lang/java; mvn -B package -DskipTests)
+
       # run interop rpc test
-      /bin/bash share/test/interop/bin/test_rpc_interop.sh
+      ./share/test/interop/bin/test_rpc_interop.sh
     ;;
 
     dist)
@@ -165,7 +168,7 @@ do
       rm -rf build dist
       (cd doc; ant clean)
 
-      (mvn clean)
+      (mvn -B clean)
       rm -rf lang/java/*/userlogs/
       rm -rf lang/java/*/dependency-reduced-pom.xml
 
diff --git a/lang/java/avro/pom.xml b/lang/java/avro/pom.xml
index 9d6ee2ee1..817bb3aa0 100644
--- a/lang/java/avro/pom.xml
+++ b/lang/java/avro/pom.xml
@@ -194,4 +194,3 @@
   </dependencies>
 
 </project>
-
diff --git a/lang/java/avro/src/test/java/org/apache/avro/AvroTestUtil.java b/lang/java/avro/src/test/java/org/apache/avro/AvroTestUtil.java
deleted file mode 100644
index bf4b2cbd9..000000000
--- a/lang/java/avro/src/test/java/org/apache/avro/AvroTestUtil.java
+++ /dev/null
@@ -1,54 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.avro;
-
-import java.io.File;
-
-/** Utilities for Avro tests. */
-public class AvroTestUtil {
-  static final File TMPDIR = new File(System.getProperty("test.dir", System.getProperty("java.io.tmpdir", "/tmp")), "tmpfiles");
-
-  private AvroTestUtil() {
-  }
-
-  /**
-   * Create a temporary file in a test-appropriate directory.
-   *
-   * @param testClass The test case class requesting the file creation
-   * @param name The name of the file to be created
-   */
-  public static File tempFile(Class testClass, String name) {
-    File testClassDir = new File(TMPDIR, testClass.getName());
-    testClassDir.mkdirs();
-    return new File(testClassDir, name);
-  }
-
-  /**
-   * Create a temporary directory in a test-appropriate directory.
-   *
-   * @param testClass The test case class requesting the directory creation
-   * @param name The name of the directory to be created
-   */
-  public static File tempDirectory(Class testClass, String name) {
-    File tmpFile = tempFile(testClass, name);
-    tmpFile.delete();
-    tmpFile.mkdir();
-    return tmpFile;
-  }
-
-}
diff --git a/lang/java/avro/src/test/java/org/apache/avro/FooBarSpecificRecord.java b/lang/java/avro/src/test/java/org/apache/avro/FooBarSpecificRecord.java
index e2737864c..6e4870295 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/FooBarSpecificRecord.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/FooBarSpecificRecord.java
@@ -21,10 +21,10 @@
  */
 package org.apache.avro;
 
-import org.apache.avro.specific.SpecificData;
-import org.apache.avro.message.BinaryMessageEncoder;
 import org.apache.avro.message.BinaryMessageDecoder;
+import org.apache.avro.message.BinaryMessageEncoder;
 import org.apache.avro.message.SchemaStore;
+import org.apache.avro.specific.SpecificData;
 
 @org.apache.avro.specific.AvroGenerated
 public class FooBarSpecificRecord extends org.apache.avro.specific.SpecificRecordBase implements org.apache.avro.specific.SpecificRecord {
diff --git a/lang/java/avro/src/test/java/org/apache/avro/GenerateBlockingData.java b/lang/java/avro/src/test/java/org/apache/avro/GenerateBlockingData.java
index 75484fbe6..d5440c2a4 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/GenerateBlockingData.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/GenerateBlockingData.java
@@ -17,16 +17,16 @@
  */
 package org.apache.avro;
 
-import org.apache.avro.generic.GenericDatumWriter;
-import org.apache.avro.io.DatumWriter;
-import org.apache.avro.io.Encoder;
-import org.apache.avro.io.EncoderFactory;
-
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.FileOutputStream;
 import java.io.IOException;
 
+import org.apache.avro.generic.GenericDatumWriter;
+import org.apache.avro.io.DatumWriter;
+import org.apache.avro.io.Encoder;
+import org.apache.avro.io.EncoderFactory;
+
 /**
  * Generates file with objects of a specific schema(that doesn't contain nesting
  * of arrays and maps) with random data. This is only for testing.
diff --git a/lang/java/avro/src/test/java/org/apache/avro/RandomData.java b/lang/java/avro/src/test/java/org/apache/avro/RandomData.java
index e250b6c11..89a4321d6 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/RandomData.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/RandomData.java
@@ -19,11 +19,7 @@
 
 import java.io.File;
 import java.nio.ByteBuffer;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Random;
+import java.util.*;
 
 import org.apache.avro.file.CodecFactory;
 import org.apache.avro.file.DataFileWriter;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestCircularReferences.java b/lang/java/avro/src/test/java/org/apache/avro/TestCircularReferences.java
index cdfd1a563..7acec0830 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestCircularReferences.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestCircularReferences.java
@@ -21,6 +21,7 @@
 import java.io.File;
 import java.io.IOException;
 import java.util.*;
+
 import org.apache.avro.file.DataFileReader;
 import org.apache.avro.file.DataFileWriter;
 import org.apache.avro.file.FileReader;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestDataFile.java b/lang/java/avro/src/test/java/org/apache/avro/TestDataFile.java
index 64e673009..6e2398dff 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestDataFile.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestDataFile.java
@@ -28,19 +28,14 @@
 import java.util.Random;
 
 import junit.framework.Assert;
-
-import org.apache.avro.file.CodecFactory;
-import org.apache.avro.file.FileReader;
-import org.apache.avro.file.DataFileReader;
-import org.apache.avro.file.DataFileStream;
-import org.apache.avro.file.DataFileWriter;
-import org.apache.avro.file.SeekableFileInput;
-import org.apache.avro.file.Syncable;
+import org.apache.avro.file.*;
 import org.apache.avro.generic.GenericData;
 import org.apache.avro.generic.GenericDatumReader;
 import org.apache.avro.generic.GenericDatumWriter;
 import org.apache.avro.io.DatumReader;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
 import org.junit.runner.RunWith;
 import org.junit.runners.Parameterized;
 import org.junit.runners.Parameterized.Parameters;
@@ -52,7 +47,10 @@
   private static final Logger LOG =
     LoggerFactory.getLogger(TestDataFile.class);
 
-  CodecFactory codec = null;
+  @Rule
+  public TemporaryFolder DIR = new TemporaryFolder();
+
+  private final CodecFactory codec;
   public TestDataFile(CodecFactory codec) {
     this.codec = codec;
     LOG.info("Running with codec: " + codec);
@@ -78,8 +76,8 @@ public TestDataFile(CodecFactory codec) {
     Integer.parseInt(System.getProperty("test.count", "200"));
   private static final boolean VALIDATE =
     !"false".equals(System.getProperty("test.validate", "true"));
-  private static final File DIR
-    = new File(System.getProperty("test.dir", "/tmp"));
+
+
   private static final long SEED = System.currentTimeMillis();
   private static final String SCHEMA_JSON =
     "{\"type\": \"record\", \"name\": \"Test\", \"fields\": ["
@@ -88,7 +86,7 @@ public TestDataFile(CodecFactory codec) {
   private static final Schema SCHEMA = new Schema.Parser().parse(SCHEMA_JSON);
 
   private File makeFile() {
-    return new File(DIR, "test-" + codec + ".avro");
+    return new File(DIR.getRoot().getPath(), "test-" + codec + ".avro");
   }
 
   @Test public void runTestsInOrder() throws Exception {
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestDataFileConcat.java b/lang/java/avro/src/test/java/org/apache/avro/TestDataFileConcat.java
index 56b2bf4f0..dfb68fa36 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestDataFileConcat.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestDataFileConcat.java
@@ -17,7 +17,7 @@
  */
 package org.apache.avro;
 
-import static org.junit.Assert.*;
+import static org.junit.Assert.assertEquals;
 
 import java.io.File;
 import java.io.IOException;
@@ -29,7 +29,9 @@
 import org.apache.avro.file.DataFileWriter;
 import org.apache.avro.generic.GenericDatumReader;
 import org.apache.avro.generic.GenericDatumWriter;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
 import org.junit.runner.RunWith;
 import org.junit.runners.Parameterized;
 import org.junit.runners.Parameterized.Parameters;
@@ -41,8 +43,11 @@
   private static final Logger LOG =
     LoggerFactory.getLogger(TestDataFileConcat.class);
 
-  CodecFactory codec = null;
-  CodecFactory codec2 = null;
+  @Rule
+  public TemporaryFolder DIR = new TemporaryFolder();
+
+  CodecFactory codec;
+  CodecFactory codec2;
   boolean recompress;
   public TestDataFileConcat(CodecFactory codec, CodecFactory codec2, Boolean recompress) {
     this.codec = codec;
@@ -80,8 +85,7 @@ public TestDataFileConcat(CodecFactory codec, CodecFactory codec2, Boolean recom
     Integer.parseInt(System.getProperty("test.count", "200"));
   private static final boolean VALIDATE =
     !"false".equals(System.getProperty("test.validate", "true"));
-  private static final File DIR
-    = new File(System.getProperty("test.dir", "/tmp"));
+
   private static final long SEED = System.currentTimeMillis();
 
   private static final String SCHEMA_JSON =
@@ -93,7 +97,7 @@ public TestDataFileConcat(CodecFactory codec, CodecFactory codec2, Boolean recom
   private static final Schema SCHEMA = new Schema.Parser().parse(SCHEMA_JSON);
 
   private File makeFile(String name) {
-    return new File(DIR, "test-" + name + ".avro");
+    return new File(DIR.getRoot().getPath(), "test-" + name + ".avro");
   }
 
   @Test
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestDataFileCorruption.java b/lang/java/avro/src/test/java/org/apache/avro/TestDataFileCorruption.java
index 40c2dd66c..60689e19c 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestDataFileCorruption.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestDataFileCorruption.java
@@ -17,10 +17,13 @@
  */
 package org.apache.avro;
 
+import static org.junit.Assert.*;
+
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.FileOutputStream;
 import java.io.IOException;
+
 import org.apache.avro.Schema.Type;
 import org.apache.avro.file.DataFileConstants;
 import org.apache.avro.file.DataFileReader;
@@ -30,14 +33,9 @@
 import org.apache.avro.util.Utf8;
 import org.junit.Test;
 
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.fail;
-
 public class TestDataFileCorruption {
 
-  private static final File DIR
-      = new File(System.getProperty("test.dir", "/tmp"));
+  private static final File DIR = new File( "/tmp");
 
   private File makeFile(String name) {
     return new File(DIR, "test-" + name + ".avro");
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestDataFileCustomSync.java b/lang/java/avro/src/test/java/org/apache/avro/TestDataFileCustomSync.java
index d9f564d74..81d6d8617 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestDataFileCustomSync.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestDataFileCustomSync.java
@@ -17,21 +17,22 @@
  */
 package org.apache.avro;
 
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.security.MessageDigest;
 import java.security.NoSuchAlgorithmException;
 import java.util.Arrays;
 import java.util.UUID;
+
 import org.apache.avro.Schema.Type;
 import org.apache.avro.file.DataFileWriter;
 import org.apache.avro.generic.GenericDatumWriter;
 import org.apache.avro.util.Utf8;
 import org.junit.Test;
 
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertTrue;
-
 public class TestDataFileCustomSync {
   private byte[] createDataFile(byte[] sync) throws IOException {
     Schema schema = Schema.create(Type.STRING);
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestDataFileMeta.java b/lang/java/avro/src/test/java/org/apache/avro/TestDataFileMeta.java
index d927f00f1..bebf85030 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestDataFileMeta.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestDataFileMeta.java
@@ -26,15 +26,20 @@
 import java.io.IOException;
 
 import junit.framework.Assert;
-
 import org.apache.avro.Schema.Type;
 import org.apache.avro.file.DataFileStream;
 import org.apache.avro.file.DataFileWriter;
 import org.apache.avro.generic.GenericDatumReader;
 import org.apache.avro.generic.GenericDatumWriter;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
 
 public class TestDataFileMeta {
+
+  @Rule
+  public TemporaryFolder DIR = new TemporaryFolder();
+
   @Test(expected=AvroRuntimeException.class)
   public void testUseReservedMeta() {
     DataFileWriter<?> w = new DataFileWriter<>(new GenericDatumWriter<>());
@@ -44,7 +49,7 @@ public void testUseReservedMeta() {
   @Test()
   public void testUseMeta() throws IOException {
     DataFileWriter<?> w = new DataFileWriter<>(new GenericDatumWriter<>());
-    File f = AvroTestUtil.tempFile(getClass(), "testDataFileMeta.avro");
+    File f = new File(DIR.getRoot().getPath(), "testDataFileMeta.avro");
     w.setMeta("hello", "bar");
     w.create(Schema.create(Type.NULL), f);
     w.close();
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestDataFileReflect.java b/lang/java/avro/src/test/java/org/apache/avro/TestDataFileReflect.java
index 2739807bb..a21f76fcc 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestDataFileReflect.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestDataFileReflect.java
@@ -31,13 +31,14 @@
 import org.apache.avro.reflect.ReflectDatumReader;
 import org.apache.avro.reflect.ReflectDatumWriter;
 import org.junit.Assert;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
 
 public class TestDataFileReflect {
 
-  private static final File DIR = new File(System.getProperty("test.dir",
-      "/tmp"));
-  private static final File FILE = new File(DIR, "test.avro");
+  @Rule
+  public TemporaryFolder DIR = new TemporaryFolder();
 
   /*
    * Test that using multiple schemas in a file works doing a union before
@@ -45,33 +46,37 @@
    */
   @Test
   public void testMultiReflectWithUnionBeforeWriting() throws IOException {
-    FileOutputStream fos = new FileOutputStream(FILE);
-
-    ReflectData reflectData = ReflectData.get();
-    List<Schema> schemas = Arrays.asList(new Schema[] {
-        reflectData.getSchema(FooRecord.class),
-        reflectData.getSchema(BarRecord.class) });
-    Schema union = Schema.createUnion(schemas);
-    DataFileWriter<Object> writer =
-      new DataFileWriter<>(new ReflectDatumWriter<>(union))
-      .create(union, fos);
-
-    // test writing to a file
+    File file = new File(DIR.getRoot().getPath(), "testMultiReflectWithUnionBeforeWriting.avro");
     CheckList<Object> check = new CheckList<>();
-    write(writer, new BarRecord("One beer please"), check);
-    write(writer, new FooRecord(10), check);
-    write(writer, new BarRecord("Two beers please"), check);
-    write(writer, new FooRecord(20), check);
-    writer.close();
-
+    try(FileOutputStream fos = new FileOutputStream(file)) {
+
+      ReflectData reflectData = ReflectData.get();
+      List<Schema> schemas = Arrays.asList(
+              reflectData.getSchema(FooRecord.class),
+              reflectData.getSchema(BarRecord.class)
+      );
+      Schema union = Schema.createUnion(schemas);
+
+      try (DataFileWriter<Object> writer = new DataFileWriter<>(new ReflectDatumWriter<>(union))) {
+        writer.create(union, fos);
+
+        // test writing to a file
+        write(writer, new BarRecord("One beer please"), check);
+        write(writer, new FooRecord(10), check);
+        write(writer, new BarRecord("Two beers please"), check);
+        write(writer, new FooRecord(20), check);
+      }
+    }
+    //new File(DIR.getRoot().getPath(), "test.avro");
     ReflectDatumReader<Object> din = new ReflectDatumReader<>();
-    SeekableFileInput sin = new SeekableFileInput(FILE);
-    DataFileReader<Object> reader = new DataFileReader<>(sin, din);
-    int count = 0;
-    for (Object datum : reader)
-      check.assertEquals(datum, count++);
-    Assert.assertEquals(count, check.size());
-    reader.close();
+    SeekableFileInput sin = new SeekableFileInput(file);
+    try(DataFileReader<Object> reader = new DataFileReader<>(sin, din)) {
+      int count = 0;
+      for (Object datum : reader) {
+        check.assertEquals(datum, count++);
+      }
+      Assert.assertEquals(count, check.size());
+    }
   }
 
   /*
@@ -79,30 +84,32 @@ public void testMultiReflectWithUnionBeforeWriting() throws IOException {
    */
   @Test
   public void testNull() throws IOException {
-    FileOutputStream fos = new FileOutputStream(FILE);
-
-    ReflectData reflectData = ReflectData.AllowNull.get();
-    Schema schema = reflectData.getSchema(BarRecord.class);
-    DataFileWriter<BarRecord> writer = new DataFileWriter<>
-      (new ReflectDatumWriter<>(BarRecord.class, reflectData))
-      .create(schema, fos);
-
-    // test writing to a file
+    File file = new File(DIR.getRoot().getPath(), "testNull.avro");
     CheckList<BarRecord> check = new CheckList<>();
-    write(writer, new BarRecord("One beer please"), check);
-    // null record here, fails when using the default reflectData instance
-    write(writer, new BarRecord(), check);
-    write(writer, new BarRecord("Two beers please"), check);
-    writer.close();
+
+    try(FileOutputStream fos = new FileOutputStream(file)) {
+      ReflectData reflectData = ReflectData.AllowNull.get();
+      Schema schema = reflectData.getSchema(BarRecord.class);
+      try(DataFileWriter<BarRecord> writer = new DataFileWriter<>(new ReflectDatumWriter<>(BarRecord.class, reflectData))) {
+        writer.create(schema, fos);
+        // test writing to a file
+        write(writer, new BarRecord("One beer please"), check);
+        // null record here, fails when using the default reflectData instance
+        write(writer, new BarRecord(), check);
+        write(writer, new BarRecord("Two beers please"), check);
+      }
+    }
 
     ReflectDatumReader<BarRecord> din = new ReflectDatumReader<>();
-    SeekableFileInput sin = new SeekableFileInput(FILE);
-    DataFileReader<BarRecord> reader = new DataFileReader<>(sin, din);
-    int count = 0;
-    for (BarRecord datum : reader)
-      check.assertEquals(datum, count++);
-    Assert.assertEquals(count, check.size());
-    reader.close();
+    try(SeekableFileInput sin = new SeekableFileInput(file)) {
+      try (DataFileReader<BarRecord> reader = new DataFileReader<>(sin, din)) {
+        int count = 0;
+        for (BarRecord datum : reader) {
+          check.assertEquals(datum, count++);
+        }
+        Assert.assertEquals(count, check.size());
+      }
+    }
   }
 
   /*
@@ -110,27 +117,30 @@ public void testNull() throws IOException {
    */
   @Test
   public void testNestedClass() throws IOException {
-    FileOutputStream fos = new FileOutputStream(FILE);
-
-    Schema schema = ReflectData.get().getSchema(BazRecord.class);
-    DataFileWriter<BazRecord> writer =
-      new DataFileWriter<>(new ReflectDatumWriter<BazRecord>(schema))
-      .create(schema, fos);
+    File file = new File(DIR.getRoot().getPath(), "testNull.avro");
 
-    // test writing to a file
     CheckList<BazRecord> check = new CheckList<>();
-    write(writer, new BazRecord(10), check);
-    write(writer, new BazRecord(20), check);
-    writer.close();
+    try(FileOutputStream fos = new FileOutputStream(file)) {
+      Schema schema = ReflectData.get().getSchema(BazRecord.class);
+      try (DataFileWriter<BazRecord> writer = new DataFileWriter<>(new ReflectDatumWriter<BazRecord>(schema))) {
+        writer.create(schema, fos);
+
+        // test writing to a file
+        write(writer, new BazRecord(10), check);
+        write(writer, new BazRecord(20), check);
+      }
+    }
 
     ReflectDatumReader<BazRecord> din = new ReflectDatumReader<>();
-    SeekableFileInput sin = new SeekableFileInput(FILE);
-    DataFileReader<BazRecord> reader = new DataFileReader<>(sin, din);
-    int count = 0;
-    for (BazRecord datum : reader)
-      check.assertEquals(datum, count++);
-    Assert.assertEquals(count, check.size());
-    reader.close();
+    try(SeekableFileInput sin = new SeekableFileInput(file)) {
+      try (DataFileReader<BazRecord> reader = new DataFileReader<>(sin, din)) {
+        int count = 0;
+        for (BazRecord datum : reader) {
+          check.assertEquals(datum, count++);
+        }
+        Assert.assertEquals(count, check.size());
+      }
+    }
   }
 
   private <T> void write(DataFileWriter<T> writer, T o, CheckList<T> l)
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestLogicalType.java b/lang/java/avro/src/test/java/org/apache/avro/TestLogicalType.java
index 2fb9c67d6..ec143b980 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestLogicalType.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestLogicalType.java
@@ -20,6 +20,7 @@
 
 import java.util.Arrays;
 import java.util.concurrent.Callable;
+
 import org.junit.Assert;
 import org.junit.Test;
 
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestProtocol.java b/lang/java/avro/src/test/java/org/apache/avro/TestProtocol.java
index 4109f6a9c..d28c10d08 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestProtocol.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestProtocol.java
@@ -17,9 +17,7 @@
  */
 package org.apache.avro;
 
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.*;
 
 import org.junit.Test;
 
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestReadingWritingDataInEvolvedSchemas.java b/lang/java/avro/src/test/java/org/apache/avro/TestReadingWritingDataInEvolvedSchemas.java
index 85a3ca705..d7c0fcbae 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestReadingWritingDataInEvolvedSchemas.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestReadingWritingDataInEvolvedSchemas.java
@@ -17,9 +17,7 @@
  */
 package org.apache.avro;
 
-import static org.junit.Assert.assertArrayEquals;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertNull;
+import static org.junit.Assert.*;
 
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
@@ -31,11 +29,7 @@
 import org.apache.avro.generic.GenericDatumReader;
 import org.apache.avro.generic.GenericDatumWriter;
 import org.apache.avro.generic.GenericRecord;
-import org.apache.avro.io.DatumWriter;
-import org.apache.avro.io.Decoder;
-import org.apache.avro.io.DecoderFactory;
-import org.apache.avro.io.Encoder;
-import org.apache.avro.io.EncoderFactory;
+import org.apache.avro.io.*;
 import org.junit.Rule;
 import org.junit.Test;
 import org.junit.rules.ExpectedException;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestSchema.java b/lang/java/avro/src/test/java/org/apache/avro/TestSchema.java
index 25858b5f9..0ca1437d7 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestSchema.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestSchema.java
@@ -17,10 +17,7 @@
  */
 package org.apache.avro;
 
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.assertTrue;
-import static org.junit.Assert.fail;
+import static org.junit.Assert.*;
 
 import java.util.ArrayList;
 import java.util.List;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaBuilder.java b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaBuilder.java
index bb0b0554a..fa6370c95 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaBuilder.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaBuilder.java
@@ -20,14 +20,9 @@
 import java.io.File;
 import java.io.IOException;
 import java.nio.ByteBuffer;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
+import java.util.*;
 
+import com.fasterxml.jackson.databind.node.NullNode;
 import org.apache.avro.Schema.Field.Order;
 import org.apache.avro.file.DataFileReader;
 import org.apache.avro.file.DataFileWriter;
@@ -36,14 +31,14 @@
 import org.apache.avro.generic.GenericDatumWriter;
 import org.apache.avro.generic.GenericRecordBuilder;
 import org.junit.Assert;
+import org.junit.Rule;
 import org.junit.Test;
-
-import com.fasterxml.jackson.databind.node.NullNode;
+import org.junit.rules.TemporaryFolder;
 
 public class TestSchemaBuilder {
 
-  private static final File DIR = new File(System.getProperty("test.dir", "/tmp"));
-  private static final File FILE = new File(DIR, "test.avro");
+  @Rule
+  public TemporaryFolder DIR = new TemporaryFolder();
 
   @Test
   public void testRecord() {
@@ -985,12 +980,14 @@ public void testDefaults() throws IOException {
     Assert.assertEquals(13, rec2.get("nullableIntWithDefault"));
 
     // write to file
-    DataFileWriter<Object> writer =
-        new DataFileWriter<>(new GenericDatumWriter<>());
-    writer.create(writeSchema, FILE);
-    writer.append(rec1);
-    writer.append(rec2);
-    writer.close();
+
+    File file = new File(DIR.getRoot().getPath(), "testDefaults.avro");
+
+    try(DataFileWriter<Object> writer = new DataFileWriter<>(new GenericDatumWriter<>())) {
+      writer.create(writeSchema, file);
+      writer.append(rec1);
+      writer.append(rec2);
+    }
 
     Schema readSchema = SchemaBuilder.record("r").fields()
         .name("requiredInt").type().intType().noDefault()
@@ -1001,21 +998,21 @@ public void testDefaults() throws IOException {
         .endRecord();
 
     DataFileReader<GenericData.Record> reader =
-        new DataFileReader<>(FILE,
+        new DataFileReader<>(file,
             new GenericDatumReader<>(writeSchema, readSchema));
 
     GenericData.Record rec1read = reader.iterator().next();
     Assert.assertEquals(1, rec1read.get("requiredInt"));
-    Assert.assertEquals(null, rec1read.get("optionalInt"));
+    Assert.assertNull(rec1read.get("optionalInt"));
     Assert.assertEquals(3, rec1read.get("nullableIntWithDefault"));
-    Assert.assertEquals(null, rec1read.get("newOptionalInt"));
+    Assert.assertNull(rec1read.get("newOptionalInt"));
     Assert.assertEquals(5, rec1read.get("newNullableIntWithDefault"));
 
     GenericData.Record rec2read = reader.iterator().next();
     Assert.assertEquals(1, rec2read.get("requiredInt"));
     Assert.assertEquals(2, rec2read.get("optionalInt"));
     Assert.assertEquals(13, rec2read.get("nullableIntWithDefault"));
-    Assert.assertEquals(null, rec2read.get("newOptionalInt"));
+    Assert.assertNull(rec2read.get("newOptionalInt"));
     Assert.assertEquals(5, rec2read.get("newNullableIntWithDefault"));
   }
 
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibility.java b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibility.java
index 05726e989..4953a10c9 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibility.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibility.java
@@ -18,79 +18,19 @@
 package org.apache.avro;
 
 import static java.util.Arrays.asList;
-import static org.apache.avro.SchemaCompatibility.checkReaderWriterCompatibility;
-import static org.apache.avro.TestSchemas.A_DINT_B_DINT_RECORD1;
-import static org.apache.avro.TestSchemas.A_DINT_RECORD1;
-import static org.apache.avro.TestSchemas.A_INT_B_DINT_RECORD1;
-import static org.apache.avro.TestSchemas.A_INT_B_INT_RECORD1;
-import static org.apache.avro.TestSchemas.A_INT_RECORD1;
-import static org.apache.avro.TestSchemas.A_LONG_RECORD1;
-import static org.apache.avro.TestSchemas.BOOLEAN_SCHEMA;
-import static org.apache.avro.TestSchemas.BYTES_SCHEMA;
-import static org.apache.avro.TestSchemas.BYTES_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.DOUBLE_SCHEMA;
-import static org.apache.avro.TestSchemas.DOUBLE_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.EMPTY_RECORD1;
-import static org.apache.avro.TestSchemas.EMPTY_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.ENUM1_ABC_SCHEMA;
-import static org.apache.avro.TestSchemas.ENUM1_AB_SCHEMA;
-import static org.apache.avro.TestSchemas.ENUM1_BC_SCHEMA;
-import static org.apache.avro.TestSchemas.ENUM_AB_FIELD_DEFAULT_A_ENUM_DEFAULT_B_RECORD;
-import static org.apache.avro.TestSchemas.ENUM_ABC_FIELD_DEFAULT_B_ENUM_DEFAULT_A_RECORD;
-import static org.apache.avro.TestSchemas.ENUM_AB_ENUM_DEFAULT_A_RECORD;
-import static org.apache.avro.TestSchemas.ENUM_ABC_ENUM_DEFAULT_A_RECORD;
-import static org.apache.avro.TestSchemas.ENUM_AB_ENUM_DEFAULT_A_SCHEMA;
-import static org.apache.avro.TestSchemas.ENUM_ABC_ENUM_DEFAULT_A_SCHEMA;
-import static org.apache.avro.TestSchemas.FIXED_4_BYTES;
-import static org.apache.avro.TestSchemas.FLOAT_SCHEMA;
-import static org.apache.avro.TestSchemas.FLOAT_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_ARRAY_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_FLOAT_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_LIST_RECORD;
-import static org.apache.avro.TestSchemas.INT_LONG_FLOAT_DOUBLE_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_LONG_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_MAP_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_STRING_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.LONG_ARRAY_SCHEMA;
-import static org.apache.avro.TestSchemas.LONG_LIST_RECORD;
-import static org.apache.avro.TestSchemas.LONG_MAP_SCHEMA;
-import static org.apache.avro.TestSchemas.LONG_SCHEMA;
-import static org.apache.avro.TestSchemas.LONG_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.NULL_SCHEMA;
-import static org.apache.avro.TestSchemas.STRING_ARRAY_SCHEMA;
-import static org.apache.avro.TestSchemas.STRING_INT_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.STRING_SCHEMA;
-import static org.apache.avro.TestSchemas.STRING_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.assertSchemaContains;
-import static org.apache.avro.TestSchemas.list;
+import static org.apache.avro.SchemaCompatibility.*;
+import static org.apache.avro.TestSchemas.*;
 import static org.junit.Assert.assertEquals;
 
 import java.io.ByteArrayOutputStream;
-import java.util.ArrayDeque;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.Deque;
-import java.util.List;
-
-import org.apache.avro.SchemaCompatibility.Incompatibility;
-import org.apache.avro.SchemaCompatibility.SchemaCompatibilityResult;
-import org.apache.avro.SchemaCompatibility.SchemaCompatibilityType;
-import org.apache.avro.SchemaCompatibility.SchemaIncompatibilityType;
-import org.apache.avro.SchemaCompatibility.SchemaPairCompatibility;
+import java.util.*;
+
+import org.apache.avro.SchemaCompatibility.*;
 import org.apache.avro.TestSchemas.ReaderWriter;
-import org.apache.avro.generic.GenericData;
 import org.apache.avro.generic.GenericData.EnumSymbol;
 import org.apache.avro.generic.GenericDatumReader;
 import org.apache.avro.generic.GenericDatumWriter;
-import org.apache.avro.generic.GenericRecord;
-import org.apache.avro.io.DatumReader;
-import org.apache.avro.io.DatumWriter;
-import org.apache.avro.io.Decoder;
-import org.apache.avro.io.DecoderFactory;
-import org.apache.avro.io.Encoder;
-import org.apache.avro.io.EncoderFactory;
+import org.apache.avro.io.*;
 import org.apache.avro.util.Utf8;
 import org.junit.Test;
 import org.slf4j.Logger;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityEnumDefaults.java b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityEnumDefaults.java
index 159733ac7..f85f3979a 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityEnumDefaults.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityEnumDefaults.java
@@ -17,27 +17,19 @@
  */
 package org.apache.avro;
 
+import static org.apache.avro.TestSchemas.*;
+import static org.junit.Assert.assertEquals;
+
+import java.io.ByteArrayOutputStream;
+
 import org.apache.avro.generic.GenericData;
 import org.apache.avro.generic.GenericDatumReader;
 import org.apache.avro.generic.GenericDatumWriter;
 import org.apache.avro.generic.GenericRecord;
-import org.apache.avro.io.DatumReader;
-import org.apache.avro.io.DatumWriter;
-import org.apache.avro.io.Decoder;
-import org.apache.avro.io.DecoderFactory;
-import org.apache.avro.io.Encoder;
-import org.apache.avro.io.EncoderFactory;
+import org.apache.avro.io.*;
 import org.junit.Rule;
 import org.junit.Test;
 import org.junit.rules.ExpectedException;
-import org.junit.runner.RunWith;
-import org.junit.runners.Parameterized;
-
-import java.io.ByteArrayOutputStream;
-
-import static org.apache.avro.TestSchemaCompatibility.validateIncompatibleSchemas;
-import static org.apache.avro.TestSchemas.*;
-import static org.junit.Assert.assertEquals;
 
 public class TestSchemaCompatibilityEnumDefaults {
   @Rule
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityFixedSizeMismatch.java b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityFixedSizeMismatch.java
index 48657e8d6..3e220866c 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityFixedSizeMismatch.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityFixedSizeMismatch.java
@@ -18,12 +18,11 @@
 package org.apache.avro;
 
 import static org.apache.avro.TestSchemaCompatibility.validateIncompatibleSchemas;
-import static org.apache.avro.TestSchemas.A_DINT_B_DFIXED_4_BYTES_RECORD1;
-import static org.apache.avro.TestSchemas.A_DINT_B_DFIXED_8_BYTES_RECORD1;
-import static org.apache.avro.TestSchemas.FIXED_4_BYTES;
-import static org.apache.avro.TestSchemas.FIXED_8_BYTES;
+import static org.apache.avro.TestSchemas.*;
+
 import java.util.ArrayList;
 import java.util.List;
+
 import org.apache.avro.SchemaCompatibility.SchemaIncompatibilityType;
 import org.junit.Test;
 import org.junit.runner.RunWith;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityMissingEnumSymbols.java b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityMissingEnumSymbols.java
index 9b1b606f8..02ddb18f4 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityMissingEnumSymbols.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityMissingEnumSymbols.java
@@ -18,11 +18,11 @@
 package org.apache.avro;
 
 import static org.apache.avro.TestSchemaCompatibility.validateIncompatibleSchemas;
-import static org.apache.avro.TestSchemas.ENUM1_ABC_SCHEMA;
-import static org.apache.avro.TestSchemas.ENUM1_AB_SCHEMA;
-import static org.apache.avro.TestSchemas.ENUM1_BC_SCHEMA;
+import static org.apache.avro.TestSchemas.*;
+
 import java.util.ArrayList;
 import java.util.List;
+
 import org.apache.avro.SchemaCompatibility.SchemaIncompatibilityType;
 import org.junit.Test;
 import org.junit.runner.RunWith;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityMissingUnionBranch.java b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityMissingUnionBranch.java
index 9075c9ecf..87e7cdf7f 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityMissingUnionBranch.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityMissingUnionBranch.java
@@ -19,27 +19,12 @@
 
 import static java.util.Arrays.asList;
 import static org.apache.avro.TestSchemaCompatibility.validateIncompatibleSchemas;
-import static org.apache.avro.TestSchemas.A_DINT_B_DINT_STRING_UNION_RECORD1;
-import static org.apache.avro.TestSchemas.A_DINT_B_DINT_UNION_RECORD1;
-import static org.apache.avro.TestSchemas.BOOLEAN_SCHEMA;
-import static org.apache.avro.TestSchemas.BYTES_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.DOUBLE_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.ENUM1_AB_SCHEMA;
-import static org.apache.avro.TestSchemas.FIXED_4_BYTES;
-import static org.apache.avro.TestSchemas.FLOAT_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_ARRAY_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_LONG_FLOAT_DOUBLE_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_MAP_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_STRING_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.LONG_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.NULL_SCHEMA;
-import static org.apache.avro.TestSchemas.STRING_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.list;
+import static org.apache.avro.TestSchemas.*;
+
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
+
 import org.apache.avro.SchemaCompatibility.SchemaIncompatibilityType;
 import org.junit.Test;
 import org.junit.runner.RunWith;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityNameMismatch.java b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityNameMismatch.java
index ed55ff224..961192e4b 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityNameMismatch.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityNameMismatch.java
@@ -18,15 +18,11 @@
 package org.apache.avro;
 
 import static org.apache.avro.TestSchemaCompatibility.validateIncompatibleSchemas;
-import static org.apache.avro.TestSchemas.A_DINT_B_DENUM_1_RECORD1;
-import static org.apache.avro.TestSchemas.A_DINT_B_DENUM_2_RECORD1;
-import static org.apache.avro.TestSchemas.EMPTY_RECORD1;
-import static org.apache.avro.TestSchemas.EMPTY_RECORD2;
-import static org.apache.avro.TestSchemas.ENUM1_AB_SCHEMA;
-import static org.apache.avro.TestSchemas.ENUM2_AB_SCHEMA;
-import static org.apache.avro.TestSchemas.FIXED_4_BYTES;
+import static org.apache.avro.TestSchemas.*;
+
 import java.util.ArrayList;
 import java.util.List;
+
 import org.apache.avro.SchemaCompatibility.SchemaIncompatibilityType;
 import org.junit.Test;
 import org.junit.runner.RunWith;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityReaderFieldMissingDefaultValue.java b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityReaderFieldMissingDefaultValue.java
index 71a8dcb33..3c61ee165 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityReaderFieldMissingDefaultValue.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityReaderFieldMissingDefaultValue.java
@@ -18,11 +18,11 @@
 package org.apache.avro;
 
 import static org.apache.avro.TestSchemaCompatibility.validateIncompatibleSchemas;
-import static org.apache.avro.TestSchemas.A_INT_B_DINT_RECORD1;
-import static org.apache.avro.TestSchemas.A_INT_RECORD1;
-import static org.apache.avro.TestSchemas.EMPTY_RECORD1;
+import static org.apache.avro.TestSchemas.*;
+
 import java.util.ArrayList;
 import java.util.List;
+
 import org.apache.avro.SchemaCompatibility.SchemaIncompatibilityType;
 import org.junit.Test;
 import org.junit.runner.RunWith;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityTypeMismatch.java b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityTypeMismatch.java
index 844e4cde6..0cc4cb2e6 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityTypeMismatch.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityTypeMismatch.java
@@ -18,27 +18,11 @@
 package org.apache.avro;
 
 import static org.apache.avro.TestSchemaCompatibility.validateIncompatibleSchemas;
-import static org.apache.avro.TestSchemas.A_INT_RECORD1;
-import static org.apache.avro.TestSchemas.BOOLEAN_SCHEMA;
-import static org.apache.avro.TestSchemas.BYTES_SCHEMA;
-import static org.apache.avro.TestSchemas.DOUBLE_SCHEMA;
-import static org.apache.avro.TestSchemas.ENUM2_AB_SCHEMA;
-import static org.apache.avro.TestSchemas.FIXED_4_BYTES;
-import static org.apache.avro.TestSchemas.FLOAT_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_ARRAY_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_FLOAT_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_LIST_RECORD;
-import static org.apache.avro.TestSchemas.INT_LONG_FLOAT_DOUBLE_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_MAP_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_SCHEMA;
-import static org.apache.avro.TestSchemas.LONG_ARRAY_SCHEMA;
-import static org.apache.avro.TestSchemas.LONG_LIST_RECORD;
-import static org.apache.avro.TestSchemas.LONG_MAP_SCHEMA;
-import static org.apache.avro.TestSchemas.LONG_SCHEMA;
-import static org.apache.avro.TestSchemas.NULL_SCHEMA;
-import static org.apache.avro.TestSchemas.STRING_SCHEMA;
+import static org.apache.avro.TestSchemas.*;
+
 import java.util.ArrayList;
 import java.util.List;
+
 import org.apache.avro.SchemaCompatibility.SchemaIncompatibilityType;
 import org.junit.Test;
 import org.junit.runner.RunWith;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaNormalization.java b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaNormalization.java
index 1459b633f..063e0b6e1 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaNormalization.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaNormalization.java
@@ -17,23 +17,23 @@
  */
 package org.apache.avro;
 
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+
 import java.io.BufferedReader;
 import java.io.FileReader;
 import java.io.IOException;
-import java.util.List;
 import java.util.ArrayList;
 import java.util.Formatter;
+import java.util.List;
 import java.util.Locale;
 
+import org.apache.avro.util.CaseFinder;
 import org.junit.Test;
+import org.junit.experimental.runners.Enclosed;
 import org.junit.runner.RunWith;
 import org.junit.runners.Parameterized;
 import org.junit.runners.Parameterized.Parameters;
-import org.junit.experimental.runners.Enclosed;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertTrue;
-
-import org.apache.avro.util.CaseFinder;
 
 
 @RunWith(Enclosed.class)
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaValidation.java b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaValidation.java
index fc933c9eb..1ede75721 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestSchemaValidation.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestSchemaValidation.java
@@ -17,50 +17,14 @@
  */
 package org.apache.avro;
 
-import static org.apache.avro.TestSchemas.A_DINT_B_DINT_RECORD1;
-import static org.apache.avro.TestSchemas.A_DINT_RECORD1;
-import static org.apache.avro.TestSchemas.A_INT_B_DINT_RECORD1;
-import static org.apache.avro.TestSchemas.A_INT_B_INT_RECORD1;
-import static org.apache.avro.TestSchemas.A_INT_RECORD1;
-import static org.apache.avro.TestSchemas.A_LONG_RECORD1;
-import static org.apache.avro.TestSchemas.BOOLEAN_SCHEMA;
-import static org.apache.avro.TestSchemas.BYTES_SCHEMA;
-import static org.apache.avro.TestSchemas.BYTES_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.DOUBLE_SCHEMA;
-import static org.apache.avro.TestSchemas.DOUBLE_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.EMPTY_RECORD1;
-import static org.apache.avro.TestSchemas.EMPTY_RECORD2;
-import static org.apache.avro.TestSchemas.EMPTY_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.ENUM1_ABC_SCHEMA;
-import static org.apache.avro.TestSchemas.ENUM1_AB_SCHEMA;
-import static org.apache.avro.TestSchemas.ENUM1_BC_SCHEMA;
-import static org.apache.avro.TestSchemas.ENUM2_AB_SCHEMA;
-import static org.apache.avro.TestSchemas.FLOAT_SCHEMA;
-import static org.apache.avro.TestSchemas.FLOAT_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_ARRAY_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_FLOAT_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_LIST_RECORD;
-import static org.apache.avro.TestSchemas.INT_LONG_FLOAT_DOUBLE_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_LONG_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_MAP_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_STRING_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.INT_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.LONG_ARRAY_SCHEMA;
-import static org.apache.avro.TestSchemas.LONG_LIST_RECORD;
-import static org.apache.avro.TestSchemas.LONG_MAP_SCHEMA;
-import static org.apache.avro.TestSchemas.LONG_SCHEMA;
-import static org.apache.avro.TestSchemas.LONG_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.NULL_SCHEMA;
-import static org.apache.avro.TestSchemas.STRING_INT_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.STRING_SCHEMA;
-import static org.apache.avro.TestSchemas.STRING_UNION_SCHEMA;
-import static org.apache.avro.TestSchemas.list;
+import static org.apache.avro.TestSchemas.*;
+
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.List;
-import org.apache.avro.TestSchemas.ReaderWriter;
+
+import org.apache.avro.TestSchemas.*;
 import org.apache.avro.reflect.ReflectData;
 import org.junit.Assert;
 import org.junit.Rule;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/TestSchemas.java b/lang/java/avro/src/test/java/org/apache/avro/TestSchemas.java
index 466f1fd63..94a48a6e9 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/TestSchemas.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/TestSchemas.java
@@ -18,10 +18,9 @@
 package org.apache.avro;
 
 import static org.junit.Assert.assertTrue;
+
 import java.util.ArrayList;
-import java.util.Arrays;
 import java.util.Collections;
-import java.util.List;
 
 import org.apache.avro.Schema.Field;
 
diff --git a/lang/java/avro/src/test/java/org/apache/avro/data/TestJsr310TimeConversions.java b/lang/java/avro/src/test/java/org/apache/avro/data/TestJsr310TimeConversions.java
index caf699e7d..ba9e9baa6 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/data/TestJsr310TimeConversions.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/data/TestJsr310TimeConversions.java
@@ -18,23 +18,15 @@
 
 package org.apache.avro.data;
 
+import java.time.*;
+
 import org.apache.avro.LogicalTypes;
 import org.apache.avro.Schema;
-import org.apache.avro.data.Jsr310TimeConversions.DateConversion;
-import org.apache.avro.data.Jsr310TimeConversions.TimeMillisConversion;
-import org.apache.avro.data.Jsr310TimeConversions.TimeMicrosConversion;
-import org.apache.avro.data.Jsr310TimeConversions.TimestampMicrosConversion;
-import org.apache.avro.data.Jsr310TimeConversions.TimestampMillisConversion;
+import org.apache.avro.data.Jsr310TimeConversions.*;
 import org.junit.Assert;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
-import java.time.Instant;
-import java.time.LocalDate;
-import java.time.LocalTime;
-import java.time.ZonedDateTime;
-import java.time.ZoneOffset;
-
 public class TestJsr310TimeConversions {
 
   public static Schema DATE_SCHEMA;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/data/TestTimeConversions.java b/lang/java/avro/src/test/java/org/apache/avro/data/TestTimeConversions.java
index 7ea44a5df..536e9ce23 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/data/TestTimeConversions.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/data/TestTimeConversions.java
@@ -18,16 +18,12 @@
 
 package org.apache.avro.data;
 
+import java.util.Date;
+
 import org.apache.avro.Conversion;
 import org.apache.avro.LogicalTypes;
 import org.apache.avro.Schema;
-import org.apache.avro.data.TimeConversions.DateConversion;
-import org.apache.avro.data.TimeConversions.LossyTimeMicrosConversion;
-import org.apache.avro.data.TimeConversions.LossyTimestampMicrosConversion;
-import org.apache.avro.data.TimeConversions.TimeMicrosConversion;
-import org.apache.avro.data.TimeConversions.TimestampMicrosConversion;
-import org.apache.avro.data.TimeConversions.TimeConversion;
-import org.apache.avro.data.TimeConversions.TimestampConversion;
+import org.apache.avro.data.TimeConversions.*;
 import org.apache.avro.reflect.ReflectData;
 import org.joda.time.DateTime;
 import org.joda.time.DateTimeZone;
@@ -37,8 +33,6 @@
 import org.junit.BeforeClass;
 import org.junit.Test;
 
-import java.util.Date;
-
 public class TestTimeConversions {
 
   public static Schema DATE_SCHEMA;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/file/TestBZip2Codec.java b/lang/java/avro/src/test/java/org/apache/avro/file/TestBZip2Codec.java
index 3e5e81832..dfa95afa1 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/file/TestBZip2Codec.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/file/TestBZip2Codec.java
@@ -17,11 +17,12 @@
  */
 package org.apache.avro.file;
 
+import static org.junit.Assert.assertTrue;
+
 import java.io.IOException;
 import java.nio.ByteBuffer;
 
 import org.junit.Test;
-import static org.junit.Assert.assertTrue;
 
 public class TestBZip2Codec {
 
diff --git a/lang/java/avro/src/test/java/org/apache/avro/file/TestCustomCodec.java b/lang/java/avro/src/test/java/org/apache/avro/file/TestCustomCodec.java
index e5f68117f..77c01ad5a 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/file/TestCustomCodec.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/file/TestCustomCodec.java
@@ -19,15 +19,13 @@
 package org.apache.avro.file;
 
 
-import org.apache.avro.file.codec.CustomCodec;
-import org.junit.Test;
+import static org.junit.Assert.*;
 
 import java.io.IOException;
 import java.nio.ByteBuffer;
 
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertTrue;
+import org.apache.avro.file.codec.CustomCodec;
+import org.junit.Test;
 
 public class TestCustomCodec {
 
diff --git a/lang/java/avro/src/test/java/org/apache/avro/file/codec/CustomCodec.java b/lang/java/avro/src/test/java/org/apache/avro/file/codec/CustomCodec.java
index dfcc5fbd2..2a0fbf1e2 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/file/codec/CustomCodec.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/file/codec/CustomCodec.java
@@ -18,10 +18,10 @@
 
 package org.apache.avro.file.codec;
 
-import org.apache.avro.file.Codec;
-
 import java.io.IOException;
-import java.nio.*;
+import java.nio.ByteBuffer;
+
+import org.apache.avro.file.Codec;
 
 /**
  * Simple Custom Codec to validate making Codec Public
diff --git a/lang/java/avro/src/test/java/org/apache/avro/generic/TestGenericData.java b/lang/java/avro/src/test/java/org/apache/avro/generic/TestGenericData.java
index 8bc160e15..ac896a0f9 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/generic/TestGenericData.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/generic/TestGenericData.java
@@ -17,38 +17,30 @@
  */
 package org.apache.avro.generic;
 
-import java.io.ByteArrayOutputStream;
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Collection;
-import java.util.ArrayDeque;
-
 import static org.apache.avro.TestCircularReferences.Reference;
 import static org.apache.avro.TestCircularReferences.Referenceable;
 import static org.junit.Assert.*;
 
-import java.util.Arrays;
-import java.util.Map;
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import java.nio.ByteBuffer;
+import java.util.*;
 
+import com.fasterxml.jackson.core.JsonFactory;
+import com.fasterxml.jackson.core.JsonParseException;
+import com.fasterxml.jackson.core.JsonParser;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import org.apache.avro.AvroRuntimeException;
 import org.apache.avro.Schema;
 import org.apache.avro.Schema.Field;
-import org.apache.avro.AvroRuntimeException;
 import org.apache.avro.Schema.Type;
 import org.apache.avro.SchemaBuilder;
 import org.apache.avro.TestCircularReferences.ReferenceManager;
+import org.apache.avro.generic.GenericData.Record;
 import org.apache.avro.io.BinaryData;
 import org.apache.avro.io.BinaryEncoder;
 import org.apache.avro.io.EncoderFactory;
-import org.apache.avro.generic.GenericData.Record;
 import org.apache.avro.util.Utf8;
-import com.fasterxml.jackson.core.JsonFactory;
-import com.fasterxml.jackson.core.JsonParseException;
-import com.fasterxml.jackson.core.JsonParser;
-import com.fasterxml.jackson.databind.ObjectMapper;
-
 import org.junit.Test;
 
 public class TestGenericData {
diff --git a/lang/java/avro/src/test/java/org/apache/avro/generic/TestGenericDatumWriter.java b/lang/java/avro/src/test/java/org/apache/avro/generic/TestGenericDatumWriter.java
index 6734def64..832871a65 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/generic/TestGenericDatumWriter.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/generic/TestGenericDatumWriter.java
@@ -17,9 +17,7 @@
  */
 package org.apache.avro.generic;
 
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertTrue;
-import static org.junit.Assert.fail;
+import static org.junit.Assert.*;
 
 import java.io.ByteArrayInputStream;
 import java.io.ByteArrayOutputStream;
@@ -28,21 +26,16 @@
 import java.util.ConcurrentModificationException;
 import java.util.HashMap;
 import java.util.Map;
-import java.util.concurrent.Callable;
-import java.util.concurrent.CountDownLatch;
-import java.util.concurrent.ExecutionException;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
-import java.util.concurrent.Future;
+import java.util.concurrent.*;
 
+import org.apache.avro.AvroTypeException;
 import org.apache.avro.Schema;
 import org.apache.avro.io.BinaryEncoder;
 import org.apache.avro.io.DecoderFactory;
 import org.apache.avro.io.Encoder;
 import org.apache.avro.io.EncoderFactory;
-import org.apache.avro.AvroTypeException;
-import org.junit.Test;
 import org.apache.avro.util.Utf8;
+import org.junit.Test;
 
 public class TestGenericDatumWriter {
   @Test
diff --git a/lang/java/avro/src/test/java/org/apache/avro/generic/TestGenericLogicalTypes.java b/lang/java/avro/src/test/java/org/apache/avro/generic/TestGenericLogicalTypes.java
index cfd75d4d8..6cab57709 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/generic/TestGenericLogicalTypes.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/generic/TestGenericLogicalTypes.java
@@ -26,11 +26,8 @@
 import java.util.Arrays;
 import java.util.List;
 import java.util.UUID;
-import org.apache.avro.Conversion;
-import org.apache.avro.Conversions;
-import org.apache.avro.LogicalType;
-import org.apache.avro.LogicalTypes;
-import org.apache.avro.Schema;
+
+import org.apache.avro.*;
 import org.apache.avro.file.DataFileReader;
 import org.apache.avro.file.DataFileWriter;
 import org.apache.avro.file.FileReader;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/io/TestBinaryDecoder.java b/lang/java/avro/src/test/java/org/apache/avro/io/TestBinaryDecoder.java
index 96e62d7c5..76f4df3dc 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/io/TestBinaryDecoder.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/io/TestBinaryDecoder.java
@@ -17,19 +17,15 @@
  */
 package org.apache.avro.io;
 
-import java.io.ByteArrayInputStream;
-import java.io.ByteArrayOutputStream;
-import java.io.EOFException;
-import java.io.IOException;
-import java.io.InputStream;
+import java.io.*;
 import java.nio.ByteBuffer;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
 
+import org.apache.avro.AvroRuntimeException;
 import org.apache.avro.RandomData;
 import org.apache.avro.Schema;
-import org.apache.avro.AvroRuntimeException;
 import org.apache.avro.generic.GenericDatumReader;
 import org.apache.avro.generic.GenericDatumWriter;
 import org.apache.avro.util.ByteBufferInputStream;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/io/TestBlockingIO.java b/lang/java/avro/src/test/java/org/apache/avro/io/TestBlockingIO.java
index 1e6c886ea..baaba95c3 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/io/TestBlockingIO.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/io/TestBlockingIO.java
@@ -17,22 +17,21 @@
  */
 package org.apache.avro.io;
 
+import static org.junit.Assert.*;
+
 import java.io.ByteArrayInputStream;
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.nio.ByteBuffer;
-import java.util.Stack;
-import java.util.Collection;
 import java.util.Arrays;
+import java.util.Collection;
+import java.util.Stack;
 
 import com.fasterxml.jackson.core.JsonFactory;
 import com.fasterxml.jackson.core.JsonParser;
 import org.junit.Test;
 import org.junit.runner.RunWith;
 import org.junit.runners.Parameterized;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertTrue;
-import static org.junit.Assert.assertFalse;
 
 @RunWith(Parameterized.class)
 public class TestBlockingIO {
diff --git a/lang/java/avro/src/test/java/org/apache/avro/io/TestBlockingIO2.java b/lang/java/avro/src/test/java/org/apache/avro/io/TestBlockingIO2.java
index 2aaefd4c6..54e03aa45 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/io/TestBlockingIO2.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/io/TestBlockingIO2.java
@@ -19,8 +19,8 @@
 
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
-import java.util.Collection;
 import java.util.Arrays;
+import java.util.Collection;
 
 import org.junit.Test;
 import org.junit.runner.RunWith;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/io/TestEncoders.java b/lang/java/avro/src/test/java/org/apache/avro/io/TestEncoders.java
index 1517693e5..f8f440765 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/io/TestEncoders.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/io/TestEncoders.java
@@ -17,6 +17,11 @@
  */
 package org.apache.avro.io;
 
+import static java.util.Arrays.asList;
+import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.is;
+import static org.junit.Assert.assertThat;
+
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.io.OutputStream;
@@ -25,23 +30,21 @@
 import java.nio.channels.FileChannel;
 import java.nio.file.Files;
 import java.nio.file.Path;
+import java.nio.file.Paths;
 import java.nio.file.StandardOpenOption;
 
+import com.fasterxml.jackson.core.JsonEncoding;
+import com.fasterxml.jackson.core.JsonFactory;
+import com.fasterxml.jackson.core.JsonGenerator;
 import org.apache.avro.AvroTypeException;
 import org.apache.avro.Schema;
 import org.apache.avro.Schema.Type;
 import org.apache.avro.generic.GenericDatumReader;
 import org.apache.avro.generic.GenericDatumWriter;
-import com.fasterxml.jackson.core.JsonEncoding;
-import com.fasterxml.jackson.core.JsonFactory;
-import com.fasterxml.jackson.core.JsonGenerator;
 import org.junit.Assert;
+import org.junit.Rule;
 import org.junit.Test;
-
-import static java.util.Arrays.asList;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.is;
-import static org.junit.Assert.assertThat;
+import org.junit.rules.TemporaryFolder;
 
 public class TestEncoders {
   private static final int ENCODER_BUFFER_SIZE = 32;
@@ -49,11 +52,14 @@
 
   private static EncoderFactory factory = EncoderFactory.get();
 
+  @Rule
+  public TemporaryFolder DIR = new TemporaryFolder();
+
   @Test
   public void testBinaryEncoderInit() throws IOException {
     OutputStream out = new ByteArrayOutputStream();
     BinaryEncoder enc = factory.binaryEncoder(out, null);
-    Assert.assertTrue(enc == factory.binaryEncoder(out, enc));
+    Assert.assertSame(enc, factory.binaryEncoder(out, enc));
   }
 
   @Test(expected=NullPointerException.class)
@@ -66,7 +72,7 @@ public void testBlockingBinaryEncoderInit() throws IOException {
     OutputStream out = new ByteArrayOutputStream();
     BinaryEncoder reuse = null;
     reuse = factory.blockingBinaryEncoder(out, reuse);
-    Assert.assertTrue(reuse == factory.blockingBinaryEncoder(out, reuse));
+    Assert.assertSame(reuse, factory.blockingBinaryEncoder(out, reuse));
     // comparison
   }
 
@@ -79,7 +85,7 @@ public void testBadBlockintBinaryEncoderInit() {
   public void testDirectBinaryEncoderInit() throws IOException {
     OutputStream out = new ByteArrayOutputStream();
     BinaryEncoder enc = factory.directBinaryEncoder(out, null);
-    Assert.assertTrue(enc ==  factory.directBinaryEncoder(out, enc));
+    Assert.assertSame(enc, factory.directBinaryEncoder(out, enc));
   }
 
   @Test(expected=NullPointerException.class)
@@ -216,7 +222,7 @@ public void testArrayBackedByteBuffer() throws IOException {
 
   @Test
   public void testMappedByteBuffer() throws IOException {
-    Path file = Files.createTempFile("test", "data");
+    Path file = Paths.get(DIR.getRoot().getPath() + "testMappedByteBuffer.avro");
     Files.write(file, someBytes(EXAMPLE_DATA_SIZE));
     MappedByteBuffer buffer = FileChannel.open(file, StandardOpenOption.READ).map(FileChannel.MapMode.READ_ONLY, 0, EXAMPLE_DATA_SIZE);
 
diff --git a/lang/java/avro/src/test/java/org/apache/avro/io/TestJsonDecoder.java b/lang/java/avro/src/test/java/org/apache/avro/io/TestJsonDecoder.java
index c63749840..eab6f25b3 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/io/TestJsonDecoder.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/io/TestJsonDecoder.java
@@ -18,11 +18,10 @@
 package org.apache.avro.io;
 
 import org.apache.avro.Schema;
-import org.apache.avro.generic.GenericRecord;
 import org.apache.avro.generic.GenericDatumReader;
-
-import org.junit.Test;
+import org.apache.avro.generic.GenericRecord;
 import org.junit.Assert;
+import org.junit.Test;
 
 public class TestJsonDecoder {
 
diff --git a/lang/java/avro/src/test/java/org/apache/avro/io/TestResolvingIO.java b/lang/java/avro/src/test/java/org/apache/avro/io/TestResolvingIO.java
index 3c96b5155..0b86b08b4 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/io/TestResolvingIO.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/io/TestResolvingIO.java
@@ -26,8 +26,8 @@
 import org.apache.avro.Schema;
 import org.apache.avro.io.TestValidatingIO.Encoding;
 import org.junit.Test;
-import org.junit.runners.Parameterized;
 import org.junit.runner.RunWith;
+import org.junit.runners.Parameterized;
 
 @RunWith(Parameterized.class)
 public class TestResolvingIO {
diff --git a/lang/java/avro/src/test/java/org/apache/avro/io/TestResolvingIOResolving.java b/lang/java/avro/src/test/java/org/apache/avro/io/TestResolvingIOResolving.java
index 4d5135de2..64e3aa6e6 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/io/TestResolvingIOResolving.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/io/TestResolvingIOResolving.java
@@ -17,14 +17,14 @@
  */
 package org.apache.avro.io;
 
-import org.junit.Test;
-import org.junit.runners.Parameterized;
-import org.junit.runner.RunWith;
-import org.apache.avro.Schema;
-
 import java.io.IOException;
-import java.util.Collection;
 import java.util.Arrays;
+import java.util.Collection;
+
+import org.apache.avro.Schema;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.junit.runners.Parameterized;
 
 @RunWith(Parameterized.class)
 public class TestResolvingIOResolving {
diff --git a/lang/java/avro/src/test/java/org/apache/avro/io/TestValidatingIO.java b/lang/java/avro/src/test/java/org/apache/avro/io/TestValidatingIO.java
index 6efe039a8..0d4112aaa 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/io/TestValidatingIO.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/io/TestValidatingIO.java
@@ -17,21 +17,14 @@
  */
 package org.apache.avro.io;
 
-import static org.junit.Assert.assertArrayEquals;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.fail;
+import static org.junit.Assert.*;
 
 import java.io.ByteArrayInputStream;
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.nio.ByteBuffer;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Random;
+import java.util.*;
 
 import org.apache.avro.Schema;
 import org.apache.avro.util.Utf8;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/io/parsing/SymbolTest.java b/lang/java/avro/src/test/java/org/apache/avro/io/parsing/SymbolTest.java
index 68a7bc673..ce4d7df96 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/io/parsing/SymbolTest.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/io/parsing/SymbolTest.java
@@ -20,6 +20,7 @@
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Set;
+
 import junit.framework.Assert;
 import org.apache.avro.Schema;
 import org.junit.Test;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/io/parsing/TestResolvingGrammarGenerator.java b/lang/java/avro/src/test/java/org/apache/avro/io/parsing/TestResolvingGrammarGenerator.java
index d96f771ce..bd0df52bc 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/io/parsing/TestResolvingGrammarGenerator.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/io/parsing/TestResolvingGrammarGenerator.java
@@ -24,6 +24,9 @@
 import java.util.Arrays;
 import java.util.Collection;
 
+import com.fasterxml.jackson.core.JsonFactory;
+import com.fasterxml.jackson.databind.JsonNode;
+import com.fasterxml.jackson.databind.ObjectMapper;
 import org.apache.avro.AvroTypeException;
 import org.apache.avro.Schema;
 import org.apache.avro.SchemaBuilder;
@@ -35,9 +38,6 @@
 import org.apache.avro.generic.GenericRecordBuilder;
 import org.apache.avro.io.Encoder;
 import org.apache.avro.io.EncoderFactory;
-import com.fasterxml.jackson.core.JsonFactory;
-import com.fasterxml.jackson.databind.JsonNode;
-import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Assert;
 import org.junit.Test;
 import org.junit.runner.RunWith;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/io/parsing/TestResolvingGrammarGenerator2.java b/lang/java/avro/src/test/java/org/apache/avro/io/parsing/TestResolvingGrammarGenerator2.java
index 494af621b..f83c9762e 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/io/parsing/TestResolvingGrammarGenerator2.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/io/parsing/TestResolvingGrammarGenerator2.java
@@ -18,10 +18,11 @@
 package org.apache.avro.io.parsing;
 
 import java.util.Arrays;
+
+import org.apache.avro.Schema;
 import org.apache.avro.SchemaBuilder;
 import org.apache.avro.SchemaValidationException;
 import org.apache.avro.SchemaValidatorBuilder;
-import org.apache.avro.Schema;
 import org.junit.Assert;
 import org.junit.Test;
 
diff --git a/lang/java/avro/src/test/java/org/apache/avro/message/TestBinaryMessageEncoding.java b/lang/java/avro/src/test/java/org/apache/avro/message/TestBinaryMessageEncoding.java
index 0685964a0..0c87189f1 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/message/TestBinaryMessageEncoding.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/message/TestBinaryMessageEncoding.java
@@ -19,6 +19,11 @@
 
 package org.apache.avro.message;
 
+import java.nio.ByteBuffer;
+import java.util.Arrays;
+import java.util.List;
+import java.util.Set;
+
 import com.google.common.collect.Iterables;
 import com.google.common.collect.Lists;
 import com.google.common.collect.Ordering;
@@ -31,10 +36,6 @@
 import org.apache.avro.generic.GenericRecordBuilder;
 import org.junit.Assert;
 import org.junit.Test;
-import java.nio.ByteBuffer;
-import java.util.Arrays;
-import java.util.List;
-import java.util.Set;
 
 public class TestBinaryMessageEncoding {
   public static final Schema SCHEMA_V1 = SchemaBuilder.record("TestRecord")
diff --git a/lang/java/avro/src/test/java/org/apache/avro/reflect/TestByteBuffer.java b/lang/java/avro/src/test/java/org/apache/avro/reflect/TestByteBuffer.java
index a8a8b7498..a46e1dc8a 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/reflect/TestByteBuffer.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/reflect/TestByteBuffer.java
@@ -20,12 +20,7 @@
 
 import static org.junit.Assert.*;
 
-import java.io.ByteArrayOutputStream;
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.FileNotFoundException;
-import java.io.FileOutputStream;
-import java.io.IOException;
+import java.io.*;
 import java.math.BigInteger;
 import java.nio.ByteBuffer;
 import java.nio.channels.FileChannel;
@@ -33,20 +28,22 @@
 import java.security.NoSuchAlgorithmException;
 import java.util.Iterator;
 
-import org.apache.avro.AvroTestUtil;
 import org.apache.avro.Schema;
 import org.apache.avro.file.DataFileReader;
 import org.apache.avro.file.DataFileWriter;
 import org.apache.avro.file.FileReader;
 import org.apache.avro.file.SeekableByteArrayInput;
 import org.apache.avro.io.DatumWriter;
-import org.apache.avro.reflect.ReflectData;
-import org.apache.avro.reflect.ReflectDatumReader;
-import org.apache.avro.reflect.ReflectDatumWriter;
 import org.junit.Before;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
 
 public class TestByteBuffer {
+
+  @Rule
+  public TemporaryFolder DIR = new TemporaryFolder();
+
   static class X{
     String name = "";
     ByteBuffer content;
@@ -54,13 +51,12 @@
   File content;
 
   @Before public void before() throws IOException{
-    File tmpdir = AvroTestUtil.tempDirectory(getClass(), "content");
-    content = new File(tmpdir,"test-content");
-    FileOutputStream out = new FileOutputStream(content);
-    for(int i=0;i<100000;i++){
-      out.write("hello world\n".getBytes());
+    content = new File(DIR.getRoot().getPath(),"test-content");
+    try(FileOutputStream out = new FileOutputStream(content)) {
+      for (int i = 0; i < 100000; i++) {
+        out.write("hello world\n".getBytes());
+      }
     }
-    out.close();
   }
 
   @Test public void test() throws Exception{
@@ -89,42 +85,30 @@ private X readOneXFromAvro(Schema schema, ByteArrayOutputStream bout)
   private void writeOneXAsAvro(Schema schema, ByteArrayOutputStream bout)
     throws IOException, FileNotFoundException {
     DatumWriter<X> datumWriter = new ReflectDatumWriter<>(schema);
-    DataFileWriter<X> writer = new DataFileWriter<>(datumWriter);
-    writer.create(schema, bout);
-    X x = new X();
-    x.name = "xxx";
-    FileInputStream fis = new FileInputStream(content);
-    try{
-      FileChannel channel = fis.getChannel();
-      try{
-        long contentLength = content.length();
-        //set the content to be a file channel.
-        ByteBuffer buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, contentLength);
-        x.content = buffer;
-        writer.append(x);
-      }finally{
-        channel.close();
+    try(DataFileWriter<X> writer = new DataFileWriter<>(datumWriter)) {
+      writer.create(schema, bout);
+      X x = new X();
+      x.name = "xxx";
+      try (FileInputStream fis = new FileInputStream(content)) {
+        try (FileChannel channel = fis.getChannel()) {
+          long contentLength = content.length();
+          //set the content to be a file channel.
+          ByteBuffer buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, contentLength);
+          x.content = buffer;
+          writer.append(x);
+        }
       }
-    }finally{
-      fis.close();
+      writer.flush();
     }
-    writer.flush();
-    writer.close();
   }
 
-  private String getmd5(File file) throws Exception{
-    FileInputStream fis = new FileInputStream(content);
-    try{
-      FileChannel channel = fis.getChannel();
-      try{
+  private String getmd5(File content) throws Exception{
+    try (FileInputStream fis = new FileInputStream(content)) {
+      try (FileChannel channel = fis.getChannel()) {
         long contentLength = content.length();
         ByteBuffer buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, contentLength);
         return getmd5(buffer);
-      }finally{
-        channel.close();
       }
-    }finally{
-      fis.close();
     }
   }
 
diff --git a/lang/java/avro/src/test/java/org/apache/avro/reflect/TestNonStringMapKeys.java b/lang/java/avro/src/test/java/org/apache/avro/reflect/TestNonStringMapKeys.java
index 458d52c29..2784fa238 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/reflect/TestNonStringMapKeys.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/reflect/TestNonStringMapKeys.java
@@ -17,19 +17,12 @@
  */
 package org.apache.avro.reflect;
 
+import static org.junit.Assert.*;
+
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Map;
+import java.util.*;
 import java.util.Map.Entry;
-
-import static org.junit.Assert.*;
-
-import java.util.TreeMap;
 import java.util.concurrent.ConcurrentHashMap;
 
 import org.apache.avro.Schema;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflect.java b/lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflect.java
index 3208f169c..45ee2af93 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflect.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflect.java
@@ -17,9 +17,7 @@
  */
 package org.apache.avro.reflect;
 
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.*;
 
 import java.io.ByteArrayInputStream;
 import java.io.ByteArrayOutputStream;
@@ -27,20 +25,9 @@
 import java.lang.reflect.Array;
 import java.lang.reflect.Type;
 import java.nio.ByteBuffer;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Random;
-
-import org.apache.avro.AvroRuntimeException;
-import org.apache.avro.AvroTypeException;
-import org.apache.avro.JsonProperties;
-import org.apache.avro.Protocol;
-import org.apache.avro.Schema;
-import org.apache.avro.SchemaBuilder;
+import java.util.*;
+
+import org.apache.avro.*;
 import org.apache.avro.Schema.Field;
 import org.apache.avro.generic.GenericData;
 import org.apache.avro.io.Decoder;
@@ -50,8 +37,6 @@
 import org.apache.avro.reflect.TestReflect.SampleRecord.AnotherSampleRecord;
 import org.junit.Test;
 
-import com.fasterxml.jackson.databind.node.NullNode;
-
 public class TestReflect {
 
   EncoderFactory factory = new EncoderFactory();
diff --git a/lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflectAllowNulls.java b/lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflectAllowNulls.java
index 1d374a444..948858884 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflectAllowNulls.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflectAllowNulls.java
@@ -18,6 +18,7 @@
 package org.apache.avro.reflect;
 
 import java.util.Arrays;
+
 import org.apache.avro.Schema;
 import org.junit.Assert;
 import org.junit.Test;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflectData.java b/lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflectData.java
index 3525d7b64..6528ad889 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflectData.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflectData.java
@@ -18,13 +18,13 @@
 
 package org.apache.avro.reflect;
 
-import org.apache.avro.Schema;
-import org.junit.Test;
+import static org.hamcrest.Matchers.lessThan;
+import static org.junit.Assert.assertThat;
 
 import java.util.Collections;
 
-import static org.hamcrest.Matchers.lessThan;
-import static org.junit.Assert.assertThat;
+import org.apache.avro.Schema;
+import org.junit.Test;
 
 public class TestReflectData {
   @Test
diff --git a/lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflectLogicalTypes.java b/lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflectLogicalTypes.java
index 23348be2d..356afe3fe 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflectLogicalTypes.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflectLogicalTypes.java
@@ -25,12 +25,8 @@
 import java.util.Arrays;
 import java.util.List;
 import java.util.UUID;
-import org.apache.avro.Conversion;
-import org.apache.avro.Conversions;
-import org.apache.avro.LogicalType;
-import org.apache.avro.LogicalTypes;
-import org.apache.avro.Schema;
-import org.apache.avro.SchemaBuilder;
+
+import org.apache.avro.*;
 import org.apache.avro.file.DataFileReader;
 import org.apache.avro.file.DataFileWriter;
 import org.apache.avro.file.FileReader;
@@ -40,11 +36,7 @@
 import org.apache.avro.io.DatumReader;
 import org.apache.avro.io.DatumWriter;
 import org.apache.avro.specific.SpecificData;
-import org.junit.Assert;
-import org.junit.Assume;
-import org.junit.BeforeClass;
-import org.junit.Rule;
-import org.junit.Test;
+import org.junit.*;
 import org.junit.rules.TemporaryFolder;
 
 /**
diff --git a/lang/java/avro/src/test/java/org/apache/avro/specific/TestRecordWithJsr310LogicalTypes.java b/lang/java/avro/src/test/java/org/apache/avro/specific/TestRecordWithJsr310LogicalTypes.java
index c42b3ca0d..56e31f4b7 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/specific/TestRecordWithJsr310LogicalTypes.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/specific/TestRecordWithJsr310LogicalTypes.java
@@ -5,8 +5,8 @@
  */
 package org.apache.avro.specific;
 
-import org.apache.avro.message.BinaryMessageEncoder;
 import org.apache.avro.message.BinaryMessageDecoder;
+import org.apache.avro.message.BinaryMessageEncoder;
 import org.apache.avro.message.SchemaStore;
 
 @SuppressWarnings("all")
diff --git a/lang/java/avro/src/test/java/org/apache/avro/specific/TestRecordWithLogicalTypes.java b/lang/java/avro/src/test/java/org/apache/avro/specific/TestRecordWithLogicalTypes.java
index 17e74ae2f..3029e39c0 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/specific/TestRecordWithLogicalTypes.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/specific/TestRecordWithLogicalTypes.java
@@ -5,12 +5,12 @@
  */
 package org.apache.avro.specific;
 
+import java.math.BigDecimal;
+
 import org.apache.avro.data.TimeConversions;
 import org.apache.avro.message.BinaryMessageDecoder;
 import org.apache.avro.message.BinaryMessageEncoder;
 
-import java.math.BigDecimal;
-
 @SuppressWarnings("all")
 @org.apache.avro.specific.AvroGenerated
 public class TestRecordWithLogicalTypes extends org.apache.avro.specific.SpecificRecordBase implements org.apache.avro.specific.SpecificRecord {
diff --git a/lang/java/avro/src/test/java/org/apache/avro/specific/TestRecordWithoutLogicalTypes.java b/lang/java/avro/src/test/java/org/apache/avro/specific/TestRecordWithoutLogicalTypes.java
index 21d2d6f3b..2fe601254 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/specific/TestRecordWithoutLogicalTypes.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/specific/TestRecordWithoutLogicalTypes.java
@@ -5,9 +5,10 @@
  */
 package org.apache.avro.specific;
 
+import java.nio.ByteBuffer;
+
 import org.apache.avro.message.BinaryMessageDecoder;
 import org.apache.avro.message.BinaryMessageEncoder;
-import java.nio.ByteBuffer;
 
 @SuppressWarnings("all")
 @org.apache.avro.specific.AvroGenerated
diff --git a/lang/java/avro/src/test/java/org/apache/avro/specific/TestSpecificData.java b/lang/java/avro/src/test/java/org/apache/avro/specific/TestSpecificData.java
index 6dede6904..037ea6221 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/specific/TestSpecificData.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/specific/TestSpecificData.java
@@ -18,17 +18,12 @@
 
 package org.apache.avro.specific;
 
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.assertTrue;
-import static org.junit.Assert.fail;
+import static org.junit.Assert.*;
 
 import java.io.ByteArrayInputStream;
 import java.io.ByteArrayOutputStream;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
-
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
diff --git a/lang/java/avro/src/test/java/org/apache/avro/specific/TestSpecificLogicalTypes.java b/lang/java/avro/src/test/java/org/apache/avro/specific/TestSpecificLogicalTypes.java
index 9a9fec410..ba8923980 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/specific/TestSpecificLogicalTypes.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/specific/TestSpecificLogicalTypes.java
@@ -17,6 +17,20 @@
  */
 package org.apache.avro.specific;
 
+import static java.time.format.DateTimeFormatter.ISO_INSTANT;
+import static java.time.format.DateTimeFormatter.ISO_LOCAL_DATE;
+import static org.hamcrest.Matchers.*;
+
+import java.io.File;
+import java.io.IOException;
+import java.math.BigDecimal;
+import java.time.format.DateTimeFormatter;
+import java.time.format.DateTimeFormatterBuilder;
+import java.time.temporal.ChronoField;
+import java.time.temporal.ChronoUnit;
+import java.util.ArrayList;
+import java.util.List;
+
 import org.apache.avro.Conversions;
 import org.apache.avro.LogicalTypes;
 import org.apache.avro.Schema;
@@ -37,21 +51,6 @@
 import org.junit.Rule;
 import org.junit.Test;
 import org.junit.rules.TemporaryFolder;
-import java.io.File;
-import java.io.IOException;
-import java.math.BigDecimal;
-import java.time.format.DateTimeFormatter;
-import java.time.temporal.ChronoUnit;
-import java.util.ArrayList;
-import java.util.List;
-
-import static java.time.format.DateTimeFormatter.ISO_INSTANT;
-import static java.time.format.DateTimeFormatter.ISO_LOCAL_DATE;
-import static java.time.format.DateTimeFormatter.ISO_LOCAL_TIME;
-import static org.hamcrest.Matchers.comparesEqualTo;
-import static org.hamcrest.Matchers.empty;
-import static org.hamcrest.Matchers.is;
-import static org.hamcrest.Matchers.not;
 
 /**
  * This tests compatibility between classes generated before and after
@@ -71,6 +70,21 @@
  */
 public class TestSpecificLogicalTypes {
 
+  // Override the default ISO_LOCAL_TIME to make sure that there are
+  // trailing zero's in the format:
+  // Expected: is "22:07:33.880"
+  //     but: was "22:07:33.88"
+  private static final DateTimeFormatter ISO_LOCAL_TIME = new DateTimeFormatterBuilder()
+          .appendValue(ChronoField.HOUR_OF_DAY, 2)
+          .appendLiteral(':')
+          .appendValue(ChronoField.MINUTE_OF_HOUR, 2)
+          .optionalStart()
+          .appendLiteral(':')
+          .appendValue(ChronoField.SECOND_OF_MINUTE, 2)
+          .optionalStart()
+          .appendFraction(ChronoField.NANO_OF_SECOND, 3, 3, true)
+          .toFormatter();
+
   @Rule
   public final TemporaryFolder temp = new TemporaryFolder();
 
diff --git a/lang/java/avro/src/test/java/org/apache/avro/specific/TestSpecificToFromByteArray.java b/lang/java/avro/src/test/java/org/apache/avro/specific/TestSpecificToFromByteArray.java
index 9cc10e302..b151003d7 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/specific/TestSpecificToFromByteArray.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/specific/TestSpecificToFromByteArray.java
@@ -17,6 +17,12 @@
  */
 package org.apache.avro.specific;
 
+import static org.junit.Assert.assertEquals;
+
+import java.io.IOException;
+import java.math.BigDecimal;
+import java.nio.ByteBuffer;
+
 import org.apache.avro.Conversions;
 import org.apache.avro.LogicalTypes;
 import org.apache.avro.data.TimeConversions;
@@ -26,11 +32,6 @@
 import org.joda.time.LocalDate;
 import org.joda.time.LocalTime;
 import org.junit.Test;
-import java.io.IOException;
-import java.math.BigDecimal;
-import java.nio.ByteBuffer;
-
-import static org.junit.Assert.assertEquals;
 
 public class TestSpecificToFromByteArray {
   @Test
diff --git a/lang/java/avro/src/test/java/org/apache/avro/util/CaseFinder.java b/lang/java/avro/src/test/java/org/apache/avro/util/CaseFinder.java
index 56a24a6b2..ea5bf2b20 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/util/CaseFinder.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/util/CaseFinder.java
@@ -20,8 +20,8 @@
 import java.io.BufferedReader;
 import java.io.IOException;
 import java.util.List;
-import java.util.regex.Pattern;
 import java.util.regex.Matcher;
+import java.util.regex.Pattern;
 
 /** Parser for files containing test cases consisting of
  * <code>&lt;String,String&gt;</code> pairs, where the first string is
diff --git a/lang/java/avro/src/test/java/org/apache/avro/util/TestCaseFinder.java b/lang/java/avro/src/test/java/org/apache/avro/util/TestCaseFinder.java
index 4cf6bdaf8..cd958be16 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/util/TestCaseFinder.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/util/TestCaseFinder.java
@@ -17,19 +17,19 @@
  */
 package org.apache.avro.util;
 
+import static org.junit.Assert.assertTrue;
+
+import java.io.BufferedReader;
+import java.io.StringReader;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
-import java.io.BufferedReader;
-import java.io.StringReader;
 
 import org.junit.Test;
+import org.junit.experimental.runners.Enclosed;
 import org.junit.runner.RunWith;
 import org.junit.runners.Parameterized;
 import org.junit.runners.Parameterized.Parameters;
-import org.junit.experimental.runners.Enclosed;
-
-import static org.junit.Assert.assertTrue;
 
 @RunWith(Enclosed.class)
 public class TestCaseFinder {
diff --git a/lang/java/avro/src/test/java/org/apache/avro/util/TestUtf8.java b/lang/java/avro/src/test/java/org/apache/avro/util/TestUtf8.java
index 3272ea378..04709f57e 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/util/TestUtf8.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/util/TestUtf8.java
@@ -17,13 +17,13 @@
  */
 package org.apache.avro.util;
 
+import static junit.framework.Assert.assertSame;
+import static org.junit.Assert.assertEquals;
+
 import java.io.UnsupportedEncodingException;
 
 import org.junit.Test;
 
-import static junit.framework.Assert.assertSame;
-import static org.junit.Assert.assertEquals;
-
 public class TestUtf8 {
   @Test public void testByteConstructor() throws Exception {
     byte[] bs = "Foo".getBytes("UTF-8");
diff --git a/lang/java/avro/src/test/java/org/apache/avro/util/internal/TestJacksonUtils.java b/lang/java/avro/src/test/java/org/apache/avro/util/internal/TestJacksonUtils.java
index 556a91a1c..9ad0eb734 100644
--- a/lang/java/avro/src/test/java/org/apache/avro/util/internal/TestJacksonUtils.java
+++ b/lang/java/avro/src/test/java/org/apache/avro/util/internal/TestJacksonUtils.java
@@ -17,27 +17,19 @@
  */
 package org.apache.avro.util.internal;
 
+import static org.apache.avro.util.internal.JacksonUtils.toJsonNode;
+import static org.apache.avro.util.internal.JacksonUtils.toObject;
+import static org.junit.Assert.assertArrayEquals;
+import static org.junit.Assert.assertEquals;
+
 import java.util.Collections;
+
+import com.fasterxml.jackson.databind.node.*;
 import org.apache.avro.JsonProperties;
 import org.apache.avro.Schema;
 import org.apache.avro.SchemaBuilder;
-import com.fasterxml.jackson.databind.node.ArrayNode;
-import com.fasterxml.jackson.databind.node.BooleanNode;
-import com.fasterxml.jackson.databind.node.DoubleNode;
-import com.fasterxml.jackson.databind.node.FloatNode;
-import com.fasterxml.jackson.databind.node.IntNode;
-import com.fasterxml.jackson.databind.node.JsonNodeFactory;
-import com.fasterxml.jackson.databind.node.LongNode;
-import com.fasterxml.jackson.databind.node.NullNode;
-import com.fasterxml.jackson.databind.node.ObjectNode;
-import com.fasterxml.jackson.databind.node.TextNode;
 import org.junit.Test;
 
-import static org.apache.avro.util.internal.JacksonUtils.toJsonNode;
-import static org.apache.avro.util.internal.JacksonUtils.toObject;
-import static org.junit.Assert.assertArrayEquals;
-import static org.junit.Assert.assertEquals;
-
 public class TestJacksonUtils {
 
   enum Direction {
diff --git a/lang/java/compiler/src/test/java/org/apache/avro/compiler/specific/TestSpecificCompiler.java b/lang/java/compiler/src/test/java/org/apache/avro/compiler/specific/TestSpecificCompiler.java
index ceae52c12..d9936726a 100644
--- a/lang/java/compiler/src/test/java/org/apache/avro/compiler/specific/TestSpecificCompiler.java
+++ b/lang/java/compiler/src/test/java/org/apache/avro/compiler/specific/TestSpecificCompiler.java
@@ -31,22 +31,19 @@
 import java.io.FileInputStream;
 import java.io.FileReader;
 import java.io.IOException;
-import java.net.URISyntaxException;
 import java.nio.charset.Charset;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.List;
 
-import org.apache.avro.AvroTestUtil;
 import org.apache.avro.LogicalTypes;
 import org.apache.avro.Schema;
 import org.apache.avro.SchemaBuilder;
 import org.apache.avro.generic.GenericData.StringType;
-import org.junit.After;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Test;
+import org.junit.*;
+import org.junit.rules.TemporaryFolder;
+import org.junit.rules.TestName;
 import org.junit.runner.RunWith;
 import org.junit.runners.JUnit4;
 import org.slf4j.Logger;
@@ -63,65 +60,51 @@
 public class TestSpecificCompiler {
   private static final Logger LOG = LoggerFactory.getLogger(TestSpecificCompiler.class);
 
-  private final String schemaSrcPath = "src/test/resources/simple_record.avsc";
-  private final String velocityTemplateDir =
-      "src/main/velocity/org/apache/avro/compiler/specific/templates/java/classic/";
-  private File src;
-  private File outputDir;
+  @Rule
+  public TemporaryFolder OUTPUT_DIR = new TemporaryFolder();
+
+  @Rule public TestName name = new TestName();
+
   private File outputFile;
 
   @Before
   public void setUp() {
-    this.src = new File(this.schemaSrcPath);
-    this.outputDir = AvroTestUtil.tempDirectory(getClass(), "specific-output");
-    this.outputFile = new File(this.outputDir, "SimpleRecord.java");
-    if (outputFile.exists() && !outputFile.delete()) {
-      throw new IllegalStateException("unable to delete " + outputFile);
-    }
+    this.outputFile = new File(this.OUTPUT_DIR.getRoot(), "SimpleRecord.java");
   }
 
-  @After
-  public void tearDown() {
-    if (this.outputFile != null) {
-      this.outputFile.delete();
-    }
-  }
+  private File src = new File("src/test/resources/simple_record.avsc");
 
   /** Uses the system's java compiler to actually compile the generated code. */
-  static void assertCompilesWithJavaCompiler(Collection<SpecificCompiler.OutputFile> outputs)
-          throws IOException {
-    if (outputs.isEmpty())
+  static void assertCompilesWithJavaCompiler(File dstDir, Collection<SpecificCompiler.OutputFile> outputs) throws IOException {
+    if (outputs.isEmpty()) {
       return;               // Nothing to compile!
+    }
 
     JavaCompiler compiler = ToolProvider.getSystemJavaCompiler();
     StandardJavaFileManager fileManager =
             compiler.getStandardFileManager(null, null, null);
 
-    File dstDir = AvroTestUtil.tempFile(TestSpecificCompiler.class, "realCompiler");
     List<File> javaFiles = new ArrayList<>();
     for (SpecificCompiler.OutputFile o : outputs) {
       javaFiles.add(o.writeToDestination(null, dstDir));
     }
 
     final List<Diagnostic<?>> warnings = new ArrayList<>();
-    DiagnosticListener<JavaFileObject> diagnosticListener = new DiagnosticListener<JavaFileObject>() {
-      @Override
-      public void report(Diagnostic<? extends JavaFileObject> diagnostic) {
-        switch (diagnostic.getKind()) {
-        case ERROR:
-          // Do not add these to warnings because they will fail the compile, anyway.
-          LOG.error("{}", diagnostic);
-          break;
-        case WARNING:
-        case MANDATORY_WARNING:
-          LOG.warn("{}", diagnostic);
-          warnings.add(diagnostic);
-          break;
-        case NOTE:
-        case OTHER:
-          LOG.debug("{}", diagnostic);
-          break;
-        }
+    DiagnosticListener<JavaFileObject> diagnosticListener = diagnostic -> {
+      switch (diagnostic.getKind()) {
+      case ERROR:
+        // Do not add these to warnings because they will fail the compile, anyway.
+        LOG.error("{}", diagnostic);
+        break;
+      case WARNING:
+      case MANDATORY_WARNING:
+        LOG.warn("{}", diagnostic);
+        warnings.add(diagnostic);
+        break;
+      case NOTE:
+      case OTHER:
+        LOG.debug("{}", diagnostic);
+        break;
       }
     };
     JavaCompiler.CompilationTask cTask = compiler.getTask(null, fileManager,
@@ -151,16 +134,17 @@ private SpecificCompiler createCompiler(SpecificCompiler.DateTimeLogicalTypeImpl
     Schema.Parser parser = new Schema.Parser();
     Schema schema = parser.parse(this.src);
     SpecificCompiler compiler = new SpecificCompiler(schema, dateTimeLogicalTypeImplementation);
-    compiler.setTemplateDir(this.velocityTemplateDir);
+    String velocityTemplateDir = "src/main/velocity/org/apache/avro/compiler/specific/templates/java/classic/";
+    compiler.setTemplateDir(velocityTemplateDir);
     compiler.setStringType(StringType.CharSequence);
     return compiler;
   }
 
   @Test
-  public void testCanReadTemplateFilesOnTheFilesystem() throws IOException, URISyntaxException{
+  public void testCanReadTemplateFilesOnTheFilesystem() throws IOException {
     SpecificCompiler compiler = createCompiler();
-    compiler.compileToDestination(this.src, this.outputDir);
-    assertTrue(this.outputFile.exists());
+    compiler.compileToDestination(this.src, OUTPUT_DIR.getRoot());
+    assertTrue(new File(OUTPUT_DIR.getRoot(),"SimpleRecord.java").exists());
   }
 
   @Test
@@ -170,54 +154,54 @@ public void testPublicFieldVisibility() throws IOException {
     assertFalse(compiler.deprecatedFields());
     assertTrue(compiler.publicFields());
     assertFalse(compiler.privateFields());
-    compiler.compileToDestination(this.src, this.outputDir);
+    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());
     assertTrue(this.outputFile.exists());
-    BufferedReader reader = new BufferedReader(new FileReader(this.outputFile));
-    String line = null;
-    while ((line = reader.readLine()) != null) {
-      // No line, once trimmed, should start with a deprecated field declaration
-      // nor a private field declaration.  Since the nested builder uses private
-      // fields, we cannot do the second check.
-      line = line.trim();
-      assertFalse("Line started with a deprecated field declaration: " + line,
-        line.startsWith("@Deprecated public int value"));
+    try(BufferedReader reader = new BufferedReader(new FileReader(this.outputFile))) {
+      String line;
+      while ((line = reader.readLine()) != null) {
+        // No line, once trimmed, should start with a deprecated field declaration
+        // nor a private field declaration.  Since the nested builder uses private
+        // fields, we cannot do the second check.
+        line = line.trim();
+        assertFalse("Line started with a deprecated field declaration: " + line,
+                line.startsWith("@Deprecated public int value"));
+      }
     }
-    reader.close();
   }
 
   @Test
   public void testCreateAllArgsConstructor() throws Exception {
     SpecificCompiler compiler = createCompiler();
-    compiler.compileToDestination(this.src, this.outputDir);
+    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());
     assertTrue(this.outputFile.exists());
-    BufferedReader reader = new BufferedReader(new FileReader(this.outputFile));
-    String line = null;
     boolean foundAllArgsConstructor = false;
-    while (!foundAllArgsConstructor && (line = reader.readLine()) != null) {
-      foundAllArgsConstructor = line.contains("All-args constructor");
+    try(BufferedReader reader = new BufferedReader(new FileReader(this.outputFile))) {
+      String line;
+      while (!foundAllArgsConstructor && (line = reader.readLine()) != null) {
+        foundAllArgsConstructor = line.contains("All-args constructor");
+      }
     }
-    reader.close();
     assertTrue(foundAllArgsConstructor);
   }
 
   @Test
   public void testMaxValidParameterCounts() throws Exception {
     Schema validSchema1 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT, 0);
-    assertCompilesWithJavaCompiler(new SpecificCompiler(validSchema1).compile());
+    assertCompilesWithJavaCompiler(new File(OUTPUT_DIR.getRoot(), name.getMethodName() + "1"), new SpecificCompiler(validSchema1).compile());
 
     Schema validSchema2 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT - 2, 1);
-    assertCompilesWithJavaCompiler(new SpecificCompiler(validSchema1).compile());
+    assertCompilesWithJavaCompiler(new File(OUTPUT_DIR.getRoot(), name.getMethodName() + "2"), new SpecificCompiler(validSchema1).compile());
   }
 
   @Test
   public void testInvalidParameterCounts() throws Exception {
     Schema invalidSchema1 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT + 1, 0);
     SpecificCompiler compiler = new SpecificCompiler(invalidSchema1);
-    assertCompilesWithJavaCompiler(compiler.compile());
+    assertCompilesWithJavaCompiler(new File(OUTPUT_DIR.getRoot(), name.getMethodName() + "1"), compiler.compile());
 
     Schema invalidSchema2 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT, 10);
     compiler = new SpecificCompiler(invalidSchema2);
-    assertCompilesWithJavaCompiler(compiler.compile());
+    assertCompilesWithJavaCompiler(new File(OUTPUT_DIR.getRoot(), name.getMethodName() + "2"), compiler.compile());
   }
 
   @Test
@@ -247,10 +231,10 @@ public void testPublicDeprecatedFieldVisibility() throws IOException {
     assertTrue(compiler.deprecatedFields());
     assertTrue(compiler.publicFields());
     assertFalse(compiler.privateFields());
-    compiler.compileToDestination(this.src, this.outputDir);
+    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());
     assertTrue(this.outputFile.exists());
     BufferedReader reader = new BufferedReader(new FileReader(this.outputFile));
-    String line = null;
+    String line;
     while ((line = reader.readLine()) != null) {
       // No line, once trimmed, should start with a public field declaration
       line = line.trim();
@@ -267,7 +251,7 @@ public void testPrivateFieldVisibility() throws IOException {
     assertFalse(compiler.deprecatedFields());
     assertFalse(compiler.publicFields());
     assertTrue(compiler.privateFields());
-    compiler.compileToDestination(this.src, this.outputDir);
+    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());
     assertTrue(this.outputFile.exists());
     BufferedReader reader = new BufferedReader(new FileReader(this.outputFile));
     String line = null;
@@ -287,19 +271,19 @@ public void testPrivateFieldVisibility() throws IOException {
   public void testSettersCreatedByDefault() throws IOException {
     SpecificCompiler compiler = createCompiler();
     assertTrue(compiler.isCreateSetters());
-    compiler.compileToDestination(this.src, this.outputDir);
+    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());
     assertTrue(this.outputFile.exists());
-    BufferedReader reader = new BufferedReader(new FileReader(this.outputFile));
     int foundSetters = 0;
-    String line = null;
-    while ((line = reader.readLine()) != null) {
-      // We should find the setter in the main class
-      line = line.trim();
-      if (line.startsWith("public void setValue(")) {
-        foundSetters++;
+    try(BufferedReader reader = new BufferedReader(new FileReader(this.outputFile))) {
+      String line;
+      while ((line = reader.readLine()) != null) {
+        // We should find the setter in the main class
+        line = line.trim();
+        if (line.startsWith("public void setValue(")) {
+          foundSetters++;
+        }
       }
     }
-    reader.close();
     assertEquals("Found the wrong number of setters", 1, foundSetters);
   }
 
@@ -308,24 +292,24 @@ public void testSettersNotCreatedWhenOptionTurnedOff() throws IOException {
     SpecificCompiler compiler = createCompiler();
     compiler.setCreateSetters(false);
     assertFalse(compiler.isCreateSetters());
-    compiler.compileToDestination(this.src, this.outputDir);
+    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());
     assertTrue(this.outputFile.exists());
-    BufferedReader reader = new BufferedReader(new FileReader(this.outputFile));
-    String line = null;
-    while ((line = reader.readLine()) != null) {
-      // No setter should be found
-      line = line.trim();
-      assertFalse("No line should include the setter: " + line,
-        line.startsWith("public void setValue("));
+    try(BufferedReader reader = new BufferedReader(new FileReader(this.outputFile))) {
+      String line;
+      while ((line = reader.readLine()) != null) {
+        // No setter should be found
+        line = line.trim();
+        assertFalse("No line should include the setter: " + line,
+                line.startsWith("public void setValue("));
+      }
     }
-    reader.close();
   }
 
   @Test
   public void testSettingOutputCharacterEncoding() throws Exception {
     SpecificCompiler compiler = createCompiler();
     // Generated file in default encoding
-    compiler.compileToDestination(this.src, this.outputDir);
+    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());
     byte[] fileInDefaultEncoding = new byte[(int) this.outputFile.length()];
     FileInputStream is = new FileInputStream(this.outputFile);
     is.read(fileInDefaultEncoding);
@@ -336,7 +320,7 @@ public void testSettingOutputCharacterEncoding() throws Exception {
     // Generate file in another encoding (make sure it has different number of bytes per character)
     String differentEncoding = Charset.defaultCharset().equals(Charset.forName("UTF-16")) ? "UTF-32" : "UTF-16";
     compiler.setOutputCharacterEncoding(differentEncoding);
-    compiler.compileToDestination(this.src, this.outputDir);
+    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());
     byte[] fileInDifferentEncoding = new byte[(int) this.outputFile.length()];
     is = new FileInputStream(this.outputFile);
     is.read(fileInDifferentEncoding);
@@ -546,7 +530,7 @@ public void testNullableTypesJavaUnbox() throws Exception {
   public void testLogicalTypesWithMultipleFields() throws Exception {
     Schema logicalTypesWithMultipleFields = new Schema.Parser().parse(
         new File("src/test/resources/logical_types_with_multiple_fields.avsc"));
-    assertCompilesWithJavaCompiler(
+    assertCompilesWithJavaCompiler(new File(OUTPUT_DIR.getRoot(), name.getMethodName()),
         new SpecificCompiler(logicalTypesWithMultipleFields).compile());
   }
 
@@ -554,7 +538,7 @@ public void testLogicalTypesWithMultipleFields() throws Exception {
   public void testUnionAndFixedFields() throws Exception {
     Schema unionTypesWithMultipleFields = new Schema.Parser().parse(
         new File("src/test/resources/union_and_fixed_fields.avsc"));
-    assertCompilesWithJavaCompiler(
+    assertCompilesWithJavaCompiler(new File(this.outputFile, name.getMethodName()),
         new SpecificCompiler(unionTypesWithMultipleFields).compile());
   }
 
@@ -562,7 +546,7 @@ public void testUnionAndFixedFields() throws Exception {
   public void testLogicalTypesWithMultipleFieldsJsr310DateTime() throws Exception {
     Schema logicalTypesWithMultipleFields = new Schema.Parser().parse(
         new File("src/test/resources/logical_types_with_multiple_fields.avsc"));
-    assertCompilesWithJavaCompiler(
+    assertCompilesWithJavaCompiler(new File(this.outputFile, name.getMethodName()),
         new SpecificCompiler(logicalTypesWithMultipleFields, JSR310).compile());
   }
 
diff --git a/lang/java/ipc/src/test/java/org/apache/avro/DataFileInteropTest.java b/lang/java/ipc/src/test/java/org/apache/avro/DataFileInteropTest.java
index ed4c95b41..08c872714 100644
--- a/lang/java/ipc/src/test/java/org/apache/avro/DataFileInteropTest.java
+++ b/lang/java/ipc/src/test/java/org/apache/avro/DataFileInteropTest.java
@@ -19,6 +19,7 @@
 
 import java.io.File;
 import java.io.IOException;
+import java.util.Objects;
 
 import org.apache.avro.file.DataFileReader;
 import org.apache.avro.file.FileReader;
@@ -32,33 +33,25 @@
 public class DataFileInteropTest {
 
   private static final File DATAFILE_DIR =
-    new File(System.getProperty("test.dir", "/tmp"));
+          new File(System.getProperty("test.dir", "/tmp"));
 
   @BeforeClass
   public static void printDir() {
     System.out.println("Reading data files from directory: "
-        + DATAFILE_DIR.getAbsolutePath());
+            + DATAFILE_DIR.getAbsolutePath());
   }
 
   @Test
   public void testGeneratedGeneric() throws IOException {
     System.out.println("Reading with generic:");
-    DatumReaderProvider<Object> provider = new DatumReaderProvider<Object>() {
-      @Override public DatumReader<Object> get() {
-        return new GenericDatumReader<>();
-        }
-      };
+    DatumReaderProvider<Object> provider = GenericDatumReader::new;
     readFiles(provider);
   }
 
   @Test
   public void testGeneratedSpecific() throws IOException {
     System.out.println("Reading with specific:");
-    DatumReaderProvider<Interop> provider = new DatumReaderProvider<Interop>() {
-      @Override public DatumReader<Interop> get() {
-        return new SpecificDatumReader<>();
-        }
-      };
+    DatumReaderProvider<Interop> provider = SpecificDatumReader::new;
     readFiles(provider);
   }
 
@@ -85,12 +78,12 @@ public void testGeneratedSpecific() throws IOException {
 //   }
 
   private  <T extends Object> void readFiles(DatumReaderProvider<T> provider) throws IOException {
-    for (File f : DATAFILE_DIR.listFiles()) {
+    for (File f : Objects.requireNonNull(DATAFILE_DIR.listFiles())) {
       System.out.println("Reading: " + f.getName());
-      FileReader<? extends Object> reader = DataFileReader.openReader(f,
-          provider.get());
-      for (Object datum : reader) {
-        Assert.assertNotNull(datum);
+      try(FileReader<? extends Object> reader = DataFileReader.openReader(f, provider.get())) {
+        for (Object datum : reader) {
+          Assert.assertNotNull(datum);
+        }
       }
     }
   }
@@ -99,4 +92,4 @@ public void testGeneratedSpecific() throws IOException {
     public DatumReader<T> get();
   }
 
-}
+}
\ No newline at end of file
diff --git a/lang/java/ipc/src/test/java/org/apache/avro/TestDataFileSpecific.java b/lang/java/ipc/src/test/java/org/apache/avro/TestDataFileSpecific.java
index 19374b416..da7ea8cf4 100644
--- a/lang/java/ipc/src/test/java/org/apache/avro/TestDataFileSpecific.java
+++ b/lang/java/ipc/src/test/java/org/apache/avro/TestDataFileSpecific.java
@@ -19,6 +19,7 @@
 
 import java.io.File;
 import java.io.IOException;
+import java.nio.file.Files;
 
 import org.apache.avro.file.DataFileReader;
 import org.apache.avro.file.DataFileWriter;
@@ -27,47 +28,49 @@
 import org.apache.avro.specific.SpecificDatumReader;
 
 import org.junit.Assert;
+import org.junit.Rule;
 import org.junit.Test;
 
 import org.apache.avro.Foo;
+import org.junit.rules.TemporaryFolder;
 
 public class TestDataFileSpecific {
 
-  private static final File DIR =
-    new File(System.getProperty("test.dir","/tmp"));
-  private static final File FILE = new File(DIR, "specific.avro");
+  @Rule
+  public TemporaryFolder DIR = new TemporaryFolder();
 
   /* Test when using SpecificDatumReader<T>() constructor to read from a file
    * with a different schema that both reader & writer schemas are found.*/
   @Test
   public void testSpecificDatumReaderDefaultCtor() throws IOException {
+    File file = new File(DIR.getRoot().getPath(), "testSpecificDatumReaderDefaultCtor");
+
     // like the specific Foo, but with another field
     Schema s1 = Schema.parse("{\"type\":\"record\",\"name\":\"Foo\","
-                             +"\"namespace\":\"org.apache.avro\",\"fields\":["
-                             +"{\"name\":\"label\",\"type\":\"string\"},"
-                             +"{\"name\":\"id\",\"type\":\"int\"}]}");
+            + "\"namespace\":\"org.apache.avro\",\"fields\":["
+            + "{\"name\":\"label\",\"type\":\"string\"},"
+            + "{\"name\":\"id\",\"type\":\"int\"}]}");
 
     // write a file using generic objects
-    DataFileWriter<Record> writer
-      = new DataFileWriter<>(new GenericDatumWriter<Record>(s1))
-      .create(s1, FILE);
-    for (int i = 0; i < 10; i++) {
-      Record r = new Record(s1);
-      r.put("label", ""+i);
-      r.put("id", i);
-      writer.append(r);
+    try (DataFileWriter<Record> writer =
+                 new DataFileWriter<>(new GenericDatumWriter<Record>(s1)).create(s1, file)) {
+      for (int i = 0; i < 10; i++) {
+        Record r = new Record(s1);
+        r.put("label", "" + i);
+        r.put("id", i);
+        writer.append(r);
+      }
     }
-    writer.close();
 
     // read using a 'new SpecificDatumReader<T>()' to force inference of
     // reader's schema from runtime
-    DataFileReader<Foo> reader =
-      new DataFileReader<>(FILE, new SpecificDatumReader<>());
-    int i = 0;
-    for (Foo f : reader)
-      Assert.assertEquals(""+(i++), f.getLabel());
-    Assert.assertEquals(10, i);
-    reader.close();
+    try (DataFileReader<Foo> reader = new DataFileReader<>(file, new SpecificDatumReader<>())) {
+      int i = 0;
+      for (Foo f : reader) {
+        Assert.assertEquals("" + (i++), f.getLabel());
+      }
+      Assert.assertEquals(10, i);
+    }
   }
 
 }
diff --git a/lang/java/ipc/src/test/java/org/apache/avro/TestProtocolSpecific.java b/lang/java/ipc/src/test/java/org/apache/avro/TestProtocolSpecific.java
index 77340fc3b..ea79b27eb 100644
--- a/lang/java/ipc/src/test/java/org/apache/avro/TestProtocolSpecific.java
+++ b/lang/java/ipc/src/test/java/org/apache/avro/TestProtocolSpecific.java
@@ -51,17 +51,13 @@
 import java.net.InetSocketAddress;
 import java.net.URL;
 import java.nio.ByteBuffer;
-import java.util.Random;
-import java.util.List;
-import java.util.ArrayList;
-import java.util.HashSet;
+import java.nio.file.Files;
+import java.util.*;
 
 
 public class TestProtocolSpecific {
 
   protected static final int REPEATING = -1;
-  protected static final File SERVER_PORTS_DIR
-  = new File(System.getProperty("test.dir", "/tmp")+"/server-ports/");
 
   public static int ackCount;
 
@@ -312,23 +308,32 @@ protected int getExpectedHandshakeCount() {
 
   public static class InteropTest {
 
-  @Test
+    private static File SERVER_PORTS_DIR;
+    static {
+      try {
+        SERVER_PORTS_DIR = Files.createTempDirectory(TestProtocolSpecific.class.getSimpleName()).toFile();
+      } catch (IOException e) {
+        e.printStackTrace();
+      }
+    }
+
+    @Test
     public void testClient() throws Exception {
-      for (File f : SERVER_PORTS_DIR.listFiles()) {
+      for (File f : Objects.requireNonNull(SERVER_PORTS_DIR.listFiles())) {
         LineNumberReader reader = new LineNumberReader(new FileReader(f));
         int port = Integer.parseInt(reader.readLine());
-        System.out.println("Validating java client to "+
-            f.getName()+" - " + port);
+        System.out.println("Validating java client to " +
+                f.getName() + " - " + port);
         Transceiver client = new SocketTransceiver(
-            new InetSocketAddress("localhost", port));
-        proxy = (Simple)SpecificRequestor.getClient(Simple.class, client);
+                new InetSocketAddress("localhost", port));
+        proxy = SpecificRequestor.getClient(Simple.class, client);
         TestProtocolSpecific proto = new TestProtocolSpecific();
         proto.testHello();
         proto.testEcho();
         proto.testEchoBytes();
         proto.testError();
-        System.out.println("Done! Validation java client to "+
-            f.getName()+" - " + port);
+        System.out.println("Done! Validation java client to " +
+                f.getName() + " - " + port);
       }
     }
 
@@ -337,8 +342,8 @@ public void testClient() throws Exception {
      */
     public static void main(String[] args) throws Exception {
       SocketServer server = new SocketServer(
-          new SpecificResponder(Simple.class, new TestImpl()),
-          new InetSocketAddress(0));
+              new SpecificResponder(Simple.class, new TestImpl()),
+              new InetSocketAddress(0));
       server.start();
       File portFile = new File(SERVER_PORTS_DIR, "java-port");
       FileWriter w = new FileWriter(portFile);
diff --git a/lang/java/ipc/src/test/java/org/apache/avro/TestSchema.java b/lang/java/ipc/src/test/java/org/apache/avro/TestSchema.java
index 31d194323..cc04e3331 100644
--- a/lang/java/ipc/src/test/java/org/apache/avro/TestSchema.java
+++ b/lang/java/ipc/src/test/java/org/apache/avro/TestSchema.java
@@ -17,16 +17,12 @@
  */
 package org.apache.avro;
 
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertNull;
-import static org.junit.Assert.assertTrue;
-import static org.junit.Assert.fail;
-
 import java.io.ByteArrayInputStream;
 import java.io.ByteArrayOutputStream;
+import java.io.File;
 import java.io.IOException;
 import java.nio.ByteBuffer;
+import java.nio.charset.StandardCharsets;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
@@ -49,10 +45,21 @@
 import org.apache.avro.io.Encoder;
 import org.apache.avro.io.EncoderFactory;
 import org.apache.avro.util.Utf8;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
+import org.junit.rules.TestName;
+
+import static org.junit.Assert.*;
 
 public class TestSchema {
 
+  @Rule
+  public TestName name = new TestName();
+
+  @Rule
+  public TemporaryFolder DIR = new TemporaryFolder();
+
   public static final String LISP_SCHEMA = "{\"type\": \"record\", \"name\": \"Lisp\", \"fields\": ["
             +"{\"name\":\"value\", \"type\":[\"null\", \"string\","
             +"{\"type\": \"record\", \"name\": \"Cons\", \"fields\": ["
@@ -87,7 +94,7 @@
   public void testNull() throws Exception {
     assertEquals(Schema.create(Type.NULL), Schema.parse("\"null\""));
     assertEquals(Schema.create(Type.NULL), Schema.parse("{\"type\":\"null\"}"));
-    check("\"null\"", "null", null);
+    check(new File(DIR.getRoot(), name.getMethodName()), "\"null\"", "null", null);
   }
 
   @Test
@@ -95,7 +102,7 @@ public void testBoolean() throws Exception {
     assertEquals(Schema.create(Type.BOOLEAN), Schema.parse("\"boolean\""));
     assertEquals(Schema.create(Type.BOOLEAN),
                  Schema.parse("{\"type\":\"boolean\"}"));
-    check("\"boolean\"", "true", Boolean.TRUE);
+    check(new File(DIR.getRoot(), name.getMethodName()),"\"boolean\"", "true", Boolean.TRUE);
   }
 
   @Test
@@ -103,7 +110,7 @@ public void testString() throws Exception {
     assertEquals(Schema.create(Type.STRING), Schema.parse("\"string\""));
     assertEquals(Schema.create(Type.STRING),
                  Schema.parse("{\"type\":\"string\"}"));
-    check("\"string\"", "\"foo\"", new Utf8("foo"));
+    check(new File(DIR.getRoot(), name.getMethodName()),"\"string\"", "\"foo\"", new Utf8("foo"));
   }
 
   @Test
@@ -111,7 +118,7 @@ public void testBytes() throws Exception {
     assertEquals(Schema.create(Type.BYTES), Schema.parse("\"bytes\""));
     assertEquals(Schema.create(Type.BYTES),
                  Schema.parse("{\"type\":\"bytes\"}"));
-    check("\"bytes\"", "\"\\u0000ABC\\u00FF\"",
+    check(new File(DIR.getRoot(), name.getMethodName()),"\"bytes\"", "\"\\u0000ABC\\u00FF\"",
           ByteBuffer.wrap(new byte[]{0,65,66,67,-1}));
   }
 
@@ -119,14 +126,14 @@ public void testBytes() throws Exception {
   public void testInt() throws Exception {
     assertEquals(Schema.create(Type.INT), Schema.parse("\"int\""));
     assertEquals(Schema.create(Type.INT), Schema.parse("{\"type\":\"int\"}"));
-    check("\"int\"", "9", new Integer(9));
+    check(new File(DIR.getRoot(), name.getMethodName()),"\"int\"", "9", 9);
   }
 
   @Test
   public void testLong() throws Exception {
     assertEquals(Schema.create(Type.LONG), Schema.parse("\"long\""));
     assertEquals(Schema.create(Type.LONG), Schema.parse("{\"type\":\"long\"}"));
-    check("\"long\"", "11", new Long(11));
+    check(new File(DIR.getRoot(), name.getMethodName()),"\"long\"", "11", 11L);
   }
 
   @Test
@@ -134,7 +141,7 @@ public void testFloat() throws Exception {
     assertEquals(Schema.create(Type.FLOAT), Schema.parse("\"float\""));
     assertEquals(Schema.create(Type.FLOAT),
                  Schema.parse("{\"type\":\"float\"}"));
-    check("\"float\"", "1.1", new Float(1.1));
+    check(new File(DIR.getRoot(), name.getMethodName()),"\"float\"", "1.1", 1.1f);
     checkDefault("\"float\"", "\"NaN\"", Float.NaN);
     checkDefault("\"float\"", "\"Infinity\"", Float.POSITIVE_INFINITY);
     checkDefault("\"float\"", "\"-Infinity\"", Float.NEGATIVE_INFINITY);
@@ -145,7 +152,7 @@ public void testDouble() throws Exception {
     assertEquals(Schema.create(Type.DOUBLE), Schema.parse("\"double\""));
     assertEquals(Schema.create(Type.DOUBLE),
                  Schema.parse("{\"type\":\"double\"}"));
-    check("\"double\"", "1.2", new Double(1.2));
+    check(new File(DIR.getRoot(), name.getMethodName()),"\"double\"", "1.2", 1.2);
     checkDefault("\"double\"", "\"NaN\"", Double.NaN);
     checkDefault("\"double\"", "\"Infinity\"", Double.POSITIVE_INFINITY);
     checkDefault("\"double\"", "\"-Infinity\"", Double.NEGATIVE_INFINITY);
@@ -157,10 +164,10 @@ public void testArray() throws Exception {
     Schema schema = Schema.parse(json);
     Collection<Long> array = new GenericData.Array<>(1, schema);
     array.add(1L);
-    check(json, "[1]", array);
+    check(new File(DIR.getRoot(), name.getMethodName()),json, "[1]", array);
     array = new ArrayList<>(1);
     array.add(1L);
-    check(json, "[1]", array);
+    check(new File(DIR.getRoot(), name.getMethodName()),json, "[1]", array);
     checkParseError("{\"type\":\"array\"}");      // items required
   }
 
@@ -168,7 +175,7 @@ public void testArray() throws Exception {
   public void testMap() throws Exception {
     HashMap<Utf8,Long> map = new HashMap<>();
     map.put(new Utf8("a"), 1L);
-    check("{\"type\":\"map\", \"values\":\"long\"}", "{\"a\":1}", map);
+    check(new File(DIR.getRoot(), name.getMethodName()),"{\"type\":\"map\", \"values\":\"long\"}", "{\"a\":1}", map);
     checkParseError("{\"type\":\"map\"}");        // values required
   }
 
@@ -181,7 +188,7 @@ public void testUnionMap() throws Exception {
         "    \"null\"]" +
         "   }]" +
         " }";
-    check(unionMapSchema, true);
+    check(new File(DIR.getRoot(), name.getMethodName()),unionMapSchema, true);
   }
 
   @Test
@@ -192,7 +199,7 @@ public void testRecord() throws Exception {
 
     GenericData.Record record = new GenericData.Record(schema);
     record.put("f", 11L);
-    check(recordJson, "{\"f\":11}", record, false);
+    check(new File(DIR.getRoot(), name.getMethodName()),recordJson, "{\"f\":11}", record, false);
 
     // test field props
     assertEquals("bar", schema.getField("f").getProp("foo"));
@@ -236,13 +243,13 @@ public void testMapInRecord() throws Exception {
     map.put(new Utf8("a"), 1L);
     GenericData.Record record = new GenericData.Record(schema);
     record.put("f", map);
-    check(json, "{\"f\":{\"a\":1}}", record, false);
+    check(new File(DIR.getRoot(), name.getMethodName()),json, "{\"f\":{\"a\":1}}", record, false);
   }
 
 
   @Test
   public void testEnum() throws Exception {
-    check(BASIC_ENUM_SCHEMA, "\"B\"",
+    check(new File(DIR.getRoot(), name.getMethodName()),BASIC_ENUM_SCHEMA, "\"B\"",
           new GenericData.EnumSymbol(Schema.parse(BASIC_ENUM_SCHEMA), "B"),
           false);
     checkParseError("{\"type\":\"enum\"}");        // symbols required
@@ -259,14 +266,15 @@ public void testEnum() throws Exception {
   public void testFixed() throws Exception {
     String json = "{\"type\": \"fixed\", \"name\":\"Test\", \"size\": 1}";
     Schema schema = Schema.parse(json);
-    check(json, "\"a\"",
+    check(new File(DIR.getRoot(), name.getMethodName()),json, "\"a\"",
           new GenericData.Fixed(schema, new byte[]{(byte)'a'}), false);
     checkParseError("{\"type\":\"fixed\"}");        // size required
   }
 
   @Test
   public void testRecursive() throws Exception {
-    check("{\"type\": \"record\", \"name\": \"Node\", \"fields\": ["
+    check(new File(DIR.getRoot(), name.getMethodName()),
+            "{\"type\": \"record\", \"name\": \"Node\", \"fields\": ["
           +"{\"name\":\"label\", \"type\":\"string\"},"
           +"{\"name\":\"children\", \"type\":"
           +"{\"type\": \"array\", \"items\": \"Node\" }}]}",
@@ -312,13 +320,13 @@ public void testSchemaExplosion() throws Exception {
 
   @Test
   public void testLisp() throws Exception {
-    check(LISP_SCHEMA, false);
+    check(new File(DIR.getRoot(), name.getMethodName()),LISP_SCHEMA, false);
   }
 
   @Test
   public void testUnion() throws Exception {
-    check("[\"string\", \"long\"]", false);
-    checkDefault("[\"double\", \"long\"]", "1.1", new Double(1.1));
+    check(new File(DIR.getRoot(), name.getMethodName()),"[\"string\", \"long\"]", false);
+    checkDefault("[\"double\", \"long\"]", "1.1", 1.1);
 
     // test that erroneous default values cause errors
     for (String type : new String[]
@@ -374,8 +382,8 @@ public void testComplexUnions() throws Exception {
     " {\"type\":\"fixed\",\"name\":\"Bar2\",\"size\": 1}," +
     " {\"type\":\"enum\",\"name\":\"Baz2\",\"symbols\": [\"X\"]}";
 
-    check(partial + namedTypes + "]", false);
-    check(partial + namedTypes + namedTypes2 + "]", false);
+    check(new File(DIR.getRoot(), name.getMethodName()),partial + namedTypes + "]", false);
+    check(new File(DIR.getRoot(), name.getMethodName()),partial + namedTypes + namedTypes2 + "]", false);
     checkParseError(partial + namedTypes + namedTypes + "]");
 
     // fail with two branches of the same unnamed type
@@ -399,19 +407,19 @@ public void testComplexUnions() throws Exception {
     u = buildUnion(new Schema[] {
         Schema.parse("{\"type\":\"record\",\"name\":\"x.A\",\"fields\":[]}"),
         Schema.parse("{\"type\":\"record\",\"name\":\"y.A\",\"fields\":[]}")});
-    check(u.toString(), false);
+    check(new File(DIR.getRoot(), name.getMethodName()),u.toString(), false);
 
     u = buildUnion(new Schema[] {
         Schema.parse
         ("{\"type\":\"enum\",\"name\":\"x.A\",\"symbols\":[\"X\"]}"),
         Schema.parse
         ("{\"type\":\"enum\",\"name\":\"y.A\",\"symbols\":[\"Y\"]}")});
-    check(u.toString(), false);
+    check(new File(DIR.getRoot(), name.getMethodName()),u.toString(), false);
 
     u = buildUnion(new Schema[] {
         Schema.parse("{\"type\":\"fixed\",\"name\":\"x.A\",\"size\":4}"),
         Schema.parse("{\"type\":\"fixed\",\"name\":\"y.A\",\"size\":8}")});
-    check(u.toString(), false);
+    check(new File(DIR.getRoot(), name.getMethodName()),u.toString(), false);
 
     // fail with two branches of the same named type, but same names
     checkUnionError(new Schema[] {Schema.createRecord("Foo", null, "org.test", false),
@@ -427,13 +435,13 @@ public void testComplexUnions() throws Exception {
   }
 
   @Test
-  public void testComplexProp() throws Exception {
+  public void testComplexProp() {
     String json = "{\"type\":\"null\", \"foo\": [0]}";
     Schema s = Schema.parse(json);
-    assertEquals(null, s.getProp("foo"));
+    assertNull(s.getProp("foo"));
   }
 
-  @Test public void testPropOrdering() throws Exception {
+  @Test public void testPropOrdering() {
     String json = "{\"type\":\"int\",\"z\":\"c\",\"yy\":\"b\",\"x\":\"a\"}";
     Schema s = Schema.parse(json);
     assertEquals(json, s.toString());
@@ -442,12 +450,12 @@ public void testComplexProp() throws Exception {
   @Test
   public void testParseInputStream() throws IOException {
     Schema s = Schema.parse(
-        new ByteArrayInputStream("\"boolean\"".getBytes("UTF-8")));
+        new ByteArrayInputStream("\"boolean\"".getBytes(StandardCharsets.UTF_8)));
     assertEquals(Schema.parse("\"boolean\""), s);
   }
 
   @Test
-  public void testNamespaceScope() throws Exception {
+  public void testNamespaceScope() {
     String z = "{\"type\":\"record\",\"name\":\"Z\",\"fields\":[]}";
     String y = "{\"type\":\"record\",\"name\":\"q.Y\",\"fields\":["
       +"{\"name\":\"f\",\"type\":"+z+"}]}";
@@ -462,7 +470,7 @@ public void testNamespaceScope() throws Exception {
   }
 
   @Test
-  public void testNamespaceNesting() throws Exception {
+  public void testNamespaceNesting() {
     String y = "{\"type\":\"record\",\"name\":\"y.Y\",\"fields\":["
       +"{\"name\":\"f\",\"type\":\"x.X\"}]}";
     String x = "{\"type\":\"record\",\"name\":\"x.X\",\"fields\":["
@@ -473,7 +481,7 @@ public void testNamespaceNesting() throws Exception {
   }
 
   @Test
-  public void testNestedNullNamespace() throws Exception {
+  public void testNestedNullNamespace() {
     Schema inner =
       Schema.parse("{\"type\":\"record\",\"name\":\"Inner\",\"fields\":[]}");
     Schema outer = Schema.createRecord("Outer", null, "space", false);
@@ -503,7 +511,7 @@ public void testNestedNullNamespaceReferencingWithUnion() {
   }
 
   @Test
-  public void testNestedNonNullNamespace1() throws Exception {
+  public void testNestedNonNullNamespace1() {
     Schema inner1 = Schema.createEnum("InnerEnum", null, "space", Arrays.asList("x"));
     Schema inner2 = Schema.parse("{\"type\":\"record\",\"namespace\":\"space\",\"name\":"
       +"\"InnerRecord\",\"fields\":[]}");
@@ -514,7 +522,7 @@ public void testNestedNonNullNamespace1() throws Exception {
   }
 
   @Test
-  public void testNestedNonNullNamespace2() throws Exception {
+  public void testNestedNonNullNamespace2() {
     Schema inner1 = Schema.createFixed("InnerFixed", null, "space", 1);
     Schema inner2 = Schema.parse("{\"type\":\"record\",\"namespace\":\"space\",\"name\":"
       +"\"InnerRecord\",\"fields\":[]}");
@@ -525,7 +533,7 @@ public void testNestedNonNullNamespace2() throws Exception {
   }
 
   @Test
-  public void testNullNamespaceAlias() throws Exception {
+  public void testNullNamespaceAlias() {
     Schema s =
       Schema.parse("{\"type\":\"record\",\"name\":\"Z\",\"fields\":[]}");
     Schema t =
@@ -564,9 +572,7 @@ private static void checkUnionError(Schema[] branches) {
     try {
       Schema.createUnion(branchList);
       fail("Union should not have constructed from: " + branchList);
-    } catch (AvroRuntimeException are) {
-      return;
-    }
+    } catch (AvroRuntimeException ignored) { }
   }
 
   private static Schema buildUnion(Schema[] branches) {
@@ -606,7 +612,7 @@ public void testFieldDocs() {
   }
 
   @Test
-  public void testAliases() throws Exception {
+  public void testAliases() {
     String t1 = "{\"type\":\"record\",\"name\":\"a.b\",\"fields\":["
       +"{\"name\":\"f\",\"type\":\"long\"},"
       +"{\"name\":\"h\",\"type\":\"int\"}]}";
@@ -622,7 +628,7 @@ public void testAliases() throws Exception {
     assertEquals(s2.getField("g").aliases(), Collections.singleton("f"));
 
     Schema s3 = Schema.applyAliases(s1,s2);
-    assertFalse(s2 == s3);
+    assertNotSame(s2, s3);
     assertEquals(s2, s3);
 
     t1 = "{\"type\":\"enum\",\"name\":\"a.b\","
@@ -632,7 +638,7 @@ public void testAliases() throws Exception {
     s1 = Schema.parse(t1);
     s2 = Schema.parse(t2);
     s3 = Schema.applyAliases(s1,s2);
-    assertFalse(s2 == s3);
+    assertNotSame(s2, s3);
     assertEquals(s2, s3);
 
     t1 = "{\"type\":\"fixed\",\"name\":\"a\","
@@ -642,23 +648,20 @@ public void testAliases() throws Exception {
     s1 = Schema.parse(t1);
     s2 = Schema.parse(t2);
     s3 = Schema.applyAliases(s1,s2);
-    assertFalse(s2 == s3);
+    assertNotSame(s2, s3);
     assertEquals(s2, s3);
   }
 
-  private static void check(String schemaJson, String defaultJson,
-                            Object defaultValue) throws Exception {
-    check(schemaJson, defaultJson, defaultValue, true);
+  private static void check(File dst, String schemaJson, String defaultJson, Object defaultValue) throws Exception {
+    check(dst, schemaJson, defaultJson, defaultValue, true);
   }
-  private static void check(String schemaJson, String defaultJson,
-                            Object defaultValue, boolean induce)
-    throws Exception {
-    check(schemaJson, induce);
+
+  private static void check(File dst, String schemaJson, String defaultJson, Object defaultValue, boolean induce) throws Exception {
+    check(dst, schemaJson, induce);
     checkDefault(schemaJson, defaultJson, defaultValue);
   }
 
-  private static void check(String jsonSchema, boolean induce)
-    throws Exception {
+  private static void check(File dst, String jsonSchema, boolean induce) throws Exception {
     Schema schema = Schema.parse(jsonSchema);
     checkProp(schema);
     Object reuse = null;
@@ -689,7 +692,7 @@ private static void check(String jsonSchema, boolean induce)
           new GenericDatumReader<>());
 
       // Check that we can generate the code for every schema we see.
-      TestSpecificCompiler.assertCompiles(schema, false);
+      TestSpecificCompiler.assertCompiles(dst, schema, false);
 
       // Check that we can read/write the json of every schema we see.
       checkBinaryJson(jsonSchema);
@@ -698,15 +701,15 @@ private static void check(String jsonSchema, boolean induce)
 
   private static void checkProp(Schema s0) throws Exception {
     if(s0.getType().equals(Schema.Type.UNION)) return; // unions have no props
-    assertEquals(null, s0.getProp("foo"));
+    assertNull(s0.getProp("foo"));
     Schema s1 = Schema.parse(s0.toString());
     s1.addProp("foo", "bar");
     assertEquals("bar", s1.getProp("foo"));
-    assertFalse(s0.equals(s1));
+    assertNotEquals(s0, s1);
     Schema s2 = Schema.parse(s1.toString());
     assertEquals("bar", s2.getProp("foo"));
     assertEquals(s1, s2);
-    assertFalse(s0.equals(s2));
+    assertNotEquals(s0, s2);
   }
 
   public static void checkBinary(Schema schema, Object datum,
@@ -806,7 +809,7 @@ private static void checkJson(Schema schema, Object datum,
     encoder.flush();
     byte[] data = out.toByteArray();
 
-    String encoded = new String(data, "UTF-8");
+    String encoded = new String(data, StandardCharsets.UTF_8);
     assertEquals("Encoded data does not match.", json, encoded);
 
     DatumReader<Object> reader = new GenericDatumReader<>();
@@ -862,9 +865,7 @@ private static void checkValidateDefaults(String schemaJson, String defaultJson)
               +"\"default\":"+defaultJson+"}]}";
       parser.parse(recordJson);
       fail("Schema of type " + schemaJson + " should not have default " + defaultJson);
-    } catch (AvroTypeException e) {
-      return;
-    }
+    } catch (AvroTypeException ignored) { }
   }
 
   @Test(expected=AvroTypeException.class)
@@ -932,8 +933,7 @@ public void testImmutability2() {
   }
 
   private static List<String> lockedArrayList() {
-    return new Schema.LockableArrayList<>(Arrays.asList(new String[]{
-        "a", "b", "c"})).lock();
+    return new Schema.LockableArrayList<>(Arrays.asList("a", "b", "c")).lock();
   }
 
   @Test(expected=IllegalStateException.class)
@@ -948,25 +948,22 @@ public void testLockedArrayList2() {
 
   @Test(expected=IllegalStateException.class)
   public void testLockedArrayList3() {
-    lockedArrayList().addAll(Arrays.asList(new String[] { "p" }));
+    lockedArrayList().addAll(Collections.singletonList("p"));
   }
 
   @Test(expected=IllegalStateException.class)
   public void testLockedArrayList4() {
-    lockedArrayList().addAll(0,
-        Arrays.asList(new String[] { "p" }));
+    lockedArrayList().addAll(0, Collections.singletonList("p"));
   }
 
   @Test(expected=IllegalStateException.class)
   public void testLockedArrayList5() {
-    lockedArrayList().
-      removeAll(Arrays.asList(new String[] { "a" }));
+    lockedArrayList().removeAll(Collections.singletonList("a"));
   }
 
   @Test(expected=IllegalStateException.class)
   public void testLockedArrayList6() {
-    lockedArrayList().
-      retainAll(Arrays.asList(new String[] { "a" }));
+    lockedArrayList().retainAll(Collections.singletonList("a"));
   }
 
   @Test(expected=IllegalStateException.class)
diff --git a/lang/java/ipc/src/test/java/org/apache/avro/compiler/specific/TestSpecificCompiler.java b/lang/java/ipc/src/test/java/org/apache/avro/compiler/specific/TestSpecificCompiler.java
index cb39b5a75..a39ab27a3 100644
--- a/lang/java/ipc/src/test/java/org/apache/avro/compiler/specific/TestSpecificCompiler.java
+++ b/lang/java/ipc/src/test/java/org/apache/avro/compiler/specific/TestSpecificCompiler.java
@@ -24,6 +24,7 @@
 import java.io.File;
 import java.io.FileWriter;
 import java.io.IOException;
+import java.nio.file.Files;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
@@ -35,7 +36,6 @@
 import javax.tools.ToolProvider;
 import javax.tools.JavaCompiler.CompilationTask;
 
-import org.apache.avro.AvroTestUtil;
 import org.apache.avro.Protocol;
 import org.apache.avro.Schema;
 import org.apache.avro.Schema.Field;
@@ -51,9 +51,22 @@
 import org.apache.avro.test.Kind;
 
 import org.apache.avro.compiler.specific.SpecificCompiler.OutputFile;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
+import org.junit.rules.TestName;
 
 public class TestSpecificCompiler {
+
+  @Rule
+  public TestName name = new TestName();
+
+  @Rule
+  public TemporaryFolder INPUT_DIR = new TemporaryFolder();
+
+  @Rule
+  public TemporaryFolder OUTPUT_DIR = new TemporaryFolder();
+
   static final String PROTOCOL = "" +
         "{ \"protocol\": \"default\",\n" +
         "  \"types\":\n" +
@@ -96,7 +109,7 @@ public void testSimpleEnumSchema() throws IOException {
     OutputFile o = outputs.iterator().next();
     assertEquals(o.path, "Test.java");
     assertTrue(o.contents.contains("public enum Test"));
-    assertCompilesWithJavaCompiler(outputs);
+    assertCompilesWithJavaCompiler(new File(INPUT_DIR.getRoot(), name.getMethodName()), outputs);
   }
 
   @Test
@@ -107,10 +120,8 @@ public void testMangleIfReserved() {
 
   @Test
   public void testManglingForProtocols() throws IOException {
-    String protocolDef = PROTOCOL;
-    Collection<OutputFile> c =
-      new SpecificCompiler(Protocol.parse(protocolDef)).compile();
-    Iterator<OutputFile> i = c.iterator();
+    Collection<OutputFile> outputs = new SpecificCompiler(Protocol.parse(PROTOCOL)).compile();
+    Iterator<OutputFile> i = outputs.iterator();
     String errType = i.next().contents;
     String protocol = i.next().contents;
 
@@ -121,7 +132,7 @@ public void testManglingForProtocols() throws IOException {
     assertTrue(protocol.contains("public interface default$"));
     assertTrue(protocol.contains("throws org.apache.avro.AvroRemoteException, finally$"));
 
-    assertCompilesWithJavaCompiler(c);
+    assertCompilesWithJavaCompiler(new File(INPUT_DIR.getRoot(), name.getMethodName()), outputs);
 
   }
 
@@ -137,16 +148,15 @@ public void testManglingForProtocols() throws IOException {
 
   @Test
   public void testManglingForRecords() throws IOException {
-    Collection<OutputFile> c =
-      new SpecificCompiler(Schema.parse(SCHEMA)).compile();
-    assertEquals(1, c.size());
-    String contents = c.iterator().next().contents;
+    Collection<OutputFile> outputs = new SpecificCompiler(Schema.parse(SCHEMA)).compile();
+    assertEquals(1, outputs.size());
+    String contents = outputs.iterator().next().contents;
 
     assertTrue(contents.contains("public java.lang.CharSequence package$;"));
     assertTrue(contents.contains("class volatile$ extends"));
     assertTrue(contents.contains("volatile$ short$;"));
 
-    assertCompilesWithJavaCompiler(c);
+    assertCompilesWithJavaCompiler(new File(INPUT_DIR.getRoot(), name.getMethodName()), outputs);
   }
 
   @Test
@@ -154,14 +164,14 @@ public void testManglingForEnums() throws IOException {
     String enumSchema = "" +
       "{ \"name\": \"instanceof\", \"type\": \"enum\"," +
       "  \"symbols\": [\"new\", \"super\", \"switch\"] }";
-    Collection<OutputFile> c =
+    Collection<OutputFile> outputs =
       new SpecificCompiler(Schema.parse(enumSchema)).compile();
-    assertEquals(1, c.size());
-    String contents = c.iterator().next().contents;
+    assertEquals(1, outputs.size());
+    String contents = outputs.iterator().next().contents;
 
     assertTrue(contents.contains("new$"));
 
-    assertCompilesWithJavaCompiler(c);
+    assertCompilesWithJavaCompiler(new File(INPUT_DIR.getRoot(), name.getMethodName()), outputs);
   }
 
   @Test
@@ -169,7 +179,7 @@ public void testSchemaSplit() throws IOException {
     SpecificCompiler compiler = new SpecificCompiler(Schema.parse(SCHEMA));
     compiler.maxStringChars = 10;
     Collection<OutputFile> files = compiler.compile();
-    assertCompilesWithJavaCompiler(files);
+    assertCompilesWithJavaCompiler(new File(INPUT_DIR.getRoot(), name.getMethodName()), files);
   }
 
   @Test
@@ -177,7 +187,7 @@ public void testProtocolSplit() throws IOException {
     SpecificCompiler compiler = new SpecificCompiler(Protocol.parse(PROTOCOL));
     compiler.maxStringChars = 10;
     Collection<OutputFile> files = compiler.compile();
-    assertCompilesWithJavaCompiler(files);
+    assertCompilesWithJavaCompiler(new File(INPUT_DIR.getRoot(), name.getMethodName()), files);
   }
 
   @Test
@@ -230,13 +240,13 @@ public void testNeedCompile() throws IOException, InterruptedException {
       "{ \"name\": \"Foo\", \"type\": \"record\", " +
       "  \"fields\": [ {\"name\": \"package\", \"type\": \"string\" }," +
       "                {\"name\": \"short\", \"type\": \"Foo\" } ] }";
-    File inputFile = AvroTestUtil.tempFile(getClass(), "input.avsc");
-    FileWriter fw = new FileWriter(inputFile);
-    fw.write(schema);
-    fw.close();
+    File inputFile = new File(INPUT_DIR.getRoot().getPath(), "input.avsc");
+    try(FileWriter fw = new FileWriter(inputFile)) {
+      fw.write(schema);
+    }
+
+    File outputDir = OUTPUT_DIR.getRoot();
 
-    File outputDir = new File(System.getProperty("test.dir", "target/test") +
-      System.getProperty("file.separator") + "test_need_compile");
     File outputFile = new File(outputDir, "Foo.java");
     outputFile.delete();
     assertTrue(!outputFile.exists());
@@ -251,9 +261,9 @@ public void testNeedCompile() throws IOException, InterruptedException {
     SpecificCompiler.compileSchema(inputFile, outputDir);
     assertEquals(lastModified, outputFile.lastModified());
 
-    fw = new FileWriter(inputFile);
-    fw.write(schema);
-    fw.close();
+    try(FileWriter fw = new FileWriter(inputFile)) {
+      fw.write(schema);
+    }
     SpecificCompiler.compileSchema(inputFile, outputDir);
     assertTrue(lastModified != outputFile.lastModified());
   }
@@ -265,8 +275,7 @@ public void testNeedCompile() throws IOException, InterruptedException {
    * @param fields the field(s) to add to the schema.
    * @return the schema.
    */
-  private Schema createRecord(String name,
-      boolean isError, Field... fields) {
+  private Schema createRecord(String name, boolean isError, Field... fields) {
     Schema record = Schema.createRecord(name, null, null, isError);
     record.setFields(Arrays.asList(fields));
     return record;
@@ -405,7 +414,6 @@ public void generateSetMethod() {
     assertEquals("setCause$", SpecificCompiler.generateSetMethod(
         createRecord("test", true, cause), cause));
 
-
     assertEquals("setClass$", SpecificCompiler.generateSetMethod(
         createRecord("test", false, clasz), clasz));
     clasz = new Field("class", Schema.create(Type.STRING), null, null);
@@ -694,13 +702,11 @@ public void testAliases() throws IOException {
    * optionally, uses the system's Java compiler to check
    * that the generated code is valid.
    */
-  public static void
-      assertCompiles(Schema schema, boolean useJavaCompiler)
-  throws IOException {
+  public static void assertCompiles(File dstDir,Schema schema, boolean useJavaCompiler) throws IOException {
     Collection<OutputFile> outputs = new SpecificCompiler(schema).compile();
-    assertTrue(null != outputs);
+    assertNotNull(outputs);
     if (useJavaCompiler) {
-      assertCompilesWithJavaCompiler(outputs);
+      assertCompilesWithJavaCompiler(dstDir, outputs);
     }
   }
 
@@ -709,22 +715,20 @@ public void testAliases() throws IOException {
    * and, optionally, uses the system's Java compiler to check
    * that the generated code is valid.
    */
-  public static void assertCompiles(Protocol protocol, boolean useJavaCompiler)
-  throws IOException {
+  public static void assertCompiles(File dstDir, Protocol protocol, boolean useJavaCompiler) throws IOException {
     Collection<OutputFile> outputs = new SpecificCompiler(protocol).compile();
-    assertTrue(null != outputs);
+    assertNotNull(outputs);
     if (useJavaCompiler) {
-      assertCompilesWithJavaCompiler(outputs);
+      assertCompilesWithJavaCompiler(dstDir, outputs);
     }
   }
 
   /** Uses the system's java compiler to actually compile the generated code. */
-  static void assertCompilesWithJavaCompiler(Collection<OutputFile> outputs)
-  throws IOException {
+  static void assertCompilesWithJavaCompiler(File dstDir, Collection<OutputFile> outputs) throws IOException {
     if (outputs.isEmpty()) {
-      return;               // Nothing to compile!
+      return; // Nothing to compile!
     }
-    File dstDir = AvroTestUtil.tempFile(TestSpecificCompiler.class, "realCompiler");
+
     List<File> javaFiles = new ArrayList<>();
     for (OutputFile o : outputs) {
       javaFiles.add(o.writeToDestination(null, dstDir));
@@ -736,8 +740,8 @@ static void assertCompilesWithJavaCompiler(Collection<OutputFile> outputs)
 
     CompilationTask cTask = compiler.getTask(null, fileManager, null, null,
         null,
-        fileManager.getJavaFileObjects(
-            javaFiles.toArray(new File[javaFiles.size()])));
+        fileManager.getJavaFileObjects(javaFiles.toArray(new File[javaFiles.size()]))
+    );
     assertTrue(cTask.call());
   }
 }
diff --git a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroInputFormat.java b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroInputFormat.java
index 2ef1fcda3..350dc7f08 100644
--- a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroInputFormat.java
+++ b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroInputFormat.java
@@ -18,12 +18,7 @@
 
 package org.apache.avro.mapred;
 
-import java.io.File;
-import java.util.HashSet;
-import java.util.Set;
-
 import junit.framework.Assert;
-
 import org.apache.hadoop.fs.FileStatus;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
@@ -31,12 +26,20 @@
 import org.apache.hadoop.mapred.JobConf;
 import org.junit.After;
 import org.junit.Before;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
+
+import java.io.IOException;
+import java.nio.file.Files;
+import java.util.HashSet;
+import java.util.Set;
 
 public class TestAvroInputFormat {
 
-  private static final String TEST_DIR = System.getProperty("test.dir", ".") +
-      File.separator + TestAvroInputFormat.class.getName();
+  @Rule
+  public TemporaryFolder DIR = new TemporaryFolder();
+
   private JobConf conf;
   private FileSystem fs;
   private Path inputDir;
@@ -45,10 +48,9 @@
   public void setUp() throws Exception {
     conf = new JobConf();
     fs = FileSystem.getLocal(conf);
-    inputDir = new Path(TEST_DIR);
+    inputDir = new Path(DIR.getRoot().getPath());
   }
 
-
   @After
   public void tearDown() throws Exception {
     fs.delete(inputDir, true);
@@ -65,7 +67,6 @@ public void testIgnoreFilesWithoutExtension() throws Exception {
 
     FileInputFormat.setInputPaths(conf, inputDir);
 
-
     AvroInputFormat inputFormat = new AvroInputFormat();
     FileStatus[] statuses = inputFormat.listStatus(conf);
     Assert.assertEquals(1, statuses.length);
diff --git a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroMultipleInputs.java b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroMultipleInputs.java
index 3eb849c05..1ba918949 100644
--- a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroMultipleInputs.java
+++ b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroMultipleInputs.java
@@ -37,18 +37,32 @@
 import org.apache.avro.reflect.ReflectData;
 import org.apache.avro.reflect.ReflectDatumWriter;
 import org.apache.avro.reflect.ReflectDatumReader;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
 
 import static org.junit.Assert.*;
 
 public class TestAvroMultipleInputs {
 
-  /** The input-1 record. */
+  @Rule
+  public TemporaryFolder OUTPUT_DIR = new TemporaryFolder();
+
+  @Rule
+  public TemporaryFolder INPUT_DIR_1 = new TemporaryFolder();
+
+  @Rule
+  public TemporaryFolder INPUT_DIR_2 = new TemporaryFolder();
+
+  /**
+   * The input-1 record.
+   */
   public static class NamesRecord {
     private int id = -1;
     private CharSequence name = "";
 
-    public NamesRecord() {}
+    public NamesRecord() {
+    }
 
     public NamesRecord(int id, CharSequence name) {
       this.id = id;
@@ -61,12 +75,15 @@ public String toString() {
     }
   }
 
-  /** The input-2 record. */
+  /**
+   * The input-2 record.
+   */
   public static class BalancesRecord {
     private int id = -1;
     private long balance = 0L;
 
-    public BalancesRecord() {}
+    public BalancesRecord() {
+    }
 
     public BalancesRecord(int id, long balance) {
       this.id = id;
@@ -79,11 +96,14 @@ public String toString() {
     }
   }
 
-  /** The map output key record. */
+  /**
+   * The map output key record.
+   */
   public static class KeyRecord {
     private int id = -1;
 
-    public KeyRecord() {}
+    public KeyRecord() {
+    }
 
     public KeyRecord(int id) {
       this.id = id;
@@ -95,9 +115,10 @@ public String toString() {
     }
   }
 
-  /** The common map output value record.
-   *  Carries a tag specifying what source
-   *  record type was.
+  /**
+   * The common map output value record.
+   * Carries a tag specifying what source
+   * record type was.
    */
   public static class JoinableRecord {
     private int id = -1;
@@ -105,13 +126,14 @@ public String toString() {
     private long balance = 0L;
     private CharSequence recType = "";
 
-    public JoinableRecord() {}
+    public JoinableRecord() {
+    }
 
     public JoinableRecord(
-        CharSequence recType,
-        int id,
-        CharSequence name,
-        long balance) {
+            CharSequence recType,
+            int id,
+            CharSequence name,
+            long balance) {
       this.id = id;
       this.recType = recType;
       this.name = name;
@@ -124,13 +146,16 @@ public String toString() {
     }
   }
 
-  /** The output, combined record. */
+  /**
+   * The output, combined record.
+   */
   public static class CompleteRecord {
     private int id = -1;
     private CharSequence name = "";
     private long balance = 0L;
 
-    public CompleteRecord() {}
+    public CompleteRecord() {
+    }
 
     public CompleteRecord(int id, CharSequence name, long balance) {
       this.name = name;
@@ -138,11 +163,17 @@ public CompleteRecord(int id, CharSequence name, long balance) {
       this.balance = balance;
     }
 
-    void setId(int id) { this.id = id; };
+    void setId(int id) {
+      this.id = id;
+    }
 
-    void setName(CharSequence name) { this.name = name; };
+    void setName(CharSequence name) {
+      this.name = name;
+    }
 
-    void setBalance(long balance) { this.balance = balance; };
+    void setBalance(long balance) {
+      this.balance = balance;
+    }
 
     @Override
     public String toString() {
@@ -151,41 +182,41 @@ public String toString() {
   }
 
   public static class NamesMapImpl
-    extends AvroMapper<NamesRecord, Pair<KeyRecord, JoinableRecord>> {
+          extends AvroMapper<NamesRecord, Pair<KeyRecord, JoinableRecord>> {
 
     @Override
     public void map(
-        NamesRecord nameRecord,
-        AvroCollector<Pair<KeyRecord, JoinableRecord>> collector,
-        Reporter reporter) throws IOException {
+            NamesRecord nameRecord,
+            AvroCollector<Pair<KeyRecord, JoinableRecord>> collector,
+            Reporter reporter) throws IOException {
       collector.collect(
-          new Pair<>(
-              new KeyRecord(nameRecord.id),
-              new JoinableRecord(nameRecord.getClass().getName(),
-                  nameRecord.id, nameRecord.name, -1L)));
+              new Pair<>(
+                      new KeyRecord(nameRecord.id),
+                      new JoinableRecord(nameRecord.getClass().getName(),
+                              nameRecord.id, nameRecord.name, -1L)));
     }
 
   }
 
   public static class BalancesMapImpl
-    extends AvroMapper<BalancesRecord, Pair<KeyRecord, JoinableRecord>> {
+          extends AvroMapper<BalancesRecord, Pair<KeyRecord, JoinableRecord>> {
 
     @Override
-      public void map(
-          BalancesRecord balanceRecord,
-          AvroCollector<Pair<KeyRecord, JoinableRecord>> collector,
-          Reporter reporter) throws IOException {
+    public void map(
+            BalancesRecord balanceRecord,
+            AvroCollector<Pair<KeyRecord, JoinableRecord>> collector,
+            Reporter reporter) throws IOException {
       collector.collect(
-          new Pair<>(
-              new KeyRecord(balanceRecord.id),
-              new JoinableRecord(balanceRecord.getClass().getName(),
-                  balanceRecord.id, "", balanceRecord.balance)));
+              new Pair<>(
+                      new KeyRecord(balanceRecord.id),
+                      new JoinableRecord(balanceRecord.getClass().getName(),
+                              balanceRecord.id, "", balanceRecord.balance)));
     }
 
   }
 
   public static class ReduceImpl
-    extends AvroReducer<KeyRecord, JoinableRecord, CompleteRecord> {
+          extends AvroReducer<KeyRecord, JoinableRecord, CompleteRecord> {
 
     @Override
     public void reduce(KeyRecord ID, Iterable<JoinableRecord> joinables,
@@ -208,31 +239,27 @@ public void reduce(KeyRecord ID, Iterable<JoinableRecord> joinables,
   @Test
   public void testJob() throws Exception {
     JobConf job = new JobConf();
-    String dir = System.getProperty("test.dir", ".") +
-        "target/testAvroMultipleInputs";
-    Path inputPath1 = new Path(dir + "/in1");
-    Path inputPath2 = new Path(dir + "/in2");
-    Path outputPath = new Path(dir + "/out");
+    Path inputPath1 = new Path(INPUT_DIR_1.getRoot().getPath());
+    Path inputPath2 = new Path(INPUT_DIR_2.getRoot().getPath());
+    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());
 
-    outputPath.getFileSystem(job).delete(outputPath, true);
-    inputPath1.getFileSystem(job).delete(inputPath1, true);
-    inputPath2.getFileSystem(job).delete(inputPath2, true);
+    outputPath.getFileSystem(job).delete(outputPath);
 
     writeNamesFiles(new File(inputPath1.toUri().getPath()));
     writeBalancesFiles(new File(inputPath2.toUri().getPath()));
 
     job.setJobName("multiple-inputs-join");
     AvroMultipleInputs.addInputPath(job, inputPath1, NamesMapImpl.class,
-        ReflectData.get().getSchema(NamesRecord.class));
+            ReflectData.get().getSchema(NamesRecord.class));
     AvroMultipleInputs.addInputPath(job, inputPath2, BalancesMapImpl.class,
-        ReflectData.get().getSchema(BalancesRecord.class));
+            ReflectData.get().getSchema(BalancesRecord.class));
 
     Schema keySchema = ReflectData.get().getSchema(KeyRecord.class);
     Schema valueSchema = ReflectData.get().getSchema(JoinableRecord.class);
     AvroJob.setMapOutputSchema(job,
-        Pair.getPairSchema(keySchema, valueSchema));
+            Pair.getPairSchema(keySchema, valueSchema));
     AvroJob.setOutputSchema(job,
-        ReflectData.get().getSchema(CompleteRecord.class));
+            ReflectData.get().getSchema(CompleteRecord.class));
 
     AvroJob.setReducerClass(job, ReduceImpl.class);
     job.setNumReduceTasks(1);
@@ -243,7 +270,7 @@ public void testJob() throws Exception {
 
     JobClient.runJob(job);
 
-    validateCompleteFile(new File(new File(dir, "out"), "part-00000.avro"));
+    validateCompleteFile(new File(OUTPUT_DIR.getRoot(), "part-00000.avro"));
   }
 
   /**
@@ -251,45 +278,42 @@ public void testJob() throws Exception {
    */
   private void writeNamesFiles(File dir) throws IOException {
     DatumWriter<NamesRecord> writer = new ReflectDatumWriter<>();
-    DataFileWriter<NamesRecord> out = new DataFileWriter<>(writer);
-    File namesFile = new File(dir+"/names.avro");
-    dir.mkdirs();
-    out.create(ReflectData.get().getSchema(NamesRecord.class), namesFile);
-    for (int i=0; i < 5; i++)
-      out.append(new NamesRecord(i, "record"+i));
-    out.close();
+    File namesFile = new File(dir + "/names.avro");
+    try (DataFileWriter<NamesRecord> out = new DataFileWriter<>(writer)) {
+      out.create(ReflectData.get().getSchema(NamesRecord.class), namesFile);
+      for (int i = 0; i < 5; i++) {
+        out.append(new NamesRecord(i, "record" + i));
+      }
+    }
   }
 
   /**
    * Writes a "balances.avro" file with five sequential <id, balance> pairs.
    */
   private void writeBalancesFiles(File dir) throws IOException {
-    DatumWriter<BalancesRecord> writer =
-        new ReflectDatumWriter<>();
-    DataFileWriter<BalancesRecord> out =
-        new DataFileWriter<>(writer);
-    File namesFile = new File(dir+"/balances.avro");
-    dir.mkdirs();
-    out.create(ReflectData.get().getSchema(BalancesRecord.class), namesFile);
-    for (int i=0; i < 5; i++)
-      out.append(new BalancesRecord(i, (long) i+100));
-    out.close();
+    DatumWriter<BalancesRecord> writer = new ReflectDatumWriter<>();
+    File namesFile = new File(dir + "/balances.avro");
+    try (DataFileWriter<BalancesRecord> out = new DataFileWriter<>(writer)) {
+      out.create(ReflectData.get().getSchema(BalancesRecord.class), namesFile);
+      for (int i = 0; i < 5; i++) {
+        out.append(new BalancesRecord(i, (long) i + 100));
+      }
+    }
   }
 
   private void validateCompleteFile(File file) throws Exception {
-    DatumReader<CompleteRecord> reader =
-        new ReflectDatumReader<>();
-    InputStream in = new BufferedInputStream(new FileInputStream(file));
-    DataFileStream<CompleteRecord> records =
-        new DataFileStream<>(in, reader);
+    DatumReader<CompleteRecord> reader = new ReflectDatumReader<>();
     int numRecs = 0;
-    for (CompleteRecord rec : records) {
-      assertEquals(rec.id, numRecs);
-      assertEquals(rec.balance-100, rec.id);
-      assertEquals(rec.name, "record"+rec.id);
-      numRecs++;
+    try(InputStream in = new BufferedInputStream(new FileInputStream(file))) {
+      try (DataFileStream<CompleteRecord> records = new DataFileStream<>(in, reader)) {
+        for (CompleteRecord rec : records) {
+          assertEquals(rec.id, numRecs);
+          assertEquals(rec.balance - 100, rec.id);
+          assertEquals(rec.name, "record" + rec.id);
+          numRecs++;
+        }
+      }
     }
-    records.close();
     assertEquals(5, numRecs);
   }
 
diff --git a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroMultipleOutputs.java b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroMultipleOutputs.java
index feb328a56..7e84e5d9f 100644
--- a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroMultipleOutputs.java
+++ b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroMultipleOutputs.java
@@ -18,29 +18,29 @@
 
 package org.apache.avro.mapred;
 
-import java.io.IOException;
-import java.util.StringTokenizer;
-
 import junit.framework.Assert;
-
+import org.apache.avro.Schema;
+import org.apache.avro.util.Utf8;
 import org.apache.hadoop.fs.FileStatus;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.io.NullWritable;
-import org.apache.hadoop.mapred.FileSplit;
-import org.apache.hadoop.mapred.JobClient;
-import org.apache.hadoop.mapred.JobConf;
-import org.apache.hadoop.mapred.FileInputFormat;
-import org.apache.hadoop.mapred.FileOutputFormat;
-import org.apache.hadoop.mapred.Reporter;
-
-import org.apache.avro.Schema;
-import org.apache.avro.util.Utf8;
+import org.apache.hadoop.mapred.*;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
+
+import java.io.File;
+import java.io.IOException;
+import java.util.StringTokenizer;
 
 public class TestAvroMultipleOutputs {
 
-  private static final String UTF8 = "UTF-8";
+  @Rule
+  public TemporaryFolder INPUT_DIR = new TemporaryFolder();
+
+  @Rule
+  public TemporaryFolder OUTPUT_DIR = new TemporaryFolder();
 
   public static class MapImpl extends AvroMapper<Utf8, Pair<Utf8, Long>> {
     private AvroMultipleOutputs amos;
@@ -50,120 +50,116 @@ public void configure(JobConf Job) {
     }
 
     @Override
-      public void map(Utf8 text, AvroCollector<Pair<Utf8,Long>> collector,
-                      Reporter reporter) throws IOException {
+    public void map(Utf8 text, AvroCollector<Pair<Utf8, Long>> collector, Reporter reporter) throws IOException {
       StringTokenizer tokens = new StringTokenizer(text.toString());
       while (tokens.hasMoreTokens()) {
         String tok = tokens.nextToken();
         collector.collect(new Pair<>(new Utf8(tok), 1L));
-        amos.getCollector("myavro2",reporter)
-          .collect(new Pair<Utf8,Long>(new Utf8(tok),1L).toString());
+        amos.getCollector("myavro2", reporter).collect(new Pair<Utf8, Long>(new Utf8(tok), 1L).toString());
       }
-
     }
+
     public void close() throws IOException {
       amos.close();
     }
-
   }
 
-  public static class ReduceImpl
-    extends AvroReducer<Utf8, Long, Pair<Utf8, Long> > {
+  public static class ReduceImpl extends AvroReducer<Utf8, Long, Pair<Utf8, Long>> {
     private AvroMultipleOutputs amos;
 
-    public void configure(JobConf Job)
-    {
-        amos=new AvroMultipleOutputs(Job);
+    public void configure(JobConf Job) {
+      amos = new AvroMultipleOutputs(Job);
     }
 
     @Override
     public void reduce(Utf8 word, Iterable<Long> counts,
-                       AvroCollector<Pair<Utf8,Long>> collector,
+                       AvroCollector<Pair<Utf8, Long>> collector,
                        Reporter reporter) throws IOException {
       long sum = 0;
       for (long count : counts)
         sum += count;
-      Pair<Utf8,Long> outputvalue= new Pair<>(word, sum);
-      amos.getCollector("myavro",reporter).collect(outputvalue);
-      amos.collect("myavro1",reporter,outputvalue.toString());
-      amos.collect("myavro",reporter,new Pair<Utf8,Long>(new Utf8(""), 0L).getSchema(),outputvalue,"testavrofile");
-      amos.collect("myavro",reporter,Schema.create(Schema.Type.STRING),outputvalue.toString(),"testavrofile1");
+      Pair<Utf8, Long> outputvalue = new Pair<>(word, sum);
+      amos.getCollector("myavro", reporter).collect(outputvalue);
+      amos.collect("myavro1", reporter, outputvalue.toString());
+      amos.collect("myavro", reporter, new Pair<Utf8, Long>(new Utf8(""), 0L).getSchema(), outputvalue, "testavrofile");
+      amos.collect("myavro", reporter, Schema.create(Schema.Type.STRING), outputvalue.toString(), "testavrofile1");
       collector.collect(new Pair<>(word, sum));
     }
-    public void close() throws IOException
-    {
+
+    public void close() throws IOException {
       amos.close();
     }
   }
 
-  @Test public void runTestsInOrder() throws Exception {
-    testJob();
-    testProjection();
-    testProjection_newmethods();
-    testProjection_newmethods_1();
-    testProjection1();
-    testJob_noreducer();
-    testProjection_noreducer();
+  @Test
+  public void runTestsInOrder() throws Exception {
+    String avroPath = OUTPUT_DIR.getRoot().getPath();
+    testJob(avroPath);
+    testProjection(avroPath);
+    testProjectionNewMethodsOne(avroPath);
+    testProjectionNewMethodsTwo(avroPath);
+    testProjection1(avroPath);
+    testJobNoreducer();
+    testProjectionNoreducer(avroPath);
   }
 
   @SuppressWarnings("deprecation")
-  public void testJob() throws Exception {
+  public void testJob(String pathOut) throws Exception {
     JobConf job = new JobConf();
 
-//    private static final String UTF8 = "UTF-8";
-    String dir = System.getProperty("test.dir", ".") + "/mapred";
-    Path outputPath = new Path(dir + "/out");
+    String pathIn = INPUT_DIR.getRoot().getPath();
+
+    File fileIn = new File(pathIn, "lines.avro");
+    Path outputPath = new Path(pathOut);
 
     outputPath.getFileSystem(job).delete(outputPath);
-    WordCountUtil.writeLinesFile();
+
+    WordCountUtil.writeLinesFile(fileIn);
 
     job.setJobName("AvroMultipleOutputs");
 
     AvroJob.setInputSchema(job, Schema.create(Schema.Type.STRING));
     AvroJob.setOutputSchema(job,
-                            new Pair<Utf8,Long>(new Utf8(""), 0L).getSchema());
+            new Pair<Utf8, Long>(new Utf8(""), 0L).getSchema());
 
     AvroJob.setMapperClass(job, MapImpl.class);
     AvroJob.setReducerClass(job, ReduceImpl.class);
 
-    FileInputFormat.setInputPaths(job, new Path(dir + "/in"));
+    FileInputFormat.setInputPaths(job, pathIn);
     FileOutputFormat.setOutputPath(job, outputPath);
     FileOutputFormat.setCompressOutput(job, false);
-    AvroMultipleOutputs.addNamedOutput(job,"myavro",AvroOutputFormat.class, new Pair<Utf8,Long>(new Utf8(""), 0L).getSchema());
-    AvroMultipleOutputs.addNamedOutput(job,"myavro1",AvroOutputFormat.class, Schema.create(Schema.Type.STRING));
-    AvroMultipleOutputs.addNamedOutput(job,"myavro2",AvroOutputFormat.class, Schema.create(Schema.Type.STRING));
+    AvroMultipleOutputs.addNamedOutput(job, "myavro", AvroOutputFormat.class, new Pair<Utf8, Long>(new Utf8(""), 0L).getSchema());
+    AvroMultipleOutputs.addNamedOutput(job, "myavro1", AvroOutputFormat.class, Schema.create(Schema.Type.STRING));
+    AvroMultipleOutputs.addNamedOutput(job, "myavro2", AvroOutputFormat.class, Schema.create(Schema.Type.STRING));
     WordCountUtil.setMeta(job);
 
-
     JobClient.runJob(job);
 
-    WordCountUtil.validateCountsFile();
+    WordCountUtil.validateCountsFile(new File(outputPath.toString(), "/part-00000.avro"));
   }
 
   @SuppressWarnings("deprecation")
-  public void testProjection() throws Exception {
+  public void testProjection(String inputDirectory) throws Exception {
     JobConf job = new JobConf();
 
-    Integer defaultRank = new Integer(-1);
+    Integer defaultRank = -1;
 
     String jsonSchema =
-      "{\"type\":\"record\"," +
-      "\"name\":\"org.apache.avro.mapred.Pair\","+
-      "\"fields\": [ " +
-        "{\"name\":\"rank\", \"type\":\"int\", \"default\": -1}," +
-        "{\"name\":\"value\", \"type\":\"long\"}" +
-      "]}";
+            "{\"type\":\"record\"," +
+                    "\"name\":\"org.apache.avro.mapred.Pair\"," +
+                    "\"fields\": [ " +
+                    "{\"name\":\"rank\", \"type\":\"int\", \"default\": -1}," +
+                    "{\"name\":\"value\", \"type\":\"long\"}" +
+                    "]}";
 
     Schema readerSchema = Schema.parse(jsonSchema);
 
     AvroJob.setInputSchema(job, readerSchema);
 
-    String dir = System.getProperty("test.dir", ".") + "/mapred";
-    Path inputPath = new Path(dir + "/out" + "/myavro-r-00000.avro");
+    Path inputPath = new Path(inputDirectory + "/myavro-r-00000.avro");
     FileStatus fileStatus = FileSystem.get(job).getFileStatus(inputPath);
     FileSplit fileSplit = new FileSplit(inputPath, 0, fileStatus.getLen(), job);
 
-
     AvroRecordReader<Pair<Integer, Long>> recordReader = new AvroRecordReader<>(job, fileSplit);
 
     AvroWrapper<Pair<Integer, Long>> inputPair = new AvroWrapper<>(null);
@@ -171,8 +167,8 @@ public void testProjection() throws Exception {
 
     long sumOfCounts = 0;
     long numOfCounts = 0;
-    while(recordReader.next(inputPair, ignore)) {
-      Assert.assertEquals((Integer)inputPair.datum().get(0), defaultRank);
+    while (recordReader.next(inputPair, ignore)) {
+      Assert.assertEquals(inputPair.datum().get(0), defaultRank);
       sumOfCounts += (Long) inputPair.datum().get(1);
       numOfCounts++;
     }
@@ -180,38 +176,35 @@ public void testProjection() throws Exception {
     Assert.assertEquals(numOfCounts, WordCountUtil.COUNTS.size());
 
     long actualSumOfCounts = 0;
-    for(Long count : WordCountUtil.COUNTS.values()) {
+    for (Long count : WordCountUtil.COUNTS.values()) {
       actualSumOfCounts += count;
     }
 
     Assert.assertEquals(sumOfCounts, actualSumOfCounts);
-
   }
 
   @SuppressWarnings("deprecation")
-  public void testProjection_newmethods() throws Exception {
+  public void testProjectionNewMethodsOne(String inputDirectory) throws Exception {
     JobConf job = new JobConf();
 
-    Integer defaultRank = new Integer(-1);
+    Integer defaultRank = -1;
 
     String jsonSchema =
-      "{\"type\":\"record\"," +
-      "\"name\":\"org.apache.avro.mapred.Pair\","+
-      "\"fields\": [ " +
-        "{\"name\":\"rank\", \"type\":\"int\", \"default\": -1}," +
-        "{\"name\":\"value\", \"type\":\"long\"}" +
-      "]}";
+            "{\"type\":\"record\"," +
+                    "\"name\":\"org.apache.avro.mapred.Pair\"," +
+                    "\"fields\": [ " +
+                    "{\"name\":\"rank\", \"type\":\"int\", \"default\": -1}," +
+                    "{\"name\":\"value\", \"type\":\"long\"}" +
+                    "]}";
 
     Schema readerSchema = Schema.parse(jsonSchema);
 
     AvroJob.setInputSchema(job, readerSchema);
 
-    String dir = System.getProperty("test.dir", ".") + "/mapred";
-    Path inputPath = new Path(dir + "/out" + "/testavrofile-r-00000.avro");
+    Path inputPath = new Path(inputDirectory + "/testavrofile-r-00000.avro");
     FileStatus fileStatus = FileSystem.get(job).getFileStatus(inputPath);
     FileSplit fileSplit = new FileSplit(inputPath, 0, fileStatus.getLen(), job);
 
-
     AvroRecordReader<Pair<Integer, Long>> recordReader = new AvroRecordReader<>(job, fileSplit);
 
     AvroWrapper<Pair<Integer, Long>> inputPair = new AvroWrapper<>(null);
@@ -219,8 +212,8 @@ public void testProjection_newmethods() throws Exception {
 
     long sumOfCounts = 0;
     long numOfCounts = 0;
-    while(recordReader.next(inputPair, ignore)) {
-      Assert.assertEquals((Integer)inputPair.datum().get(0), defaultRank);
+    while (recordReader.next(inputPair, ignore)) {
+      Assert.assertEquals(inputPair.datum().get(0), defaultRank);
       sumOfCounts += (Long) inputPair.datum().get(1);
       numOfCounts++;
     }
@@ -228,7 +221,7 @@ public void testProjection_newmethods() throws Exception {
     Assert.assertEquals(numOfCounts, WordCountUtil.COUNTS.size());
 
     long actualSumOfCounts = 0;
-    for(Long count : WordCountUtil.COUNTS.values()) {
+    for (Long count : WordCountUtil.COUNTS.values()) {
       actualSumOfCounts += count;
     }
 
@@ -236,16 +229,14 @@ public void testProjection_newmethods() throws Exception {
 
   }
 
-
   @SuppressWarnings("deprecation")
   // Test for a different schema output
-  public void testProjection1() throws Exception {
+  public void testProjection1(String inputDirectory) throws Exception {
     JobConf job = new JobConf();
     Schema readerSchema = Schema.create(Schema.Type.STRING);
     AvroJob.setInputSchema(job, readerSchema);
 
-    String dir = System.getProperty("test.dir", ".") + "/mapred";
-    Path inputPath = new Path(dir + "/out" + "/myavro1-r-00000.avro");
+    Path inputPath = new Path(inputDirectory + "/myavro1-r-00000.avro");
     FileStatus fileStatus = FileSystem.get(job).getFileStatus(inputPath);
     FileSplit fileSplit = new FileSplit(inputPath, 0, fileStatus.getLen(), job);
     AvroWrapper<Utf8> inputPair = new AvroWrapper<>(null);
@@ -253,27 +244,26 @@ public void testProjection1() throws Exception {
     AvroRecordReader<Utf8> recordReader = new AvroRecordReader<>(job, fileSplit);
     long sumOfCounts = 0;
     long numOfCounts = 0;
-    while(recordReader.next(inputPair, ignore)) {
-        sumOfCounts += Long.parseLong(inputPair.datum().toString().split(":")[2].replace("}","").trim());
-        numOfCounts++;
+    while (recordReader.next(inputPair, ignore)) {
+      sumOfCounts += Long.parseLong(inputPair.datum().toString().split(":")[2].replace("}", "").trim());
+      numOfCounts++;
     }
     Assert.assertEquals(numOfCounts, WordCountUtil.COUNTS.size());
     long actualSumOfCounts = 0;
-    for(Long count : WordCountUtil.COUNTS.values()) {
-     actualSumOfCounts += count;
+    for (Long count : WordCountUtil.COUNTS.values()) {
+      actualSumOfCounts += count;
     }
     Assert.assertEquals(sumOfCounts, actualSumOfCounts);
   }
 
   @SuppressWarnings("deprecation")
   // Test for a different schema output
-  public void testProjection_newmethods_1() throws Exception {
+  public void testProjectionNewMethodsTwo(String inputDirectory) throws Exception {
     JobConf job = new JobConf();
     Schema readerSchema = Schema.create(Schema.Type.STRING);
     AvroJob.setInputSchema(job, readerSchema);
 
-    String dir = System.getProperty("test.dir", ".") + "/mapred";
-    Path inputPath = new Path(dir + "/out" + "/testavrofile1-r-00000.avro");
+    Path inputPath = new Path(inputDirectory + "/testavrofile1-r-00000.avro");
     FileStatus fileStatus = FileSystem.get(job).getFileStatus(inputPath);
     FileSplit fileSplit = new FileSplit(inputPath, 0, fileStatus.getLen(), job);
     AvroWrapper<Utf8> inputPair = new AvroWrapper<>(null);
@@ -281,60 +271,56 @@ public void testProjection_newmethods_1() throws Exception {
     AvroRecordReader<Utf8> recordReader = new AvroRecordReader<>(job, fileSplit);
     long sumOfCounts = 0;
     long numOfCounts = 0;
-    while(recordReader.next(inputPair, ignore)) {
-        sumOfCounts += Long.parseLong(inputPair.datum().toString().split(":")[2].replace("}","").trim());
-        numOfCounts++;
+    while (recordReader.next(inputPair, ignore)) {
+      sumOfCounts += Long.parseLong(inputPair.datum().toString().split(":")[2].replace("}", "").trim());
+      numOfCounts++;
     }
     Assert.assertEquals(numOfCounts, WordCountUtil.COUNTS.size());
     long actualSumOfCounts = 0;
-    for(Long count : WordCountUtil.COUNTS.values()) {
-     actualSumOfCounts += count;
+    for (Long count : WordCountUtil.COUNTS.values()) {
+      actualSumOfCounts += count;
     }
     Assert.assertEquals(sumOfCounts, actualSumOfCounts);
   }
 
   @SuppressWarnings("deprecation")
-  public void testJob_noreducer() throws Exception {
+  public void testJobNoreducer() throws Exception {
     JobConf job = new JobConf();
     job.setNumReduceTasks(0);
-//    private static final String UTF8 = "UTF-8";
-    String dir = System.getProperty("test.dir", ".") + "/mapred";
-    Path outputPath = new Path(dir + "/out");
 
+    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());
     outputPath.getFileSystem(job).delete(outputPath);
-    WordCountUtil.writeLinesFile();
+
+    WordCountUtil.writeLinesFile(new File(INPUT_DIR.getRoot(),"lines.avro"));
 
     job.setJobName("AvroMultipleOutputs_noreducer");
 
     AvroJob.setInputSchema(job, Schema.create(Schema.Type.STRING));
-    AvroJob.setOutputSchema(job,
-                            new Pair<Utf8,Long>(new Utf8(""), 0L).getSchema());
+    AvroJob.setOutputSchema(job, new Pair<Utf8, Long>(new Utf8(""), 0L).getSchema());
 
     AvroJob.setMapperClass(job, MapImpl.class);
 
-    FileInputFormat.setInputPaths(job, new Path(dir + "/in"));
+    FileInputFormat.setInputPaths(job, new Path(INPUT_DIR.getRoot().toString()));
     FileOutputFormat.setOutputPath(job, outputPath);
     FileOutputFormat.setCompressOutput(job, false);
-    AvroMultipleOutputs.addNamedOutput(job,"myavro2",AvroOutputFormat.class, Schema.create(Schema.Type.STRING));
+    AvroMultipleOutputs.addNamedOutput(job, "myavro2", AvroOutputFormat.class, Schema.create(Schema.Type.STRING));
     JobClient.runJob(job);
   }
 
-  public void testProjection_noreducer() throws Exception {
+  public void testProjectionNoreducer(String inputDirectory) throws Exception {
     JobConf job = new JobConf();
     long onel = 1;
     Schema readerSchema = Schema.create(Schema.Type.STRING);
     AvroJob.setInputSchema(job, readerSchema);
-    String dir= System.getProperty("test.dir", ".") + "/mapred";
-    Path inputPath = new Path(dir + "/out" + "/myavro2-m-00000.avro");
+    Path inputPath = new Path(inputDirectory + "/myavro2-m-00000.avro");
     FileStatus fileStatus = FileSystem.get(job).getFileStatus(inputPath);
     FileSplit fileSplit = new FileSplit(inputPath, 0, fileStatus.getLen(), job);
-    AvroRecordReader<Utf8> recordReader_new = new AvroRecordReader<>(job, fileSplit);
-    AvroWrapper<Utf8> inputPair_new = new AvroWrapper<>(null);
+    AvroRecordReader<Utf8> recordReader = new AvroRecordReader<>(job, fileSplit);
+    AvroWrapper<Utf8> inputPair = new AvroWrapper<>(null);
     NullWritable ignore = NullWritable.get();
-    long testl=0;
-     while(recordReader_new.next(inputPair_new, ignore)) {
-       testl=Long.parseLong(inputPair_new.datum().toString().split(":")[2].replace("}","").trim());
-       Assert.assertEquals(onel,testl);
+    while (recordReader.next(inputPair, ignore)) {
+      long testl = Long.parseLong(inputPair.datum().toString().split(":")[2].replace("}", "").trim());
+      Assert.assertEquals(onel, testl);
     }
   }
 }
diff --git a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroOutputFormat.java b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroOutputFormat.java
index d710ac18b..6d356b8af 100644
--- a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroOutputFormat.java
+++ b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroOutputFormat.java
@@ -21,8 +21,7 @@
 import org.apache.hadoop.mapred.JobConf;
 import org.junit.Test;
 
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.*;
 
 public class TestAvroOutputFormat {
   @Test
@@ -32,23 +31,23 @@ public void testSetSyncInterval() {
     AvroOutputFormat.setSyncInterval(jobConf, newSyncInterval);
 
     assertEquals(newSyncInterval, jobConf.getInt(
-        AvroOutputFormat.SYNC_INTERVAL_KEY, -1));
+            AvroOutputFormat.SYNC_INTERVAL_KEY, -1));
   }
 
   @Test
   public void testNoCodec() {
     JobConf job = new JobConf();
-    assertTrue(AvroOutputFormat.getCodecFactory(job) == null);
+    assertNull(AvroOutputFormat.getCodecFactory(job));
 
     job = new JobConf();
     job.set("mapred.output.compress", "false");
     job.set("mapred.output.compression.codec", "org.apache.hadoop.io.compress.BZip2Codec");
-    assertTrue(AvroOutputFormat.getCodecFactory(job) == null);
+    assertNull(AvroOutputFormat.getCodecFactory(job));
 
     job = new JobConf();
     job.set("mapred.output.compress", "false");
     job.set(AvroJob.OUTPUT_CODEC, "bzip2");
-    assertTrue(AvroOutputFormat.getCodecFactory(job) == null);
+    assertNull(AvroOutputFormat.getCodecFactory(job));
   }
 
   @Test
@@ -59,8 +58,8 @@ public void testBZip2CodecUsingHadoopClass() {
     job.set("mapred.output.compress", "true");
     job.set("mapred.output.compression.codec", "org.apache.hadoop.io.compress.BZip2Codec");
     CodecFactory factory = AvroOutputFormat.getCodecFactory(job);
-    assertTrue(factory != null);
-    assertTrue(factory.getClass().equals(avroBZip2Codec.getClass()));
+    assertNotNull(factory);
+    assertEquals(factory.getClass(), avroBZip2Codec.getClass());
   }
 
   @Test
@@ -71,8 +70,8 @@ public void testBZip2CodecUsingAvroCodec() {
     job.set("mapred.output.compress", "true");
     job.set(AvroJob.OUTPUT_CODEC, "bzip2");
     CodecFactory factory = AvroOutputFormat.getCodecFactory(job);
-    assertTrue(factory != null);
-    assertTrue(factory.getClass().equals(avroBZip2Codec.getClass()));
+    assertNotNull(factory);
+    assertEquals(factory.getClass(), avroBZip2Codec.getClass());
   }
 
   @Test
@@ -83,8 +82,8 @@ public void testDeflateCodecUsingHadoopClass() {
     job.set("mapred.output.compress", "true");
     job.set("mapred.output.compression.codec", "org.apache.hadoop.io.compress.DeflateCodec");
     CodecFactory factory = AvroOutputFormat.getCodecFactory(job);
-    assertTrue(factory != null);
-    assertTrue(factory.getClass().equals(avroDeflateCodec.getClass()));
+    assertNotNull(factory);
+    assertEquals(factory.getClass(), avroDeflateCodec.getClass());
   }
 
   @Test
@@ -95,8 +94,8 @@ public void testDeflateCodecUsingAvroCodec() {
     job.set("mapred.output.compress", "true");
     job.set(AvroJob.OUTPUT_CODEC, "deflate");
     CodecFactory factory = AvroOutputFormat.getCodecFactory(job);
-    assertTrue(factory != null);
-    assertTrue(factory.getClass().equals(avroDeflateCodec.getClass()));
+    assertNotNull(factory);
+    assertEquals(factory.getClass(), avroDeflateCodec.getClass());
   }
 
   @Test
@@ -107,8 +106,8 @@ public void testSnappyCodecUsingHadoopClass() {
     job.set("mapred.output.compress", "true");
     job.set("mapred.output.compression.codec", "org.apache.hadoop.io.compress.SnappyCodec");
     CodecFactory factory = AvroOutputFormat.getCodecFactory(job);
-    assertTrue(factory != null);
-    assertTrue(factory.getClass().equals(avroSnappyCodec.getClass()));
+    assertNotNull(factory);
+    assertEquals(factory.getClass(), avroSnappyCodec.getClass());
   }
 
   @Test
@@ -119,8 +118,8 @@ public void testSnappyCodecUsingAvroCodec() {
     job.set("mapred.output.compress", "true");
     job.set(AvroJob.OUTPUT_CODEC, "snappy");
     CodecFactory factory = AvroOutputFormat.getCodecFactory(job);
-    assertTrue(factory != null);
-    assertTrue(factory.getClass().equals(avroSnappyCodec.getClass()));
+    assertNotNull(factory);
+    assertEquals(factory.getClass(), avroSnappyCodec.getClass());
   }
 
   @Test
@@ -131,9 +130,7 @@ public void testGZipCodecUsingHadoopClass() {
     job.set("mapred.output.compress", "true");
     job.set("mapred.output.compression.codec", "org.apache.hadoop.io.compress.GZipCodec");
     CodecFactory factory = AvroOutputFormat.getCodecFactory(job);
-    assertTrue(factory != null);
-    assertTrue(factory.getClass().equals(avroDeflateCodec.getClass()));
+    assertNotNull(factory);
+    assertEquals(factory.getClass(), avroDeflateCodec.getClass());
   }
-
-
 }
diff --git a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroTextOutputFormat.java b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroTextOutputFormat.java
index 1e1d77ad3..13846d9d3 100644
--- a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroTextOutputFormat.java
+++ b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroTextOutputFormat.java
@@ -35,15 +35,19 @@
 import org.apache.hadoop.io.NullWritable;
 import org.apache.hadoop.io.Text;
 import org.apache.hadoop.mapred.RecordWriter;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
 
 public class TestAvroTextOutputFormat {
+  @Rule
+  public TemporaryFolder tmpFolder = new TemporaryFolder();
 
   private static final String UTF8 = "UTF-8";
 
   @Test
   public void testAvroTextRecordWriter() throws Exception {
-    File file = new File(System.getProperty("test.dir", "."), "writer");
+    File file = new File(tmpFolder.getRoot().getPath(), "writer");
     Schema schema = Schema.create(Schema.Type.BYTES);
     DatumWriter<ByteBuffer> datumWriter =
       new GenericDatumWriter<>(schema);
diff --git a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroTextSort.java b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroTextSort.java
index 6f0b618d4..a468f4e1c 100644
--- a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroTextSort.java
+++ b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestAvroTextSort.java
@@ -24,10 +24,21 @@
 import org.apache.hadoop.mapred.FileOutputFormat;
 import org.apache.hadoop.mapred.JobClient;
 import org.apache.hadoop.mapred.JobConf;
+import org.apache.hadoop.yarn.webapp.hamlet.Hamlet;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
+
+import java.nio.file.Files;
 
 public class TestAvroTextSort {
 
+  @Rule
+  public TemporaryFolder INPUT_DIR = new TemporaryFolder();
+
+  @Rule
+  public TemporaryFolder OUTPUT_DIR = new TemporaryFolder();
+
   @Test
   /**
    * Run the identity job on a "bytes" Avro file using AvroAsTextInputFormat
@@ -35,22 +46,22 @@
    */
   public void testSort() throws Exception {
     JobConf job = new JobConf();
-    String dir = System.getProperty("test.dir", ".") + "/mapred";
-    Path outputPath = new Path(dir + "/out");
-
+    String inputPath = INPUT_DIR.getRoot().getPath();
+    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());
     outputPath.getFileSystem(job).delete(outputPath);
-    WordCountUtil.writeLinesBytesFile();
+
+    WordCountUtil.writeLinesBytesFile(inputPath);
 
     job.setInputFormat(AvroAsTextInputFormat.class);
     job.setOutputFormat(AvroTextOutputFormat.class);
     job.setOutputKeyClass(Text.class);
 
-    FileInputFormat.setInputPaths(job, new Path(dir + "/in"));
+    FileInputFormat.setInputPaths(job, new Path(inputPath));
     FileOutputFormat.setOutputPath(job, outputPath);
 
     JobClient.runJob(job);
 
-    WordCountUtil.validateSortedFile();
+    WordCountUtil.validateSortedFile(outputPath.toString() + "/part-00000.avro");
   }
 
 }
diff --git a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestGenericJob.java b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestGenericJob.java
index b5ff707ad..495eae459 100644
--- a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestGenericJob.java
+++ b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestGenericJob.java
@@ -20,8 +20,10 @@
 import java.io.File;
 import java.io.IOException;
 import java.io.RandomAccessFile;
+import java.nio.file.Files;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collections;
 import java.util.List;
 
 import org.apache.avro.Schema;
@@ -49,12 +51,14 @@
 import org.apache.hadoop.mapred.TextInputFormat;
 import org.junit.After;
 import org.junit.Before;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
 
 @SuppressWarnings("deprecation")
 public class TestGenericJob {
-  private static final String dir =
-    System.getProperty("test.dir", ".") + "target/testGenericJob";
+  @Rule
+  public TemporaryFolder DIR = new TemporaryFolder();
 
   private static Schema createSchema() {
     List<Field> fields = new ArrayList<>();
@@ -80,15 +84,14 @@ private static Schema createArraySchema() {
   private static Schema createInnerSchema(String name) {
     Schema innerrecord = Schema.createRecord(name, "", "", false);
     innerrecord.setFields
-      (Arrays.asList(new Field(name, Schema.create(Type.LONG), "", 0L)));
+      (Collections.singletonList(new Field(name, Schema.create(Type.LONG), "", 0L)));
     return innerrecord;
   }
 
   @Before
     public void setup() throws IOException {
     // needed to satisfy the framework only - input ignored in mapper
-    File indir = new File(dir);
-    indir.mkdirs();
+    String dir = DIR.getRoot().getPath();
     File infile = new File(dir + "/in");
     RandomAccessFile file = new RandomAccessFile(infile, "rw");
     // add some data so framework actually calls our mapper
@@ -96,11 +99,6 @@ public void setup() throws IOException {
     file.close();
   }
 
-  @After
-    public void tearDown() throws IOException {
-    FileUtil.fullyDelete(new File(dir));
-  }
-
   static class AvroTestConverter
     extends MapReduceBase
     implements Mapper<LongWritable, Text,
@@ -128,11 +126,11 @@ public void map(LongWritable key, Text value,
   @Test
     public void testJob() throws Exception {
     JobConf job = new JobConf();
-    Path outputPath = new Path(dir + "/out");
+    Path outputPath = new Path(DIR.getRoot().getPath() + "/out");
     outputPath.getFileSystem(job).delete(outputPath);
 
     job.setInputFormat(TextInputFormat.class);
-    FileInputFormat.setInputPaths(job, dir + "/in");
+    FileInputFormat.setInputPaths(job, DIR.getRoot().getPath() + "/in");
 
     job.setMapperClass(AvroTestConverter.class);
     job.setNumReduceTasks(0);
diff --git a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestReflectJob.java b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestReflectJob.java
index 8fdb5fb0f..05c6be25f 100644
--- a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestReflectJob.java
+++ b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestReflectJob.java
@@ -99,7 +99,7 @@ public void reduce(Text word, Iterable<Count> counts,
   @SuppressWarnings("deprecation")
   public void testJob() throws Exception {
     JobConf job = new JobConf();
-    String dir = System.getProperty("test.dir", ".") + "target/testReflectJob";
+    String dir = "target/testReflectJob";
     Path inputPath = new Path(dir + "/in");
     Path outputPath = new Path(dir + "/out");
 
@@ -122,7 +122,7 @@ public void testJob() throws Exception {
     FileInputFormat.setInputPaths(job, inputPath);
     FileOutputFormat.setOutputPath(job, outputPath);
 
-    AvroJob.setReflect(job);                      // use reflection
+    AvroJob.setReflect(job); // use reflection
 
     JobClient.runJob(job);
 
diff --git a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestSequenceFileReader.java b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestSequenceFileReader.java
index 394a496aa..c17154097 100644
--- a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestSequenceFileReader.java
+++ b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestSequenceFileReader.java
@@ -22,6 +22,7 @@
 import java.io.IOException;
 import java.io.File;
 import java.net.URI;
+import java.nio.file.Files;
 import java.util.Iterator;
 
 import org.apache.hadoop.io.SequenceFile;
@@ -50,41 +51,51 @@
 import org.apache.avro.util.Utf8;
 
 import org.junit.BeforeClass;
+import org.junit.ClassRule;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
 
 public class TestSequenceFileReader {
-  private static final int COUNT =
-    Integer.parseInt(System.getProperty("test.count", "10"));
-  private static final File DIR
-    = new File(System.getProperty("test.dir", "."));
-  private static final File FILE = new File(DIR, "test.seq");
 
-  private static final Schema SCHEMA
-    = Pair.getPairSchema(Schema.create(Schema.Type.LONG),
-                         Schema.create(Schema.Type.STRING));
+  private static final int COUNT = Integer.parseInt(System.getProperty("test.count", "10"));
+
+  @ClassRule
+  public static TemporaryFolder INPUT_DIR = new TemporaryFolder();
+
+  @Rule
+  public TemporaryFolder OUTPUT_DIR = new TemporaryFolder();
+
+  public static File file() {
+    return new File(INPUT_DIR.getRoot().getPath(), "test.seq");
+  }
+
+  private static final Schema SCHEMA = Pair.getPairSchema(
+          Schema.create(Schema.Type.LONG),
+          Schema.create(Schema.Type.STRING)
+  );
 
   @BeforeClass
   public static void testWriteSequenceFile() throws IOException {
-    FILE.delete();
     Configuration c = new Configuration();
-    URI uri = FILE.toURI();
-    SequenceFile.Writer writer
+    URI uri = file().toURI();
+    try(SequenceFile.Writer writer
       = new SequenceFile.Writer(FileSystem.get(uri, c), c,
                                 new Path(uri.toString()),
-                                LongWritable.class, Text.class);
-    final LongWritable key = new LongWritable();
-    final Text val = new Text();
-    for (int i = 0; i < COUNT; ++i) {
-      key.set(i);
-      val.set(Integer.toString(i));
-      writer.append(key, val);
+                                LongWritable.class, Text.class)) {
+      final LongWritable key = new LongWritable();
+      final Text val = new Text();
+      for (int i = 0; i < COUNT; ++i) {
+        key.set(i);
+        val.set(Integer.toString(i));
+        writer.append(key, val);
+      }
     }
-    writer.close();
   }
 
   @Test
   public void testReadSequenceFile() throws Exception {
-    checkFile(new SequenceFileReader<>(FILE));
+    checkFile(new SequenceFileReader<>(file()));
   }
 
   public void checkFile(FileReader<Pair<Long,CharSequence>> reader) throws Exception {
@@ -101,13 +112,12 @@ public void checkFile(FileReader<Pair<Long,CharSequence>> reader) throws Excepti
   @Test
   public void testSequenceFileInputFormat() throws Exception {
     JobConf job = new JobConf();
-    Path output = new Path(System.getProperty("test.dir",".")+"/seq-out");
-
-    output.getFileSystem(job).delete(output);
+    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());
+    outputPath.getFileSystem(job).delete(outputPath);
 
     // configure input for Avro from sequence file
     AvroJob.setInputSequenceFile(job);
-    FileInputFormat.setInputPaths(job, FILE.toURI().toString());
+    FileInputFormat.setInputPaths(job, file().toURI().toString());
     AvroJob.setInputSchema(job, SCHEMA);
 
     // mapper is default, identity
@@ -115,12 +125,12 @@ public void testSequenceFileInputFormat() throws Exception {
 
     // configure output for avro
     AvroJob.setOutputSchema(job, SCHEMA);
-    FileOutputFormat.setOutputPath(job, output);
+    FileOutputFormat.setOutputPath(job, outputPath);
 
     JobClient.runJob(job);
 
     checkFile(new DataFileReader<>
-              (new File(output.toString() + "/part-00000.avro"),
+              (new File(outputPath.toString() + "/part-00000.avro"),
                new SpecificDatumReader<>()));
   }
 
@@ -139,13 +149,12 @@ public void map(LongWritable key, Text value,
   @Test
   public void testNonAvroMapper() throws Exception {
     JobConf job = new JobConf();
-    Path output = new Path(System.getProperty("test.dir",".")+"/seq-out");
-
-    output.getFileSystem(job).delete(output);
+    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());
+    outputPath.getFileSystem(job).delete(outputPath);
 
     // configure input for non-Avro sequence file
     job.setInputFormat(SequenceFileInputFormat.class);
-    FileInputFormat.setInputPaths(job, FILE.toURI().toString());
+    FileInputFormat.setInputPaths(job, file().toURI().toString());
 
     // use a hadoop mapper that emits Avro output
     job.setMapperClass(NonAvroMapper.class);
@@ -153,13 +162,13 @@ public void testNonAvroMapper() throws Exception {
     // reducer is default, identity
 
     // configure output for avro
-    FileOutputFormat.setOutputPath(job, output);
+    FileOutputFormat.setOutputPath(job, outputPath);
     AvroJob.setOutputSchema(job, SCHEMA);
 
     JobClient.runJob(job);
 
     checkFile(new DataFileReader<>
-              (new File(output.toString() + "/part-00000.avro"),
+              (new File(outputPath.toString() + "/part-00000.avro"),
                new SpecificDatumReader<>()));
   }
 
@@ -178,27 +187,25 @@ public void map(LongWritable key, Text value,
   @Test
   public void testNonAvroMapOnly() throws Exception {
     JobConf job = new JobConf();
-    Path output = new Path(System.getProperty("test.dir",".")+"/seq-out");
-
-    output.getFileSystem(job).delete(output);
-
+    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());
+    outputPath.getFileSystem(job).delete(outputPath);
 
     // configure input for non-Avro sequence file
     job.setInputFormat(SequenceFileInputFormat.class);
-    FileInputFormat.setInputPaths(job, FILE.toURI().toString());
+    FileInputFormat.setInputPaths(job, file().toURI().toString());
 
     // use a hadoop mapper that emits Avro output
     job.setMapperClass(NonAvroOnlyMapper.class);
 
     // configure output for avro
     job.setNumReduceTasks(0);                     // map-only
-    FileOutputFormat.setOutputPath(job, output);
+    FileOutputFormat.setOutputPath(job, outputPath);
     AvroJob.setOutputSchema(job, SCHEMA);
 
     JobClient.runJob(job);
 
     checkFile(new DataFileReader<>
-              (new File(output.toString() + "/part-00000.avro"),
+              (new File(outputPath.toString() + "/part-00000.avro"),
                new SpecificDatumReader<>()));
   }
 
@@ -220,14 +227,13 @@ public void reduce(AvroKey<Long> key, Iterator<AvroValue<Utf8>> values,
   @Test
   public void testNonAvroReducer() throws Exception {
     JobConf job = new JobConf();
-    Path output = new Path(System.getProperty("test.dir",".")+"/seq-out");
-
-    output.getFileSystem(job).delete(output);
+    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());
+    outputPath.getFileSystem(job).delete(outputPath);
 
     // configure input for Avro from sequence file
     AvroJob.setInputSequenceFile(job);
     AvroJob.setInputSchema(job, SCHEMA);
-    FileInputFormat.setInputPaths(job, FILE.toURI().toString());
+    FileInputFormat.setInputPaths(job, file().toURI().toString());
 
     // mapper is default, identity
 
@@ -235,16 +241,16 @@ public void testNonAvroReducer() throws Exception {
     AvroJob.setMapOutputSchema(job, SCHEMA);
     job.setReducerClass(NonAvroReducer.class);
 
-    // configure output for non-Avro SequenceFile
+    // configure outputPath for non-Avro SequenceFile
     job.setOutputFormat(SequenceFileOutputFormat.class);
-    FileOutputFormat.setOutputPath(job, output);
+    FileOutputFormat.setOutputPath(job, outputPath);
 
     // output key/value classes are default, LongWritable/Text
 
     JobClient.runJob(job);
 
     checkFile(new SequenceFileReader<>
-              (new File(output.toString() + "/part-00000")));
+              (new File(outputPath.toString() + "/part-00000")));
   }
 
 }
diff --git a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestWeather.java b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestWeather.java
index 0140c763d..eb1c06f54 100644
--- a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestWeather.java
+++ b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestWeather.java
@@ -66,7 +66,7 @@ public void testMapOnly() throws Exception {
     JobConf job = new JobConf();
     String inDir = System.getProperty("share.dir","../../../share")+"/test/data";
     Path input = new Path(inDir+"/weather.avro");
-    Path output = new Path(System.getProperty("test.dir","target/test")+"/weather-ident");
+    Path output = new Path("target/test/weather-ident");
 
     output.getFileSystem(job).delete(output);
 
@@ -141,9 +141,9 @@ public void configure(JobConf jobConf) {
   @SuppressWarnings("deprecation")
   public void testSort() throws Exception {
     JobConf job = new JobConf();
-    String inDir = System.getProperty("share.dir","../../../share")+"/test/data";
+    String inDir = "../../../share/test/data";
     Path input = new Path(inDir+"/weather.avro");
-    Path output = new Path(System.getProperty("test.dir","target/test")+"/weather-sort");
+    Path output = new Path("target/test/weather-sort");
 
     output.getFileSystem(job).delete(output);
 
diff --git a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestWordCount.java b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestWordCount.java
index f25a9c889..f3128ec64 100644
--- a/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestWordCount.java
+++ b/lang/java/mapred/src/test/java/org/apache/avro/mapred/TestWordCount.java
@@ -18,32 +18,34 @@
 
 package org.apache.avro.mapred;
 
-import java.io.IOException;
-import java.util.StringTokenizer;
-
 import junit.framework.Assert;
-
+import org.apache.avro.Schema;
+import org.apache.avro.util.Utf8;
 import org.apache.hadoop.fs.FileStatus;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.io.NullWritable;
-import org.apache.hadoop.mapred.FileSplit;
-import org.apache.hadoop.mapred.JobClient;
-import org.apache.hadoop.mapred.JobConf;
-import org.apache.hadoop.mapred.FileInputFormat;
-import org.apache.hadoop.mapred.FileOutputFormat;
-import org.apache.hadoop.mapred.Reporter;
-
-import org.apache.avro.Schema;
-import org.apache.avro.util.Utf8;
+import org.apache.hadoop.mapred.*;
+import org.junit.ClassRule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
+
+import java.io.File;
+import java.io.IOException;
+import java.util.StringTokenizer;
 
 public class TestWordCount {
 
-  public static class MapImpl extends AvroMapper<Utf8, Pair<Utf8, Long> > {
+  @ClassRule
+  public static TemporaryFolder INPUT_DIR = new TemporaryFolder();
+
+  @ClassRule
+  public static TemporaryFolder OUTPUT_DIR = new TemporaryFolder();
+
+  public static class MapImpl extends AvroMapper<Utf8, Pair<Utf8, Long>> {
     @Override
-      public void map(Utf8 text, AvroCollector<Pair<Utf8,Long>> collector,
-                      Reporter reporter) throws IOException {
+    public void map(Utf8 text, AvroCollector<Pair<Utf8, Long>> collector,
+                    Reporter reporter) throws IOException {
       StringTokenizer tokens = new StringTokenizer(text.toString());
       while (tokens.hasMoreTokens())
         collector.collect(new Pair<>(new Utf8(tokens.nextToken()), 1L));
@@ -51,10 +53,10 @@ public void map(Utf8 text, AvroCollector<Pair<Utf8,Long>> collector,
   }
 
   public static class ReduceImpl
-    extends AvroReducer<Utf8, Long, Pair<Utf8, Long> > {
+          extends AvroReducer<Utf8, Long, Pair<Utf8, Long>> {
     @Override
     public void reduce(Utf8 word, Iterable<Long> counts,
-                       AvroCollector<Pair<Utf8,Long>> collector,
+                       AvroCollector<Pair<Utf8, Long>> collector,
                        Reporter reporter) throws IOException {
       long sum = 0;
       for (long count : counts)
@@ -63,61 +65,62 @@ public void reduce(Utf8 word, Iterable<Long> counts,
     }
   }
 
-  @Test public void runTestsInOrder() throws Exception {
-    testJob();
-    testProjection();
+  @Test
+  public void runTestsInOrder() throws Exception {
+    String pathOut = OUTPUT_DIR.getRoot().getPath();
+    testJob(pathOut);
+    testProjection(pathOut);
   }
 
   @SuppressWarnings("deprecation")
-  public void testJob() throws Exception {
+  public void testJob(String pathOut) throws Exception {
     JobConf job = new JobConf();
-    String dir = System.getProperty("test.dir", ".") + "/mapred";
-    Path outputPath = new Path(dir + "/out");
+    String pathIn = INPUT_DIR.getRoot().getPath();
+
+    WordCountUtil.writeLinesFile(pathIn + "/lines.avro");
 
+    Path outputPath = new Path(pathOut);
     outputPath.getFileSystem(job).delete(outputPath);
-    WordCountUtil.writeLinesFile();
 
     job.setJobName("wordcount");
 
     AvroJob.setInputSchema(job, Schema.create(Schema.Type.STRING));
-    AvroJob.setOutputSchema(job,
-                            new Pair<Utf8,Long>(new Utf8(""), 0L).getSchema());
+    AvroJob.setOutputSchema(job, new Pair<Utf8, Long>(new Utf8(""), 0L).getSchema());
 
     AvroJob.setMapperClass(job, MapImpl.class);
     AvroJob.setCombinerClass(job, ReduceImpl.class);
     AvroJob.setReducerClass(job, ReduceImpl.class);
 
-    FileInputFormat.setInputPaths(job, new Path(dir + "/in"));
-    FileOutputFormat.setOutputPath(job, outputPath);
+    FileInputFormat.setInputPaths(job, new Path(pathIn));
+    FileOutputFormat.setOutputPath(job, new Path(pathOut));
     FileOutputFormat.setCompressOutput(job, true);
 
     WordCountUtil.setMeta(job);
 
     JobClient.runJob(job);
 
-    WordCountUtil.validateCountsFile();
+    WordCountUtil.validateCountsFile(new File(pathOut, "part-00000.avro"));
   }
 
   @SuppressWarnings("deprecation")
-  public void testProjection() throws Exception {
+  public void testProjection(String inputPathString) throws Exception {
     JobConf job = new JobConf();
 
-    Integer defaultRank = new Integer(-1);
+    Integer defaultRank = -1;
 
     String jsonSchema =
-      "{\"type\":\"record\"," +
-      "\"name\":\"org.apache.avro.mapred.Pair\","+
-      "\"fields\": [ " +
-        "{\"name\":\"rank\", \"type\":\"int\", \"default\": -1}," +
-        "{\"name\":\"value\", \"type\":\"long\"}" +
-      "]}";
+            "{\"type\":\"record\"," +
+                    "\"name\":\"org.apache.avro.mapred.Pair\"," +
+                    "\"fields\": [ " +
+                    "{\"name\":\"rank\", \"type\":\"int\", \"default\": -1}," +
+                    "{\"name\":\"value\", \"type\":\"long\"}" +
+                    "]}";
 
     Schema readerSchema = Schema.parse(jsonSchema);
 
     AvroJob.setInputSchema(job, readerSchema);
 
-    String dir = System.getProperty("test.dir", ".") + "/mapred";
-    Path inputPath = new Path(dir + "/out" + "/part-00000" + AvroOutputFormat.EXT);
+    Path inputPath = new Path(inputPathString + "/part-00000.avro");
     FileStatus fileStatus = FileSystem.get(job).getFileStatus(inputPath);
     FileSplit fileSplit = new FileSplit(inputPath, 0, fileStatus.getLen(), job);
 
@@ -128,8 +131,8 @@ public void testProjection() throws Exception {
 
     long sumOfCounts = 0;
     long numOfCounts = 0;
-    while(recordReader.next(inputPair, ignore)) {
-      Assert.assertEquals((Integer)inputPair.datum().get(0), defaultRank);
+    while (recordReader.next(inputPair, ignore)) {
+      Assert.assertEquals(inputPair.datum().get(0), defaultRank);
       sumOfCounts += (Long) inputPair.datum().get(1);
       numOfCounts++;
     }
@@ -137,7 +140,7 @@ public void testProjection() throws Exception {
     Assert.assertEquals(numOfCounts, WordCountUtil.COUNTS.size());
 
     long actualSumOfCounts = 0;
-    for(Long count : WordCountUtil.COUNTS.values()) {
+    for (Long count : WordCountUtil.COUNTS.values()) {
       actualSumOfCounts += count;
     }
 
diff --git a/lang/java/mapred/src/test/java/org/apache/avro/mapred/WordCountUtil.java b/lang/java/mapred/src/test/java/org/apache/avro/mapred/WordCountUtil.java
index a47675eab..a881f9816 100644
--- a/lang/java/mapred/src/test/java/org/apache/avro/mapred/WordCountUtil.java
+++ b/lang/java/mapred/src/test/java/org/apache/avro/mapred/WordCountUtil.java
@@ -27,6 +27,7 @@
 import java.io.BufferedInputStream;
 import java.io.PrintStream;
 import java.nio.ByteBuffer;
+import java.nio.charset.StandardCharsets;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
@@ -50,103 +51,104 @@
 
 public class WordCountUtil {
 
-  private static final File DIR
-    = new File(System.getProperty("test.dir", ".") + "/mapred");
-  public static final File LINES_FILE
-    = new File(new File(DIR, "in"), "lines.avro");
-  private static final File LINES_TEXT_FILE
-    = new File(new File(DIR, "in"), "lines.txt");
-  public static final File COUNTS_FILE
-    = new File(new File(DIR, "out"), "part-00000.avro");
-  private static final File SORTED_FILE
-    = new File(new File(DIR, "out"), "part-00000.avro");
-
   public static final String[] LINES = new String[] {
     "the quick brown fox jumps over the lazy dog",
     "the cow jumps over the moon",
     "the rain in spain falls mainly on the plains"
   };
 
-  public static final Map<String,Long> COUNTS =
-    new TreeMap<>();
+  public static final Map<String,Long> COUNTS = new TreeMap<>();
   static {
     for (String line : LINES) {
       StringTokenizer tokens = new StringTokenizer(line);
       while (tokens.hasMoreTokens()) {
         String word = tokens.nextToken();
-        long count = COUNTS.containsKey(word) ? COUNTS.get(word) : 0L;
+        long count = COUNTS.getOrDefault(word, 0L);
         count++;
         COUNTS.put(word, count);
       }
     }
   }
 
-  public static void writeLinesFile() throws IOException {
-    FileUtil.fullyDelete(DIR);
+  public static void writeLinesFile(String dir) throws IOException {
+    writeLinesFile(new File(dir));
+  }
+
+  public static void writeLinesFile(File dir) throws IOException {
     DatumWriter<Utf8> writer = new GenericDatumWriter<>();
-    DataFileWriter<Utf8> out = new DataFileWriter<>(writer);
-    LINES_FILE.getParentFile().mkdirs();
-    out.create(Schema.create(Schema.Type.STRING), LINES_FILE);
-    for (String line : LINES)
-      out.append(new Utf8(line));
-    out.close();
+    try(DataFileWriter<Utf8> out = new DataFileWriter<>(writer)) {
+      out.create(Schema.create(Schema.Type.STRING), dir);
+      for (String line : LINES) {
+        out.append(new Utf8(line));
+      }
+    }
   }
 
-  public static void writeLinesBytesFile() throws IOException {
-    FileUtil.fullyDelete(DIR);
+  public static void writeLinesBytesFile(String dir) throws IOException {
+    writeLinesBytesFile(new File(dir));
+  }
+
+  public static void writeLinesBytesFile(File dir) throws IOException {
+    FileUtil.fullyDelete(dir);
+    File fileLines = new File(dir + "/lines.avro");
+    fileLines.getParentFile().mkdirs();
+
     DatumWriter<ByteBuffer> writer = new GenericDatumWriter<>();
-    DataFileWriter<ByteBuffer> out = new DataFileWriter<>(writer);
-    LINES_FILE.getParentFile().mkdirs();
-    out.create(Schema.create(Schema.Type.BYTES), LINES_FILE);
-    for (String line : LINES)
-      out.append(ByteBuffer.wrap(line.getBytes("UTF-8")));
-    out.close();
+    try(DataFileWriter<ByteBuffer> out = new DataFileWriter<>(writer)) {
+      out.create(Schema.create(Schema.Type.BYTES), fileLines);
+      for (String line : LINES) {
+        out.append(ByteBuffer.wrap(line.getBytes(StandardCharsets.UTF_8)));
+      }
+    }
   }
 
-  public static void writeLinesTextFile() throws IOException {
-    FileUtil.fullyDelete(DIR);
-    LINES_FILE.getParentFile().mkdirs();
-    PrintStream out = new PrintStream(LINES_TEXT_FILE);
-    for (String line : LINES)
-      out.println(line);
-    out.close();
+  public static void writeLinesTextFile(File dir) throws IOException {
+    FileUtil.fullyDelete(dir);
+    File fileLines = new File(dir, "lines.avro");
+    fileLines.getParentFile().mkdirs();
+    try(PrintStream out = new PrintStream(fileLines)) {
+      for (String line : LINES) {
+        out.println(line);
+      }
+    }
   }
 
-  public static void validateCountsFile() throws Exception {
-    DatumReader<Pair<Utf8,Long>> reader
-      = new SpecificDatumReader<>();
-    InputStream in = new BufferedInputStream(new FileInputStream(COUNTS_FILE));
-    DataFileStream<Pair<Utf8,Long>> counts
-      = new DataFileStream<>(in, reader);
+  public static void validateCountsFile(File file) throws Exception {
     int numWords = 0;
-    for (Pair<Utf8,Long> wc : counts) {
-      assertEquals(wc.key().toString(),
-                   COUNTS.get(wc.key().toString()), wc.value());
-      numWords++;
+
+    DatumReader<Pair<Utf8,Long>> reader = new SpecificDatumReader<>();
+    try(InputStream in = new BufferedInputStream(new FileInputStream(file))) {
+      try (DataFileStream<Pair<Utf8, Long>> counts = new DataFileStream<>(in, reader)) {
+        for (Pair<Utf8, Long> wc : counts) {
+          assertEquals(wc.key().toString(), COUNTS.get(wc.key().toString()), wc.value());
+          numWords++;
+        }
+        checkMeta(counts);
+      }
     }
-    checkMeta(counts);
-    in.close();
+
     assertEquals(COUNTS.size(), numWords);
   }
 
-  public static void validateSortedFile() throws Exception {
+  public static void validateSortedFile(String file) throws Exception {
+    validateSortedFile(new File(file));
+  }
+
+  public static void validateSortedFile(File file) throws Exception {
     DatumReader<ByteBuffer> reader = new GenericDatumReader<>();
-    InputStream in = new BufferedInputStream(
-        new FileInputStream(SORTED_FILE));
-    DataFileStream<ByteBuffer> lines =
-        new DataFileStream<>(in, reader);
-    List<String> sortedLines = new ArrayList<>();
-    for (String line : LINES) {
-      sortedLines.add(line);
-    }
-    Collections.sort(sortedLines);
-    for (String expectedLine : sortedLines) {
-      ByteBuffer buf = lines.next();
-      byte[] b = new byte[buf.remaining()];
-      buf.get(b);
-      assertEquals(expectedLine, new String(b, "UTF-8").trim());
+    try(InputStream in = new BufferedInputStream(new FileInputStream(file))) {
+     try(DataFileStream<ByteBuffer> lines = new DataFileStream<>(in, reader)) {
+       List<String> sortedLines = new ArrayList<>(Arrays.asList(LINES));
+       Collections.sort(sortedLines);
+       for (String expectedLine : sortedLines) {
+         ByteBuffer buf = lines.next();
+         byte[] b = new byte[buf.remaining()];
+         buf.get(b);
+         assertEquals(expectedLine, new String(b, StandardCharsets.UTF_8).trim());
+       }
+       assertFalse(lines.hasNext());
+     }
     }
-    assertFalse(lines.hasNext());
   }
 
   // metadata tests
@@ -156,8 +158,7 @@ public static void validateSortedFile() throws Exception {
 
   private static final String STRING_META_VALUE = "value";
   private static final long LONG_META_VALUE = 666;
-  private static final byte[] BYTES_META_VALUE
-    = new byte[] {(byte)0x00, (byte)0x80, (byte)0xff};
+  private static final byte[] BYTES_META_VALUE = new byte[] {(byte)0x00, (byte)0x80, (byte)0xff};
 
   public static void setMeta(JobConf job) {
     AvroJob.setOutputMeta(job, STRING_KEY, STRING_META_VALUE);
diff --git a/lang/java/mapred/src/test/java/org/apache/avro/mapred/tether/TestWordCountTether.java b/lang/java/mapred/src/test/java/org/apache/avro/mapred/tether/TestWordCountTether.java
index b4007d73d..2bf2bdba1 100644
--- a/lang/java/mapred/src/test/java/org/apache/avro/mapred/tether/TestWordCountTether.java
+++ b/lang/java/mapred/src/test/java/org/apache/avro/mapred/tether/TestWordCountTether.java
@@ -24,6 +24,7 @@
 import java.io.File;
 import java.io.FileInputStream;
 import java.io.InputStream;
+import java.nio.file.Files;
 import java.util.ArrayList;
 import java.util.List;
 
@@ -32,6 +33,7 @@
 import org.apache.hadoop.mapred.FileInputFormat;
 import org.apache.hadoop.mapred.FileOutputFormat;
 
+import org.junit.Rule;
 import org.junit.Test;
 
 import org.apache.avro.file.DataFileStream;
@@ -42,35 +44,37 @@
 import org.apache.avro.Schema;
 import org.apache.avro.util.Utf8;
 import org.apache.avro.specific.SpecificDatumReader;
+import org.junit.rules.TemporaryFolder;
 
 /**
  * See also TestTetherTool for an example of how to submit jobs using the thether tool.
- *
  */
 public class TestWordCountTether {
 
+  @Rule
+  public TemporaryFolder INPUT_DIR = new TemporaryFolder();
+
+  @Rule
+  public TemporaryFolder OUTPUT_DIR = new TemporaryFolder();
 
   /**
    * Run a job using the given transport protocol
+   *
    * @param proto
    */
-  private void _runjob(String proto)throws Exception {
-    // System.out.println(System.getProperty("java.class.path").replace(":", "\n"));
-    System.out.println(System.getProperty("java.class.path"));
+  private void _runjob(String proto) throws Exception {
+    String outputPathStr = OUTPUT_DIR.getRoot().getPath();
+    File inputPath = new File(INPUT_DIR.getRoot(), "lines.avro");
+
     JobConf job = new JobConf();
-    String dir = System.getProperty("test.dir", ".") + "/mapred";
-    Path outputPath = new Path(dir + "/out");
+    Path outputPath = new Path(outputPathStr);
 
     outputPath.getFileSystem(job).delete(outputPath);
 
     // create the input file
-    WordCountUtil.writeLinesFile();
-
-    File exec =
-      new File(System.getProperty("java.home")+"/bin/java");
+    WordCountUtil.writeLinesFile(inputPath);
 
-    //input path
-    String in=dir+"/in";
+    File exec = new File(System.getProperty("java.home") + "/bin/java");
 
     //create a string of the arguments
     List<String> execargs = new ArrayList<>();
@@ -78,11 +82,11 @@ private void _runjob(String proto)throws Exception {
     execargs.add(System.getProperty("java.class.path"));
     execargs.add("org.apache.avro.mapred.tether.WordCountTask");
 
-    FileInputFormat.addInputPaths(job, in);
+    FileInputFormat.addInputPaths(job, inputPath.toString());
     FileOutputFormat.setOutputPath(job, outputPath);
     TetherJob.setExecutable(job, exec, execargs, false);
 
-    Schema outscheme= new Pair<Utf8,Long>(new Utf8(""), 0L).getSchema();
+    Schema outscheme = new Pair<Utf8, Long>(new Utf8(""), 0L).getSchema();
     AvroJob.setInputSchema(job, Schema.create(Schema.Type.STRING));
     job.set(AvroJob.OUTPUT_SCHEMA, outscheme.toString());
 
@@ -90,15 +94,12 @@ private void _runjob(String proto)throws Exception {
     TetherJob.runJob(job);
 
     // validate the output
-    DatumReader<Pair<Utf8,Long>> reader
-      = new SpecificDatumReader<>();
-    InputStream cin = new BufferedInputStream(new FileInputStream(WordCountUtil.COUNTS_FILE));
-    DataFileStream<Pair<Utf8,Long>> counts
-      = new DataFileStream<>(cin, reader);
+    DatumReader<Pair<Utf8, Long>> reader = new SpecificDatumReader<>();
+    InputStream cin = new BufferedInputStream(new FileInputStream(outputPath + "/part-00000.avro"));
+    DataFileStream<Pair<Utf8, Long>> counts = new DataFileStream<>(cin, reader);
     int numWords = 0;
-    for (Pair<Utf8,Long> wc : counts) {
-      assertEquals(wc.key().toString(),
-                   WordCountUtil.COUNTS.get(wc.key().toString()), wc.value());
+    for (Pair<Utf8, Long> wc : counts) {
+      assertEquals(wc.key().toString(), WordCountUtil.COUNTS.get(wc.key().toString()), wc.value());
       numWords++;
     }
 
@@ -109,16 +110,18 @@ private void _runjob(String proto)throws Exception {
 
   /**
    * Test the job using the sasl protocol
+   *
    * @throws Exception
    */
   @Test
   @SuppressWarnings("deprecation")
   public void testJob() throws Exception {
-      _runjob("sasl");
+    _runjob("sasl");
   }
 
   /**
    * Test the job using the http protocol
+   *
    * @throws Exception
    */
   @Test
diff --git a/lang/java/mapred/src/test/java/org/apache/avro/mapreduce/TestAvroMultipleOutputs.java b/lang/java/mapred/src/test/java/org/apache/avro/mapreduce/TestAvroMultipleOutputs.java
index f4df991ff..5e66ecce8 100644
--- a/lang/java/mapred/src/test/java/org/apache/avro/mapreduce/TestAvroMultipleOutputs.java
+++ b/lang/java/mapred/src/test/java/org/apache/avro/mapreduce/TestAvroMultipleOutputs.java
@@ -20,6 +20,7 @@
 package org.apache.avro.mapreduce;
 
 import java.io.IOException;
+import java.nio.file.Files;
 import java.util.HashMap;
 import java.util.Map;
 
@@ -52,15 +53,16 @@
 
 public class TestAvroMultipleOutputs {
   @Rule
-  public TemporaryFolder tmpFolder = new TemporaryFolder();
+  public TemporaryFolder DIR = new TemporaryFolder();
+
   public static final Schema STATS_SCHEMA =
-      Schema.parse("{\"name\":\"stats\",\"type\":\"record\","
-          + "\"fields\":[{\"name\":\"count\",\"type\":\"int\"},"
-          + "{\"name\":\"name\",\"type\":\"string\"}]}");
+          Schema.parse("{\"name\":\"stats\",\"type\":\"record\","
+                  + "\"fields\":[{\"name\":\"count\",\"type\":\"int\"},"
+                  + "{\"name\":\"name\",\"type\":\"string\"}]}");
   public static final Schema STATS_SCHEMA_2 =
-      Schema.parse("{\"name\":\"stats\",\"type\":\"record\","
-          + "\"fields\":[{\"name\":\"count1\",\"type\":\"int\"},"
-          + "{\"name\":\"name1\",\"type\":\"string\"}]}");
+          Schema.parse("{\"name\":\"stats\",\"type\":\"record\","
+                  + "\"fields\":[{\"name\":\"count1\",\"type\":\"int\"},"
+                  + "{\"name\":\"name1\",\"type\":\"string\"}]}");
 
   private static class LineCountMapper extends Mapper<LongWritable, Text, Text, IntWritable> {
     private IntWritable mOne;
@@ -72,13 +74,13 @@ protected void setup(Context context) {
 
     @Override
     protected void map(LongWritable fileByteOffset, Text line, Context context)
-        throws IOException, InterruptedException {
+            throws IOException, InterruptedException {
       context.write(line, mOne);
     }
   }
 
   private static class StatCountMapper
-      extends Mapper<AvroKey<TextStats>, NullWritable, Text, IntWritable> {
+          extends Mapper<AvroKey<TextStats>, NullWritable, Text, IntWritable> {
     private IntWritable mCount;
     private Text mText;
 
@@ -90,7 +92,7 @@ protected void setup(Context context) {
 
     @Override
     protected void map(AvroKey<TextStats> record, NullWritable ignore, Context context)
-        throws IOException, InterruptedException {
+            throws IOException, InterruptedException {
       mCount.set(record.datum().count);
       mText.set(record.datum().name.toString());
       context.write(mText, mCount);
@@ -98,7 +100,7 @@ protected void map(AvroKey<TextStats> record, NullWritable ignore, Context conte
   }
 
   private static class GenericStatsReducer
-      extends Reducer<Text, IntWritable, AvroKey<GenericData.Record>, NullWritable> {
+          extends Reducer<Text, IntWritable, AvroKey<GenericData.Record>, NullWritable> {
     private AvroKey<GenericData.Record> mStats;
     private AvroMultipleOutputs amos;
 
@@ -110,7 +112,7 @@ protected void setup(Context context) {
 
     @Override
     protected void reduce(Text line, Iterable<IntWritable> counts, Context context)
-        throws IOException, InterruptedException {
+            throws IOException, InterruptedException {
       GenericData.Record record = new GenericData.Record(STATS_SCHEMA);
       GenericData.Record record2 = new GenericData.Record(STATS_SCHEMA_2);
       int sum = 0;
@@ -121,27 +123,27 @@ protected void reduce(Text line, Iterable<IntWritable> counts, Context context)
       record.put("count", new Integer(sum));
       mStats.datum(record);
       context.write(mStats, NullWritable.get());
-      amos.write("myavro",mStats,NullWritable.get());
+      amos.write("myavro", mStats, NullWritable.get());
       record2.put("name1", new Utf8(line.toString()));
       record2.put("count1", new Integer(sum));
       mStats.datum(record2);
       amos.write(mStats, NullWritable.get(), STATS_SCHEMA_2, null, "testnewwrite2");
-      amos.write("myavro1",mStats);
+      amos.write("myavro1", mStats);
       amos.write(mStats, NullWritable.get(), STATS_SCHEMA, null, "testnewwrite");
       amos.write(mStats, NullWritable.get(), "testwritenonschema");
     }
 
     @Override
-    protected void cleanup(Context context) throws IOException,InterruptedException
-    {
+    protected void cleanup(Context context) throws IOException, InterruptedException {
       amos.close();
     }
   }
 
   private static class SpecificStatsReducer
-      extends Reducer<Text, IntWritable, AvroKey<TextStats>, NullWritable> {
+          extends Reducer<Text, IntWritable, AvroKey<TextStats>, NullWritable> {
     private AvroKey<TextStats> mStats;
     private AvroMultipleOutputs amos;
+
     @Override
     protected void setup(Context context) {
       mStats = new AvroKey<>(null);
@@ -150,7 +152,7 @@ protected void setup(Context context) {
 
     @Override
     protected void reduce(Text line, Iterable<IntWritable> counts, Context context)
-        throws IOException, InterruptedException {
+            throws IOException, InterruptedException {
       TextStats record = new TextStats();
       record.count = 0;
       for (IntWritable count : counts) {
@@ -159,29 +161,29 @@ protected void reduce(Text line, Iterable<IntWritable> counts, Context context)
       record.name = line.toString();
       mStats.datum(record);
       context.write(mStats, NullWritable.get());
-      amos.write("myavro3",mStats,NullWritable.get());
+      amos.write("myavro3", mStats, NullWritable.get());
     }
+
     @Override
-    protected void cleanup(Context context) throws IOException,InterruptedException
-    {
+    protected void cleanup(Context context) throws IOException, InterruptedException {
       amos.close();
     }
   }
 
   private static class SortMapper
-      extends Mapper<AvroKey<TextStats>, NullWritable, AvroKey<TextStats>, NullWritable> {
+          extends Mapper<AvroKey<TextStats>, NullWritable, AvroKey<TextStats>, NullWritable> {
     @Override
     protected void map(AvroKey<TextStats> key, NullWritable value, Context context)
-        throws IOException, InterruptedException {
+            throws IOException, InterruptedException {
       context.write(key, value);
     }
   }
 
   private static class SortReducer
-      extends Reducer<AvroKey<TextStats>, NullWritable, AvroKey<TextStats>, NullWritable> {
+          extends Reducer<AvroKey<TextStats>, NullWritable, AvroKey<TextStats>, NullWritable> {
     @Override
     protected void reduce(AvroKey<TextStats> key, Iterable<NullWritable> ignore, Context context)
-        throws IOException, InterruptedException {
+            throws IOException, InterruptedException {
       context.write(key, NullWritable.get());
     }
   }
@@ -201,11 +203,11 @@ public void testAvroGenericOutput() throws Exception {
 
     job.setReducerClass(GenericStatsReducer.class);
     AvroJob.setOutputKeySchema(job, STATS_SCHEMA);
-    AvroMultipleOutputs.addNamedOutput(job,"myavro",AvroKeyOutputFormat.class,STATS_SCHEMA,null);
-    AvroMultipleOutputs.addNamedOutput(job,"myavro1", AvroKeyOutputFormat.class, STATS_SCHEMA_2);
+    AvroMultipleOutputs.addNamedOutput(job, "myavro", AvroKeyOutputFormat.class, STATS_SCHEMA, null);
+    AvroMultipleOutputs.addNamedOutput(job, "myavro1", AvroKeyOutputFormat.class, STATS_SCHEMA_2);
     job.setOutputFormatClass(AvroKeyOutputFormat.class);
-    String dir = System.getProperty("test.dir", ".") + "/mapred";
-    Path outputPath = new Path(dir + "/out");
+
+    Path outputPath = new Path(DIR.getRoot().getPath() + "/testAvroGenericOutput");
     outputPath.getFileSystem(job.getConfiguration()).delete(outputPath);
     FileOutputFormat.setOutputPath(job, outputPath);
 
@@ -215,14 +217,16 @@ public void testAvroGenericOutput() throws Exception {
     FileSystem fileSystem = FileSystem.get(job.getConfiguration());
     FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/myavro-r-00000.avro"));
     Assert.assertEquals(1, outputFiles.length);
-    DataFileReader<GenericData.Record> reader = new DataFileReader<>(
-        new FsInput(outputFiles[0].getPath(), job.getConfiguration()),
-        new GenericDatumReader<>(STATS_SCHEMA));
+
     Map<String, Integer> counts = new HashMap<>();
-    for (GenericData.Record record : reader) {
-      counts.put(((Utf8) record.get("name")).toString(), (Integer) record.get("count"));
+
+    try (DataFileReader<GenericData.Record> reader = new DataFileReader<>(
+            new FsInput(outputFiles[0].getPath(), job.getConfiguration()),
+            new GenericDatumReader<>(STATS_SCHEMA))) {
+      for (GenericData.Record record : reader) {
+        counts.put(((Utf8) record.get("name")).toString(), (Integer) record.get("count"));
+      }
     }
-    reader.close();
 
     Assert.assertEquals(3, counts.get("apple").intValue());
     Assert.assertEquals(2, counts.get("banana").intValue());
@@ -230,14 +234,14 @@ public void testAvroGenericOutput() throws Exception {
 
     outputFiles = fileSystem.globStatus(outputPath.suffix("/myavro1-r-00000.avro"));
     Assert.assertEquals(1, outputFiles.length);
-    reader = new DataFileReader<>(
-        new FsInput(outputFiles[0].getPath(), job.getConfiguration()),
-        new GenericDatumReader<>(STATS_SCHEMA_2));
-    counts = new HashMap<>();
-    for (GenericData.Record record : reader) {
-      counts.put(((Utf8) record.get("name1")).toString(), (Integer) record.get("count1"));
+    counts.clear();
+    try (DataFileReader<GenericData.Record> reader = new DataFileReader<>(
+            new FsInput(outputFiles[0].getPath(), job.getConfiguration()),
+            new GenericDatumReader<>(STATS_SCHEMA_2))) {
+      for (GenericData.Record record : reader) {
+        counts.put(((Utf8) record.get("name1")).toString(), (Integer) record.get("count1"));
+      }
     }
-    reader.close();
 
     Assert.assertEquals(3, counts.get("apple").intValue());
     Assert.assertEquals(2, counts.get("banana").intValue());
@@ -245,14 +249,14 @@ public void testAvroGenericOutput() throws Exception {
 
     outputFiles = fileSystem.globStatus(outputPath.suffix("/testnewwrite-r-00000.avro"));
     Assert.assertEquals(1, outputFiles.length);
-    reader = new DataFileReader<>(
-        new FsInput(outputFiles[0].getPath(), job.getConfiguration()),
-        new GenericDatumReader<>(STATS_SCHEMA));
-    counts = new HashMap<>();
-    for (GenericData.Record record : reader) {
-       counts.put(((Utf8) record.get("name")).toString(), (Integer) record.get("count"));
+    counts.clear();
+    try (DataFileReader<GenericData.Record> reader = new DataFileReader<>(
+            new FsInput(outputFiles[0].getPath(), job.getConfiguration()),
+            new GenericDatumReader<>(STATS_SCHEMA))) {
+      for (GenericData.Record record : reader) {
+        counts.put(((Utf8) record.get("name")).toString(), (Integer) record.get("count"));
+      }
     }
-    reader.close();
 
     Assert.assertEquals(3, counts.get("apple").intValue());
     Assert.assertEquals(2, counts.get("banana").intValue());
@@ -260,34 +264,32 @@ public void testAvroGenericOutput() throws Exception {
 
     outputFiles = fileSystem.globStatus(outputPath.suffix("/testnewwrite2-r-00000.avro"));
     Assert.assertEquals(1, outputFiles.length);
-    reader = new DataFileReader<>(
-        new FsInput(outputFiles[0].getPath(), job.getConfiguration()),
-        new GenericDatumReader<>(STATS_SCHEMA_2));
-    counts = new HashMap<>();
-    for (GenericData.Record record : reader) {
-     counts.put(((Utf8) record.get("name1")).toString(), (Integer) record.get("count1"));
+    counts.clear();
+    try (DataFileReader<GenericData.Record> reader = new DataFileReader<>(
+            new FsInput(outputFiles[0].getPath(), job.getConfiguration()),
+            new GenericDatumReader<>(STATS_SCHEMA_2))) {
+      for (GenericData.Record record : reader) {
+        counts.put(((Utf8) record.get("name1")).toString(), (Integer) record.get("count1"));
+      }
     }
-    reader.close();
     Assert.assertEquals(3, counts.get("apple").intValue());
     Assert.assertEquals(2, counts.get("banana").intValue());
     Assert.assertEquals(1, counts.get("carrot").intValue());
 
     outputFiles = fileSystem.globStatus(outputPath.suffix("/testwritenonschema-r-00000.avro"));
     Assert.assertEquals(1, outputFiles.length);
-    reader = new DataFileReader<>(
-        new FsInput(outputFiles[0].getPath(), job.getConfiguration()),
-        new GenericDatumReader<>(STATS_SCHEMA));
-    counts = new HashMap<>();
-    for (GenericData.Record record : reader) {
-      counts.put(((Utf8) record.get("name")).toString(), (Integer) record.get("count"));
+    counts.clear();
+    try (DataFileReader<GenericData.Record> reader = new DataFileReader<>(
+            new FsInput(outputFiles[0].getPath(), job.getConfiguration()),
+            new GenericDatumReader<>(STATS_SCHEMA))) {
+      for (GenericData.Record record : reader) {
+        counts.put(((Utf8) record.get("name")).toString(), (Integer) record.get("count"));
+      }
     }
-    reader.close();
 
     Assert.assertEquals(3, counts.get("apple").intValue());
     Assert.assertEquals(2, counts.get("banana").intValue());
     Assert.assertEquals(1, counts.get("carrot").intValue());
-
-
   }
 
   @Test
@@ -302,14 +304,13 @@ public void testAvroSpecificOutput() throws Exception {
     job.setMapperClass(LineCountMapper.class);
     job.setMapOutputKeyClass(Text.class);
     job.setMapOutputValueClass(IntWritable.class);
-    AvroMultipleOutputs.addNamedOutput(job,"myavro3",AvroKeyOutputFormat.class,TextStats.SCHEMA$,null);
+    AvroMultipleOutputs.addNamedOutput(job, "myavro3", AvroKeyOutputFormat.class, TextStats.SCHEMA$, null);
 
     job.setReducerClass(SpecificStatsReducer.class);
     AvroJob.setOutputKeySchema(job, TextStats.SCHEMA$);
 
     job.setOutputFormatClass(AvroKeyOutputFormat.class);
-    String dir = System.getProperty("test.dir", ".") + "/mapred";
-    Path outputPath = new Path(dir + "/out-specific");
+    Path outputPath = new Path(DIR.getRoot().getPath() + "/testAvroSpecificOutput");
     outputPath.getFileSystem(job.getConfiguration()).delete(outputPath);
     FileOutputFormat.setOutputPath(job, outputPath);
 
@@ -317,14 +318,14 @@ public void testAvroSpecificOutput() throws Exception {
     FileSystem fileSystem = FileSystem.get(job.getConfiguration());
     FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/myavro3-*"));
     Assert.assertEquals(1, outputFiles.length);
-    DataFileReader<TextStats> reader = new DataFileReader<>(
-        new FsInput(outputFiles[0].getPath(), job.getConfiguration()),
-        new SpecificDatumReader<>());
     Map<String, Integer> counts = new HashMap<>();
-    for (TextStats record : reader) {
-      counts.put(record.name.toString(), record.count);
+    try (DataFileReader<TextStats> reader = new DataFileReader<>(
+            new FsInput(outputFiles[0].getPath(), job.getConfiguration()),
+            new SpecificDatumReader<>())) {
+      for (TextStats record : reader) {
+        counts.put(record.name.toString(), record.count);
+      }
     }
-    reader.close();
 
     Assert.assertEquals(3, counts.get("apple").intValue());
     Assert.assertEquals(2, counts.get("banana").intValue());
@@ -340,7 +341,7 @@ public void testAvroInput() throws Exception {
             .toURI().toString()));
     job.setInputFormatClass(AvroKeyInputFormat.class);
     AvroJob.setInputKeySchema(job, TextStats.SCHEMA$);
-    AvroMultipleOutputs.addNamedOutput(job,"myavro3",AvroKeyOutputFormat.class,TextStats.SCHEMA$,null);
+    AvroMultipleOutputs.addNamedOutput(job, "myavro3", AvroKeyOutputFormat.class, TextStats.SCHEMA$, null);
 
     job.setMapperClass(StatCountMapper.class);
     job.setMapOutputKeyClass(Text.class);
@@ -350,7 +351,7 @@ public void testAvroInput() throws Exception {
     AvroJob.setOutputKeySchema(job, TextStats.SCHEMA$);
 
     job.setOutputFormatClass(AvroKeyOutputFormat.class);
-    Path outputPath = new Path(tmpFolder.getRoot().getPath() + "/out-specific-input");
+    Path outputPath = new Path(DIR.getRoot().getPath() + "/testAvroInput");
     FileOutputFormat.setOutputPath(job, outputPath);
 
     Assert.assertTrue(job.waitForCompletion(true));
@@ -359,14 +360,14 @@ public void testAvroInput() throws Exception {
     FileSystem fileSystem = FileSystem.get(job.getConfiguration());
     FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/myavro3-*"));
     Assert.assertEquals(1, outputFiles.length);
-    DataFileReader<TextStats> reader = new DataFileReader<>(
-        new FsInput(outputFiles[0].getPath(), job.getConfiguration()),
-        new SpecificDatumReader<>());
     Map<String, Integer> counts = new HashMap<>();
-    for (TextStats record : reader) {
-      counts.put(record.name.toString(), record.count);
+    try (DataFileReader<TextStats> reader = new DataFileReader<>(
+            new FsInput(outputFiles[0].getPath(), job.getConfiguration()),
+            new SpecificDatumReader<>())) {
+      for (TextStats record : reader) {
+        counts.put(record.name.toString(), record.count);
+      }
     }
-    reader.close();
 
     Assert.assertEquals(3, counts.get("apple").intValue());
     Assert.assertEquals(2, counts.get("banana").intValue());
@@ -391,7 +392,7 @@ public void testAvroMapOutput() throws Exception {
     AvroJob.setOutputKeySchema(job, TextStats.SCHEMA$);
 
     job.setOutputFormatClass(AvroKeyOutputFormat.class);
-    Path outputPath = new Path(tmpFolder.getRoot().getPath() + "/out-specific-input");
+    Path outputPath = new Path(DIR.getRoot().getPath() + "/testAvroMapOutput");
     FileOutputFormat.setOutputPath(job, outputPath);
 
     Assert.assertTrue(job.waitForCompletion(true));
@@ -400,14 +401,14 @@ public void testAvroMapOutput() throws Exception {
     FileSystem fileSystem = FileSystem.get(job.getConfiguration());
     FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/part-*"));
     Assert.assertEquals(1, outputFiles.length);
-    DataFileReader<TextStats> reader = new DataFileReader<>(
-        new FsInput(outputFiles[0].getPath(), job.getConfiguration()),
-        new SpecificDatumReader<>());
     Map<String, Integer> counts = new HashMap<>();
-    for (TextStats record : reader) {
-      counts.put(record.name.toString(), record.count);
+    try (DataFileReader<TextStats> reader = new DataFileReader<>(
+            new FsInput(outputFiles[0].getPath(), job.getConfiguration()),
+            new SpecificDatumReader<>())) {
+      for (TextStats record : reader) {
+        counts.put(record.name.toString(), record.count);
+      }
     }
-    reader.close();
 
     Assert.assertEquals(3, counts.get("apple").intValue());
     Assert.assertEquals(2, counts.get("banana").intValue());
diff --git a/lang/java/mapred/src/test/java/org/apache/avro/mapreduce/TestAvroMultipleOutputsSyncable.java b/lang/java/mapred/src/test/java/org/apache/avro/mapreduce/TestAvroMultipleOutputsSyncable.java
index b438ab6e1..e713f9aba 100644
--- a/lang/java/mapred/src/test/java/org/apache/avro/mapreduce/TestAvroMultipleOutputsSyncable.java
+++ b/lang/java/mapred/src/test/java/org/apache/avro/mapreduce/TestAvroMultipleOutputsSyncable.java
@@ -52,6 +52,7 @@
 public class TestAvroMultipleOutputsSyncable {
   @Rule
   public TemporaryFolder tmpFolder = new TemporaryFolder();
+
   public static final Schema STATS_SCHEMA =
       Schema.parse("{\"name\":\"stats\",\"type\":\"record\","
           + "\"fields\":[{\"name\":\"count\",\"type\":\"int\"},"
@@ -117,13 +118,13 @@ protected void reduce(Text line, Iterable<IntWritable> counts, Context context)
         sum += count.get();
       }
       record.put("name", new Utf8(line.toString()));
-      record.put("count", new Integer(sum));
+      record.put("count", sum);
       mStats.datum(record);
       context.write(mStats, NullWritable.get());
       amos.sync("myavro","myavro");
       amos.write("myavro",mStats,NullWritable.get());
       record2.put("name1", new Utf8(line.toString()));
-      record2.put("count1", new Integer(sum));
+      record2.put("count1", sum);
       mStats.datum(record2);
       amos.write(mStats, NullWritable.get(), STATS_SCHEMA_2, null, "testnewwrite2");
       amos.sync("myavro1","myavro1");
@@ -206,8 +207,7 @@ public void testAvroGenericOutput() throws Exception {
     AvroMultipleOutputs.addNamedOutput(job,"myavro",AvroKeyOutputFormat.class,STATS_SCHEMA,null);
     AvroMultipleOutputs.addNamedOutput(job,"myavro1", AvroKeyOutputFormat.class, STATS_SCHEMA_2);
     job.setOutputFormatClass(AvroKeyOutputFormat.class);
-    String dir = System.getProperty("test.dir", ".") + "/mapred";
-    Path outputPath = new Path(dir + "/out");
+    Path outputPath = new Path(tmpFolder.getRoot().getPath() + "/out");
     outputPath.getFileSystem(job.getConfiguration()).delete(outputPath);
     FileOutputFormat.setOutputPath(job, outputPath);
 
@@ -310,8 +310,7 @@ public void testAvroSpecificOutput() throws Exception {
     AvroJob.setOutputKeySchema(job, TextStats.SCHEMA$);
 
     job.setOutputFormatClass(AvroKeyOutputFormat.class);
-    String dir = System.getProperty("test.dir", ".") + "/mapred";
-    Path outputPath = new Path(dir + "/out-specific");
+    Path outputPath = new Path(tmpFolder.getRoot().getPath() + "/out-specific");
     outputPath.getFileSystem(job.getConfiguration()).delete(outputPath);
     FileOutputFormat.setOutputPath(job, outputPath);
 
diff --git a/lang/java/mapred/src/test/java/org/apache/avro/mapreduce/TestFsInput.java b/lang/java/mapred/src/test/java/org/apache/avro/mapreduce/TestFsInput.java
index 33adc6c8d..3d4f9c60f 100644
--- a/lang/java/mapred/src/test/java/org/apache/avro/mapreduce/TestFsInput.java
+++ b/lang/java/mapred/src/test/java/org/apache/avro/mapreduce/TestFsInput.java
@@ -29,15 +29,12 @@
 import java.io.PrintWriter;
 import java.nio.charset.Charset;
 
-import org.apache.avro.AvroTestUtil;
 import org.apache.avro.mapred.FsInput;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
-import org.junit.After;
-import org.junit.Before;
-import org.junit.BeforeClass;
-import org.junit.Test;
+import org.junit.*;
+import org.junit.rules.TemporaryFolder;
 
 public class TestFsInput {
   private static File file;
@@ -45,22 +42,18 @@
   private Configuration conf;
   private FsInput fsInput;
 
-  @BeforeClass
-  public static void setUpBeforeClass() throws Exception {
-    File directory = AvroTestUtil.tempDirectory(TestFsInput.class, "file");
-    file = new File(directory, "file.txt");
-    PrintWriter out = new PrintWriter(new OutputStreamWriter(new FileOutputStream(file), Charset.forName("UTF-8")));
-    try {
-      out.print(FILE_CONTENTS);
-    } finally {
-      out.close();
-    }
-  }
+  @Rule
+  public TemporaryFolder DIR = new TemporaryFolder();
 
   @Before
   public void setUp() throws Exception {
     conf = new Configuration();
     conf.set("fs.default.name", "file:///");
+    file = new File(DIR.getRoot(), "file.txt");
+
+    try (PrintWriter out = new PrintWriter(new OutputStreamWriter(new FileOutputStream(file), Charset.forName("UTF-8")))) {
+      out.print(FILE_CONTENTS);
+    }
     fsInput = new FsInput(new Path(file.getPath()), conf);
   }
 
@@ -73,14 +66,11 @@ public void tearDown() throws Exception {
 
   @Test
   public void testConfigurationConstructor() throws Exception {
-    FsInput in = new FsInput(new Path(file.getPath()), conf);
-    try {
+    try (FsInput in = new FsInput(new Path(file.getPath()), conf)) {
       int expectedByteCount = 1;
       byte[] readBytes = new byte[expectedByteCount];
       int actualByteCount = fsInput.read(readBytes, 0, expectedByteCount);
       assertThat(actualByteCount, is(equalTo(expectedByteCount)));
-    } finally {
-      in.close();
     }
   }
 
@@ -88,14 +78,11 @@ public void testConfigurationConstructor() throws Exception {
   public void testFileSystemConstructor() throws Exception {
     Path path = new Path(file.getPath());
     FileSystem fs = path.getFileSystem(conf);
-    FsInput in = new FsInput(path, fs);
-    try {
+    try (FsInput in = new FsInput(path, fs)) {
       int expectedByteCount = 1;
       byte[] readBytes = new byte[expectedByteCount];
       int actualByteCount = fsInput.read(readBytes, 0, expectedByteCount);
       assertThat(actualByteCount, is(equalTo(expectedByteCount)));
-    } finally {
-      in.close();
     }
   }
 
diff --git a/lang/java/pom.xml b/lang/java/pom.xml
index 0abf3c090..eae6899de 100644
--- a/lang/java/pom.xml
+++ b/lang/java/pom.xml
@@ -204,7 +204,6 @@
               <configuration>
                 <systemPropertyVariables>
                   <org.apache.avro.specific.use_custom_coders>true</org.apache.avro.specific.use_custom_coders>
-                  <test.dir>${project.basedir}/target/</test.dir>
                 </systemPropertyVariables>
               </configuration>
             </execution>
@@ -236,9 +235,6 @@
             <redirectTestOutputToFile>true</redirectTestOutputToFile>
             <failIfNoTests>false</failIfNoTests>
             <argLine>-Xmx1000m</argLine>
-            <systemPropertyVariables>
-              <test.dir>${project.basedir}/target/</test.dir>
-            </systemPropertyVariables>
           </configuration>
         </plugin>
         <plugin>
@@ -393,7 +389,6 @@
             <artifactId>maven-surefire-plugin</artifactId>
             <configuration>
               <systemPropertyVariables>
-                <test.dir>${project.basedir}/target/</test.dir>
                 <!-- avro-mapred will fail in tests on mac without this -->
                 <java.security.krb5.realm>OX.AC.UK</java.security.krb5.realm>
                 <java.security.krb5.kdc>kdc0.ox.ac.uk:kdc1.ox.ac.uk</java.security.krb5.kdc>
diff --git a/lang/java/tools/src/test/compiler/output-string/avro/examples/baseball/Player.java b/lang/java/tools/src/test/compiler/output-string/avro/examples/baseball/Player.java
index 26cc31fc0..c972235ed 100644
--- a/lang/java/tools/src/test/compiler/output-string/avro/examples/baseball/Player.java
+++ b/lang/java/tools/src/test/compiler/output-string/avro/examples/baseball/Player.java
@@ -541,13 +541,3 @@ public Player build() {
     }
   }
 }
-
-
-
-
-
-
-
-
-
-
diff --git a/lang/java/tools/src/test/compiler/output/Player.java b/lang/java/tools/src/test/compiler/output/Player.java
index 8eaf5d7ad..af4e8f783 100644
--- a/lang/java/tools/src/test/compiler/output/Player.java
+++ b/lang/java/tools/src/test/compiler/output/Player.java
@@ -541,13 +541,3 @@ public Player build() {
     }
   }
 }
-
-
-
-
-
-
-
-
-
-
diff --git a/lang/java/tools/src/test/java/org/apache/avro/tool/TestCatTool.java b/lang/java/tools/src/test/java/org/apache/avro/tool/TestCatTool.java
index cfc38c990..4b2312547 100644
--- a/lang/java/tools/src/test/java/org/apache/avro/tool/TestCatTool.java
+++ b/lang/java/tools/src/test/java/org/apache/avro/tool/TestCatTool.java
@@ -33,7 +33,6 @@
 import java.util.Map;
 import java.util.Map.Entry;
 
-import org.apache.avro.AvroTestUtil;
 import org.apache.avro.Schema;
 import org.apache.avro.Schema.Type;
 import org.apache.avro.file.CodecFactory;
@@ -43,9 +42,19 @@
 import org.apache.avro.generic.GenericDatumReader;
 import org.apache.avro.generic.GenericDatumWriter;
 import org.apache.avro.generic.GenericRecord;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
+import org.junit.rules.TestName;
 
 public class TestCatTool {
+
+  @Rule
+  public TestName name = new TestName();
+
+  @Rule
+  public TemporaryFolder DIR = new TemporaryFolder();
+
   private static final int ROWS_IN_INPUT_FILES = 100000;
   private static final int OFFSET = 1000;
   private static final int LIMIT_WITHIN_INPUT_BOUNDS = 100;
@@ -69,7 +78,7 @@
 
 
   private GenericRecord aDatum(Type ofType, int forRow) {
-    GenericRecord record = null;
+    GenericRecord record;
     switch (ofType) {
       case STRING:
         record = new GenericData.Record(STRINGSCHEMA);
@@ -85,7 +94,7 @@ private GenericRecord aDatum(Type ofType, int forRow) {
   }
 
   private File generateData(String file, Type type, Map<String, String> metadata, CodecFactory codec) throws Exception {
-    File inputFile = AvroTestUtil.tempFile(getClass(), file);
+    File inputFile = new File(DIR.getRoot(), file);
     inputFile.deleteOnExit();
 
     Schema schema = null;
@@ -146,7 +155,7 @@ public void testCat() throws Exception {
     File input2 = generateData("input2.avro", Type.INT, metadata, SNAPPY);
     File input3 = generateData("input3.avro", Type.INT, metadata, DEFLATE);
 
-    File output = AvroTestUtil.tempFile(getClass(), "out/default-output.avro");
+    File output = new File(DIR.getRoot(), name.getMethodName() + ".avro");
     output.deleteOnExit();
 
 //    file input
@@ -203,7 +212,7 @@ public void testLimitOutOfBounds() throws Exception {
     metadata.put("myMetaKey", "myMetaValue");
 
     File input1 = generateData("input1.avro", Type.INT, metadata, DEFLATE);
-    File output = AvroTestUtil.tempFile(getClass(), "out/default-output.avro");
+    File output = new File(DIR.getRoot(), name.getMethodName() + ".avro");
     output.deleteOnExit();
 
     List<String> args = asList(
@@ -226,7 +235,7 @@ public void testSamplerateAccuracy() throws Exception {
     metadata.put("myMetaKey", "myMetaValue");
 
     File input1 = generateData("input1.avro", Type.INT, metadata, DEFLATE);
-    File output = AvroTestUtil.tempFile(getClass(), "out/default-output.avro");
+    File output = new File(DIR.getRoot(), name.getMethodName() + ".avro");
     output.deleteOnExit();
 
     List<String>args = asList(
@@ -252,7 +261,7 @@ public void testOffSetAccuracy() throws Exception {
     metadata.put("myMetaKey", "myMetaValue");
 
     File input1 = generateData("input1.avro", Type.INT, metadata, DEFLATE);
-    File output = AvroTestUtil.tempFile(getClass(), "out/default-output.avro");
+    File output = new File(DIR.getRoot(), name.getMethodName() + ".avro");
     output.deleteOnExit();
 
     List<String> args = asList(
@@ -277,7 +286,7 @@ public void testOffsetBiggerThanInput() throws Exception{
     metadata.put("myMetaKey", "myMetaValue");
 
     File input1 = generateData("input1.avro", Type.INT, metadata, DEFLATE);
-    File output = AvroTestUtil.tempFile(getClass(), "out/default-output.avro");
+    File output = new File(DIR.getRoot(), name.getMethodName() + ".avro");
     output.deleteOnExit();
 
     List<String> args = asList(
@@ -300,14 +309,14 @@ public void testSamplerateSmallerThanInput() throws Exception{
     metadata.put("myMetaKey", "myMetaValue");
 
     File input1 = generateData("input1.avro", Type.INT, metadata, DEFLATE);
-    File output = AvroTestUtil.tempFile(getClass(), "out/default-output.avro");
+    File output = new File(DIR.getRoot(), name.getMethodName() + ".avro");
     output.deleteOnExit();
 
     List<String> args = asList(
       input1.getAbsolutePath(),
       output.getAbsolutePath(),
-      "--offset=" +  new Integer(OFFSET).toString(),
-      "--samplerate=" + new Double(SAMPLERATE_TOO_SMALL).toString());
+      "--offset=" + Integer.toString(OFFSET),
+      "--samplerate=" + Double.toString(SAMPLERATE_TOO_SMALL));
     int returnCode = new CatTool().run(
       System.in,
       System.out,
@@ -328,7 +337,7 @@ public void testDifferentSchemasFail() throws Exception {
     File input1 = generateData("input1.avro", Type.STRING, metadata, DEFLATE);
     File input2 = generateData("input2.avro", Type.INT, metadata, DEFLATE);
 
-    File output = AvroTestUtil.tempFile(getClass(), "out/default-output.avro");
+    File output = new File(DIR.getRoot(), name.getMethodName() + ".avro");
     output.deleteOnExit();
 
     List<String> args = asList(
@@ -345,13 +354,14 @@ public void testDifferentSchemasFail() throws Exception {
   @Test
   public void testHelpfulMessageWhenNoArgsGiven() throws Exception {
     ByteArrayOutputStream buffer = new ByteArrayOutputStream(1024);
-    PrintStream out = new PrintStream(buffer);
-    int returnCode = new CatTool().run(
-      System.in,
-      out,
-      System.err,
-      Collections.emptyList());
-    out.close(); // flushes too
+    int returnCode;
+    try(PrintStream out = new PrintStream(buffer)) {
+      returnCode = new CatTool().run(
+              System.in,
+              out,
+              System.err,
+              Collections.emptyList());
+    }
 
     assertEquals(0, returnCode);
     assertTrue(
diff --git a/lang/java/tools/src/test/java/org/apache/avro/tool/TestConcatTool.java b/lang/java/tools/src/test/java/org/apache/avro/tool/TestConcatTool.java
index 777d83ed7..4c0c57147 100644
--- a/lang/java/tools/src/test/java/org/apache/avro/tool/TestConcatTool.java
+++ b/lang/java/tools/src/test/java/org/apache/avro/tool/TestConcatTool.java
@@ -27,14 +27,9 @@
 import java.io.FileInputStream;
 import java.io.FileNotFoundException;
 import java.io.PrintStream;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
+import java.util.*;
 import java.util.Map.Entry;
 
-import org.apache.avro.AvroTestUtil;
 import org.apache.avro.Schema;
 import org.apache.avro.Schema.Type;
 import org.apache.avro.file.CodecFactory;
@@ -44,12 +39,25 @@
 import org.apache.avro.generic.GenericDatumReader;
 import org.apache.avro.generic.GenericDatumWriter;
 import org.apache.avro.generic.GenericRecord;
+import org.apache.avro.util.Utf8;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
+import org.junit.rules.TestName;
 
 public class TestConcatTool {
   private static final int ROWS_IN_INPUT_FILES = 100000;
   private static final CodecFactory DEFLATE = CodecFactory.deflateCodec(9);
 
+  @Rule
+  public TestName name = new TestName();
+
+  @Rule
+  public TemporaryFolder INPUT_DIR = new TemporaryFolder();
+
+  @Rule
+  public TemporaryFolder OUTPUT_DIR = new TemporaryFolder();
+
   private Object aDatum(Type ofType, int forRow) {
     switch (ofType) {
       case STRING:
@@ -57,54 +65,44 @@ private Object aDatum(Type ofType, int forRow) {
       case INT:
         return forRow;
       default:
-       throw new AssertionError("I can't generate data for this type");
+        throw new AssertionError("I can't generate data for this type");
     }
   }
 
   private File generateData(String file, Type type, Map<String, String> metadata, CodecFactory codec) throws Exception {
-    File inputFile = AvroTestUtil.tempFile(getClass(), file);
-    inputFile.deleteOnExit();
-
+    File inputFile = new File(INPUT_DIR.getRoot(), file);
     Schema schema = Schema.create(type);
-    DataFileWriter<Object> writer = new DataFileWriter<>(
-        new GenericDatumWriter<>(schema));
-    for(Entry<String, String> metadatum : metadata.entrySet()) {
+    try (DataFileWriter<Object> writer = new DataFileWriter<>(new GenericDatumWriter<>(schema))) {
+      for (Entry<String, String> metadatum : metadata.entrySet()) {
         writer.setMeta(metadatum.getKey(), metadatum.getValue());
-    }
-    writer.setCodec(codec);
-    writer.create(schema, inputFile);
+      }
+      writer.setCodec(codec);
+      writer.create(schema, inputFile);
 
-    for (int i = 0; i < ROWS_IN_INPUT_FILES; i++) {
-      writer.append(aDatum(type, i));
+      for (int i = 0; i < ROWS_IN_INPUT_FILES; i++) {
+        writer.append(aDatum(type, i));
+      }
     }
-    writer.close();
-
     return inputFile;
   }
 
   private CodecFactory getCodec(File output) throws Exception {
-      DataFileStream<GenericRecord> reader = new DataFileStream<>(
-        new FileInputStream(output),
-        new GenericDatumReader<>());
+    try (DataFileStream<GenericRecord> reader = new DataFileStream<>(
+            new FileInputStream(output),
+            new GenericDatumReader<>())) {
       String codec = reader.getMetaString(DataFileConstants.CODEC);
-      try {
-        return codec == null ? CodecFactory.nullCodec() : CodecFactory.fromString(codec);
-      }finally{
-        reader.close();
-      }
+
+      return codec == null ? CodecFactory.nullCodec() : CodecFactory.fromString(codec);
+    }
   }
 
   private int numRowsInFile(File output) throws Exception {
-    DataFileStream<GenericRecord> reader = new DataFileStream<>(
-      new FileInputStream(output),
-      new GenericDatumReader<>());
-    Iterator<GenericRecord> rows = reader.iterator();
     int rowcount = 0;
-    while(rows.hasNext()) {
-      ++rowcount;
-      rows.next();
+    try (DataFileStream<Utf8> reader = new DataFileStream<>(new FileInputStream(output), new GenericDatumReader<>())) {
+      for (Utf8 ignored : reader) {
+        ++rowcount;
+      }
     }
-    reader.close();
     return rowcount;
   }
 
@@ -112,28 +110,23 @@ private int numRowsInFile(File output) throws Exception {
   public void testDirConcat() throws Exception {
     Map<String, String> metadata = new HashMap<>();
 
-    File dir = AvroTestUtil.tempDirectory(getClass(), "input");
-
     for (int i = 0; i < 3; i++) {
-      String filename = "input" + i + ".avro";
-      File input = generateData(filename, Type.STRING, metadata, DEFLATE);
-      boolean ok = input.renameTo(new File(dir, input.getName()));
-      assertTrue(ok);
+      generateData(name.getMethodName() + "-" + i + ".avro", Type.STRING, metadata, DEFLATE);
     }
 
-    File output = AvroTestUtil.tempFile(getClass(), "default-output.avro");
-    output.deleteOnExit();
+    File output = new File(OUTPUT_DIR.getRoot(), name.getMethodName() + ".avro");
 
     List<String> args = asList(
-      dir.getAbsolutePath(),
-      output.getAbsolutePath());
+            INPUT_DIR.getRoot().getAbsolutePath(),
+            output.getAbsolutePath()
+    );
     int returnCode = new ConcatTool().run(
-      System.in,
-      System.out,
-      System.err,
-      args);
-    assertEquals(0, returnCode);
+            System.in,
+            System.out,
+            System.err,
+            args);
 
+    assertEquals(0, returnCode);
     assertEquals(ROWS_IN_INPUT_FILES * 3, numRowsInFile(output));
   }
 
@@ -141,48 +134,37 @@ public void testDirConcat() throws Exception {
   public void testGlobPatternConcat() throws Exception {
     Map<String, String> metadata = new HashMap<>();
 
-    File dir = AvroTestUtil.tempDirectory(getClass(), "input");
-
     for (int i = 0; i < 3; i++) {
-      String filename = "input" + i + ".avro";
-      File input = generateData(filename, Type.STRING, metadata, DEFLATE);
-      boolean ok = input.renameTo(new File(dir, input.getName()));
-      assertTrue(ok);
+      generateData(name.getMethodName() + "-" + i + ".avro", Type.STRING, metadata, DEFLATE);
     }
 
-    File output = AvroTestUtil.tempFile(getClass(), "default-output.avro");
-    output.deleteOnExit();
+    File output = new File(OUTPUT_DIR.getRoot(), name.getMethodName() + ".avro");
 
     List<String> args = asList(
-      new File(dir, "/*").getAbsolutePath(),
-      output.getAbsolutePath());
+            new File(INPUT_DIR.getRoot(), "/*").getAbsolutePath(),
+            output.getAbsolutePath());
     int returnCode = new ConcatTool().run(
-      System.in,
-      System.out,
-      System.err,
-      args);
-    assertEquals(0, returnCode);
+            System.in,
+            System.out,
+            System.err,
+            args);
 
+    assertEquals(0, returnCode);
     assertEquals(ROWS_IN_INPUT_FILES * 3, numRowsInFile(output));
   }
 
   @Test(expected = FileNotFoundException.class)
   public void testFileDoesNotExist() throws Exception {
-    Map<String, String> metadata = new HashMap<>();
-
-    File dir = AvroTestUtil.tempDirectory(getClass(), "input");
-
-    File output = AvroTestUtil.tempFile(getClass(), "default-output.avro");
-    output.deleteOnExit();
+    File output = new File(INPUT_DIR.getRoot(), name.getMethodName() + ".avro");
 
     List<String> args = asList(
-      new File(dir, "/doNotExist").getAbsolutePath(),
-      output.getAbsolutePath());
+            new File(INPUT_DIR.getRoot(), "/doNotExist").getAbsolutePath(),
+            output.getAbsolutePath());
     new ConcatTool().run(
-      System.in,
-      System.out,
-      System.err,
-      args);
+            System.in,
+            System.out,
+            System.err,
+            args);
   }
 
   @Test
@@ -190,23 +172,22 @@ public void testConcat() throws Exception {
     Map<String, String> metadata = new HashMap<>();
     metadata.put("myMetaKey", "myMetaValue");
 
-    File input1 = generateData("input1.avro", Type.STRING, metadata, DEFLATE);
-    File input2 = generateData("input2.avro", Type.STRING, metadata, DEFLATE);
-    File input3 = generateData("input3.avro", Type.STRING, metadata, DEFLATE);
+    File input1 = generateData(name.getMethodName() + "-1.avro", Type.STRING, metadata, DEFLATE);
+    File input2 = generateData(name.getMethodName() + "-2.avro", Type.STRING, metadata, DEFLATE);
+    File input3 = generateData(name.getMethodName() + "-3.avro", Type.STRING, metadata, DEFLATE);
 
-    File output = AvroTestUtil.tempFile(getClass(), "default-output.avro");
-    output.deleteOnExit();
+    File output = new File(OUTPUT_DIR.getRoot(), name.getMethodName() + ".avro");
 
     List<String> args = asList(
-      input1.getAbsolutePath(),
-      input2.getAbsolutePath(),
-      input3.getAbsolutePath(),
-      output.getAbsolutePath());
+            input1.getAbsolutePath(),
+            input2.getAbsolutePath(),
+            input3.getAbsolutePath(),
+            output.getAbsolutePath());
     int returnCode = new ConcatTool().run(
-      System.in,
-      System.out,
-      System.err,
-      args);
+            System.in,
+            System.out,
+            System.err,
+            args);
     assertEquals(0, returnCode);
 
     assertEquals(ROWS_IN_INPUT_FILES * 3, numRowsInFile(output));
@@ -218,21 +199,20 @@ public void testDifferentSchemasFail() throws Exception {
     Map<String, String> metadata = new HashMap<>();
     metadata.put("myMetaKey", "myMetaValue");
 
-    File input1 = generateData("input1.avro", Type.STRING, metadata, DEFLATE);
-    File input2 = generateData("input2.avro", Type.INT, metadata, DEFLATE);
+    File input1 = generateData(name.getMethodName() + "-1.avro", Type.STRING, metadata, DEFLATE);
+    File input2 = generateData(name.getMethodName() + "-2.avro", Type.INT, metadata, DEFLATE);
 
-    File output = AvroTestUtil.tempFile(getClass(), "default-output.avro");
-    output.deleteOnExit();
+    File output = new File(OUTPUT_DIR.getRoot(), name.getMethodName() + ".avro");
 
     List<String> args = asList(
-      input1.getAbsolutePath(),
-      input2.getAbsolutePath(),
-      output.getAbsolutePath());
+            input1.getAbsolutePath(),
+            input2.getAbsolutePath(),
+            output.getAbsolutePath());
     int returnCode = new ConcatTool().run(
-      System.in,
-      System.out,
-      System.err,
-      args);
+            System.in,
+            System.out,
+            System.err,
+            args);
     assertEquals(1, returnCode);
   }
 
@@ -243,21 +223,20 @@ public void testDifferentMetadataFail() throws Exception {
     Map<String, String> metadata2 = new HashMap<>();
     metadata2.put("myOtherMetaKey", "myOtherMetaValue");
 
-    File input1 = generateData("input1.avro", Type.STRING, metadata1, DEFLATE);
-    File input2 = generateData("input2.avro", Type.STRING, metadata2, DEFLATE);
+    File input1 = generateData(name.getMethodName() + "-1.avro", Type.STRING, metadata1, DEFLATE);
+    File input2 = generateData(name.getMethodName() + "-2.avro", Type.STRING, metadata2, DEFLATE);
 
-    File output = AvroTestUtil.tempFile(getClass(), "default-output.avro");
-    output.deleteOnExit();
+    File output = new File(OUTPUT_DIR.getRoot(), name.getMethodName() + ".avro");
 
     List<String> args = asList(
-      input1.getAbsolutePath(),
-      input2.getAbsolutePath(),
-      output.getAbsolutePath());
+            input1.getAbsolutePath(),
+            input2.getAbsolutePath(),
+            output.getAbsolutePath());
     int returnCode = new ConcatTool().run(
-      System.in,
-      System.out,
-      System.err,
-      args);
+            System.in,
+            System.out,
+            System.err,
+            args);
     assertEquals(2, returnCode);
   }
 
@@ -266,38 +245,38 @@ public void testDifferentCodecFail() throws Exception {
     Map<String, String> metadata = new HashMap<>();
     metadata.put("myMetaKey", "myMetaValue");
 
-    File input1 = generateData("input1.avro", Type.STRING, metadata, DEFLATE);
-    File input2 = generateData("input2.avro", Type.STRING, metadata, CodecFactory.nullCodec());
+    File input1 = generateData(name.getMethodName() + "-1.avro", Type.STRING, metadata, DEFLATE);
+    File input2 = generateData(name.getMethodName() + "-2.avro", Type.STRING, metadata, CodecFactory.nullCodec());
 
-    File output = AvroTestUtil.tempFile(getClass(), "default-output.avro");
-    output.deleteOnExit();
+    File output = new File(OUTPUT_DIR.getRoot(), name.getMethodName() + ".avro");
 
     List<String> args = asList(
-      input1.getAbsolutePath(),
-      input2.getAbsolutePath(),
-      output.getAbsolutePath());
+            input1.getAbsolutePath(),
+            input2.getAbsolutePath(),
+            output.getAbsolutePath());
     int returnCode = new ConcatTool().run(
-      System.in,
-      System.out,
-      System.err,
-      args);
+            System.in,
+            System.out,
+            System.err,
+            args);
     assertEquals(3, returnCode);
   }
 
   @Test
   public void testHelpfulMessageWhenNoArgsGiven() throws Exception {
-    ByteArrayOutputStream buffer = new ByteArrayOutputStream(1024);
-    PrintStream out = new PrintStream(buffer);
-    int returnCode = new ConcatTool().run(
-      System.in,
-      out,
-      System.err,
-      Collections.emptyList());
-    out.close(); // flushes too
-
+    int returnCode;
+    try (ByteArrayOutputStream buffer = new ByteArrayOutputStream(1024)) {
+      try (PrintStream out = new PrintStream(buffer)) {
+        returnCode = new ConcatTool().run(
+                System.in,
+                out,
+                System.err,
+                Collections.emptyList());
+      }
+      assertTrue(
+              "should have lots of help",
+              buffer.toString().trim().length() > 200);
+    }
     assertEquals(0, returnCode);
-    assertTrue(
-      "should have lots of help",
-      buffer.toString().trim().length() > 200);
   }
 }
diff --git a/lang/java/tools/src/test/java/org/apache/avro/tool/TestCreateRandomFileTool.java b/lang/java/tools/src/test/java/org/apache/avro/tool/TestCreateRandomFileTool.java
index d47eedd84..62d6e9af0 100644
--- a/lang/java/tools/src/test/java/org/apache/avro/tool/TestCreateRandomFileTool.java
+++ b/lang/java/tools/src/test/java/org/apache/avro/tool/TestCreateRandomFileTool.java
@@ -41,8 +41,7 @@
 
 public class TestCreateRandomFileTool {
   private static final String COUNT = System.getProperty("test.count", "200");
-  private static final File DIR
-    = new File(System.getProperty("test.dir", "/tmp"));
+  private static final File DIR = new File("/tmp");
   private static final File OUT_FILE = new File(DIR, "random.avro");
   private static final File SCHEMA_FILE =
     new File("../../../share/test/schemas/weather.avsc");
diff --git a/lang/java/tools/src/test/java/org/apache/avro/tool/TestDataFileRepairTool.java b/lang/java/tools/src/test/java/org/apache/avro/tool/TestDataFileRepairTool.java
index 2a4ed492f..191b7bed1 100644
--- a/lang/java/tools/src/test/java/org/apache/avro/tool/TestDataFileRepairTool.java
+++ b/lang/java/tools/src/test/java/org/apache/avro/tool/TestDataFileRepairTool.java
@@ -24,7 +24,7 @@
 import java.io.InputStream;
 import java.io.PrintStream;
 import java.util.Arrays;
-import org.apache.avro.AvroTestUtil;
+
 import org.apache.avro.Schema;
 import org.apache.avro.file.DataFileConstants;
 import org.apache.avro.file.DataFileReader;
@@ -33,10 +33,9 @@
 import org.apache.avro.generic.GenericDatumWriter;
 import org.apache.avro.io.BinaryData;
 import org.apache.avro.util.Utf8;
-import org.junit.After;
-import org.junit.Before;
-import org.junit.BeforeClass;
-import org.junit.Test;
+import org.junit.*;
+import org.junit.rules.TemporaryFolder;
+import org.junit.rules.TestName;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
@@ -44,6 +43,9 @@
 
 public class TestDataFileRepairTool {
 
+  @ClassRule
+  public static TemporaryFolder DIR = new TemporaryFolder();
+
   private static final Schema SCHEMA = Schema.create(Schema.Type.STRING);
   private static File corruptBlockFile;
   private static File corruptRecordFile;
@@ -52,21 +54,22 @@
 
   @BeforeClass
   public static void writeCorruptFile() throws IOException {
-    // Write a data file
-    DataFileWriter<Utf8> w = new DataFileWriter<>(new GenericDatumWriter<>(SCHEMA));
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
-    w.create(SCHEMA, baos);
-    w.append(new Utf8("apple"));
-    w.append(new Utf8("banana"));
-    w.append(new Utf8("celery"));
-    w.sync();
-    w.append(new Utf8("date"));
-    w.append(new Utf8("endive"));
-    w.append(new Utf8("fig"));
-    long pos = w.sync();
-    w.append(new Utf8("guava"));
-    w.append(new Utf8("hazelnut"));
-    w.close();
+    long pos;
+    // Write a data file
+    try(DataFileWriter<Utf8> w = new DataFileWriter<>(new GenericDatumWriter<>(SCHEMA))) {
+      w.create(SCHEMA, baos);
+      w.append(new Utf8("apple"));
+      w.append(new Utf8("banana"));
+      w.append(new Utf8("celery"));
+      w.sync();
+      w.append(new Utf8("date"));
+      w.append(new Utf8("endive"));
+      w.append(new Utf8("fig"));
+      pos = w.sync();
+      w.append(new Utf8("guava"));
+      w.append(new Utf8("hazelnut"));
+    }
 
     byte[] original = baos.toByteArray();
 
@@ -78,36 +81,28 @@ public static void writeCorruptFile() throws IOException {
     System.arraycopy(original, corruptPosition,
         corrupted, corruptPosition + corruptedBytes, original.length - corruptPosition);
 
-    corruptBlockFile = AvroTestUtil.tempFile(TestDataFileRepairTool.class,
-        "corruptBlock.avro");
+    corruptBlockFile = new File(DIR.getRoot(), "corruptBlock.avro");
     corruptBlockFile.deleteOnExit();
-    FileOutputStream out = new FileOutputStream(corruptBlockFile);
-    out.write(corrupted);
-    out.close();
+    try(FileOutputStream out = new FileOutputStream(corruptBlockFile)) {
+      out.write(corrupted);
+    }
 
     // Corrupt the "endive" record by changing the length of the string to be negative
-    corruptPosition = (int) pos - DataFileConstants.SYNC_SIZE -
-        (1 + "fig".length() + 1 + "endive".length());
+    corruptPosition = (int) pos - DataFileConstants.SYNC_SIZE - (1 + "fig".length() + 1 + "endive".length());
     corrupted = new byte[original.length];
     System.arraycopy(original, 0, corrupted, 0, original.length);
     BinaryData.encodeLong(-1, corrupted, corruptPosition);
 
-    corruptRecordFile = AvroTestUtil.tempFile(TestDataFileRepairTool.class,
-        "corruptRecord.avro");
+    corruptRecordFile = new File(DIR.getRoot(), "corruptRecord.avro");
     corruptRecordFile.deleteOnExit();
-    out = new FileOutputStream(corruptRecordFile);
-    out.write(corrupted);
-    out.close();
+    try(FileOutputStream out = new FileOutputStream(corruptRecordFile) ) {
+      out.write(corrupted);
+    }
   }
 
   @Before
   public void setUp() {
-    repairedFile = AvroTestUtil.tempFile(TestDataFileRepairTool.class, "repaired.avro");
-  }
-
-  @After
-  public void tearDown() {
-    repairedFile.delete();
+    repairedFile = new File(DIR.getRoot(), "repaired.avro");
   }
 
   private String run(Tool tool, String... args) throws Exception {
diff --git a/lang/java/tools/src/test/java/org/apache/avro/tool/TestDataFileTools.java b/lang/java/tools/src/test/java/org/apache/avro/tool/TestDataFileTools.java
index cab28d42c..341b6af4c 100644
--- a/lang/java/tools/src/test/java/org/apache/avro/tool/TestDataFileTools.java
+++ b/lang/java/tools/src/test/java/org/apache/avro/tool/TestDataFileTools.java
@@ -35,7 +35,6 @@
 import java.util.Collections;
 import java.util.List;
 
-import org.apache.avro.AvroTestUtil;
 import org.apache.avro.Schema;
 import org.apache.avro.Schema.Type;
 import org.apache.avro.file.DataFileReader;
@@ -43,7 +42,9 @@
 import org.apache.avro.generic.GenericDatumReader;
 import org.apache.avro.generic.GenericDatumWriter;
 import org.junit.BeforeClass;
+import org.junit.ClassRule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
 
 @SuppressWarnings("deprecation")
 public class TestDataFileTools {
@@ -56,30 +57,29 @@
   private static final String KEY_NEEDING_ESCAPES = "trn\\\r\t\n";
   private static final String ESCAPED_KEY = "trn\\\\\\r\\t\\n";
 
+  @ClassRule
+  public static TemporaryFolder DIR = new TemporaryFolder();
+
   @BeforeClass
   public static void writeSampleFile() throws IOException {
-    sampleFile = AvroTestUtil.tempFile(TestDataFileTools.class,
-      TestDataFileTools.class.getName() + ".avro");
+    sampleFile = new File(DIR.getRoot(), TestDataFileTools.class.getName() + ".avro");
     schema = Schema.create(Type.INT);
-    schemaFile = AvroTestUtil.tempFile(TestDataFileTools.class, "schema-temp.schema");
-    FileWriter fw = new FileWriter(schemaFile);
-    fw.append(schema.toString());
-    fw.close();
-
-    DataFileWriter<Object> writer
-      = new DataFileWriter<>(new GenericDatumWriter<>(schema))
-      .setMeta(KEY_NEEDING_ESCAPES, "")
-      .create(schema, sampleFile);
-    StringBuilder builder = new StringBuilder();
-
-    for (int i = 0; i < COUNT; ++i) {
-      builder.append(Integer.toString(i));
-      builder.append("\n");
-      writer.append(i);
+    schemaFile = new File(DIR.getRoot(), "schema-temp.schema");
+    try(FileWriter fw = new FileWriter(schemaFile)) {
+      fw.append(schema.toString());
     }
 
-    writer.flush();
-    writer.close();
+    StringBuilder builder = new StringBuilder();
+    try(DataFileWriter<Object> writer = new DataFileWriter<>(new GenericDatumWriter<>(schema))) {
+      writer.setMeta(KEY_NEEDING_ESCAPES, "");
+      writer.create(schema, sampleFile);
+
+      for (int i = 0; i < COUNT; ++i) {
+        builder.append(Integer.toString(i));
+        builder.append("\n");
+        writer.append(i);
+      }
+    }
 
     jsonData = builder.toString();
   }
@@ -127,8 +127,7 @@ public void testGetMeta() throws Exception {
   @Test
   public void testGetMetaForSingleKey() throws Exception {
     assertEquals(schema.toString() + "\n",
-        run(new DataFileGetMetaTool(), sampleFile.getPath(), "--key",
-            "avro.schema"));
+        run(new DataFileGetMetaTool(), sampleFile.getPath(), "--key", "avro.schema"));
   }
 
   @Test
@@ -152,59 +151,53 @@ public void testWrite(String name, List<String> extra, String expectedCodec)
       testWrite(name, extra, expectedCodec, "-schema", schema.toString());
       testWrite(name, extra, expectedCodec, "-schema-file", schemaFile.toString());
   }
+
   public void testWrite(String name, List<String> extra, String expectedCodec, String... extraArgs)
   throws Exception {
-    File outFile = AvroTestUtil.tempFile(getClass(),
-        TestDataFileTools.class + ".testWrite." + name + ".avro");
-    FileOutputStream fout = new FileOutputStream(outFile);
-    PrintStream out = new PrintStream(fout);
-    List<String> args = new ArrayList<>();
-    for (String arg : extraArgs) {
-        args.add(arg);
+    File outFile = new File(DIR.getRoot(), TestDataFileTools.class + ".testWrite." + name + ".avro");
+    try(FileOutputStream fout = new FileOutputStream(outFile)) {
+      try(PrintStream out = new PrintStream(fout)) {
+        List<String> args = new ArrayList<>();
+        Collections.addAll(args, extraArgs);
+        args.add("-");
+        args.addAll(extra);
+        new DataFileWriteTool().run(
+                new StringBufferInputStream(jsonData),
+                new PrintStream(out), // stdout
+                null, // stderr
+                args);
+      }
     }
-    args.add("-");
-    args.addAll(extra);
-    new DataFileWriteTool().run(
-        new StringBufferInputStream(jsonData),
-        new PrintStream(out), // stdout
-        null, // stderr
-        args);
-    out.close();
-    fout.close();
 
     // Read it back, and make sure it's valid.
     GenericDatumReader<Object> reader = new GenericDatumReader<>();
-    DataFileReader<Object> fileReader = new DataFileReader<>(outFile, reader);
-    int i = 0;
-    for (Object datum : fileReader) {
-      assertEquals(i, datum);
-      i++;
-    }
-    assertEquals(COUNT, i);
-    assertEquals(schema, fileReader.getSchema());
-    String codecStr = fileReader.getMetaString("avro.codec");
-    if (null == codecStr) {
-      codecStr = "null";
+    try (DataFileReader<Object> fileReader = new DataFileReader<>(outFile, reader)) {
+      int i = 0;
+      for (Object datum : fileReader) {
+        assertEquals(i, datum);
+        i++;
+      }
+      assertEquals(COUNT, i);
+      assertEquals(schema, fileReader.getSchema());
+      String codecStr = fileReader.getMetaString("avro.codec");
+      if (null == codecStr) {
+        codecStr = "null";
+      }
+      assertEquals(expectedCodec, codecStr);
     }
-    assertEquals(expectedCodec, codecStr);
   }
 
-  @Test
+  @Test(expected=IOException.class)
   public void testFailureOnWritingPartialJSONValues() throws Exception {
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
     PrintStream out = new PrintStream(baos);
-    try {
-      new DataFileWriteTool().run(
-          new StringBufferInputStream("{"),
-          new PrintStream(out), // stdout
-          null, // stderr
-          Arrays.asList("-schema", "{ \"type\":\"record\", \"fields\":" +
-                        "[{\"name\":\"foo\", \"type\":\"string\"}], " +
-                        "\"name\":\"boring\" }", "-"));
-      fail("Expected exception.");
-    } catch (IOException expected) {
-      // expected
-    }
+    new DataFileWriteTool().run(
+        new StringBufferInputStream("{"),
+        new PrintStream(out), // stdout
+        null, // stderr
+        Arrays.asList("-schema", "{ \"type\":\"record\", \"fields\":" +
+                      "[{\"name\":\"foo\", \"type\":\"string\"}], " +
+                      "\"name\":\"boring\" }", "-"));
   }
 
   @Test
@@ -217,13 +210,13 @@ public void testWritingZeroJsonValues() throws Exception {
 
   private int countRecords(File outFile) throws IOException {
     GenericDatumReader<Object> reader = new GenericDatumReader<>();
-    DataFileReader<Object> fileReader =
-      new DataFileReader<>(outFile, reader);
-    int i = 0;
-    for (@SuppressWarnings("unused") Object datum : fileReader) {
-      i++;
+    try(DataFileReader<Object> fileReader = new DataFileReader<>(outFile, reader)) {
+      int i = 0;
+      for (@SuppressWarnings("unused") Object datum : fileReader) {
+        i++;
+      }
+      return i;
     }
-    return i;
   }
 
   @Test
@@ -236,18 +229,16 @@ public void testDifferentSeparatorsBetweenJsonRecords() throws Exception {
   }
 
   public File writeToAvroFile(String testName, String schema, String json) throws Exception {
-    File outFile = AvroTestUtil.tempFile(getClass(),
-        TestDataFileTools.class + "." + testName + ".avro");
-    FileOutputStream fout = new FileOutputStream(outFile);
-    PrintStream out = new PrintStream(fout);
-    new DataFileWriteTool().run(
-        new StringBufferInputStream(json),
-        new PrintStream(out), // stdout
-        null, // stderr
-        Arrays.asList("-schema", schema, "-"));
-    out.close();
-    fout.close();
+    File outFile = new File(DIR.getRoot(), TestDataFileTools.class + "." + testName + ".avro");
+    try(FileOutputStream fout = new FileOutputStream(outFile)) {
+      try(PrintStream out = new PrintStream(fout)) {
+        new DataFileWriteTool().run(
+                new StringBufferInputStream(json),
+                new PrintStream(out), // stdout
+                null, // stderr
+                Arrays.asList("-schema", schema, "-"));
+      }
+    }
     return outFile;
   }
-
 }
diff --git a/lang/java/tools/src/test/java/org/apache/avro/tool/TestJsonToFromBinaryFragmentTools.java b/lang/java/tools/src/test/java/org/apache/avro/tool/TestJsonToFromBinaryFragmentTools.java
index 849968788..7e25a3bd4 100644
--- a/lang/java/tools/src/test/java/org/apache/avro/tool/TestJsonToFromBinaryFragmentTools.java
+++ b/lang/java/tools/src/test/java/org/apache/avro/tool/TestJsonToFromBinaryFragmentTools.java
@@ -19,21 +19,17 @@
 
 import static org.junit.Assert.assertEquals;
 
-import java.io.ByteArrayInputStream;
-import java.io.ByteArrayOutputStream;
-import java.io.BufferedOutputStream;
-import java.io.File;
-import java.io.FileWriter;
-import java.io.IOException;
-import java.io.PrintStream;
+import java.io.*;
+import java.nio.charset.StandardCharsets;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
 
-import org.apache.avro.AvroTestUtil;
 import org.apache.avro.Schema;
 import org.apache.avro.Schema.Type;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
 
 /**
  * Tests both {@link JsonToBinaryFragmentTool}
@@ -42,10 +38,11 @@
 public class TestJsonToFromBinaryFragmentTools {
   private static final String STRING_SCHEMA = Schema.create(Type.STRING).toString();
   private static final String UTF8 = "utf-8";
-  private static final String AVRO =
-    "ZLong string implies readable length encoding.";
-  private static final String JSON =
-    "\"Long string implies readable length encoding.\"\n";
+  private static final String AVRO = "ZLong string implies readable length encoding.";
+  private static final String JSON = "\"Long string implies readable length encoding.\"\n";
+
+  @Rule
+  public TemporaryFolder DIR = new TemporaryFolder();
 
   @Test
   public void testBinaryToJson() throws Exception {
@@ -79,23 +76,22 @@ public void testMultiBinaryToNoPrettyJson() throws Exception {
 
   @Test
   public void testBinaryToJsonSchemaFile() throws Exception {
-    binaryToJson(AVRO, JSON, "--schema-file", schemaFile());
+    binaryToJson(AVRO, JSON, "--schema-file", schemaFile(DIR.getRoot()));
   }
 
   @Test
     public void testJsonToBinarySchemaFile() throws Exception {
-    jsonToBinary(JSON, AVRO, "--schema-file", schemaFile());
+    jsonToBinary(JSON, AVRO, "--schema-file", schemaFile(DIR.getRoot()));
   }
 
   private void binaryToJson(String avro, String json, String... options) throws Exception {
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
     PrintStream p = new PrintStream(new BufferedOutputStream(baos));
 
-    List<String> args = new ArrayList<>();
-    args.addAll(Arrays.asList(options));
+    List<String> args = new ArrayList<>(Arrays.asList(options));
     args.add("-");
     new BinaryFragmentToJsonTool().run(
-        new ByteArrayInputStream(avro.getBytes(UTF8)), // stdin
+        new ByteArrayInputStream(avro.getBytes(StandardCharsets.UTF_8)), // stdin
         p, // stdout
         null, // stderr
         args);
@@ -107,22 +103,21 @@ private void jsonToBinary(String json, String avro, String... options) throws Ex
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
     PrintStream p = new PrintStream(new BufferedOutputStream(baos));
 
-    List<String> args = new ArrayList<>();
-    args.addAll(Arrays.asList(options));
+    List<String> args = new ArrayList<>(Arrays.asList(options));
     args.add("-");
     new JsonToBinaryFragmentTool().run(
-        new ByteArrayInputStream(json.getBytes(UTF8)), // stdin
+        new ByteArrayInputStream(json.getBytes(StandardCharsets.UTF_8)), // stdin
         p, // stdout
         null, // stderr
         args);
     assertEquals(avro, baos.toString(UTF8));
   }
 
-  private static String schemaFile() throws IOException {
-    File schemaFile = AvroTestUtil.tempFile(TestJsonToFromBinaryFragmentTools.class, "String.avsc");
-    FileWriter fw = new FileWriter(schemaFile);
-    fw.append(STRING_SCHEMA);
-    fw.close();
+  private static String schemaFile(File dir) throws IOException {
+    File schemaFile = new File(dir, "String.avsc");
+    try(FileWriter fw = new FileWriter(schemaFile)) {
+      fw.append(STRING_SCHEMA);
+    }
     return schemaFile.toString();
   }
 }
diff --git a/lang/java/tools/src/test/java/org/apache/avro/tool/TestRecodecTool.java b/lang/java/tools/src/test/java/org/apache/avro/tool/TestRecodecTool.java
index 894bc206e..c2134f750 100644
--- a/lang/java/tools/src/test/java/org/apache/avro/tool/TestRecodecTool.java
+++ b/lang/java/tools/src/test/java/org/apache/avro/tool/TestRecodecTool.java
@@ -24,7 +24,6 @@
 import java.io.PrintStream;
 import java.util.ArrayList;
 
-import org.apache.avro.AvroTestUtil;
 import org.apache.avro.Schema;
 import org.apache.avro.Schema.Type;
 import org.apache.avro.file.DataFileReader;
@@ -32,15 +31,20 @@
 import org.apache.avro.generic.GenericDatumReader;
 import org.apache.avro.generic.GenericDatumWriter;
 import org.junit.Assert;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
 
 public class TestRecodecTool {
+  @Rule
+  public TemporaryFolder DIR = new TemporaryFolder();
+
   @Test
   public void testRecodec() throws Exception {
     String metaKey = "myMetaKey";
     String metaValue = "myMetaValue";
 
-    File inputFile = AvroTestUtil.tempFile(getClass(), "input.avro");
+    File inputFile = new File(DIR.getRoot(), "input.avro");
 
     Schema schema = Schema.create(Type.STRING);
     DataFileWriter<String> writer = new DataFileWriter<>(
@@ -56,11 +60,11 @@ public void testRecodec() throws Exception {
     }
     writer.close();
 
-    File defaultOutputFile = AvroTestUtil.tempFile(getClass(), "default-output.avro");
-    File nullOutputFile = AvroTestUtil.tempFile(getClass(), "null-output.avro");
-    File deflateDefaultOutputFile = AvroTestUtil.tempFile(getClass(), "deflate-default-output.avro");
-    File deflate1OutputFile = AvroTestUtil.tempFile(getClass(), "deflate-1-output.avro");
-    File deflate9OutputFile = AvroTestUtil.tempFile(getClass(), "deflate-9-output.avro");
+    File defaultOutputFile = new File(DIR.getRoot(), "default-output.avro");
+    File nullOutputFile = new File(DIR.getRoot(),  "null-output.avro");
+    File deflateDefaultOutputFile = new File(DIR.getRoot(),  "deflate-default-output.avro");
+    File deflate1OutputFile = new File(DIR.getRoot(),  "deflate-1-output.avro");
+    File deflate9OutputFile = new File(DIR.getRoot(),  "deflate-9-output.avro");
 
     new RecodecTool().run(new FileInputStream(inputFile), new PrintStream(defaultOutputFile), null, new ArrayList<>());
     new RecodecTool().run(new FileInputStream(inputFile), new PrintStream(nullOutputFile), null, asList("--codec=null"));
@@ -85,20 +89,6 @@ public void testRecodec() throws Exception {
 
     // The "level 9" file should be smaller than the "level 1" file.
     assertLessThan(deflate9OutputFile.length(), deflate1OutputFile.length());
-
-//    System.err.println(inputFile.length());
-//    System.err.println(defaultOutputFile.length());
-//    System.err.println(nullOutputFile.length());
-//    System.err.println(deflateDefaultOutputFile.length());
-//    System.err.println(deflate1OutputFile.length());
-//    System.err.println(deflate9OutputFile.length());
-
-    inputFile.delete();
-    defaultOutputFile.delete();
-    nullOutputFile.delete();
-    deflateDefaultOutputFile.delete();
-    deflate1OutputFile.delete();
-    deflate9OutputFile.delete();
   }
 
   private static void assertLessThan(long less, long more) {
diff --git a/lang/java/tools/src/test/java/org/apache/avro/tool/TestTetherTool.java b/lang/java/tools/src/test/java/org/apache/avro/tool/TestTetherTool.java
index 118ccf772..0a8db4872 100644
--- a/lang/java/tools/src/test/java/org/apache/avro/tool/TestTetherTool.java
+++ b/lang/java/tools/src/test/java/org/apache/avro/tool/TestTetherTool.java
@@ -26,9 +26,9 @@
 import java.io.FileInputStream;
 import java.io.InputStream;
 import java.io.FileWriter;
+import java.nio.file.Files;
 
 
-import org.apache.avro.AvroTestUtil;
 import org.apache.avro.Schema;
 import org.apache.avro.file.DataFileStream;
 import org.apache.avro.io.DatumReader;
@@ -38,13 +38,21 @@
 import org.apache.avro.util.Utf8;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.mapred.JobConf;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
 
 public class TestTetherTool {
 
+  @Rule
+  public TemporaryFolder INPUT_DIR = new TemporaryFolder();
+
+  @Rule
+  public TemporaryFolder OUTPUT_DIR = new TemporaryFolder();
+
   /**
    * Test that the tether tool works with the mapreduce example
-   *
+   * <p>
    * TODO: How can we ensure that when we run, the WordCountTether example has
    * been properly compiled?
    */
@@ -52,39 +60,23 @@
   public void test() throws Exception {
 
     // Create the schema files.
-    Schema outscheme = new Pair<Utf8,Long>(new Utf8(""), 0L).getSchema();
+    Schema outscheme = new Pair<Utf8, Long>(new Utf8(""), 0L).getSchema();
 
     // we need to write the schemas to a file
-    File midscfile = AvroTestUtil.tempFile(getClass(), "midschema.avpr");
-
-    FileWriter hf = null;
-    try {
-      hf =new FileWriter(midscfile);
+    File midscfile = new File(INPUT_DIR.getRoot().getPath(), "midschema.avpr");
+    try (FileWriter hf = new FileWriter(midscfile)) {
       hf.write(outscheme.toString());
     }
-    finally {
-      if (hf != null) {
-        hf.close();
-      }
-    }
-
-    // Get the classpath to use as an argument.
-    String cp = System.getProperty("java.class.path");
 
     JobConf job = new JobConf();
-    String dir = System.getProperty("test.dir", ".") + "/mapred";
-    Path outputPath = new Path(dir + "/out");
+    String inputPathStr = INPUT_DIR.getRoot().getPath();
+    String outputPathStr = OUTPUT_DIR.getRoot().getPath();
+    Path outputPath = new Path(outputPathStr);
 
     outputPath.getFileSystem(job).delete(outputPath);
 
     // create the input file
-    WordCountUtil.writeLinesFile();
-
-    // Executable is java? Argument will be WordCountTask.java - Is the classpath
-    // set appropriately automatically?
-    java.net.URI exec = new java.net.URI("java");
-    //input path
-    String in = dir + "/in";
+    WordCountUtil.writeLinesFile(inputPathStr + "/lines.avro");
 
     // create a string of the arguments
     String execargs = "-classpath " + System.getProperty("java.class.path");
@@ -95,9 +87,9 @@ public void test() throws Exception {
 
 
     runargs.addAll(java.util.Arrays.asList("--program", "java"));
-    runargs.addAll(asList("--exec_args", '"'+execargs+'"'));
+    runargs.addAll(asList("--exec_args", '"' + execargs + '"'));
     runargs.addAll(asList("--exec_cached", "false"));
-    runargs.addAll(asList("--in", in));
+    runargs.addAll(asList("--in", inputPathStr));
     runargs.addAll(asList("--out", outputPath.toString()));
     runargs.addAll(asList("--outschema", midscfile.toString()));
 
@@ -107,16 +99,16 @@ public void test() throws Exception {
 
     // TODO:: We should probably do some validation
     // validate the output
-    DatumReader<Pair<Utf8,Long>> reader = new SpecificDatumReader<>();
-    InputStream cin = new BufferedInputStream(new FileInputStream(WordCountUtil.COUNTS_FILE));
-    DataFileStream<Pair<Utf8,Long>> counts = new DataFileStream<>(cin, reader);
     int numWords = 0;
-    for (Pair<Utf8,Long> wc : counts) {
-      assertEquals(wc.key().toString(),
-      WordCountUtil.COUNTS.get(wc.key().toString()), wc.value());
-      numWords++;
+    DatumReader<Pair<Utf8, Long>> reader = new SpecificDatumReader<>();
+    try(InputStream cin
+                = new BufferedInputStream(new FileInputStream(outputPathStr + "/part-00000.avro"))) {
+      DataFileStream<Pair<Utf8, Long>> counts = new DataFileStream<>(cin, reader);
+      for (Pair<Utf8, Long> wc : counts) {
+        assertEquals(wc.key().toString(), WordCountUtil.COUNTS.get(wc.key().toString()), wc.value());
+        numWords++;
+      }
     }
-    cin.close();
     assertEquals(WordCountUtil.COUNTS.size(), numWords);
   }
 }
diff --git a/lang/java/tools/src/test/java/org/apache/avro/tool/TestTextFileTools.java b/lang/java/tools/src/test/java/org/apache/avro/tool/TestTextFileTools.java
index 9d1615cab..b33330135 100644
--- a/lang/java/tools/src/test/java/org/apache/avro/tool/TestTextFileTools.java
+++ b/lang/java/tools/src/test/java/org/apache/avro/tool/TestTextFileTools.java
@@ -32,14 +32,12 @@
 import java.util.Arrays;
 import java.util.Random;
 
-import org.apache.avro.AvroTestUtil;
 import org.apache.avro.Schema;
 import org.apache.avro.Schema.Type;
 import org.apache.avro.file.DataFileReader;
 import org.apache.avro.generic.GenericDatumReader;
-import org.junit.BeforeClass;
-import org.junit.AfterClass;
-import org.junit.Test;
+import org.junit.*;
+import org.junit.rules.TemporaryFolder;
 
 @SuppressWarnings("deprecation")
 public class TestTextFileTools {
@@ -47,16 +45,18 @@
     Integer.parseInt(System.getProperty("test.count", "10"));
 
   private static final byte[] LINE_SEP = System.getProperty("line.separator").getBytes();
-  static File linesFile;
-  static ByteBuffer[] lines;
+  private static File linesFile;
+  private static ByteBuffer[] lines;
   static Schema schema;
-  static File schemaFile;
+
+  @ClassRule
+  public static TemporaryFolder DIR = new TemporaryFolder();
 
   @BeforeClass
   public static void writeRandomFile() throws IOException {
     schema = Schema.create(Type.BYTES);
     lines = new ByteBuffer[COUNT];
-    linesFile = AvroTestUtil.tempFile(TestTextFileTools.class, "random.lines");
+    linesFile = new File(DIR.getRoot(), "random.lines");
 
     OutputStream out =
       new BufferedOutputStream(new FileOutputStream(linesFile));
@@ -78,10 +78,9 @@ public static void writeRandomFile() throws IOException {
   }
 
   private void fromText(String name, String... args) throws Exception {
-    File avroFile = AvroTestUtil.tempFile(getClass(), name + ".avro");
+    File avroFile = new File(DIR.getRoot(), name + ".avro");
 
-    ArrayList<String> arglist = new ArrayList<>();
-    arglist.addAll(Arrays.asList(args));
+    ArrayList<String> arglist = new ArrayList<>(Arrays.asList(args));
     arglist.add(linesFile.toString());
     arglist.add(avroFile.toString());
 
@@ -114,8 +113,8 @@ public static void testToText() throws Exception {
   }
 
   private static void toText(String name) throws Exception {
-    File avroFile = AvroTestUtil.tempFile(TestTextFileTools.class, name + ".avro");
-    File outFile = AvroTestUtil.tempFile(TestTextFileTools.class, name + ".lines");
+    File avroFile = new File(DIR.getRoot(), name + ".avro");
+    File outFile = new File(DIR.getRoot(), name + ".lines");
 
     ArrayList<String> arglist = new ArrayList<>();
     arglist.add(avroFile.toString());
@@ -124,16 +123,14 @@ private static void toText(String name) throws Exception {
     new ToTextTool().run(null, null, null, arglist);
 
     // Read it back, and make sure it's valid.
-    InputStream orig = new BufferedInputStream(new FileInputStream(linesFile));
-    InputStream after = new BufferedInputStream(new FileInputStream(outFile));
-
-    int b;
-    while ((b = orig.read()) != -1)
-      assertEquals(b, after.read());
-    assertEquals(-1, after.read());
-
-    orig.close();
-    after.close();
+    try(InputStream orig = new BufferedInputStream(new FileInputStream(linesFile))) {
+      try (InputStream after = new BufferedInputStream(new FileInputStream(outFile))) {
+        int b;
+        while ((b = orig.read()) != -1) {
+          assertEquals(b, after.read());
+        }
+        assertEquals(-1, after.read());
+      }
+    }
   }
-
 }
diff --git a/lang/java/tools/src/test/java/org/apache/avro/tool/TestToTrevniTool.java b/lang/java/tools/src/test/java/org/apache/avro/tool/TestToTrevniTool.java
index 663c6c819..980885f12 100644
--- a/lang/java/tools/src/test/java/org/apache/avro/tool/TestToTrevniTool.java
+++ b/lang/java/tools/src/test/java/org/apache/avro/tool/TestToTrevniTool.java
@@ -35,8 +35,7 @@
 public class TestToTrevniTool {
   private static final int COUNT =
     Integer.parseInt(System.getProperty("test.count", "200"));
-  private static final File DIR
-    = new File(System.getProperty("test.dir", "/tmp"));
+  private static final File DIR = new File("/tmp");
   private static final File AVRO_FILE = new File(DIR, "random.avro");
   private static final File TREVNI_FILE = new File(DIR, "random.trv");
   private static final File SCHEMA_FILE =
diff --git a/pom.xml b/pom.xml
index e3f48442c..0dfecbd5b 100644
--- a/pom.xml
+++ b/pom.xml
@@ -280,7 +280,10 @@
                 <exclude>**/*.iml</exclude>
                 <exclude>lang/csharp/Avro.sln</exclude> <!-- visual studio -->
                 <!-- build-related files -->
+                <exclude>README.md</exclude>
                 <exclude>BUILD.md</exclude>
+                <exclude>.travis.yml</exclude>
+                <exclude>share/precommit/README.md</exclude>
                 <exclude>**/VERSION.txt</exclude>
                 <exclude>**/dependency-reduced-pom.xml</exclude>
                 <exclude>lang/perl/.shipit</exclude>
diff --git a/share/docker/Dockerfile b/share/docker/Dockerfile
index de09220a1..ec8ac34f4 100644
--- a/share/docker/Dockerfile
+++ b/share/docker/Dockerfile
@@ -27,8 +27,8 @@ SHELL ["/bin/bash", "-o", "pipefail", "-c"]
 RUN curl -sL https://deb.nodesource.com/setup_4.x | bash -
 
 # Install dependencies from packages
-RUN apt-get update && \
-  apt-get install --no-install-recommends -y \
+RUN apt-get -qq update && \
+  apt-get -qq install --no-install-recommends -y \
     ant \
     asciidoc \
     bison \
@@ -64,7 +64,7 @@ RUN apt-get update && \
     ruby-dev \
     source-highlight \
     subversion && \
-  apt-get clean && \
+  apt-get -qq clean && \
   rm -rf /var/lib/apt/lists/*
 
 # Install Forrest in /usr/local/apache-forrest
diff --git a/share/precommit/README.md b/share/precommit/README.md
new file mode 100644
index 000000000..0e19b8b2a
--- /dev/null
+++ b/share/precommit/README.md
@@ -0,0 +1,9 @@
+# Apache Yetus integration
+
+The plugin under `buildtest.sh` will provide the plugin to run the base `build.sh test` which will trigger the tests of the main Avro projects, and the sections below `lang/*/build.sh`. To run this, use:
+
+```bash
+test-patch --plugins=buildtest --user-plugins=share/precommit/ --run-tests --empty-patch --docker --dockerfile=share/docker/Dockerfile --dirty-workspace --verbose=true
+```
+
+Note, that this is still a very crude implementation of Apache Yetus, and in the future we would like to refine this to provide plugins for the different languages.
diff --git a/share/precommit/buildtest.sh b/share/precommit/buildtest.sh
new file mode 100644
index 000000000..e9fd01b65
--- /dev/null
+++ b/share/precommit/buildtest.sh
@@ -0,0 +1,62 @@
+#!/usr/bin/env bash
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRCMAKEIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+add_test_type buildtest
+
+VERBOSE=false
+
+# files that we want to kick off
+BUILD_FILES=( build.sh )
+
+
+function buildtest_usage {
+  yetus_add_option "--verbose=<true|false>" "print output to console (default: false)"
+}
+
+# For now we only kick off the root build.sh
+# buildtest_filefilter {
+#   local filename=$1
+#
+#   if [[ ${filename} =~ build\.sh$ ]]; then
+#     yetus_debug "Buildtest: run the tests for ${filename}"
+#     add_test buildtest
+#     yetus_add_array_element BUILD_FILES "${filename}"
+#   fi
+# }
+
+function buildtest_postcompile {
+  for file in "${BUILD_FILES[@]}"; do
+
+    big_console_header "Running ${file}"
+
+    #shellcheck disable=SC2001
+    sanitized_filename=$(echo "${file}" | sed -e 's,[/\.],-,g')
+
+    # Write both to stdout and the file using tee
+    (cd ${BASEDIR} && ./${file} test) | tee -a ${PATCH_DIR}/build-${sanitized_filename}.txt
+    result=${PIPESTATUS[0]}
+
+    yetus_debug "Process exited with ${result}"
+
+    if  (( result != 0 )); then
+      add_vote_table -1 buildtest "The testsuite failed, please check the output"
+      add_footer_table buildtest "@@BASE@@/build-${sanitized_filename}.txt"
+      return 1
+    fi
+
+    add_vote_table +1 buildtest "The build has passed"
+  done
+}
diff --git a/share/test/interop/bin/test_rpc_interop.sh b/share/test/interop/bin/test_rpc_interop.sh
index 20ee77f76..f8ef7f5e8 100755
--- a/share/test/interop/bin/test_rpc_interop.sh
+++ b/share/test/interop/bin/test_rpc_interop.sh
@@ -21,7 +21,7 @@ cd `dirname "$0"`/../../../..   # connect to root
 
 VERSION=`cat share/VERSION.txt`
 
-#set -x                          # echo commands
+set -x                          # echo commands
 
 java_client="java -jar lang/java/tools/target/avro-tools-$VERSION.jar rpcsend"
 java_server="java -jar lang/java/tools/target/avro-tools-$VERSION.jar rpcreceive"
@@ -29,21 +29,25 @@ java_server="java -jar lang/java/tools/target/avro-tools-$VERSION.jar rpcreceive
 py_client="python lang/py/build/src/avro/tool.py rpcsend"
 py_server="python lang/py/build/src/avro/tool.py rpcreceive"
 
-ruby_client="ruby -rubygems -Ilang/ruby/lib lang/ruby/test/tool.rb rpcsend"
-ruby_server="ruby -rubygems -Ilang/ruby/lib lang/ruby/test/tool.rb rpcreceive"
+#ruby_client="ruby -rubygems -Ilang/ruby/lib lang/ruby/test/tool.rb rpcsend"
+#ruby_server="ruby -rubygems -Ilang/ruby/lib lang/ruby/test/tool.rb rpcreceive"
 
 export PYTHONPATH=lang/py/build/src      # path to avro Python module
 
-clients=("$java_client" "$py_client" "$ruby_client")
-servers=("$java_server" "$py_server" "$ruby_server")
+#clients=("$java_client" "$py_client" "$ruby_client")
+#servers=("$java_server" "$py_server" "$ruby_server")
+clients=("$java_client" "$py_client")
+servers=("$java_server" "$py_server")
 
 proto=share/test/schemas/simple.avpr
 
 portfile=/tmp/interop_$$
 
 function cleanup() {
-  rm -rf $portfile
-  for job in `jobs -p` ; do kill $job; done
+  rm -rf "$portfile"
+  for job in `jobs -p` ; do
+    kill $(jobs -p) 2>/dev/null || true;
+  done
 }
 
 trap 'cleanup' EXIT
@@ -58,9 +62,8 @@ do
       echo TEST: $c
       for client in "${clients[@]}"
       do
-        rm -rf $portfile
-        $server http://127.0.0.1:0/ $proto $msg -file $c/response.avro \
-            > $portfile &
+        rm -rf "$portfile"
+        $server http://127.0.0.1:0/ $proto $msg -file $c/response.avro > $portfile &
         count=0
         while [ ! -s $portfile ]
         do
@@ -79,5 +82,3 @@ do
     done
     done
 done
-
-echo RPC INTEROP TESTS PASS


 

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


Commit 25032e10a86851bdabfa29b99885ccfc03c6667e in avro's branch refs/heads/master from [~Fokko]
[ https://gitbox.apache.org/repos/asf?p=avro.git;h=25032e1 ]

AVRO-1887 Integrate Yetus and fix tests (#353)

* AVRO-1887 Setup precommit checks via Apache Yetus

Signed-off-by: sacharya <suraj.spa@gmail.com>

* AVRO-1887 Integrate Yetus

Add a precommit hook using Apache Yetus that will invoke the test
suite of the different languages

- Disable Ruby integration tests tests
- Fix Flaky Java Datetime test
  When the milsecons would have trailing zero, it would get trimmed
- Align the order of imports


Commit 25032e10a86851bdabfa29b99885ccfc03c6667e in avro's branch refs/heads/master from [~Fokko]
[ https://gitbox.apache.org/repos/asf?p=avro.git;h=25032e1 ]

AVRO-1887 Integrate Yetus and fix tests (#353)

* AVRO-1887 Setup precommit checks via Apache Yetus

Signed-off-by: sacharya <suraj.spa@gmail.com>

* AVRO-1887 Integrate Yetus

Add a precommit hook using Apache Yetus that will invoke the test
suite of the different languages

- Disable Ruby integration tests tests
- Fix Flaky Java Datetime test
  When the milsecons would have trailing zero, it would get trimmed
- Align the order of imports


Commit 25032e10a86851bdabfa29b99885ccfc03c6667e in avro's branch refs/heads/master from [~Fokko]
[ https://gitbox.apache.org/repos/asf?p=avro.git;h=25032e1 ]

AVRO-1887 Integrate Yetus and fix tests (#353)

* AVRO-1887 Setup precommit checks via Apache Yetus

Signed-off-by: sacharya <suraj.spa@gmail.com>

* AVRO-1887 Integrate Yetus

Add a precommit hook using Apache Yetus that will invoke the test
suite of the different languages

- Disable Ruby integration tests tests
- Fix Flaky Java Datetime test
  When the milsecons would have trailing zero, it would get trimmed
- Align the order of imports


kojiromike commented on issue #353: AVRO-1887 Integrate Yetus and fix tests
URL: https://github.com/apache/avro/pull/353#issuecomment-436630307
 
 
   @Fokko Congratulations/Thanks for getting this merged. I'll take a look at those shell scripts. Am I correct that now we can rely on automated checks to validate a lot of our PRs? Is there a way to trigger the tests on all the open PRs?
   

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


Fokko commented on issue #353: AVRO-1887 Integrate Yetus and fix tests
URL: https://github.com/apache/avro/pull/353#issuecomment-436642301
 
 
   @kojiromike with pleasure. They need to rebase onto master, then Travis will run automatically. I'm going through a couple of the PR's that are still open.

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


aw-was-here commented on issue #353: AVRO-1887 Integrate Yetus and fix tests
URL: https://github.com/apache/avro/pull/353#issuecomment-436646341
 
 
   FWIW, very specific support for Travis (and other CI systems) is something that will hopefully be coming to Yetus soon.   I've got it in a fork already: https://github.com/aw-was-here/buretoolbox/commit/f055aa3c78ffdd9bf42e11b457b1283bc3582960 

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org


