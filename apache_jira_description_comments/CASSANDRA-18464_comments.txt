I applied this to a branch and had circle take a first pass.

||Branch||CI||
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-18464-trunk]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra/977/workflows/677ded2a-f1bf-416c-ae8b-bdf32f18a2eb], [j11|https://app.circleci.com/pipelines/github/driftx/cassandra/977/workflows/9554a2d4-0322-492d-9f6b-b7e70eb8dab0]|


What are the chances that we just drop Java 8 support for 6.0?

Java 8 is going to be dropped for 5.0, see CASSANDRA-18255 

I feel that this ci must be able to pass（of course the build /compile stage should pass first) , as the there lack of relevant ut test cases for Direct IO and the use_jna_for_commitlog_io is set to fasle so the related code are not coverd.

bq. Java version 8 does not have native support to enable Direct I/O. So, JNA library usage is must. The same implementation should also work across other versions of Java (like 11 and beyond).

This ^ is the reason I ask. Feels like native support would be the way to go over JNA if possible.

I think this is all moot since we will remove j8, however JNA isn't going anywhere and we are the first project they list as a user, so I think it's fine to use if needed.

bq. it's fine to use if needed

Agreed...just saying it looks like it is not if J11 is our floor.

Making fixVersion 5.x, as 6.x is reserved for stuff that won't be compatible with 4.x. And IIUC there's nothing here that requires such a breakage. (Putting it as 5.x says nothing about whether it's feasible time-wise that this will land in 5.x or not.)

I don't understand, if jdk11 is the floor here, what the benefit of going through JNA is? 
Simpler code, and less config options, seems like a win to me.

Hello everyone,

 

Myself Amit and new to this developers community. Since 24th April not seen any comments or suggestions. Please let me know if I required to do something for this patch. Thanks.

[~amit_pawar] The discussion above around JDK11 and JNA seems like the thing we'd want to resolve?

[~maedhroz] Thank you for your reply. Is there a plan to drop JNA support also ?

bq. As per the community suggestion, less in code complex is good to have. Direct I/O enablement looked promising but there was one issue. 
Java version 8 does not have native support to enable Direct I/O. So, JNA library usage is must. The same implementation should also work across other versions of Java (like 11 and beyond).

I don't know about dropping JNA support, but it seems like (from the conversation above), we'd like to avoid JNA when Java 11 natively supports {{O_DIRECT}}. Does that make sense?

[~amit_pawar], what Caleb says.

If you can update the patch so it doesn't use JNA (or need java 8), then (once it is reviewed, which can start immediately) we can merge it as soon as CASSANDRA-18255 lands (which is expected to ~next month).

Thank you [~maedhroz] and [~mck]  for your suggestions and would like share my observation one last time before jumping to implementation using native API's.

Enabling Direct I/O feature using JNA going to be better than using native API's.

Why ?
Due to number of buffers required and along with un-necessary copying the same data before initiating the OS flush call. Lets see available current implementation described below.
 # Encrypted and Compressed segments
 ## ByteBuffer is allocated on Java GC heap to hold the data (threads updates in this buffer) by "COMMIT-LOG-ALLOCATOR" thread.
 ## Periodic syncing thread initiates flush operation on recent data
 ### Recent data is duplicated and memory is allocated on Java GC heap for this duplicate copy of data.
 ### Compression or encryption is done
 ### Call FileChannel.write with "compressed or encrypted" data to flush.
 ### FileChannel.write will copy incoming data to internal buffer again which is allocated in Java GC heap (when file was opened).
 ### Then FileChannel.write will call C library write function to flush the data.
 ### Syncing thread finishes flushing.
 ## Advantage of this implementation.
 ### Memory for ByteBuffer is allocated on Java GC
 ## Dis-advantage of this implementation
 ### Data is copied twice before initiating C library write function.
 ### Allocating large object sizes on Java GC increases GC pressure. Default CommitLog segment size is 32MB and increasing this size will increase this pressure further.
 ### Affects scaling 
 # MemoryMapped segment
 ## Memory for ByteBuffer is allocated using FileChannel.map which uses mmap system call to get the memory from OS and not from Java GC heap.
 ## Syncing thread initiates flush operation by calling C library "msync" function and not involved in any copy operation
 ## Advantage
 ### No copying of data and threads directly updates the file content mapped through mmap system call.
 ### Implementation is simpler
 ## Dis-advantage
    a. Syncing thread calls MSYNC system call and fails to exploit available disk throughput.
    b. MSYNC does not update in serialized manner so Direct I/O available bandwidth is not utilized.
    c. Scaling is poor

If native version of implementation is preferred then it's implementation will be similar "Encrypted and Compressed" segments type. The difference between
JNA vs native API's implementation is given below.
 # Using native API's to enable Direct I/O feature
 ## Implementation almost similar to "Encrypted and Compressed" segment. Memory for ByteBuffer needs to be allocated (for threads to update the file) and internal buffer for FileChannel is allocated for flush/write call.
 ## Periodic syncing thread initiates flush operation on recent data.
 ### Call FileChannel.write to flush the data
 ### FileChannel.write will copy incoming data to internal buffer that is allocated in Java GC heap (when file was opened).
 ### Then FileChannel.write will call C library write function to flush the data available in internal buffer.
 ### Syncing thread finishes flushing.
 ## Advantages
 ### Performance will be better than current implementation.
 ### Scaling will be better due to Direct I/O feature.
 ## Dis-advantages
 ### Data needs to be copied at-least once to FileChannel internal buffer and actual sync call is initiated.
 ### Allocating large object sizes on Java GC increases GC pressure. Increasing CommitLog Segment size will increase this pressure further.
 ### NVME disk may have different block size to obtain high disk throughput. Does JVM FileChannel classes provide such knobs to control the preferred block size?
 # Using JNA to enable Direct IO.
 ## Implementation almost similar to MemoryMapped segment. Memory is allocated to ByteBuffer using ByteBuffer.allocateDirect to get memory from OS and this is where threads updates similar to MemoryMappedSegment. This is not backed by any file.
 ## Syncer thread initiates flush operation
 ### ByteBuffer holding data is converted to JNA pointer
 ### Call C library write function through JNA
 ### Syncing is done
 ## Advantage
 ### Performance will be better than native version of implementation as this thread is not involved in any copy operation.
 ### GC pressure will be less as memory for ByteBuffer allocated using mmap and not on Java GC heap. Changing CommitLog segment size will not be an issue due to OS memory allocation
 ### Scaling will be better due to Direct I/O feature.
 ### Buffer alignment can be controlled based on disk type (only if necessary) through yaml file.
 ### Block size is configurable through yaml file based on disk type and this will help to get high disk throughput.
 ## Dis-advantage
 ### Direct I/O needs to be enabled through JNA and not using native API's. JNA is already used in Cassandra and should not be an issue.

So, I feel JNA version of implementation should be preferred due to its advantage and performance. Does these points are good to consider JNA version of implementation to enable Direct IO feature ? 

I will try implementing using native API also and please let me know your opinion on my previous reply. Thanks.

It seems to me if JNA has superior performance then we should go with that since we already have it and agree that it's fine to use.

I am able to enable Direct-IO feature on CommitLog files using Java native API's and file [^EnableDirectIOForCommitLogUsingNativeAPI.patch] can be used to test the same.

Summary of changes:
 # ExtendedOpenOption.DIRECT option is passed while opening the CommitLog file to enable Direct-IO.
 # ByteBuffer.allocateDirect is used to allocate memory to segment
 ## To reduce pressure on Java heap
 ## Buffer markers position and limit are aligned to 4K to prevent write errors. Java-11 enforces this alignment else error will be thrown.
 ## Minimum page size 4K is allowed to write and lower than 4K is not allowed. In case of JNA minimum is 512 bytes.
 # On sync data is flushed from start marker "lastSyncedOffset" to "nextMarker" marker.

 

Test results:
 # Patch is tested with limited commitlog testcases and it passes as per my previous testlist.
 # Performance difference
 ## With CMSGC, JNA version of implementation is ~35% better than native version
 ## With G1GC, JNA version of implementation is ~16% better than native version

 

Please check and share your feedback. Thanks.

Please set the flag "use_directio_for_commitlog" to true in cassandra.yaml config file to enable the Direct-IO feature.

 

Any feedback ?

{quote} 
    With CMSGC, JNA version of implementation is ~35% better than native version
    With G1GC, JNA version of implementation is ~16% better than native version
{quote}

Seems like JNA is the way to go, here is CI with it enabled:

||Branch||CI||
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-18464-trunk]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra/1069/workflows/f675fffd-15c5-4da5-819b-ab084e613899], [j11|https://app.circleci.com/pipelines/github/driftx/cassandra/1069/workflows/9fb80903-2e11-4beb-9963-d0b536a09e96]|


I am a little confused as to why memory mapped files are slow for sequential writes from multiple threads and if the fix for this should be to switch to direct IO?

Sure direct IO will bring all the bottlenecks for managing memory, and sending commands to the disk, and managing concurrency to Cassandra where can address them directly, but why can't we saturate an NVMe disk using memory mapped files?

I wrote a quick and dirty program that writes 1mb at a time to a memory mapped buffer and syncs it every 2gb of append and that has no problem saturating the 2gb/sec disk on my MBP (apples and oranges I know). So if you remove concurrency bottlenecks it seems like memory mapped files work on that particular platform.

One thing I did observe running commit log stress is the throughput increases as mutation goes up, so there is definitely some contention around each append. It started at 1gb/sec and then settled down to 650mb/sec after about 10 seconds which is an odd.

I'll take a look at the patch now.

So short patch :-)

I am not married at all to using MMAP for writing.

For direct IO I think we definitely want to pool two of the commit log buffers, and then dynamically allocate the rest if writing out commit log segments falls behind.

I am not sure this is crash safe, I can't remember if extending the length of a file with direct IO also updates the metadata of the file. Would need to do some googling. See https://ext4.wiki.kernel.org/index.php/Clarifying_Direct_IO%27s_Semantics "Allocating Writes".

Is the issue this is addressing contention around page cache data structures either when touching each 4k page as we append, or a contention around msync, or both? It certainly seems like a relatively straightforward way to address it vs. trying to work around performance issues with msync.

Can you factor out the rest of Cassandra and run commit log stress and demonstrate the speed difference between the two implementations on NVMe? Here are some changes I made to help with testing that https://pastebin.com/JXJv0tSd

Thank you [~brandon.williams]  for initiating the test process. Direct-IO feature is not yet enabled for compression and encryption segments and mostly all relevant tests will fail. My initial idea was to propose this feature and then fix remaining issues further. Thanks.

Thank you [~aweisberg] for reviewing the patch. Please check my inline reply.

>>For direct IO I think we definitely want to pool two of the commit log buffers, and then dynamically allocate the rest if writing out commit log segments falls behind.

Good idea, will work on this.

>>I am not sure this is crash safe, I can't remember if extending the length of a file with direct IO also updates the metadata of the file. Would need to do some googling. See[ https://ext4.wiki.kernel.org/index.php/Clarifying_Direct_IO%27s_Semantics|https://ext4.wiki.kernel.org/index.php/Clarifying_Direct_IO%27s_Semantics] "Allocating Writes".

Using O_SYNC or D_SYNC should address this issue. Otherwise need to call fsync on file descriptor.

>>Is the issue this is addressing contention around page cache data structures either when touching each 4k page as we append, or a contention around msync, or both? It certainly seems like a relatively straightforward way to address it vs. trying to work around performance issues with msync.

I too feel it is better to switch and not sure exactly what is the real issue. Majorly two advantages are seen here. First, reducing SYS activity helps other threads to use available CPU cycles. Second, Direct-IO transfer rate is consistent and didn't notice going down similar to msync.

>>Can you factor out the rest of Cassandra and run commit log stress and demonstrate the speed difference between the two implementations on NVMe? Here are some changes I made to help with testing that [https://pastebin.com/JXJv0tSd]

Sure, will check.

thanks again.

 

[~aweisberg] thanks for sharing the initial testcase and it helped lot. Following results are obtained by testing MMap and DirectIO based segments (with Native API's and JNA based).

 
  !image-2023-06-29-01-12-49-382.png!
 
 
 
 

Files used are:
 # Could not test Native API's based implementation as CommitLog file size was zero when created. Applying [^SetCommitLogFileSize.patch] helped to fix this.
 # PeriodicCommitLogStressTest configured to run for 100 seconds to create commitlog files. After the test it reports total disk space used by all the CommitLog files. Used this metric to show the IO speed. Please use [^PeriodicCommitLogStressTest.tar.bz2]  to refer the test logs.
 # [^CommitLogStressTest.patch] contains necessary changes further to run the test. New function is defined to get the status of Direct-IO feature.

 

Note:

[1] File open flags O_DSYNC & O_SYNC can be used to update the file metadata. O_DSYNC is already used and didn't see much difference with and without O_SYNC usage.

Observation: Linux dstat metrics shows
 # MemoryMappedSegment segment
 ## Data flush rate is 700-1200 MB/s. During this testing system is really not loaded
 ## In real scenario it is in the range of 300-500 MB/s.
 ## MemoryMappedSegment segment
 # DirectIO segment
 ## JNA based implementation
 ### Data flush rate is 1800-2000 MB/s.
 ### In real testing it is in the range of 800 - 1100 MB/s.
 ## Using Native API's implementation
 ### Data flush rate is 1800-2000 MB/s. Similar to JNA based.
 ### In real testing it is in the range of 700 - 900 MB/s.

Please let me know your feedback on this. Thanks.

 

Initial table was not looking properly and changed with image based to avoid confusion. thanks.

 

Any suggestion on this test?

 

This test also shows that Direct-IO feature for replaying Commitlog files will improve node bring up time after unexpected crash. Thanks.

Ping...

[~amit_pawar], I suspect no one will have spare cycles to look into this for a few months.

Must you have this in 5.0 (vs 5.1), and if so why?

[~mck], thanks for taking time to check this. The improvement discussed here also seen when Cassandra configured to run on say 4 to 8 cores too and my observations are listed below.
 # Seen 5-10% improvement in my test environment with 4-8 cores. TPCx-IOT is of type insert heavy and does range scanning. Basically, it mimics worst case scenario.
 # "PERIODIC-COMMIT-LOG-SYNCER" thread CPU utilization goes down and these saved cycles are available for other threads.
 # Any spike in insert operations can sustain for longer time due to Direct-IO and this benefits every user of Cassandra.

This fix is good candidate for insert heavy type operations. So, I think it is better to push to 5.0 if possible else 5.1 is also fine. I totally understand and will agree/follow as per reviewer's feedback/suggestion, Thanks.

Sorry to ping again. I understand that lot of work might be there during the release time. 5.0 code freezing is planned next week (first week of August) and is it possible to consider this change to 5.0 release?

I don't think I'll have time to look at this any time soon, unfortunately. Maybe we should shoot for 5.1...

This patch is very valuable, and I support if going into 5.0 as well as 5.1.

In separate tests we have often found a memory-mapped commit log to be a serious performance problem for a node with a lot of data. Even without DIRECT or JNA, not using `msync` is making a huge difference. Because of this most of the performance testing I personally do is done with compressed commit log.

I added comments to [the latest published branch|https://github.com/driftx/cassandra/tree/CASSANDRA-18464-trunk] with some suggested changes. I am curious, if the NIO option is constructed correctly (with aligned direct buffers, possibly also issuing the writes to be page-aligned and containing whole pages), is it still copying to internal buffers?

Thank you for reviewing the patch. Ideally having it into 5.0 helps those users where high insert operations affecting node performance. It is possible that this feature avoids adding more nodes during peak time.

 

>>I added comments to [the latest published branch|https://github.com/driftx/cassandra/tree/CASSANDRA-18464-trunk] with some suggested changes. I am curious, if the NIO option is constructed correctly (with aligned direct buffers, possibly also issuing the writes to be page-aligned and containing whole pages), is it still copying to internal buffers?

No, it does not. [FileChannel (Java Platform SE 7 ) (oracle.com)|https://docs.oracle.com/javase%2F7%2Fdocs%2Fapi%2F%2F/java/nio/channels/FileChannel.html#force(boolean)] does not mention about copying. Explored jdk11 sources to find out the same. As per the sources ([jdk11u-dev/src/java.base/share/classes/sun/nio/ch/IOUtil.java at 682bcf22312a5ec8cadec3b0241507cca42dec60 · openjdk/jdk11u-dev (github.com)|https://github.com/openjdk/jdk11u-dev/blob/682bcf22312a5ec8cadec3b0241507cca42dec60/src/java.base/share/classes/sun/nio/ch/IOUtil.java#L67], it creates a temporary buffer using (allocated using allocateDirect and aligned to boundry) and then copies. 

 

Would like to highlight to another difference here. Java forces 4096 bytes to be written with native APIs for Direct-IO. JNA allows minimum block size to be used as per the disk. Testing showed 512 bytes. This affects disk health during following two conditions.
 # Head and tail parts needs to be aligned to 4K. In worst case, 8K bytes are written un-necessarily to commit the head/tail part of the buffer. With JNA maximum 1024 bytes are written.
 # Under low activity, still 4K bytes are written. Even for 100 bytes during periodic timeout. Here JNA may write maximum 512 bytes.

Direct-IO feature is very much needed either through native or JNA based. It overall reduces kernel IO activity for commitlog files.

 

There was a typo in my response above, I am in favour of having the patch land in 5.0.

Just the 512 vs 4k difference is not something I would personally consider a good reason to include the JNA writing; the sync segments are usually much larger than that. I would rather go with the simpler NIO option. 

I can't find my code comments with the link above any more. They are [here|https://github.com/driftx/cassandra/commit/cb5bd169f0a9331f957f96a7318fee02a744e006#r128716588].

Thank you for considering to 5.0. 

 

I can see the submitted patch in the above shared link but unable to see the latest suggested changes.

 

This is my first patch and submitted it through mailing list. Just FYI.

To make the review easier, could you fork the {{apache/cassandra}} repository on github, push a branch with the changes to your fork on top of {{cassandra-5.0}}, and open a pull request against {{apache/cassandra-5.0}}?

My comments so far are these:

On [Config.java 117|https://github.com/driftx/cassandra/commit/cb5bd169f0a9331f957f96a7318fee02a744e006#diff-e966f41bc2a418becfe687134ec8cf542eb051eead7fb4917e65a3a2e7c9bce3R117]:
{quote}
Using booleans makes it very unclear which options are actually valid, and what the alternative means. Please change the configuration to an enum, e.g. {{commit_log_access_mode}} with values {{direct_jna}}, {{direct}}, and {{mmap}}.
{quote}
{quote}
Actually, there should be only one direct option, and whether it uses nio or jni is an implementation detail that the users needn't care about.

The next question is whether or not non-direct should be supported at all, and I personally prefer to not support it as this adds configuration complexity for no expected benefit.

This also means that it makes sense to simply switch all other commit log segment types to be written direct, and this is simple enough to do in this ticket (especially since we dropped Java 8 and can use NIO's {{DIRECT}} option).
{quote}

On [Config.java 517|https://github.com/driftx/cassandra/commit/cb5bd169f0a9331f957f96a7318fee02a744e006#diff-e966f41bc2a418becfe687134ec8cf542eb051eead7fb4917e65a3a2e7c9bce3R517]:
{quote}
When would someone need to change this?
{quote}


Sure, will do.

Just an update. Creating PR for the patch [^EnableDirectIOForCommitLogUsingNativeAPI.patch] which is based on native API's to avoid JNA based changes. If needed then please let me know to include JNA changes too.

 

PR is initiated: [Enable Direct-IO feature for CommitLog files using Java native API's. by amitdpawar · Pull Request #2777 · apache/cassandra (github.com)|https://github.com/apache/cassandra/pull/2777]

thanks.

I found that there is no test for this pr, and I also want to know how to test this pr ？Can you give me some advice? [~blambov] . Besides, I have left some comments  too. 

[~amit_pawar]Any update on this ?

If you need, I think I can do some help  too.

bq. I found that there is no test for this pr, and I also want to know how to test this pr

We already have plenty of commitlog tests, I would think enabling direct IO for them is enough.

Thanks for your reply [~brandon.williams]， I may not expressed it clearly, I have saw [commit log uts|https://github.com/apache/cassandra/tree/trunk/test/unit/org/apache/cassandra/db/commitlog] and some stress tests for commit log too.
What I mean is that ,how to make sure the direct io flag  takes effect ? Besides, I think we may also need to add some stress tests too. 

But looking at the pr's conservations , some questions for me have been resolved. :)

Thanks [~brandon.williams] and thought to give some update here. Test "CommitLogStressTest.java" is changed to test plain direct I/O feature. Compressed and Encrypted segments with direct I/O are not yet supported. This can be planned next.

Thanks [~maxwellguo] for your continuous feedback and will be happy to support to upstream this change.

So we have a PR ready to re-review (https://github.com/apache/cassandra/pull/2894) - the original commits by [~amit_pawar] were mostly accepted and I added some cosmetic refactorings and tests. 

I'm linking the updated PR, [~blambov], [~maxwellguo] - would you take a look one last time?

Note that there are some configuration changes which will be either reverted or adjusted to the PR with optimized configuration. I've used "auto" so that all tests can be run with direct access and we can be sure it works.


I think we are ready to merge, testing was difficult because of flakies. The detailed information below (copied from pull request):

trunk: https://github.com/apache/cassandra/pull/2931
-------------------------------------------------------------------------------------
https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/1122/workflows/a6889c2a-3b62-4f04-91e5-4a4e270a6368 (j11)
https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/1122/workflows/0c4f1d43-810b-47bb-a83a-0d645f20efc0 (j17)

In both builds there are many failures, most of them are mentioned in CASSANDRA-19055 (CEP-21 follow-up). For few others, I've run them locally on trunk and they failed, thus I've created tickets for them (CASSANDRA-19102, CASSANDRA-19101).

The only thing left is org.apache.cassandra.distributed.test.ReadRepairEmptyRangeTombstonesTest - it failed once on CircleCI by timeout in teardown method of the entire class, when the cluster was being shutdown. It does not seem related. I could not reproduce it locally on either feature branch or trunk. Here https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/1123/workflows/a62417d7-5ecf-4d4e-9303-ff05df3282c0/jobs/51273 I couldn't reproduce it on CircleCI as well. It might have been some infra problem I think.

cassandra-5.0: https://github.com/apache/cassandra/pull/2894
---------------------------------------------------------------------------------
https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/1115/workflows/fd53b9c8-ee4d-4e25-8a06-2079f1732f8e (j11)
test_stop_failure_policy passes locally and repeated run (100x) on this branch passed https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/1120/workflows/4a9716c9-24c3-485f-9f11-bb596cbbca5f/jobs/50783/steps 

{{test_shutdown_wiped_node_cannot_join}} is flaky on both this branch (https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/1118/workflows/0eb8dc23-980d-45bc-9fc6-890ea05941a9/jobs/50573/tests 
13% flakiness) and on {{cassandra-5.0}} (https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/1119/workflows/932a44e3-c25e-4c5e-b677-66579380faeb/jobs/50782/tests 
17% flakiness), there is a ticket for this and links are
https://issues.apache.org/jira/browse/CASSANDRA-19097

Repeated unit tests seems to pass all tests but has some problems collecting logs - the same problem is present on {{cassandra-5.0}} - https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/1114/workflows/a1d02a59-31ee-48e2-9426-a4eca52ed3ff/jobs/50107 and I've created a ticket for that: https://issues.apache.org/jira/browse/CASSANDRA-19086

https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/1120/workflows/2dc9ef3b-0a64-47bf-a05b-de7a36b1ca2c (j17)
{{test_stop_failure_policy}} failed 1/100 in repeated run; therefore, I'm rerunning the repeated run on {{cassandra-5.0}} here: https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/1121/workflows/fce907b1-0526-4d4d-beb5-b6620737a5f3 - (failed 2/500, thus the test is flaky, creating ticket for it)


Thank you [~jlewandowski].(y)

