Commit 88825071fad314819358e8feb2f34481dd3c1d64 in geode's branch refs/heads/develop from [~bschuchardt]
[ https://git-wip-us.apache.org/repos/asf?p=geode.git;h=8882507 ]

GEODE-3052 Restarting locators causes potential locator split brain

When restarting from a locatorView.dat file we should ignore any locator
entries in the view.  Recovery tries to get this state from other locators
before resorting to using the persisted view so there we know all of the
locator entries in the view are invalid.  This allows the locators to
quickly move into the concurrent-startup algorithm and find each other.

I removed the Flaky categorization of the test that I modified to
reproduce the problem.  A subclass's use of the test was reported as
a Flaky failure but I found that the ticket was closed.


If there were servers in the recovered view locators can still come up in a split-brain configuration with the fix I checked in yesterday.

{noformat}
locator1/locator1.log: [info 2017/06/09 10:13:29.365 PDT locator1 <main> tid=0x1] Peer locator recovering from /export/trout1/users/bschuchardt/devel/testing/splitbrain/locator1/locator12345view.dat

locator1/locator1.log: [info 2017/06/09 10:13:29.367 PDT locator1 <main> tid=0x1] Peer locator initial membership is View[trout(locator1:9450:locator)<ec><v0>:1024|3] members: [trout(server2:9684)<v2>:1026{lead}, trout(server1:9796)<v3>:1027]




locator2/locator2.log: [info 2017/06/09 10:13:30.093 PDT locator2 <main> tid=0x1] Attempting to join the distributed system through coordinator 10.118.26.122(server2:9684)<v2>:1026 using address 10.118.26.122(locator2:9961:locator)<ec>:1025


locator1/locator1.log: [info 2017/06/09 10:13:38.678 PDT locator1 <main> tid=0x1] This member is becoming the membership coordinator with address 10.118.26.122(locator1:9937:locator)<ec>:1024

locator1/locator1.log: [info 2017/06/09 10:13:38.679 PDT locator1 <main> tid=0x1] received new view: View[10.118.26.122(locator1:9937:locator)<ec><v0>:1024|0] members: [10.118.26.122(locator1:9937:locator)<ec><v0>:1024]
  old view is: null

locator1/locator1.log: [info 2017/06/09 10:13:38.679 PDT locator1 <main> tid=0x1] Peer locator received new membership view: View[10.118.26.122(locator1:9937:locator)<ec><v0>:1024|0] members: [10.118.26.122(locator1:9937:locator)<ec><v0>:1024]

locator1/locator1.log: [info 2017/06/09 10:13:38.692 PDT locator1 <main> tid=0x1] ViewCreator starting on:10.118.26.122(locator1:9937:locator)<ec><v0>:1024

locator1/locator1.log: [info 2017/06/09 10:13:38.692 PDT locator1 <Geode Membership View Creator> tid=0x24] View Creator thread is starting

locator1/locator1.log: [info 2017/06/09 10:13:38.693 PDT locator1 <main> tid=0x1] Finished joining (took 9030ms).

locator1/locator1.log: [info 2017/06/09 10:13:38.694 PDT locator1 <Geode Membership View Creator> tid=0x24] no recipients for new view aside from myself

locator1/locator1.log: [info 2017/06/09 10:13:38.695 PDT locator1 <main> tid=0x1] Starting DistributionManager 10.118.26.122(locator1:9937:locator)<ec><v0>:1024.  (took 9250 ms)

locator1/locator1.log: [info 2017/06/09 10:13:38.697 PDT locator1 <main> tid=0x1] Initial (distribution manager) view =  View[10.118.26.122(locator1:9937:locator)<ec><v0>:1024|0] members: [10.118.26.122(locator1:9937:locator)<ec><v0>:1024]

locator1/locator1.log: [info 2017/06/09 10:13:38.697 PDT locator1 <main> tid=0x1] Admitting member <10.118.26.122(locator1:9937:locator)<ec><v0>:1024>. Now there are 1 non-admin member(s).

locator1/locator1.log: [info 2017/06/09 10:13:38.697 PDT locator1 <main> tid=0x1] 10.118.26.122(locator1:9937:locator)<ec><v0>:1024 is the elder and the only member.

locator1/locator1.log: [info 2017/06/09 10:13:38.700 PDT locator1 <main> tid=0x1] Did not hear back from any other system. I am the first one.

locator1/locator1.log: [info 2017/06/09 10:13:38.726 PDT locator1 <main> tid=0x1] Creating cache for locator.

locator1/locator1.log: [info 2017/06/09 10:13:38.895 PDT locator1 <main> tid=0x1] Requesting cluster configuration

locator1/locator1.log: [info 2017/06/09 10:13:38.982 PDT locator1 <main> tid=0x1] Initializing region _monitoringRegion_10.118.26.122<v0>1024

locator1/locator1.log: [info 2017/06/09 10:13:38.986 PDT locator1 <main> tid=0x1] Initialization of region _monitoringRegion_10.118.26.122<v0>1024 completed

locator2/locator2.log: [info 2017/06/09 10:13:39.103 PDT locator2 <main> tid=0x1] This member is becoming the membership coordinator with address 10.118.26.122(locator2:9961:locator)<ec>:1025

locator2/locator2.log: [info 2017/06/09 10:13:39.103 PDT locator2 <main> tid=0x1] received new view: View[10.118.26.122(locator2:9961:locator)<ec><v0>:1025|0] members: [10.118.26.122(locator2:9961:locator)<ec><v0>:1025]
  old view is: null

locator2/locator2.log: [info 2017/06/09 10:13:39.104 PDT locator2 <main> tid=0x1] Peer locator received new membership view: View[10.118.26.122(locator2:9961:locator)<ec><v0>:1025|0] members: [10.118.26.122(locator2:9961:locator)<ec><v0>:1025]

locator2/locator2.log: [info 2017/06/09 10:13:39.117 PDT locator2 <main> tid=0x1] ViewCreator starting on:10.118.26.122(locator2:9961:locator)<ec><v0>:1025

locator2/locator2.log: [info 2017/06/09 10:13:39.118 PDT locator2 <main> tid=0x1] Finished joining (took 9033ms).

locator2/locator2.log: [info 2017/06/09 10:13:39.119 PDT locator2 <main> tid=0x1] Starting DistributionManager 10.118.26.122(locator2:9961:locator)<ec><v0>:1025.  (took 9247 ms)

locator2/locator2.log: [info 2017/06/09 10:13:39.120 PDT locator2 <Geode Membership View Creator> tid=0x24] View Creator thread is starting

locator2/locator2.log: [info 2017/06/09 10:13:39.121 PDT locator2 <Geode Membership View Creator> tid=0x24] no recipients for new view aside from myself
{noformat}


Commit bad2dcdb1fa0638f958bd382852664be86138dfd in geode's branch refs/heads/feature/GEODE-3023 from [~bschuchardt]
[ https://git-wip-us.apache.org/repos/asf?p=geode.git;h=bad2dcd ]

GEODE-3052 Restarting locators causes potential locator split brain

When restarting from a locatorView.dat file we should ignore any locator
entries in the view.  Recovery tries to get this state from other locators
before resorting to using the persisted view so there we know all of the
locator entries in the view are invalid.  This allows the locators to
quickly move into the concurrent-startup algorithm and find each other.

I removed the Flaky categorization of the test that I modified to
reproduce the problem.  A subclass's use of the test was reported as
a Flaky failure but I found that the ticket was closed.


Is the fix for this issue will be available on 1.2 release ?
Is there any known solution to this issue ?

[~aravindm], we are still working on this ticket.
In the parent ticket there is a proposed, but not recommended, work around made by [~bschuchardt]. In addition to this, it has been found that if the starting of the locators is staggered manner (start locatorA, wait a few seconds, start locatorB) this problem does not manifest itself.

Commit 3ee585c5844607e5da9756afb089405a30ae3dd3 in geode's branch refs/heads/develop from [~bschuchardt]
[ https://git-wip-us.apache.org/repos/asf?p=geode.git;h=3ee585c ]

GEODE-3052 Restarting 2 locators together causes potential locator split brain

There were four problems that new unit tests hit:
1. when recovering a view from disk we were treating it as a definitive
(live) view.  I've moved it to a new variable in GMSLocator and set its
viewId to -1.  At the same time I set the initial GMSJoinLeave
SearchState.viewId to -100 so it will be overridden by the one returned
by the locator.  These changes allow GmsJoinLeave to know that the
potential coordinator is from a recovered view.

2. when trying to join with a recovered view GMSJoinLeave.join() was giving
up after the second ID in the view and becoming the coordinator.  It needs
to keep trying until the list is exhausted, and it shouldn't sleep between
attempts.

3. GMSLocator wasn't returning registrants for use in
findCoordinatorFromView().  This was causing it to choose itself as
the coordinator instead of using registrant sort order and choosing
a different registrant as the coordinator.

4. During concurrent startup GMSLocator didn't know when the decision
was made to become coordinator.  It is now notified of this decision
and processRequest() uses this flag to have it override anything in
the registrants set or in the recovered view.


Commit 0254a60f5939b537284aba4a59a7cff4da5f3fc4 in geode's branch refs/heads/develop from [~bschuchardt]
[ https://git-wip-us.apache.org/repos/asf?p=geode.git;h=0254a60 ]

GEODE-3052 Restarting 2 locators together causes potential locator split brain

The fix for this issue introduced different timing in GMSJoinLeave's
discovery process that affected one of the unit tests for that class,
causing periodic failures.  I've added an Awaitility.await() to stabilize
the test.


we need to reset isCoordinator flag in GMSLocator, when ViewCreator thread stops.

Commit 15a3b5a6eb789b01639a03c4318f5d3c10bd2158 in geode's branch refs/heads/develop from [~hitesh.khamesra]
[ https://git-wip-us.apache.org/repos/asf?p=geode.git;h=15a3b5a ]

GEODE-3052 Need to reset isCoordinator flag in GMSLocator.

isCoordinator flag ensures that this process is becoming the
coordinator thus other process should join this process. But
when network parttion happens, we were not resetting this flag.

Now we reset isCoordinator flag when viewCreator thread shutdowns.

added unit test for it.


